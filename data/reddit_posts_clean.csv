id,title,selftext,score,num_comments,created_utc,subreddit,url,text,clean_text,lemmatized_text
1lvmphl,"All of my data comes from spreadsheets. As I receive more over time, what’s the best way to manage and access multiple files efficiently? Ideally in a way that scales and still lets me work interactively with the data?","I’m working on a project where all incoming data is provided via spreadsheets (Excel/CSV). The number of files is growing, and I need to manage them in a structured way that allows for:

1. Easy access to different uploads over time
2. Avoiding duplication or version confusion
3. Interactive analysis (e.g., via Jupyter notebooks or a lightweight dashboard)

I’m currently loading files manually, but I want a better system. Whether that means a file management structure, metadata tagging, or loading/parsing automation. Eventually I’d like to scale this up to support analysis across many uploads or clients.

What are good patterns, tools, or Python-based workflows to support this?",1,1,2025-07-09T16:07:05+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lvmphl/all_of_my_data_comes_from_spreadsheets_as_i/,"All of my data comes from spreadsheets. As I receive more over time, what’s the best way to manage and access multiple files efficiently? Ideally in a way that scales and still lets me work interactively with the data? I’m working on a project where all incoming data is provided via spreadsheets (Excel/CSV). The number of files is growing, and I need to manage them in a structured way that allows for:

1. Easy access to different uploads over time
2. Avoiding duplication or version confusion
3. Interactive analysis (e.g., via Jupyter notebooks or a lightweight dashboard)

I’m currently loading files manually, but I want a better system. Whether that means a file management structure, metadata tagging, or loading/parsing automation. Eventually I’d like to scale this up to support analysis across many uploads or clients.

What are good patterns, tools, or Python-based workflows to support this?",all of my data comes from spreadsheets as i receive more over time whats the best way to manage and access multiple files efficiently ideally in a way that scales and still lets me work interactively with the data im working on a project where all incoming data is provided via spreadsheets excelcsv the number of files is growing and i need to manage them in a structured way that allows for easy access to different uploads over time avoiding duplication or version confusion interactive analysis eg via jupyter notebooks or a lightweight dashboard im currently loading files manually but i want a better system whether that means a file management structure metadata tagging or loadingparsing automation eventually id like to scale this up to support analysis across many uploads or clients what are good patterns tools or pythonbased workflows to support this,datum come spreadsheet receive time s good way manage access multiple file efficiently ideally way scale let work interactively datum m work project incoming datum provide spreadsheet excelcsv number file grow need manage structured way allow easy access different upload time avoid duplication version confusion interactive analysis eg jupyt notebook lightweight dashboard m currently load file manually want well system mean file management structure metadata tagging loadingparse automation eventually d like scale support analysis upload client good pattern tool pythonbase workflow support
1lvl0wp,Open source or not?,"Hi all,  
I am building an AI agent, similar to Github copilot / Cursor but very specialized on data science / ML. It is integrated in VSCode as an extension.  
Here is a few examples of use cases:  
\- Combine different data sources, clean and preprocess for ML pipeline.  
\- Refactor R&D notebooks into ready for production project: Docker, package, tests, documentation.

We are approaching an MVP in the next few weeks and I am hesitating between 2 business models:  
1- Closed source, similar to cursor, with fixed price subscription with limit by request.  
2- Open source, pay per token. User can plug their own API or use our backend which offers all frontier models. Charge a topup % on top of token consumption (similar to Cline).

The question is also whether the data science community would contribute to a vscode extension in React, Typescript.

What do you think make senses as a data scientist / ML engineer?",0,4,2025-07-09T15:01:23+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lvl0wp/open_source_or_not/,"Open source or not? Hi all,  
I am building an AI agent, similar to Github copilot / Cursor but very specialized on data science / ML. It is integrated in VSCode as an extension.  
Here is a few examples of use cases:  
\- Combine different data sources, clean and preprocess for ML pipeline.  
\- Refactor R&D notebooks into ready for production project: Docker, package, tests, documentation.

We are approaching an MVP in the next few weeks and I am hesitating between 2 business models:  
1- Closed source, similar to cursor, with fixed price subscription with limit by request.  
2- Open source, pay per token. User can plug their own API or use our backend which offers all frontier models. Charge a topup % on top of token consumption (similar to Cline).

The question is also whether the data science community would contribute to a vscode extension in React, Typescript.

What do you think make senses as a data scientist / ML engineer?",open source or not hi all i am building an ai agent similar to github copilot cursor but very specialized on data science ml it is integrated in vscode as an extension here is a few examples of use cases combine different data sources clean and preprocess for ml pipeline refactor rd notebooks into ready for production project docker package tests documentation we are approaching an mvp in the next few weeks and i am hesitating between business models closed source similar to cursor with fixed price subscription with limit by request open source pay per token user can plug their own api or use our backend which offers all frontier models charge a topup on top of token consumption similar to cline the question is also whether the data science community would contribute to a vscode extension in react typescript what do you think make senses as a data scientist ml engineer,open source hi build ai agent similar github copilot cursor specialized datum science ml integrate vscode extension example use case combine different data source clean preprocess ml pipeline refactor rd notebook ready production project docker package test documentation approach mvp week hesitate business model close source similar cursor fix price subscription limit request open source pay token user plug api use backend offer frontier model charge topup token consumption similar cline question data science community contribute vscode extension react typescript think sense data scientist ml engineer
1lux7bt,Saved $100k per year by explaining how AI/LLM work.,"I work in a data science field, and I bring this up because I think it's data science related.

We have an internal website that is very bare bones. It's made to be simplistic, because it's the reference document for our end-users (1000 of them) use.

Executives heard about a software that would be completely AI driven, build detailed statistical insights, and change the world as they know it.

I had a demo with the company and they explained its RAG capabilities, but mentioned it doesn't really ""learn"" like the assumption AI does. Our repo is so small and not at all needed for AI. We have used a fuzzy search that has worked for the past three years. Additionally, I have already built out dashboards that retrieve all the information executives have asked for via API (who's viewing pages, what are they searching, etc.)

I showed the c-suite executives our current dashboards in Tableau, and how the actual search works. I also explained what RAG is, and how AI/LLMs work at a high level. I explained to them that AI is a fantastic tool, but I'm not sure if we should be spending 100k a year on it. They also asked if I have built any predictive models. I don't think they quite understood what that was as well, because we don't have the amount of data or need to predict anything.

Needless to say, they decided it was best not to move forward ""for now"". I am shocked, but also not, that executives want to change the structure of how my team and end-users digest information just because they heard ""AI is awesome!"" They had zero idea how anything works in our shop.

Oh yeah, our company has already laid of 250 people this year due to ""financial turbulence"", and now they're wanting to spend 100k on this?!

It just goes to show you how deep the AI train runs. Did I handle this correctly and can I put this on my resume? LOL",805,78,2025-07-08T19:03:19+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lux7bt/saved_100k_per_year_by_explaining_how_aillm_work/,"Saved $100k per year by explaining how AI/LLM work. I work in a data science field, and I bring this up because I think it's data science related.

We have an internal website that is very bare bones. It's made to be simplistic, because it's the reference document for our end-users (1000 of them) use.

Executives heard about a software that would be completely AI driven, build detailed statistical insights, and change the world as they know it.

I had a demo with the company and they explained its RAG capabilities, but mentioned it doesn't really ""learn"" like the assumption AI does. Our repo is so small and not at all needed for AI. We have used a fuzzy search that has worked for the past three years. Additionally, I have already built out dashboards that retrieve all the information executives have asked for via API (who's viewing pages, what are they searching, etc.)

I showed the c-suite executives our current dashboards in Tableau, and how the actual search works. I also explained what RAG is, and how AI/LLMs work at a high level. I explained to them that AI is a fantastic tool, but I'm not sure if we should be spending 100k a year on it. They also asked if I have built any predictive models. I don't think they quite understood what that was as well, because we don't have the amount of data or need to predict anything.

Needless to say, they decided it was best not to move forward ""for now"". I am shocked, but also not, that executives want to change the structure of how my team and end-users digest information just because they heard ""AI is awesome!"" They had zero idea how anything works in our shop.

Oh yeah, our company has already laid of 250 people this year due to ""financial turbulence"", and now they're wanting to spend 100k on this?!

It just goes to show you how deep the AI train runs. Did I handle this correctly and can I put this on my resume? LOL",saved k per year by explaining how aillm work i work in a data science field and i bring this up because i think its data science related we have an internal website that is very bare bones its made to be simplistic because its the reference document for our endusers of them use executives heard about a software that would be completely ai driven build detailed statistical insights and change the world as they know it i had a demo with the company and they explained its rag capabilities but mentioned it doesnt really learn like the assumption ai does our repo is so small and not at all needed for ai we have used a fuzzy search that has worked for the past three years additionally i have already built out dashboards that retrieve all the information executives have asked for via api whos viewing pages what are they searching etc i showed the csuite executives our current dashboards in tableau and how the actual search works i also explained what rag is and how aillms work at a high level i explained to them that ai is a fantastic tool but im not sure if we should be spending k a year on it they also asked if i have built any predictive models i dont think they quite understood what that was as well because we dont have the amount of data or need to predict anything needless to say they decided it was best not to move forward for now i am shocked but also not that executives want to change the structure of how my team and endusers digest information just because they heard ai is awesome they had zero idea how anything works in our shop oh yeah our company has already laid of people this year due to financial turbulence and now theyre wanting to spend k on this it just goes to show you how deep the ai train runs did i handle this correctly and can i put this on my resume lol,save k year explain aillm work work data science field bring think data science relate internal website bare bone simplistic reference document enduser use executive hear software completely ai drive build detailed statistical insight change world know demo company explain rag capability mention not learn like assumption ai repo small need ai fuzzy search work past year additionally build dashboard retrieve information executive ask api s view page search etc show csuite executive current dashboard tableau actual search work explain rag aillm work high level explain ai fantastic tool m sure spend k year ask build predictive model not think understand not datum need predict needless decide good forward shock executive want change structure team enduser digest information hear ai awesome zero idea work shop oh yeah company lay people year financial turbulence want spend k go deep ai train run handle correctly resume lol
1lum3ih,Path to product management,"I’m a student interested in working as a product manager in tech. 

I know it’s tough to land a first role directly in PM, so I’m considering alternative paths that could lead there.

My question is: how common is the transition from data scientist/product data scientist to product manager? Is it a viable path?

Also would it make more sense to go down the software engineering route instead (even though I’m not particularly passionate about it) if it makes the transition to PM easier?",1,9,2025-07-08T11:27:33+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lum3ih/path_to_product_management/,"Path to product management I’m a student interested in working as a product manager in tech. 

I know it’s tough to land a first role directly in PM, so I’m considering alternative paths that could lead there.

My question is: how common is the transition from data scientist/product data scientist to product manager? Is it a viable path?

Also would it make more sense to go down the software engineering route instead (even though I’m not particularly passionate about it) if it makes the transition to PM easier?",path to product management im a student interested in working as a product manager in tech i know its tough to land a first role directly in pm so im considering alternative paths that could lead there my question is how common is the transition from data scientistproduct data scientist to product manager is it a viable path also would it make more sense to go down the software engineering route instead even though im not particularly passionate about it if it makes the transition to pm easier,path product management m student interested work product manager tech know tough land role directly pm m consider alternative path lead question common transition datum scientistproduct datum scientist product manager viable path sense software engineering route instead m particularly passionate make transition pm easy
1lu7gqq,How to deal with time series unbalanced situations?,"**Hi everyone,**

I’m working on a challenge to **predict the probability of a product becoming unavailable the next day**.

The dataset contains one row per product per day, with a binary target (`failure` or not) and 10 additional features. There are over 1 million rows without failure, and only 100 with failure — so it's a highly imbalanced dataset.

Here are some key points I’m considering:

1. **The target should reflect the next day**, not the current one. For example, if product X has data from day 1 to day 10, each row should indicate whether a failure will happen on the following day. Day 10 is used only to label day 9 and is not used as input for prediction.
2. **The features are on different scales**, so I’ll need to apply normalization or standardization depending on the model I choose (e.g., for Logistic Regression or KNN).
3. **There are no missing values**, so I won’t need to worry about imputation.
4. **To avoid data leakage**, I’ll split the data by product, making sure that each product's full time series appears entirely in either the training or test set — never both. For example, if product X has data from day 1 to day 9, those rows must all go to either train **or** test.
5. Since the output should be a **probability**, I’m planning to use models like Logistic Regression, Random Forest, XGBoost, Naive Bayes, or KNN.
6. Due to the strong class imbalance, my **main evaluation metric will be ROC AUC**, since it handles imbalanced datasets well.
7. Would it make sense to include calendar-based features, like the day of the week, weekend indicators, or holidays?
8. How useful would it be to add rolling window statistics (e.g., 3-day averages or standard deviations) to capture recent trends in the attributes?
9. Any best practices for flagging anomalies, such as sudden spikes in certain attributes or values above a specific percentile (like the 90th)?

**My questions:**  
Does this approach make sense?  
I’m not entirely confident about some of these steps, so I’d really appreciate feedback from more experienced data scientists!",54,66,2025-07-07T22:03:11+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lu7gqq/how_to_deal_with_time_series_unbalanced_situations/,"How to deal with time series unbalanced situations? **Hi everyone,**

I’m working on a challenge to **predict the probability of a product becoming unavailable the next day**.

The dataset contains one row per product per day, with a binary target (`failure` or not) and 10 additional features. There are over 1 million rows without failure, and only 100 with failure — so it's a highly imbalanced dataset.

Here are some key points I’m considering:

1. **The target should reflect the next day**, not the current one. For example, if product X has data from day 1 to day 10, each row should indicate whether a failure will happen on the following day. Day 10 is used only to label day 9 and is not used as input for prediction.
2. **The features are on different scales**, so I’ll need to apply normalization or standardization depending on the model I choose (e.g., for Logistic Regression or KNN).
3. **There are no missing values**, so I won’t need to worry about imputation.
4. **To avoid data leakage**, I’ll split the data by product, making sure that each product's full time series appears entirely in either the training or test set — never both. For example, if product X has data from day 1 to day 9, those rows must all go to either train **or** test.
5. Since the output should be a **probability**, I’m planning to use models like Logistic Regression, Random Forest, XGBoost, Naive Bayes, or KNN.
6. Due to the strong class imbalance, my **main evaluation metric will be ROC AUC**, since it handles imbalanced datasets well.
7. Would it make sense to include calendar-based features, like the day of the week, weekend indicators, or holidays?
8. How useful would it be to add rolling window statistics (e.g., 3-day averages or standard deviations) to capture recent trends in the attributes?
9. Any best practices for flagging anomalies, such as sudden spikes in certain attributes or values above a specific percentile (like the 90th)?

**My questions:**  
Does this approach make sense?  
I’m not entirely confident about some of these steps, so I’d really appreciate feedback from more experienced data scientists!",how to deal with time series unbalanced situations hi everyone im working on a challenge to predict the probability of a product becoming unavailable the next day the dataset contains one row per product per day with a binary target failure or not and additional features there are over million rows without failure and only with failure so its a highly imbalanced dataset here are some key points im considering the target should reflect the next day not the current one for example if product x has data from day to day each row should indicate whether a failure will happen on the following day day is used only to label day and is not used as input for prediction the features are on different scales so ill need to apply normalization or standardization depending on the model i choose eg for logistic regression or knn there are no missing values so i wont need to worry about imputation to avoid data leakage ill split the data by product making sure that each products full time series appears entirely in either the training or test set never both for example if product x has data from day to day those rows must all go to either train or test since the output should be a probability im planning to use models like logistic regression random forest xgboost naive bayes or knn due to the strong class imbalance my main evaluation metric will be roc auc since it handles imbalanced datasets well would it make sense to include calendarbased features like the day of the week weekend indicators or holidays how useful would it be to add rolling window statistics eg day averages or standard deviations to capture recent trends in the attributes any best practices for flagging anomalies such as sudden spikes in certain attributes or values above a specific percentile like the th my questions does this approach make sense im not entirely confident about some of these steps so id really appreciate feedback from more experienced data scientists,deal time series unbalanced situation hi m work challenge predict probability product unavailable day dataset contain row product day binary target failure additional feature million row failure failure highly imbalance dataset key point m consider target reflect day current example product x datum day day row indicate failure happen follow day day label day input prediction feature different scale ill need apply normalization standardization depend model choose eg logistic regression knn miss value will not need worry imputation avoid data leakage ill split datum product make sure product time series appear entirely training test set example product x datum day day row train test output probability m plan use model like logistic regression random forest xgboost naive baye knn strong class imbalance main evaluation metric roc auc handles imbalance dataset sense include calendarbase feature like day week weekend indicator holiday useful add rolling window statistic eg day average standard deviation capture recent trend attribute good practice flag anomaly sudden spike certain attribute value specific percentile like th question approach sense m entirely confident step d appreciate feedback experienced data scientist
1lu7fxv,Python package for pickup/advanced booking models for forecasting?,Recently discovered pickup models that use reservation data to generate forecasts (see [https://www.scitepress.org/papers/2016/56319/56319.pdf](https://www.scitepress.org/papers/2016/56319/56319.pdf) ) Seems used often in the hotel and airline industry. Is there a python package for this? Maybe it goes by a different name but I'm not seeing anything,8,2,2025-07-07T22:02:16+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lu7fxv/python_package_for_pickupadvanced_booking_models/,Python package for pickup/advanced booking models for forecasting? Recently discovered pickup models that use reservation data to generate forecasts (see [https://www.scitepress.org/papers/2016/56319/56319.pdf](https://www.scitepress.org/papers/2016/56319/56319.pdf) ) Seems used often in the hotel and airline industry. Is there a python package for this? Maybe it goes by a different name but I'm not seeing anything,python package for pickupadvanced booking models for forecasting recently discovered pickup models that use reservation data to generate forecasts see seems used often in the hotel and airline industry is there a python package for this maybe it goes by a different name but im not seeing anything,python package pickupadvanced booking model forecasting recently discover pickup model use reservation datum generate forecast hotel airline industry python package maybe go different m see
1lu1cve,"I don't drink, but I'm still tired because my dogs hate fireworks.  Did everyone in the US take a long weekend at least?",,0,0,2025-07-07T18:06:15+00:00,datascience,https://i.redd.it/5cprt2scshbf1.png,"I don't drink, but I'm still tired because my dogs hate fireworks.  Did everyone in the US take a long weekend at least? ",i dont drink but im still tired because my dogs hate fireworks did everyone in the us take a long weekend at least,not drink m tired dog hate firework long weekend
1ltkjwx,"Weekly Entering & Transitioning - Thread 07 Jul, 2025 - 14 Jul, 2025"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",10,16,2025-07-07T04:02:03+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ltkjwx/weekly_entering_transitioning_thread_07_jul_2025/,"Weekly Entering & Transitioning - Thread 07 Jul, 2025 - 14 Jul, 2025  

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",weekly entering transitioning thread jul jul welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the and resources pages on our wiki you can also search for answers in,weekly enter transition thread jul jul welcome week enter transition thread thread question getting start study transition data science field topic include learn resource eg book tutorial video traditional education eg schools degree elective alternative education eg online course bootcamp job search question eg resume apply career prospect elementary question eg start wait answer community check resource page wiki search answer
1lt464v,"With Generative AI looking so ominous, would there be any further research in any other domains like Computer Vision or NLP or Graph Analytics ever?","So as the title suggest, last few years have been just Generative AI all over the place. Every new research is somehow focussed towards it. So does this mean other fields stands still ? Or eventually everything will merge into GenAI somehow? What's your thoughts ",0,18,2025-07-06T15:37:22+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lt464v/with_generative_ai_looking_so_ominous_would_there/,"With Generative AI looking so ominous, would there be any further research in any other domains like Computer Vision or NLP or Graph Analytics ever? So as the title suggest, last few years have been just Generative AI all over the place. Every new research is somehow focussed towards it. So does this mean other fields stands still ? Or eventually everything will merge into GenAI somehow? What's your thoughts ",with generative ai looking so ominous would there be any further research in any other domains like computer vision or nlp or graph analytics ever so as the title suggest last few years have been just generative ai all over the place every new research is somehow focussed towards it so does this mean other fields stands still or eventually everything will merge into genai somehow whats your thoughts,generative ai look ominous research domain like computer vision nlp graph analytic title suggest year generative ai place new research focusse mean field stand eventually merge genai s thought
1lss1c5,Reliable DS Adjacent Fields Hiring for Bachelor's Degree?,"Hello all. To try and condense a lot of context for this question, I am an adult who went back to school to complete my bachelor's, in order to support myself and my partner on one income. Admittedly, I did this because I heard how good data science was as a field, but it seems I jumped in at the wrong time. 

Consequently, now that I am one year out from graduating with my bachelor's, I am starting to think about what fields would be best to apply in, beyond simply ""data science"" and ""data analysis."" Any leads on fields that are reliably hiring that are similar to data science but not exact? I am really open to anything that would pay the bills for two people.",35,24,2025-07-06T03:56:29+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lss1c5/reliable_ds_adjacent_fields_hiring_for_bachelors/,"Reliable DS Adjacent Fields Hiring for Bachelor's Degree? Hello all. To try and condense a lot of context for this question, I am an adult who went back to school to complete my bachelor's, in order to support myself and my partner on one income. Admittedly, I did this because I heard how good data science was as a field, but it seems I jumped in at the wrong time. 

Consequently, now that I am one year out from graduating with my bachelor's, I am starting to think about what fields would be best to apply in, beyond simply ""data science"" and ""data analysis."" Any leads on fields that are reliably hiring that are similar to data science but not exact? I am really open to anything that would pay the bills for two people.",reliable ds adjacent fields hiring for bachelors degree hello all to try and condense a lot of context for this question i am an adult who went back to school to complete my bachelors in order to support myself and my partner on one income admittedly i did this because i heard how good data science was as a field but it seems i jumped in at the wrong time consequently now that i am one year out from graduating with my bachelors i am starting to think about what fields would be best to apply in beyond simply data science and data analysis any leads on fields that are reliably hiring that are similar to data science but not exact i am really open to anything that would pay the bills for two people,reliable ds adjacent field hire bachelor degree hello try condense lot context question adult go school complete bachelor order support partner income admittedly hear good datum science field jump wrong time consequently year graduate bachelor start think field good apply simply datum science datum analysis lead field reliably hire similar data science exact open pay bill people
1lsk0sd,What’s the best way to automate pulling content performance metrics from LinkedIn beyond just downloading spreadsheets?,"I’ve been stuck manually exporting post data from the LinkedIn analytics dashboard for months. Automating via API sounds ideal, but this is uncharted territory!",0,3,2025-07-05T21:01:41+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lsk0sd/whats_the_best_way_to_automate_pulling_content/,"What’s the best way to automate pulling content performance metrics from LinkedIn beyond just downloading spreadsheets? I’ve been stuck manually exporting post data from the LinkedIn analytics dashboard for months. Automating via API sounds ideal, but this is uncharted territory!",whats the best way to automate pulling content performance metrics from linkedin beyond just downloading spreadsheets ive been stuck manually exporting post data from the linkedin analytics dashboard for months automating via api sounds ideal but this is uncharted territory,s good way automate pull content performance metric linkedin download spreadsheet ve stick manually export post datum linkedin analytic dashboard month automate api sound ideal uncharted territory
1lsjfj4,Long-timers at companies — what’s your secret?,"Hi everyone,

I’ve been a job hopper throughout my career—never stayed at one place for more than 1-2 years, usually for various reasons.

Now, I’m entering a phase where I want to get more settled. I’m about to start a new job and would love to hear from those who have successfully stayed long-term at a job.

What’s the secret sauce besides just hard work and taking ownership? Lay your knowledge on me—your hacks, tips, rituals.

Thanks in advance.",137,67,2025-07-05T20:35:14+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lsjfj4/longtimers_at_companies_whats_your_secret/,"Long-timers at companies — what’s your secret? Hi everyone,

I’ve been a job hopper throughout my career—never stayed at one place for more than 1-2 years, usually for various reasons.

Now, I’m entering a phase where I want to get more settled. I’m about to start a new job and would love to hear from those who have successfully stayed long-term at a job.

What’s the secret sauce besides just hard work and taking ownership? Lay your knowledge on me—your hacks, tips, rituals.

Thanks in advance.",longtimers at companies whats your secret hi everyone ive been a job hopper throughout my careernever stayed at one place for more than years usually for various reasons now im entering a phase where i want to get more settled im about to start a new job and would love to hear from those who have successfully stayed longterm at a job whats the secret sauce besides just hard work and taking ownership lay your knowledge on meyour hacks tips rituals thanks in advance,longtimer company s secret hi ve job hopper careernever stay place year usually reason m enter phase want settled m start new job love hear successfully stay longterm job s secret sauce hard work take ownership lay knowledge meyour hack tip ritual thank advance
1lsfyeo,A Brief Guide to UV,"Python has been largely devoid of easy to use environment and package management tooling, with various developers employing their own cocktail of `pip`, `virtualenv`, `poetry`, and `conda` to get the job done. However, it looks like `uv` is rapidly emerging to be a standard in the industry, and I'm super excited about it.

In a nutshell `uv` is like `npm` for Python. It's also written in rust so it's crazy fast.

As new ML approaches and frameworks have emerged around the greater ML space (A2A, MCP, etc) the cumbersome nature of Python environment management has transcended from an annoyance to a major hurdle. This seems to be the major reason `uv` has seen such meteoric adoption, especially in the ML/AI community.

[star history of uv vs poetry vs pip. Of course, github star history isn't necessarily emblematic of adoption.  \<ore importantly, uv is being used all over the shop in high-profile, cutting-edge repos that are governing the way modern software is evolving. Anthropic’s Python repo for MCP uses UV, Google’s Python repo for A2A uses UV, Open-WebUI seems to use UV, and that’s just to name a few.](https://preview.redd.it/b6myln1ve3bf1.png?width=1050&format=png&auto=webp&s=89d275ad7b050bbe8a365dd731e37910182592c4)

I wrote [an article](https://iaee.substack.com/p/uv-intuitively-and-exhaustively-explained) that goes over `uv` in greater depth, and includes some examples of `uv` in action, but I figured a brief pass would make a decent Reddit post.

**Why UV**  
`uv` allows you to manage dependencies and environments with a single tool, allowing you to create isolated python environments for different projects. While there are a few existing tools in Python to do this, there's one critical feature which makes it groundbreaking: *it's easy to use*.

**Installing UV**  
`uv` can be installed via `curl`

    curl -LsSf https://astral.sh/uv/install.sh | sh

or via `pip`

    pipx install uv

the docs have a [more in-depth guide to install](https://iaee.substack.com/p/uv-intuitively-and-exhaustively-explained#:~:text=Check%20out%20the-,uv%20docs,-for%20more%20information).

**Initializing a Project with UV**  
Once you have `uv` installed, you can run

    uv init

This initializes a uv project within your directory. You can think of this as an isolated python environment that's tied to your project.

**Adding Dependencies to your Project**  
You can add dependencies to your project with

    uv add <dependency name>

You can download all the dependencies you might install via `pip`:

    uv add pandas
    uv add scipy
    uv add numpy sklearn matplotlib

And you can install from various other sources, including github repos, local wheel files, etc.

**Running Within an Environment**  
if you have a python script within your environment, you can run it with

    uv run <file name>

this will run the file with the dependencies and python version specified for this particular environment.  This makes it super easy and convenient to bounce around between different projects. Also, if you clone a `uv` managed project, all dependencies will be installed and synchronized before the file is run.

**My Thoughts**  
I didn't realize I've been waiting for this for a long time. I always found off the cuff quick implementation of Python locally to be a pain, and I think I've been using ephemeral environments like Colab as a crutch to get around this issue. I find local development of Python projects to be significantly more enjoyable with `uv` , and thus I'll likely be adopting it as my go to approach when developing in Python locally.",97,57,2025-07-05T18:01:17+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lsfyeo/a_brief_guide_to_uv/,"A Brief Guide to UV Python has been largely devoid of easy to use environment and package management tooling, with various developers employing their own cocktail of `pip`, `virtualenv`, `poetry`, and `conda` to get the job done. However, it looks like `uv` is rapidly emerging to be a standard in the industry, and I'm super excited about it.

In a nutshell `uv` is like `npm` for Python. It's also written in rust so it's crazy fast.

As new ML approaches and frameworks have emerged around the greater ML space (A2A, MCP, etc) the cumbersome nature of Python environment management has transcended from an annoyance to a major hurdle. This seems to be the major reason `uv` has seen such meteoric adoption, especially in the ML/AI community.

[star history of uv vs poetry vs pip. Of course, github star history isn't necessarily emblematic of adoption.  \<ore importantly, uv is being used all over the shop in high-profile, cutting-edge repos that are governing the way modern software is evolving. Anthropic’s Python repo for MCP uses UV, Google’s Python repo for A2A uses UV, Open-WebUI seems to use UV, and that’s just to name a few.](https://preview.redd.it/b6myln1ve3bf1.png?width=1050&format=png&auto=webp&s=89d275ad7b050bbe8a365dd731e37910182592c4)

I wrote [an article](https://iaee.substack.com/p/uv-intuitively-and-exhaustively-explained) that goes over `uv` in greater depth, and includes some examples of `uv` in action, but I figured a brief pass would make a decent Reddit post.

**Why UV**  
`uv` allows you to manage dependencies and environments with a single tool, allowing you to create isolated python environments for different projects. While there are a few existing tools in Python to do this, there's one critical feature which makes it groundbreaking: *it's easy to use*.

**Installing UV**  
`uv` can be installed via `curl`

    curl -LsSf https://astral.sh/uv/install.sh | sh

or via `pip`

    pipx install uv

the docs have a [more in-depth guide to install](https://iaee.substack.com/p/uv-intuitively-and-exhaustively-explained#:~:text=Check%20out%20the-,uv%20docs,-for%20more%20information).

**Initializing a Project with UV**  
Once you have `uv` installed, you can run

    uv init

This initializes a uv project within your directory. You can think of this as an isolated python environment that's tied to your project.

**Adding Dependencies to your Project**  
You can add dependencies to your project with

    uv add <dependency name>

You can download all the dependencies you might install via `pip`:

    uv add pandas
    uv add scipy
    uv add numpy sklearn matplotlib

And you can install from various other sources, including github repos, local wheel files, etc.

**Running Within an Environment**  
if you have a python script within your environment, you can run it with

    uv run <file name>

this will run the file with the dependencies and python version specified for this particular environment.  This makes it super easy and convenient to bounce around between different projects. Also, if you clone a `uv` managed project, all dependencies will be installed and synchronized before the file is run.

**My Thoughts**  
I didn't realize I've been waiting for this for a long time. I always found off the cuff quick implementation of Python locally to be a pain, and I think I've been using ephemeral environments like Colab as a crutch to get around this issue. I find local development of Python projects to be significantly more enjoyable with `uv` , and thus I'll likely be adopting it as my go to approach when developing in Python locally.",a brief guide to uv python has been largely devoid of easy to use environment and package management tooling with various developers employing their own cocktail of pip virtualenv poetry and conda to get the job done however it looks like uv is rapidly emerging to be a standard in the industry and im super excited about it in a nutshell uv is like npm for python its also written in rust so its crazy fast as new ml approaches and frameworks have emerged around the greater ml space aa mcp etc the cumbersome nature of python environment management has transcended from an annoyance to a major hurdle this seems to be the major reason uv has seen such meteoric adoption especially in the mlai community i wrote that goes over uv in greater depth and includes some examples of uv in action but i figured a brief pass would make a decent reddit post why uv uv allows you to manage dependencies and environments with a single tool allowing you to create isolated python environments for different projects while there are a few existing tools in python to do this theres one critical feature which makes it groundbreaking its easy to use installing uv uv can be installed via curl curl lssf sh or via pip pipx install uv the docs have a initializing a project with uv once you have uv installed you can run uv init this initializes a uv project within your directory you can think of this as an isolated python environment thats tied to your project adding dependencies to your project you can add dependencies to your project with uv add dependency name you can download all the dependencies you might install via pip uv add pandas uv add scipy uv add numpy sklearn matplotlib and you can install from various other sources including github repos local wheel files etc running within an environment if you have a python script within your environment you can run it with uv run file name this will run the file with the dependencies and python version specified for this particular environment this makes it super easy and convenient to bounce around between different projects also if you clone a uv managed project all dependencies will be installed and synchronized before the file is run my thoughts i didnt realize ive been waiting for this for a long time i always found off the cuff quick implementation of python locally to be a pain and i think ive been using ephemeral environments like colab as a crutch to get around this issue i find local development of python projects to be significantly more enjoyable with uv and thus ill likely be adopting it as my go to approach when developing in python locally,brief guide uv python largely devoid easy use environment package management tooling developer employ cocktail pip virtualenv poetry conda job look like uv rapidly emerge standard industry m super excited nutshell uv like npm python write rust crazy fast new ml approach framework emerge great ml space aa mcp etc cumbersome nature python environment management transcend annoyance major hurdle major reason uv see meteoric adoption especially mlai community write go uv great depth include example uv action figure brief pass decent reddit post uv uv allow manage dependency environment single tool allow create isolate python environment different project exist tool python s critical feature make groundbreake easy use instal uv uv instal curl curl lssf sh pip pipx install uv doc initialize project uv uv instal run uv init initialize uv project directory think isolated python environment s tie project add dependency project add dependency project uv add dependency download dependency install pip uv add panda uv add scipy uv add numpy sklearn matplotlib install source include github repos local wheel file etc run environment python script environment run uv run file run file dependency python version specify particular environment make super easy convenient bounce different project clone uv manage project dependency instal synchronize file run thought not realize ve wait long time find cuff quick implementation python locally pain think ve ephemeral environment like colab crutch issue find local development python project significantly enjoyable uv ill likely adopt approach develop python locally
1lrojc3,How easy is it to be pigeonholed in DS?,"Although in my PhD I used experiments and traditional statistics, my first DS role is entirely focused on NLP. There are no opportunities to use casual inference, time series, or other traditional statistical methods. 

How much will this hurt my ability to apply to roles focused on these kinds of analyses? Basically, I'm wondering if my current role's focus on NLP is going to make it hard for me to get non-NLP data science positions when I'm ready to leave. 

Is it common for data scientists to get stuck in a niche?",34,23,2025-07-04T17:33:47+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lrojc3/how_easy_is_it_to_be_pigeonholed_in_ds/,"How easy is it to be pigeonholed in DS? Although in my PhD I used experiments and traditional statistics, my first DS role is entirely focused on NLP. There are no opportunities to use casual inference, time series, or other traditional statistical methods. 

How much will this hurt my ability to apply to roles focused on these kinds of analyses? Basically, I'm wondering if my current role's focus on NLP is going to make it hard for me to get non-NLP data science positions when I'm ready to leave. 

Is it common for data scientists to get stuck in a niche?",how easy is it to be pigeonholed in ds although in my phd i used experiments and traditional statistics my first ds role is entirely focused on nlp there are no opportunities to use casual inference time series or other traditional statistical methods how much will this hurt my ability to apply to roles focused on these kinds of analyses basically im wondering if my current roles focus on nlp is going to make it hard for me to get nonnlp data science positions when im ready to leave is it common for data scientists to get stuck in a niche,easy pigeonhole ds phd experiment traditional statistic ds role entirely focus nlp opportunity use casual inference time series traditional statistical method hurt ability apply role focus kind analysis basically m wonder current role focus nlp go hard nonnlp data science position m ready leave common datum scientist stick niche
1lrluwg,Any good resources for fraud detection and credit risk modelling?,"Hello, I am very much interested in using ML/DS in banking domain like fraud detection, loan prediction, credit risk, etc..


I have read this book about fraud detection.
https://fraud-detection-handbook.github.io/fraud-detection-handbook/Foreword.html

Understood everything and it was fun. Now, I am looking for similar resources to work on.

Thank you.",59,15,2025-07-04T15:41:49+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lrluwg/any_good_resources_for_fraud_detection_and_credit/,"Any good resources for fraud detection and credit risk modelling? Hello, I am very much interested in using ML/DS in banking domain like fraud detection, loan prediction, credit risk, etc..


I have read this book about fraud detection.
https://fraud-detection-handbook.github.io/fraud-detection-handbook/Foreword.html

Understood everything and it was fun. Now, I am looking for similar resources to work on.

Thank you.",any good resources for fraud detection and credit risk modelling hello i am very much interested in using mlds in banking domain like fraud detection loan prediction credit risk etc i have read this book about fraud detection understood everything and it was fun now i am looking for similar resources to work on thank you,good resource fraud detection credit risk model hello interested mld banking domain like fraud detection loan prediction credit risk etc read book fraud detection understand fun look similar resource work thank
1lrghkc,Causes of the 'Bad Market',"I'm just opening the floor to speculation / source dumping but everyone's talking about a suddenly very bad market for DS and DS related fields

  
I live in the north of the UK and it feels impossible to get a job out here. It sounds like its similar in the US. Is this a DS specific issue or are we just feeling what everyone else is feeling? I'm only now just emerging from a post-grad degree and I thought that hearing all these news stories about people illegally gathering and storing data that it was an indicator in how data driven so many decisions are now... which in my mind means that you'd need more DS/ ML engineers to wade through the quagmire and build solutions

  
obviously I'm wrong but why?",99,63,2025-07-04T11:31:24+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lrghkc/causes_of_the_bad_market/,"Causes of the 'Bad Market' I'm just opening the floor to speculation / source dumping but everyone's talking about a suddenly very bad market for DS and DS related fields

  
I live in the north of the UK and it feels impossible to get a job out here. It sounds like its similar in the US. Is this a DS specific issue or are we just feeling what everyone else is feeling? I'm only now just emerging from a post-grad degree and I thought that hearing all these news stories about people illegally gathering and storing data that it was an indicator in how data driven so many decisions are now... which in my mind means that you'd need more DS/ ML engineers to wade through the quagmire and build solutions

  
obviously I'm wrong but why?",causes of the bad market im just opening the floor to speculation source dumping but everyones talking about a suddenly very bad market for ds and ds related fields i live in the north of the uk and it feels impossible to get a job out here it sounds like its similar in the us is this a ds specific issue or are we just feeling what everyone else is feeling im only now just emerging from a postgrad degree and i thought that hearing all these news stories about people illegally gathering and storing data that it was an indicator in how data driven so many decisions are now which in my mind means that youd need more ds ml engineers to wade through the quagmire and build solutions obviously im wrong but why,cause bad market m open floor speculation source dumping everyone talk suddenly bad market ds ds relate field live north uk feel impossible job sound like similar ds specific issue feel feel m emerge postgrad degree think hear news story people illegally gather store datum indicator datum drive decision mind mean d need ds ml engineer wade quagmire build solution obviously m wrong
1lr8l54,"I just got LinkedIn Learning, what courses do you recommend I take on Data Science?","I’m kinda new to it but dont shy away from giving me the more advanced courses as I’ll be able to learn more

Im going to charge my phone",0,11,2025-07-04T03:22:35+00:00,datascience,https://i.redd.it/xdw8w4h60saf1.jpeg,"I just got LinkedIn Learning, what courses do you recommend I take on Data Science? I’m kinda new to it but dont shy away from giving me the more advanced courses as I’ll be able to learn more

Im going to charge my phone",i just got linkedin learning what courses do you recommend i take on data science im kinda new to it but dont shy away from giving me the more advanced courses as ill be able to learn more im going to charge my phone,get linkedin learn course recommend data science m kinda new not shy away give advanced course ill able learn m go charge phone
1lqno9m,People who have been in the field before 2020: how do you keep up with the constantly new and changing technologies in ML/AI?,"As someone who genuinely enjoys learning new tech, sometimes I feel it's too much to constantly keep up. I feel like it was only barely a year ago when I first learned RAG and then agents soon after, and now MCP servers.

I have a life outside tech and work and I feel that I'm getting lazier and burnt out in having to keep up. Not to mention only AI-specific tech, but even with adjacent tech like MLFlow, Kubernetes, etc, there seems to be so much that I feel I should be knowing. 

The reason why I asked *before 2020* is because I don't recall AI moving at this fast pace before then. Really feels like only after ChatGPT was released to the masses did the pace really pickup that now AI engineering actually feels quite different to the more classic ML engineering I was doing.",224,114,2025-07-03T11:56:18+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lqno9m/people_who_have_been_in_the_field_before_2020_how/,"People who have been in the field before 2020: how do you keep up with the constantly new and changing technologies in ML/AI? As someone who genuinely enjoys learning new tech, sometimes I feel it's too much to constantly keep up. I feel like it was only barely a year ago when I first learned RAG and then agents soon after, and now MCP servers.

I have a life outside tech and work and I feel that I'm getting lazier and burnt out in having to keep up. Not to mention only AI-specific tech, but even with adjacent tech like MLFlow, Kubernetes, etc, there seems to be so much that I feel I should be knowing. 

The reason why I asked *before 2020* is because I don't recall AI moving at this fast pace before then. Really feels like only after ChatGPT was released to the masses did the pace really pickup that now AI engineering actually feels quite different to the more classic ML engineering I was doing.",people who have been in the field before how do you keep up with the constantly new and changing technologies in mlai as someone who genuinely enjoys learning new tech sometimes i feel its too much to constantly keep up i feel like it was only barely a year ago when i first learned rag and then agents soon after and now mcp servers i have a life outside tech and work and i feel that im getting lazier and burnt out in having to keep up not to mention only aispecific tech but even with adjacent tech like mlflow kubernetes etc there seems to be so much that i feel i should be knowing the reason why i asked before is because i dont recall ai moving at this fast pace before then really feels like only after chatgpt was released to the masses did the pace really pickup that now ai engineering actually feels quite different to the more classic ml engineering i was doing,people field constantly new changing technology mlai genuinely enjoy learn new tech feel constantly feel like barely year ago learn rag agent soon mcp server life outside tech work feel m get lazier burn have mention aispecific tech adjacent tech like mlflow kubernete etc feel know reason ask not recall ai move fast pace feel like chatgpt release masse pace pickup ai engineering actually feel different classic ml engineering
1lqn6pu,How I Use MLflow 3.1 to Bring Observability to Multi-Agent AI Applications,"Hi everyone,

If you've been diving into the world of multi-agent AI applications, you've probably noticed a recurring issue: most tutorials and code examples out there feel like toys. They’re fun to play with, but when it comes to building something reliable and production-ready, they fall short. You run the code, and half the time, the results are unpredictable.

This was exactly the challenge I faced when I started working on enterprise-grade AI applications. I wanted my applications to not only work but also be robust, explainable, and observable. By ""observable,"" I mean being able to monitor what’s happening at every step — the inputs, outputs, errors, and even the thought process of the AI. And ""explainable"" means being able to answer questions like: *Why did the model give this result? What went wrong when it didn’t?*

But here’s the catch: as multi-agent frameworks have become more abstract and convenient to use, they’ve also made it harder to see under the hood. Often, you can’t even tell what prompt was finally sent to the large language model (LLM), let alone why the result wasn’t what you expected.

So, I started looking for tools that could help me monitor and evaluate my AI agents more effectively. That’s when I turned to MLflow. If you’ve worked in machine learning before, you might know MLflow as a model tracking and experimentation tool. But with its latest 3.x release, MLflow has added specialized support for GenAI projects. And trust me, it’s a game-changer.

[MLflow's tracking records. ](https://preview.redd.it/k3i2hbh18naf1.png?width=948&format=png&auto=webp&s=91cd9c33943b0d612fda2e8874b4979c60ce0618)

# Why Observability Matters

Before diving into the details, let’s talk about why this is important. In any AI application, but especially in multi-agent setups, you need three key capabilities:

1. **Observability:** Can you monitor the application in real time? Are there logs or visualizations to see what’s happening at each step?
2. **Explainability:** If something goes wrong, can you figure out why? Can the algorithm explain its decisions?
3. **Traceability:** If results deviate from expectations, can you reproduce the issue and pinpoint its cause?

[Three key metrics for evaluating the stability of enterprise GenAI applications. Image by Author](https://preview.redd.it/azgs0y3j7naf1.png?width=820&format=png&auto=webp&s=9fbf70b52379d8e8e869eab3bb3acc9b9450942f)

Without these, you’re flying blind. And when you’re building enterprise-grade systems where reliability is critical, flying blind isn’t an option.

# How MLflow Helps

MLflow is best known for its model tracking capabilities, but its GenAI features are what really caught my attention. It lets you track everything — from the prompts you send to the LLM to the outputs it generates, even in streaming scenarios where the model responds token by token.

[The Events tab in MLflow interface records every SSE message.](https://preview.redd.it/7mteb23c8naf1.png?width=858&format=png&auto=webp&s=1d0de24b21a58abeca9db0bbc7feeddd106c7fbc)

[MLflow's Autolog can also stitch together streaming messages in the Chat interface.](https://preview.redd.it/h77q9y3h8naf1.png?width=859&format=png&auto=webp&s=b3ab949f1cab02c2d71da952d6b6fc60bb2bac91)

The setup is straightforward. You can annotate your code, use MLflow’s ""autolog"" feature for automatic tracking, or leverage its context managers for more granular control. For example:

* Want to know exactly what prompt was sent to the model? Tracked.
* Want to log the inputs and outputs of every function your agent calls? Done.
* Want to monitor errors or unusual behavior? MLflow makes it easy to capture that too.

[You can view code execution error messages in the Events interface.](https://preview.redd.it/svx0fnpm8naf1.png?width=854&format=png&auto=webp&s=d7edbc819dbbccad8a0e881efce310c4b9553a02)

And the best part? MLflow’s UI makes all this data accessible in a clean, organized way. You can filter, search, and drill down into specific runs or spans (i.e., individual events in your application).

# A Real-World Example

I have a project involving building a workflow using Autogen, a popular multi-agent framework. The system included three agents:

1. A **generator** that creates ideas based on user input.
2. A **reviewer** that evaluates and refines those ideas.
3. A **summarizer** that compiles the final output.

While the framework made it easy to orchestrate these agents, it also abstracted away a lot of the details. At first, everything seemed fine — the agents were producing outputs, and the workflow ran smoothly. But when I looked closer, I realized the summarizer wasn’t getting all the information it needed. The final summaries were vague and uninformative.

With MLflow, I was able to trace the issue step by step. By examining the inputs and outputs at each stage, I discovered that the summarizer wasn’t receiving the generator’s final output. A simple configuration change fixed the problem, but without MLflow, I might never have noticed it.

[I might never have noticed that the agent wasn't passing the right info to the LLM until MLflow helped me out.](https://preview.redd.it/q7giinxu8naf1.png?width=960&format=png&auto=webp&s=05a3e7c983191836e6ceae8a8f689613d5acf77c)

# Why I’m Sharing This

I’m not here to sell you on MLflow — it’s open source, after all. I’m sharing this because I know how frustrating it can be to feel like you’re stumbling around in the dark when things go wrong. Whether you’re debugging a flaky chatbot or trying to optimize a complex workflow, having the right tools can make all the difference.

If you’re working on multi-agent applications and struggling with observability, I’d encourage you to give MLflow a try. It’s not perfect (I had to patch a few bugs in the Autogen integration, for example), but it’s the tool I’ve found for the job so far.",28,2,2025-07-03T11:29:11+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lqn6pu/how_i_use_mlflow_31_to_bring_observability_to/,"How I Use MLflow 3.1 to Bring Observability to Multi-Agent AI Applications Hi everyone,

If you've been diving into the world of multi-agent AI applications, you've probably noticed a recurring issue: most tutorials and code examples out there feel like toys. They’re fun to play with, but when it comes to building something reliable and production-ready, they fall short. You run the code, and half the time, the results are unpredictable.

This was exactly the challenge I faced when I started working on enterprise-grade AI applications. I wanted my applications to not only work but also be robust, explainable, and observable. By ""observable,"" I mean being able to monitor what’s happening at every step — the inputs, outputs, errors, and even the thought process of the AI. And ""explainable"" means being able to answer questions like: *Why did the model give this result? What went wrong when it didn’t?*

But here’s the catch: as multi-agent frameworks have become more abstract and convenient to use, they’ve also made it harder to see under the hood. Often, you can’t even tell what prompt was finally sent to the large language model (LLM), let alone why the result wasn’t what you expected.

So, I started looking for tools that could help me monitor and evaluate my AI agents more effectively. That’s when I turned to MLflow. If you’ve worked in machine learning before, you might know MLflow as a model tracking and experimentation tool. But with its latest 3.x release, MLflow has added specialized support for GenAI projects. And trust me, it’s a game-changer.

[MLflow's tracking records. ](https://preview.redd.it/k3i2hbh18naf1.png?width=948&format=png&auto=webp&s=91cd9c33943b0d612fda2e8874b4979c60ce0618)

# Why Observability Matters

Before diving into the details, let’s talk about why this is important. In any AI application, but especially in multi-agent setups, you need three key capabilities:

1. **Observability:** Can you monitor the application in real time? Are there logs or visualizations to see what’s happening at each step?
2. **Explainability:** If something goes wrong, can you figure out why? Can the algorithm explain its decisions?
3. **Traceability:** If results deviate from expectations, can you reproduce the issue and pinpoint its cause?

[Three key metrics for evaluating the stability of enterprise GenAI applications. Image by Author](https://preview.redd.it/azgs0y3j7naf1.png?width=820&format=png&auto=webp&s=9fbf70b52379d8e8e869eab3bb3acc9b9450942f)

Without these, you’re flying blind. And when you’re building enterprise-grade systems where reliability is critical, flying blind isn’t an option.

# How MLflow Helps

MLflow is best known for its model tracking capabilities, but its GenAI features are what really caught my attention. It lets you track everything — from the prompts you send to the LLM to the outputs it generates, even in streaming scenarios where the model responds token by token.

[The Events tab in MLflow interface records every SSE message.](https://preview.redd.it/7mteb23c8naf1.png?width=858&format=png&auto=webp&s=1d0de24b21a58abeca9db0bbc7feeddd106c7fbc)

[MLflow's Autolog can also stitch together streaming messages in the Chat interface.](https://preview.redd.it/h77q9y3h8naf1.png?width=859&format=png&auto=webp&s=b3ab949f1cab02c2d71da952d6b6fc60bb2bac91)

The setup is straightforward. You can annotate your code, use MLflow’s ""autolog"" feature for automatic tracking, or leverage its context managers for more granular control. For example:

* Want to know exactly what prompt was sent to the model? Tracked.
* Want to log the inputs and outputs of every function your agent calls? Done.
* Want to monitor errors or unusual behavior? MLflow makes it easy to capture that too.

[You can view code execution error messages in the Events interface.](https://preview.redd.it/svx0fnpm8naf1.png?width=854&format=png&auto=webp&s=d7edbc819dbbccad8a0e881efce310c4b9553a02)

And the best part? MLflow’s UI makes all this data accessible in a clean, organized way. You can filter, search, and drill down into specific runs or spans (i.e., individual events in your application).

# A Real-World Example

I have a project involving building a workflow using Autogen, a popular multi-agent framework. The system included three agents:

1. A **generator** that creates ideas based on user input.
2. A **reviewer** that evaluates and refines those ideas.
3. A **summarizer** that compiles the final output.

While the framework made it easy to orchestrate these agents, it also abstracted away a lot of the details. At first, everything seemed fine — the agents were producing outputs, and the workflow ran smoothly. But when I looked closer, I realized the summarizer wasn’t getting all the information it needed. The final summaries were vague and uninformative.

With MLflow, I was able to trace the issue step by step. By examining the inputs and outputs at each stage, I discovered that the summarizer wasn’t receiving the generator’s final output. A simple configuration change fixed the problem, but without MLflow, I might never have noticed it.

[I might never have noticed that the agent wasn't passing the right info to the LLM until MLflow helped me out.](https://preview.redd.it/q7giinxu8naf1.png?width=960&format=png&auto=webp&s=05a3e7c983191836e6ceae8a8f689613d5acf77c)

# Why I’m Sharing This

I’m not here to sell you on MLflow — it’s open source, after all. I’m sharing this because I know how frustrating it can be to feel like you’re stumbling around in the dark when things go wrong. Whether you’re debugging a flaky chatbot or trying to optimize a complex workflow, having the right tools can make all the difference.

If you’re working on multi-agent applications and struggling with observability, I’d encourage you to give MLflow a try. It’s not perfect (I had to patch a few bugs in the Autogen integration, for example), but it’s the tool I’ve found for the job so far.",how i use mlflow to bring observability to multiagent ai applications hi everyone if youve been diving into the world of multiagent ai applications youve probably noticed a recurring issue most tutorials and code examples out there feel like toys theyre fun to play with but when it comes to building something reliable and productionready they fall short you run the code and half the time the results are unpredictable this was exactly the challenge i faced when i started working on enterprisegrade ai applications i wanted my applications to not only work but also be robust explainable and observable by observable i mean being able to monitor whats happening at every step the inputs outputs errors and even the thought process of the ai and explainable means being able to answer questions like why did the model give this result what went wrong when it didnt but heres the catch as multiagent frameworks have become more abstract and convenient to use theyve also made it harder to see under the hood often you cant even tell what prompt was finally sent to the large language model llm let alone why the result wasnt what you expected so i started looking for tools that could help me monitor and evaluate my ai agents more effectively thats when i turned to mlflow if youve worked in machine learning before you might know mlflow as a model tracking and experimentation tool but with its latest x release mlflow has added specialized support for genai projects and trust me its a gamechanger why observability matters before diving into the details lets talk about why this is important in any ai application but especially in multiagent setups you need three key capabilities observability can you monitor the application in real time are there logs or visualizations to see whats happening at each step explainability if something goes wrong can you figure out why can the algorithm explain its decisions traceability if results deviate from expectations can you reproduce the issue and pinpoint its cause without these youre flying blind and when youre building enterprisegrade systems where reliability is critical flying blind isnt an option how mlflow helps mlflow is best known for its model tracking capabilities but its genai features are what really caught my attention it lets you track everything from the prompts you send to the llm to the outputs it generates even in streaming scenarios where the model responds token by token the setup is straightforward you can annotate your code use mlflows autolog feature for automatic tracking or leverage its context managers for more granular control for example want to know exactly what prompt was sent to the model tracked want to log the inputs and outputs of every function your agent calls done want to monitor errors or unusual behavior mlflow makes it easy to capture that too and the best part mlflows ui makes all this data accessible in a clean organized way you can filter search and drill down into specific runs or spans ie individual events in your application a realworld example i have a project involving building a workflow using autogen a popular multiagent framework the system included three agents a generator that creates ideas based on user input a reviewer that evaluates and refines those ideas a summarizer that compiles the final output while the framework made it easy to orchestrate these agents it also abstracted away a lot of the details at first everything seemed fine the agents were producing outputs and the workflow ran smoothly but when i looked closer i realized the summarizer wasnt getting all the information it needed the final summaries were vague and uninformative with mlflow i was able to trace the issue step by step by examining the inputs and outputs at each stage i discovered that the summarizer wasnt receiving the generators final output a simple configuration change fixed the problem but without mlflow i might never have noticed it why im sharing this im not here to sell you on mlflow its open source after all im sharing this because i know how frustrating it can be to feel like youre stumbling around in the dark when things go wrong whether youre debugging a flaky chatbot or trying to optimize a complex workflow having the right tools can make all the difference if youre working on multiagent applications and struggling with observability id encourage you to give mlflow a try its not perfect i had to patch a few bugs in the autogen integration for example but its the tool ive found for the job so far,use mlflow bring observability multiagent ai application hi ve dive world multiagent ai application ve probably notice recur issue tutorial code example feel like toy fun play come build reliable productionready fall short run code half time result unpredictable exactly challenge face start work enterprisegrade ai application want application work robust explainable observable observable mean able monitor s happen step input output error thought process ai explainable mean able answer question like model result go wrong not here catch multiagent framework abstract convenient use ve hard hood not tell prompt finally send large language model llm let result not expect start look tool help monitor evaluate ai agent effectively s turn mlflow ve work machine learn know mlflow model tracking experimentation tool late x release mlflow add specialized support genai project trust gamechanger observability matter dive detail lets talk important ai application especially multiagent setup need key capability observability monitor application real time log visualization s happen step explainability go wrong figure algorithm explain decision traceability result deviate expectation reproduce issue pinpoint cause fly blind build enterprisegrade system reliability critical fly blind not option mlflow help mlflow well know model tracking capability genai feature catch attention let track prompt send llm output generate stream scenario model respond token token setup straightforward annotate code use mlflow autolog feature automatic tracking leverage context manager granular control example want know exactly prompt send model track want log input output function agent call want monitor error unusual behavior mlflow make easy capture good mlflow ui make datum accessible clean organize way filter search drill specific run span ie individual event application realworld example project involve build workflow autogen popular multiagent framework system include agent generator create idea base user input reviewer evaluate refine idea summarizer compile final output framework easy orchestrate agent abstract away lot detail fine agent produce output workflow run smoothly look close realize summarizer not get information need final summary vague uninformative mlflow able trace issue step step examine input output stage discover summarizer not receive generator final output simple configuration change fix problem mlflow notice m share m sell mlflow open source m share know frustrating feel like stumble dark thing wrong debug flaky chatbot try optimize complex workflow have right tool difference work multiagent application struggle observability d encourage mlflow try perfect patch bug autogen integration example tool ve find job far
1lq8shf,How can I get international remote positions?,"Hello folks! I am a data scientist in Brazil and in general, I have a good resume. I have experience working in big techs, startup,  consulting and a MsC degree. 

I get Brazilian interviews easily but not abroad, even if I have a LinkedIn profile in English. How can I get considered for a remote position from US or Europe so I can keep working from my country?",93,72,2025-07-02T22:06:14+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lq8shf/how_can_i_get_international_remote_positions/,"How can I get international remote positions? Hello folks! I am a data scientist in Brazil and in general, I have a good resume. I have experience working in big techs, startup,  consulting and a MsC degree. 

I get Brazilian interviews easily but not abroad, even if I have a LinkedIn profile in English. How can I get considered for a remote position from US or Europe so I can keep working from my country?",how can i get international remote positions hello folks i am a data scientist in brazil and in general i have a good resume i have experience working in big techs startup consulting and a msc degree i get brazilian interviews easily but not abroad even if i have a linkedin profile in english how can i get considered for a remote position from us or europe so i can keep working from my country,international remote position hello folk data scientist brazil general good resume experience work big tech startup consulting msc degree brazilian interview easily abroad linkedin profile english consider remote position europe work country
1lq79vo,"A Breakdown of A2A, MCP, and Agentic Interoperability","MCP and A2A are both emerging standards in AI. In this post I want to cover what they're both useful for (based on my experience) from a practical level, and some of my thoughts about where the two protocols will go moving forward. Both of these protocols are still actively evolving, and I think there's room for interpretation around where they should go moving forward. As a result, I don't think there is a single, correct interpretation of A2A and MCP. These are my thoughts.

**What is MCP?**  
From it's highest level, MCP (model context protocol) is a standard way to expose tools to AI agents. More specifically, it's a standard way to communicate tools to a client which is managing the execution of an LLM within a logical loop. There's not really one, single, god almighty way to feed tools into an LLM, but MCP defines a standard on how tools are defined to make that process more streamlined.

The whole idea of MCP is derivative from LSP (language server protocol), which emerged due to a practical need from programming language and code editor developers. If you're working on something like VS Code, for instance, you don't want to implement hooks for Rust, Python, Java, etc. If you make a new programming language, you don't want to integrate it into vscode, sublime, jetbrains, etc.  The problem of ""connect programming language to text editor, with syntax highlighting and autocomplete"" was abstracted to a generalized problem, and solved with LSP. The idea is that, if you're making a new language, you create an LSP server so that language will work in any text editor. If you're building a new text editor, you can support LSP to automatically support any modern programming language.

[A conceptual diagram of LSPs \(source: MCP IAEE\)](https://preview.redd.it/wz60k2hswiaf1.jpg?width=1050&format=pjpg&auto=webp&s=1c42845286b2bb05047bd0c32caf6a25ca7fdcac)

MCP does something similar, but for agents and tools. The idea is to represent tool use in a standardized way, such developers can put tools in an MCP server, and so developers working on agentic systems can use those tools via a standardized interface.

[LSP and MCP are conceptually similar in terms of their core workflow \(source: MCP IAEE\)](https://preview.redd.it/clc7u0qehiaf1.png?width=1050&format=png&auto=webp&s=6790f5a438aff994337a2224736ba986f1c17777)

I think it's important to note, MCP presents a standardized **interface** for tools, but there is leeway in terms of how a developer might choose to build tools and resources within an MCP server, and there is leeway around how MCP client developers might choose to use those tools and resources.

MCP has various ""transports"" defined, transports being means of communication between the client and the server. MCP can communicate both over the internet, and over local channels (allowing the MCP client to control local tools like applications or web browsers). In my estimation, the latter is really what MCP was designed for. In theory you can connect with an MCP server hosted on the internet, but MCP is chiefly designed to allow clients to execute a locally defined server.

Here's an example of a simple MCP server:

    """"""A very simple MCP server, which exposes a single very simple tool. In most
    practical applications of MCP, a script like this would be launched by the client,
    then the client can talk with that server to execute tools as needed.
    source: MCP IAEE.
    """"""
    
    from mcp.server.fastmcp import FastMCP
    
    mcp = FastMCP(""server"")
    
    u/mcp.tool()
    def say_hello(name: str) -> str:
        """"""Constructs a greeting from a name""""""
        return f""hello {name}, from the server!

In the normal workflow, the MCP client would spawn an MCP server based on a script like this, then would work with that server to execute tools as needed.

**What is A2A?**  
If MCP is designed to expose tools to AI agents, A2A is designed to allow AI agents to talk to one another. I think this diagram summarizes how the two technologies interoperate with on another nicely:

[A conceptual diagram of how A2A and MCP might work together. \(Source: A2A Home Page\)](https://preview.redd.it/gb2bj773ziaf1.png?width=640&format=png&auto=webp&s=c74c1ced5fc1e9026670f68487431392f79d0a4e)

Similarly to MCP, A2A is designed to standardize communication between AI resource. However, A2A is specifically designed for allowing agents to communicate with one another. It does this with two fundamental concepts:

1. Agent Cards: a structure description of what an agent does and where it can be found.
2. Tasks: requests can be sent to an agent, allowing it to execute on tasks via back and forth communication.

A2A is peer-to-peer, asynchronous, and is natively designed to support online communication. In python, A2A is built on top of ASGI (asynchronous server gateway interface), which is the same technology that powers FastAPI and Django.

Here's an example of a simple A2A server:

    from a2a.server.agent_execution import AgentExecutor, RequestContext
    from a2a.server.apps import A2AStarletteApplication
    from a2a.server.request_handlers import DefaultRequestHandler
    from a2a.server.tasks import InMemoryTaskStore
    from a2a.server.events import EventQueue
    from a2a.utils import new_agent_text_message
    from a2a.types import AgentCard, AgentSkill, AgentCapabilities
    
    import uvicorn
    
    class HelloExecutor(AgentExecutor):
        async def execute(self, context: RequestContext, event_queue: EventQueue) -> None:
            # Respond with a static hello message
            event_queue.enqueue_event(new_agent_text_message(""Hello from A2A!""))
    
        async def cancel(self, context: RequestContext, event_queue: EventQueue) -> None:
            pass  # No-op
    
    
    def create_app():
        skill = AgentSkill(
            id=""hello"",
            name=""Hello"",
            description=""Say hello to the world."",
            tags=[""hello"", ""greet""],
            examples=[""hello"", ""hi""]
        )
    
        agent_card = AgentCard(
            name=""HelloWorldAgent"",
            description=""A simple A2A agent that says hello."",
            version=""0.1.0"",
            url=""http://localhost:9000"",
            skills=[skill],
            capabilities=AgentCapabilities(),
            authenticationSchemes=[""public""],
            defaultInputModes=[""text""],
            defaultOutputModes=[""text""],
        )
    
        handler = DefaultRequestHandler(
            agent_executor=HelloExecutor(),
            task_store=InMemoryTaskStore()
        )
    
        app = A2AStarletteApplication(agent_card=agent_card, http_handler=handler)
        return app.build()
    
    
    if __name__ == ""__main__"":
        uvicorn.run(create_app(), host=""127.0.0.1"", port=9000)

Thus A2A has important distinctions from MCP:

* A2A is designed to support ""discoverability"" with agent cards. MCP is designed to be explicitly pointed to.
* A2A is designed for asynchronous communication, allowing for complex implementations of multi-agent workloads working in parallel.
* A2A is designed to be peer-to-peer, rather than having the rigid hierarchy of MCP clients and servers.

**A Point of Friction**  
I think the high level conceptualization around MCP and A2A is pretty solid; MCP is for tools, A2A is for inter-agent communication.

[A high level breakdown of the core usage of MCP and A2A \(source: MCP vs A2A\)](https://preview.redd.it/s8ba9ov6ziaf1.png?width=1080&format=png&auto=webp&s=7c4db19dde15d13cc34372e9c7449ad91939ad28)

Despite the high level clarity, I find these clean distinctions have a tendency to break down practically in terms of implementation. I was working on an example of an application which leveraged both MCP and A2A. I poked around the internet, and found [a repo of examples](https://github.com/a2aproject/a2a-samples/tree/main/samples/python/agents/a2a_mcp) from the official a2a github account. In these examples, they actually use MCP to expose A2A as a set of tools. So, instead of the two protocols existing independently:

[How MCP and A2A might commonly be conceptualized, within a sample application consisting of a travel agent, a car agent, and an airline agent. \(source: A2A IAEE\)](https://preview.redd.it/5wxavpimniaf1.png?width=1050&format=png&auto=webp&s=b092517d6df915c72b673898f3bf563f5dda16d0)

Communication over A2A happens within MCP servers:

[Another approach of implementing A2A and MCP. \(source: A2A IAEE\)](https://preview.redd.it/dh3de5xuniaf1.png?width=1050&format=png&auto=webp&s=d3f46df060e30bb2d71b24ecfc670566f643322f)

This violates the conventional wisdom I see online of A2A and MCP essentially operating as completely separate and isolated protocols. I think the key benefit of this approach is ease of implementation: You don't have to expose both A2A and MCP as two seperate sets of tools to the LLM. Instead, you can expose only a single MCP server to an LLM (that MCP server containing tools for A2A communication). This makes it much easier to manage the integration of A2A and MCP into a single agent. Many LLM providers have plenty of demos of MCP tool use, so using MCP as a vehicle to serve up A2A is compelling.

You can also use the two protocols in isolation, I imagine. There are a ton of ways MCP and A2A enabled projects can practically be implemented, which leads to closing thoughts on the subject.

**My thoughts on MCP and A2A**  
It doesn't matter how standardized MCP and A2A are; if we can't all agree on the larger structure they exist in, there's no interoperability. In the future I expect frameworks to be built on top of both MCP and A2A to establish and enforce best practices. Once the industry converges on these new frameworks, I think issues of ""should this be behind MCP or A2A"" and ""how should I integrate MCP and A2A into this agent"" will start to go away. This is a standard part of the lifecycle of software development, and we've seen the same thing happen with countless protocols in the past.

Standardizing prompting, though, is a different beast entirely.

Having managed the development of LLM powered applications for a while now, I've found prompt engineering to have an interesting role in the greater product development lifecycle. Non-technical stakeholders have a tendency to flock to prompt engineering as a catch all way to solve any problem, which is totally untrue. Developers have a tendency to disregard prompt engineering as a secondary concern, which is also totally untrue. The fact is, prompt engineering won't magically make an LLM powered application better, but bad prompt engineering sure can make it worse. When you hook into MCP and A2A enabled systems, you are essentially allowing for arbitrary injection of prompts as they are defined in these systems. This may have some security concerns if your code isn't designed in a hardened manner, but more palpably there are massive performance concerns. Simply put, if your prompts aren't synergistic with one another throughout an LLM powered application, you won't get good performance. This seriously undermines the practical utility of MCP and A2A enabling turn-key integration.

I think the problem of a framework to define when a tool should be MCP vs A2A is immediately solvable. In terms of prompt engineering, though, I'm curious if we'll need to build rigid best practices around it, or if we can devise clever systems to make interoperable agents more robust to prompting inconsistencies.

**Sources:**  
MCP [vs A2A](https://www.eyelevel.ai/post/a2a-vs-mcp-how-agent-protocols-really-work-and-where-each-one-wins) (I co-authored)  
[MCP IAEE ](https://iaee.substack.com/p/model-context-protocol-intuitively) (I authored)  
[A2A IAEE](https://iaee.substack.com/p/agent-to-agent-protocol-intuitively?utm_source=publication-search) (I authored)  
[A2A MCP Examples](https://github.com/a2aproject/a2a-samples/tree/main/samples/python/agents/a2a_mcp)  
[A2A Home Page](https://a2aproject.github.io/A2A/latest/)

  


  
",31,6,2025-07-02T21:02:43+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lq79vo/a_breakdown_of_a2a_mcp_and_agentic/,"A Breakdown of A2A, MCP, and Agentic Interoperability MCP and A2A are both emerging standards in AI. In this post I want to cover what they're both useful for (based on my experience) from a practical level, and some of my thoughts about where the two protocols will go moving forward. Both of these protocols are still actively evolving, and I think there's room for interpretation around where they should go moving forward. As a result, I don't think there is a single, correct interpretation of A2A and MCP. These are my thoughts.

**What is MCP?**  
From it's highest level, MCP (model context protocol) is a standard way to expose tools to AI agents. More specifically, it's a standard way to communicate tools to a client which is managing the execution of an LLM within a logical loop. There's not really one, single, god almighty way to feed tools into an LLM, but MCP defines a standard on how tools are defined to make that process more streamlined.

The whole idea of MCP is derivative from LSP (language server protocol), which emerged due to a practical need from programming language and code editor developers. If you're working on something like VS Code, for instance, you don't want to implement hooks for Rust, Python, Java, etc. If you make a new programming language, you don't want to integrate it into vscode, sublime, jetbrains, etc.  The problem of ""connect programming language to text editor, with syntax highlighting and autocomplete"" was abstracted to a generalized problem, and solved with LSP. The idea is that, if you're making a new language, you create an LSP server so that language will work in any text editor. If you're building a new text editor, you can support LSP to automatically support any modern programming language.

[A conceptual diagram of LSPs \(source: MCP IAEE\)](https://preview.redd.it/wz60k2hswiaf1.jpg?width=1050&format=pjpg&auto=webp&s=1c42845286b2bb05047bd0c32caf6a25ca7fdcac)

MCP does something similar, but for agents and tools. The idea is to represent tool use in a standardized way, such developers can put tools in an MCP server, and so developers working on agentic systems can use those tools via a standardized interface.

[LSP and MCP are conceptually similar in terms of their core workflow \(source: MCP IAEE\)](https://preview.redd.it/clc7u0qehiaf1.png?width=1050&format=png&auto=webp&s=6790f5a438aff994337a2224736ba986f1c17777)

I think it's important to note, MCP presents a standardized **interface** for tools, but there is leeway in terms of how a developer might choose to build tools and resources within an MCP server, and there is leeway around how MCP client developers might choose to use those tools and resources.

MCP has various ""transports"" defined, transports being means of communication between the client and the server. MCP can communicate both over the internet, and over local channels (allowing the MCP client to control local tools like applications or web browsers). In my estimation, the latter is really what MCP was designed for. In theory you can connect with an MCP server hosted on the internet, but MCP is chiefly designed to allow clients to execute a locally defined server.

Here's an example of a simple MCP server:

    """"""A very simple MCP server, which exposes a single very simple tool. In most
    practical applications of MCP, a script like this would be launched by the client,
    then the client can talk with that server to execute tools as needed.
    source: MCP IAEE.
    """"""
    
    from mcp.server.fastmcp import FastMCP
    
    mcp = FastMCP(""server"")
    
    u/mcp.tool()
    def say_hello(name: str) -> str:
        """"""Constructs a greeting from a name""""""
        return f""hello {name}, from the server!

In the normal workflow, the MCP client would spawn an MCP server based on a script like this, then would work with that server to execute tools as needed.

**What is A2A?**  
If MCP is designed to expose tools to AI agents, A2A is designed to allow AI agents to talk to one another. I think this diagram summarizes how the two technologies interoperate with on another nicely:

[A conceptual diagram of how A2A and MCP might work together. \(Source: A2A Home Page\)](https://preview.redd.it/gb2bj773ziaf1.png?width=640&format=png&auto=webp&s=c74c1ced5fc1e9026670f68487431392f79d0a4e)

Similarly to MCP, A2A is designed to standardize communication between AI resource. However, A2A is specifically designed for allowing agents to communicate with one another. It does this with two fundamental concepts:

1. Agent Cards: a structure description of what an agent does and where it can be found.
2. Tasks: requests can be sent to an agent, allowing it to execute on tasks via back and forth communication.

A2A is peer-to-peer, asynchronous, and is natively designed to support online communication. In python, A2A is built on top of ASGI (asynchronous server gateway interface), which is the same technology that powers FastAPI and Django.

Here's an example of a simple A2A server:

    from a2a.server.agent_execution import AgentExecutor, RequestContext
    from a2a.server.apps import A2AStarletteApplication
    from a2a.server.request_handlers import DefaultRequestHandler
    from a2a.server.tasks import InMemoryTaskStore
    from a2a.server.events import EventQueue
    from a2a.utils import new_agent_text_message
    from a2a.types import AgentCard, AgentSkill, AgentCapabilities
    
    import uvicorn
    
    class HelloExecutor(AgentExecutor):
        async def execute(self, context: RequestContext, event_queue: EventQueue) -> None:
            # Respond with a static hello message
            event_queue.enqueue_event(new_agent_text_message(""Hello from A2A!""))
    
        async def cancel(self, context: RequestContext, event_queue: EventQueue) -> None:
            pass  # No-op
    
    
    def create_app():
        skill = AgentSkill(
            id=""hello"",
            name=""Hello"",
            description=""Say hello to the world."",
            tags=[""hello"", ""greet""],
            examples=[""hello"", ""hi""]
        )
    
        agent_card = AgentCard(
            name=""HelloWorldAgent"",
            description=""A simple A2A agent that says hello."",
            version=""0.1.0"",
            url=""http://localhost:9000"",
            skills=[skill],
            capabilities=AgentCapabilities(),
            authenticationSchemes=[""public""],
            defaultInputModes=[""text""],
            defaultOutputModes=[""text""],
        )
    
        handler = DefaultRequestHandler(
            agent_executor=HelloExecutor(),
            task_store=InMemoryTaskStore()
        )
    
        app = A2AStarletteApplication(agent_card=agent_card, http_handler=handler)
        return app.build()
    
    
    if __name__ == ""__main__"":
        uvicorn.run(create_app(), host=""127.0.0.1"", port=9000)

Thus A2A has important distinctions from MCP:

* A2A is designed to support ""discoverability"" with agent cards. MCP is designed to be explicitly pointed to.
* A2A is designed for asynchronous communication, allowing for complex implementations of multi-agent workloads working in parallel.
* A2A is designed to be peer-to-peer, rather than having the rigid hierarchy of MCP clients and servers.

**A Point of Friction**  
I think the high level conceptualization around MCP and A2A is pretty solid; MCP is for tools, A2A is for inter-agent communication.

[A high level breakdown of the core usage of MCP and A2A \(source: MCP vs A2A\)](https://preview.redd.it/s8ba9ov6ziaf1.png?width=1080&format=png&auto=webp&s=7c4db19dde15d13cc34372e9c7449ad91939ad28)

Despite the high level clarity, I find these clean distinctions have a tendency to break down practically in terms of implementation. I was working on an example of an application which leveraged both MCP and A2A. I poked around the internet, and found [a repo of examples](https://github.com/a2aproject/a2a-samples/tree/main/samples/python/agents/a2a_mcp) from the official a2a github account. In these examples, they actually use MCP to expose A2A as a set of tools. So, instead of the two protocols existing independently:

[How MCP and A2A might commonly be conceptualized, within a sample application consisting of a travel agent, a car agent, and an airline agent. \(source: A2A IAEE\)](https://preview.redd.it/5wxavpimniaf1.png?width=1050&format=png&auto=webp&s=b092517d6df915c72b673898f3bf563f5dda16d0)

Communication over A2A happens within MCP servers:

[Another approach of implementing A2A and MCP. \(source: A2A IAEE\)](https://preview.redd.it/dh3de5xuniaf1.png?width=1050&format=png&auto=webp&s=d3f46df060e30bb2d71b24ecfc670566f643322f)

This violates the conventional wisdom I see online of A2A and MCP essentially operating as completely separate and isolated protocols. I think the key benefit of this approach is ease of implementation: You don't have to expose both A2A and MCP as two seperate sets of tools to the LLM. Instead, you can expose only a single MCP server to an LLM (that MCP server containing tools for A2A communication). This makes it much easier to manage the integration of A2A and MCP into a single agent. Many LLM providers have plenty of demos of MCP tool use, so using MCP as a vehicle to serve up A2A is compelling.

You can also use the two protocols in isolation, I imagine. There are a ton of ways MCP and A2A enabled projects can practically be implemented, which leads to closing thoughts on the subject.

**My thoughts on MCP and A2A**  
It doesn't matter how standardized MCP and A2A are; if we can't all agree on the larger structure they exist in, there's no interoperability. In the future I expect frameworks to be built on top of both MCP and A2A to establish and enforce best practices. Once the industry converges on these new frameworks, I think issues of ""should this be behind MCP or A2A"" and ""how should I integrate MCP and A2A into this agent"" will start to go away. This is a standard part of the lifecycle of software development, and we've seen the same thing happen with countless protocols in the past.

Standardizing prompting, though, is a different beast entirely.

Having managed the development of LLM powered applications for a while now, I've found prompt engineering to have an interesting role in the greater product development lifecycle. Non-technical stakeholders have a tendency to flock to prompt engineering as a catch all way to solve any problem, which is totally untrue. Developers have a tendency to disregard prompt engineering as a secondary concern, which is also totally untrue. The fact is, prompt engineering won't magically make an LLM powered application better, but bad prompt engineering sure can make it worse. When you hook into MCP and A2A enabled systems, you are essentially allowing for arbitrary injection of prompts as they are defined in these systems. This may have some security concerns if your code isn't designed in a hardened manner, but more palpably there are massive performance concerns. Simply put, if your prompts aren't synergistic with one another throughout an LLM powered application, you won't get good performance. This seriously undermines the practical utility of MCP and A2A enabling turn-key integration.

I think the problem of a framework to define when a tool should be MCP vs A2A is immediately solvable. In terms of prompt engineering, though, I'm curious if we'll need to build rigid best practices around it, or if we can devise clever systems to make interoperable agents more robust to prompting inconsistencies.

**Sources:**  
MCP [vs A2A](https://www.eyelevel.ai/post/a2a-vs-mcp-how-agent-protocols-really-work-and-where-each-one-wins) (I co-authored)  
[MCP IAEE ](https://iaee.substack.com/p/model-context-protocol-intuitively) (I authored)  
[A2A IAEE](https://iaee.substack.com/p/agent-to-agent-protocol-intuitively?utm_source=publication-search) (I authored)  
[A2A MCP Examples](https://github.com/a2aproject/a2a-samples/tree/main/samples/python/agents/a2a_mcp)  
[A2A Home Page](https://a2aproject.github.io/A2A/latest/)

  


  
",a breakdown of aa mcp and agentic interoperability mcp and aa are both emerging standards in ai in this post i want to cover what theyre both useful for based on my experience from a practical level and some of my thoughts about where the two protocols will go moving forward both of these protocols are still actively evolving and i think theres room for interpretation around where they should go moving forward as a result i dont think there is a single correct interpretation of aa and mcp these are my thoughts what is mcp from its highest level mcp model context protocol is a standard way to expose tools to ai agents more specifically its a standard way to communicate tools to a client which is managing the execution of an llm within a logical loop theres not really one single god almighty way to feed tools into an llm but mcp defines a standard on how tools are defined to make that process more streamlined the whole idea of mcp is derivative from lsp language server protocol which emerged due to a practical need from programming language and code editor developers if youre working on something like vs code for instance you dont want to implement hooks for rust python java etc if you make a new programming language you dont want to integrate it into vscode sublime jetbrains etc the problem of connect programming language to text editor with syntax highlighting and autocomplete was abstracted to a generalized problem and solved with lsp the idea is that if youre making a new language you create an lsp server so that language will work in any text editor if youre building a new text editor you can support lsp to automatically support any modern programming language mcp does something similar but for agents and tools the idea is to represent tool use in a standardized way such developers can put tools in an mcp server and so developers working on agentic systems can use those tools via a standardized interface i think its important to note mcp presents a standardized interface for tools but there is leeway in terms of how a developer might choose to build tools and resources within an mcp server and there is leeway around how mcp client developers might choose to use those tools and resources mcp has various transports defined transports being means of communication between the client and the server mcp can communicate both over the internet and over local channels allowing the mcp client to control local tools like applications or web browsers in my estimation the latter is really what mcp was designed for in theory you can connect with an mcp server hosted on the internet but mcp is chiefly designed to allow clients to execute a locally defined server heres an example of a simple mcp server a very simple mcp server which exposes a single very simple tool in most practical applications of mcp a script like this would be launched by the client then the client can talk with that server to execute tools as needed source mcp iaee from mcpserverfastmcp import fastmcp mcp fastmcpserver umcptool def sayhelloname str str constructs a greeting from a name return fhello name from the server in the normal workflow the mcp client would spawn an mcp server based on a script like this then would work with that server to execute tools as needed what is aa if mcp is designed to expose tools to ai agents aa is designed to allow ai agents to talk to one another i think this diagram summarizes how the two technologies interoperate with on another nicely similarly to mcp aa is designed to standardize communication between ai resource however aa is specifically designed for allowing agents to communicate with one another it does this with two fundamental concepts agent cards a structure description of what an agent does and where it can be found tasks requests can be sent to an agent allowing it to execute on tasks via back and forth communication aa is peertopeer asynchronous and is natively designed to support online communication in python aa is built on top of asgi asynchronous server gateway interface which is the same technology that powers fastapi and django heres an example of a simple aa server from aaserveragentexecution import agentexecutor requestcontext from aaserverapps import aastarletteapplication from aaserverrequesthandlers import defaultrequesthandler from aaservertasks import inmemorytaskstore from aaserverevents import eventqueue from aautils import newagenttextmessage from aatypes import agentcard agentskill agentcapabilities import uvicorn class helloexecutoragentexecutor async def executeself context requestcontext eventqueue eventqueue none respond with a static hello message eventqueueenqueueeventnewagenttextmessagehello from aa async def cancelself context requestcontext eventqueue eventqueue none pass noop def createapp skill agentskill idhello namehello descriptionsay hello to the world tagshello greet exampleshello hi agentcard agentcard namehelloworldagent descriptiona simple aa agent that says hello version url skillsskill capabilitiesagentcapabilities authenticationschemespublic defaultinputmodestext defaultoutputmodestext handler defaultrequesthandler agentexecutorhelloexecutor taskstoreinmemorytaskstore app aastarletteapplicationagentcardagentcard return appbuild if name main uvicornruncreateapp host port thus aa has important distinctions from mcp aa is designed to support discoverability with agent cards mcp is designed to be explicitly pointed to aa is designed for asynchronous communication allowing for complex implementations of multiagent workloads working in parallel aa is designed to be peertopeer rather than having the rigid hierarchy of mcp clients and servers a point of friction i think the high level conceptualization around mcp and aa is pretty solid mcp is for tools aa is for interagent communication despite the high level clarity i find these clean distinctions have a tendency to break down practically in terms of implementation i was working on an example of an application which leveraged both mcp and aa i poked around the internet and found from the official aa github account in these examples they actually use mcp to expose aa as a set of tools so instead of the two protocols existing independently communication over aa happens within mcp servers this violates the conventional wisdom i see online of aa and mcp essentially operating as completely separate and isolated protocols i think the key benefit of this approach is ease of implementation you dont have to expose both aa and mcp as two seperate sets of tools to the llm instead you can expose only a single mcp server to an llm that mcp server containing tools for aa communication this makes it much easier to manage the integration of aa and mcp into a single agent many llm providers have plenty of demos of mcp tool use so using mcp as a vehicle to serve up aa is compelling you can also use the two protocols in isolation i imagine there are a ton of ways mcp and aa enabled projects can practically be implemented which leads to closing thoughts on the subject my thoughts on mcp and aa it doesnt matter how standardized mcp and aa are if we cant all agree on the larger structure they exist in theres no interoperability in the future i expect frameworks to be built on top of both mcp and aa to establish and enforce best practices once the industry converges on these new frameworks i think issues of should this be behind mcp or aa and how should i integrate mcp and aa into this agent will start to go away this is a standard part of the lifecycle of software development and weve seen the same thing happen with countless protocols in the past standardizing prompting though is a different beast entirely having managed the development of llm powered applications for a while now ive found prompt engineering to have an interesting role in the greater product development lifecycle nontechnical stakeholders have a tendency to flock to prompt engineering as a catch all way to solve any problem which is totally untrue developers have a tendency to disregard prompt engineering as a secondary concern which is also totally untrue the fact is prompt engineering wont magically make an llm powered application better but bad prompt engineering sure can make it worse when you hook into mcp and aa enabled systems you are essentially allowing for arbitrary injection of prompts as they are defined in these systems this may have some security concerns if your code isnt designed in a hardened manner but more palpably there are massive performance concerns simply put if your prompts arent synergistic with one another throughout an llm powered application you wont get good performance this seriously undermines the practical utility of mcp and aa enabling turnkey integration i think the problem of a framework to define when a tool should be mcp vs aa is immediately solvable in terms of prompt engineering though im curious if well need to build rigid best practices around it or if we can devise clever systems to make interoperable agents more robust to prompting inconsistencies sources mcp i coauthored i authored i authored,breakdown aa mcp agentic interoperability mcp aa emerge standard ai post want cover useful base experience practical level thought protocol move forward protocol actively evolve think s room interpretation move forward result not think single correct interpretation aa mcp thought mcp high level mcp model context protocol standard way expose tool ai agent specifically standard way communicate tool client manage execution llm logical loop s single god almighty way feed tool llm mcp define standard tool define process streamline idea mcp derivative lsp language server protocol emerge practical need program language code editor developer work like vs code instance not want implement hook rust python java etc new programming language not want integrate vscode sublime jetbrain etc problem connect programming language text editor syntax highlighting autocomplete abstract generalized problem solve lsp idea make new language create lsp server language work text editor build new text editor support lsp automatically support modern programming language mcp similar agent tool idea represent tool use standardized way developer tool mcp server developer work agentic system use tool standardized interface think important note mcp present standardized interface tool leeway term developer choose build tool resource mcp server leeway mcp client developer choose use tool resource mcp transport define transport mean communication client server mcp communicate internet local channel allow mcp client control local tool like application web browser estimation mcp design theory connect mcp server host internet mcp chiefly design allow client execute locally define server here example simple mcp server simple mcp server expose single simple tool practical application mcp script like launch client client talk server execute tool need source mcp iaee mcpserverfastmcp import fastmcp mcp fastmcpserver umcptool def sayhelloname str str construct greeting return fhello server normal workflow mcp client spawn mcp server base script like work server execute tool need aa mcp design expose tool ai agent aa design allow ai agent talk think diagram summarize technology interoperate nicely similarly mcp aa design standardize communication ai resource aa specifically design allow agent communicate fundamental concept agent card structure description agent find task request send agent allow execute task forth communication aa peertopeer asynchronous natively design support online communication python aa build asgi asynchronous server gateway interface technology power fastapi django here example simple aa server aaserveragentexecution import agentexecutor requestcontext aaserverapp import aastarletteapplication aaserverrequesthandler import defaultrequesthandler aaservertask import inmemorytaskstore aaserverevent import eventqueue aautil import newagenttextmessage aatype import agentcard agentskill agentcapabilitie import uvicorn class helloexecutoragentexecutor async def executeself context requestcontext eventqueue eventqueue respond static hello message eventqueueenqueueeventnewagenttextmessagehello aa async def cancelself context requestcontext eventqueue eventqueue pass noop def createapp skill agentskill idhello namehello descriptionsay hello world tagshello greet exampleshello hi agentcard agentcard namehelloworldagent descriptiona simple aa agent say hello version url skillsskill capabilitiesagentcapabilitie authenticationschemespublic defaultinputmodestext defaultoutputmodestext handler defaultrequesthandler agentexecutorhelloexecutor taskstoreinmemorytaskstore app aastarletteapplicationagentcardagentcard return appbuild main uvicornruncreateapp host port aa important distinction mcp aa design support discoverability agent card mcp design explicitly point aa design asynchronous communication allow complex implementation multiagent workload work parallel aa design peertopeer have rigid hierarchy mcp client server point friction think high level conceptualization mcp aa pretty solid mcp tool aa interagent communication despite high level clarity find clean distinction tendency break practically term implementation work example application leverage mcp aa poke internet find official aa github account example actually use mcp expose aa set tool instead protocol exist independently communication aa happen mcp server violate conventional wisdom online aa mcp essentially operate completely separate isolated protocol think key benefit approach ease implementation not expose aa mcp seperate set tool llm instead expose single mcp server llm mcp server contain tool aa communication make easy manage integration aa mcp single agent llm provider plenty demo mcp tool use mcp vehicle serve aa compelling use protocol isolation imagine ton way mcp aa enable project practically implement lead closing thought subject thought mcp aa not matter standardized mcp aa not agree large structure exist s interoperability future expect framework build mcp aa establish enforce good practice industry converge new framework think issue mcp aa integrate mcp aa agent start away standard lifecycle software development ve see thing happen countless protocol past standardizing prompt different beast entirely having manage development llm power application ve find prompt engineering interesting role great product development lifecycle nontechnical stakeholder tendency flock prompt engineering catch way solve problem totally untrue developer tendency disregard prompt engineering secondary concern totally untrue fact prompt engineering will not magically llm power application well bad prompt engineering sure bad hook mcp aa enable system essentially allow arbitrary injection prompt define system security concern code not design harden manner palpably massive performance concern simply prompt not synergistic llm power application will not good performance seriously undermine practical utility mcp aa enable turnkey integration think problem framework define tool mcp vs aa immediately solvable term prompt engineering m curious need build rigid good practice devise clever system interoperable agent robust prompt inconsistency source mcp coauthore author author
1lq4xgr,How much wiggle room do you give yourself on DS projects?,"When you’re starting a project, how much extra time do you give yourself for the deadline that you share with stakeholders?

I personally will multiply the time I think I can complete something in by 1.5-2. Honestly might start multiplying by 3 to make multitasking easier.

There’s just so much that can go wrong in DS related projects so I feel it’s necessary to do this. Basically just underpromise overdeliver as they say.

Interested to hear about different situations.",49,26,2025-07-02T19:27:18+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lq4xgr/how_much_wiggle_room_do_you_give_yourself_on_ds/,"How much wiggle room do you give yourself on DS projects? When you’re starting a project, how much extra time do you give yourself for the deadline that you share with stakeholders?

I personally will multiply the time I think I can complete something in by 1.5-2. Honestly might start multiplying by 3 to make multitasking easier.

There’s just so much that can go wrong in DS related projects so I feel it’s necessary to do this. Basically just underpromise overdeliver as they say.

Interested to hear about different situations.",how much wiggle room do you give yourself on ds projects when youre starting a project how much extra time do you give yourself for the deadline that you share with stakeholders i personally will multiply the time i think i can complete something in by honestly might start multiplying by to make multitasking easier theres just so much that can go wrong in ds related projects so i feel its necessary to do this basically just underpromise overdeliver as they say interested to hear about different situations,wiggle room ds project start project extra time deadline share stakeholder personally multiply time think complete honestly start multiply multitaske easy s wrong ds relate project feel necessary basically underpromise overdeliver interested hear different situation
1lq0v8p,I am currently a data scientist. How can I move to a more business oriented rule?,"Hey folks! I have worked as a DS for about 5 years now. I wanted to move to a position that I still work with data, but I am  looking for something less technical and more business related. I will list some of my strengths that are also things I like to work with:

- Build proof of concepts projects and explore techniques in the literature to solve business problems with data science approaches;
- Do presentation for technical and non technical peers;
- Build documentation and produce online content;
- I also love to create training and manage projects related to data culture, education, and onboarding.
- Work in groups /having group discussions with multidisciplinary teams. 

Do you know names for positions that are more focused on that? I'd like to search for them! ",47,36,2025-07-02T16:47:58+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lq0v8p/i_am_currently_a_data_scientist_how_can_i_move_to/,"I am currently a data scientist. How can I move to a more business oriented rule? Hey folks! I have worked as a DS for about 5 years now. I wanted to move to a position that I still work with data, but I am  looking for something less technical and more business related. I will list some of my strengths that are also things I like to work with:

- Build proof of concepts projects and explore techniques in the literature to solve business problems with data science approaches;
- Do presentation for technical and non technical peers;
- Build documentation and produce online content;
- I also love to create training and manage projects related to data culture, education, and onboarding.
- Work in groups /having group discussions with multidisciplinary teams. 

Do you know names for positions that are more focused on that? I'd like to search for them! ",i am currently a data scientist how can i move to a more business oriented rule hey folks i have worked as a ds for about years now i wanted to move to a position that i still work with data but i am looking for something less technical and more business related i will list some of my strengths that are also things i like to work with build proof of concepts projects and explore techniques in the literature to solve business problems with data science approaches do presentation for technical and non technical peers build documentation and produce online content i also love to create training and manage projects related to data culture education and onboarding work in groups having group discussions with multidisciplinary teams do you know names for positions that are more focused on that id like to search for them,currently data scientist business orient rule hey folk work ds year want position work datum look technical business relate list strength thing like work build proof concept project explore technique literature solve business problem data science approach presentation technical non technical peer build documentation produce online content love create training manage project relate datum culture education onboarding work group have group discussion multidisciplinary team know name position focused d like search
1lpucaf,Need advise on cross-functional collaboration,"Hi data science community,

I need your advice on how to handle a work situation. Curious to know how others would handle or if they have been in a similar situation.

I lead a data science team and I also have a peer who leads a BI team and we report to the same executive.

A couple months ago, BI lead reached out and was excited to see if we can collaborate and create an AI/BI chat bot for our internal structured data. I thought this was a good idea and would be a great opportunity to collaborate with him and his team. So I spent a couple of weeks to build out a POC, I show cased it to him and our executive, it was well received and I outlined next steps on how we can collaborate to make it better.

I got no response from him about my next steps email. I figured no harm no foul he got busy I’m sure. Well come to find out, he had his team build almost an exact replica of the POC I did and essentially boxed my team and I out of this idea and decided he would just do it himself internally. Mind you, all the BI people had to learn how to use LLMs and how to orchestrate agents, etc. it’s a skill set we have but he decided to do it himself despite this.

How would you all handle this?

I was planning on a 1:1 with him where I essentially lay out the facts that he wasted my time by giving me the illusion that we would work together and collaborate but instead just did things himself. We have been getting pushed by our executive team to work together more and this was a great opportunity to show them we work together but instead he decided to take a different route.",18,8,2025-07-02T12:17:58+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lpucaf/need_advise_on_crossfunctional_collaboration/,"Need advise on cross-functional collaboration Hi data science community,

I need your advice on how to handle a work situation. Curious to know how others would handle or if they have been in a similar situation.

I lead a data science team and I also have a peer who leads a BI team and we report to the same executive.

A couple months ago, BI lead reached out and was excited to see if we can collaborate and create an AI/BI chat bot for our internal structured data. I thought this was a good idea and would be a great opportunity to collaborate with him and his team. So I spent a couple of weeks to build out a POC, I show cased it to him and our executive, it was well received and I outlined next steps on how we can collaborate to make it better.

I got no response from him about my next steps email. I figured no harm no foul he got busy I’m sure. Well come to find out, he had his team build almost an exact replica of the POC I did and essentially boxed my team and I out of this idea and decided he would just do it himself internally. Mind you, all the BI people had to learn how to use LLMs and how to orchestrate agents, etc. it’s a skill set we have but he decided to do it himself despite this.

How would you all handle this?

I was planning on a 1:1 with him where I essentially lay out the facts that he wasted my time by giving me the illusion that we would work together and collaborate but instead just did things himself. We have been getting pushed by our executive team to work together more and this was a great opportunity to show them we work together but instead he decided to take a different route.",need advise on crossfunctional collaboration hi data science community i need your advice on how to handle a work situation curious to know how others would handle or if they have been in a similar situation i lead a data science team and i also have a peer who leads a bi team and we report to the same executive a couple months ago bi lead reached out and was excited to see if we can collaborate and create an aibi chat bot for our internal structured data i thought this was a good idea and would be a great opportunity to collaborate with him and his team so i spent a couple of weeks to build out a poc i show cased it to him and our executive it was well received and i outlined next steps on how we can collaborate to make it better i got no response from him about my next steps email i figured no harm no foul he got busy im sure well come to find out he had his team build almost an exact replica of the poc i did and essentially boxed my team and i out of this idea and decided he would just do it himself internally mind you all the bi people had to learn how to use llms and how to orchestrate agents etc its a skill set we have but he decided to do it himself despite this how would you all handle this i was planning on a with him where i essentially lay out the facts that he wasted my time by giving me the illusion that we would work together and collaborate but instead just did things himself we have been getting pushed by our executive team to work together more and this was a great opportunity to show them we work together but instead he decided to take a different route,need advise crossfunctional collaboration hi data science community need advice handle work situation curious know handle similar situation lead data science team peer lead bi team report executive couple month ago bi lead reach excited collaborate create aibi chat bot internal structured datum think good idea great opportunity collaborate team spend couple week build poc case executive receive outline step collaborate well get response step email figure harm foul get busy m sure come find team build exact replica poc essentially box team idea decide internally mind bi people learn use llm orchestrate agent etc skill set decide despite handle plan essentially lie fact waste time give illusion work collaborate instead thing getting push executive team work great opportunity work instead decide different route
1lpnkj0,"Beta release: Minds AI Filter for EEG — Physics-informed preprocessing for real-time BCI (+17% gain on noisy data from commercial headsets, 0.2s latency)","We at MindsApplied specialize in the development of machine learning models for the enhancement of EEG signal quality and emotional state classification. We're excited to share our latest model—the Minds AI Filter—and would love your feedback.

* [👉 Download the Python package here](https://drive.google.com/drive/folders/1_4Q9voe5j88G_EMF8YanoeEPVoUt_D2B?usp=drive_link)
* 🔑Use key: ''REDDIT-KEY-VRG44S' to initialize
* 📄 Includes setup instructions

The Minds AI Filter is a physics-informed, real-time EEG preprocessing tool that relies on sensor fusion for low-latency noise and artifact removal. It's built to improve signal quality before feature extraction or classification, especially for online systems. To dive (very briefly) into the details, it works in part by **reducing high-frequency noise (\~40 Hz) and sharpening low-frequency activity (\~3–7 Hz)**.

We tested it alongside standard bandpass filtering, using both:

* Commercial EEG hardware (OpenBCI Mark IV, BrainBit Dragon)
* The public DEAP dataset, a 32-participant benchmark for emotional state classification

Here are our experimental results:

* Commercial Devices (OpenBCI Mark IV, BrainBit Dragon)
   * \+15% average improvement in balanced accuracy using only 12 trials of 60 seconds per subject per device
   * Improvement attributed to higher baseline noise in these systems
* DEAP Dataset
   * \+6% average improvement across 32 subjects and 32 channels
   * Maximum individual gain: +35%
   * Average gain in classification accuracy was 17% for cases where the filter led to improvement.
   * No decline in accuracy for any participant
* Performance
   * \~0.2 seconds to filter 60 seconds of data

Note: Comparisons were made between bandpass-only and bandpass + Minds AI Filter. Filtering occurred before bandpass.

Methodology:

To generate these experimental results, we used 2-fold stratified cross-validation grid search to tune the filter's key hyperparameter (λ). Classification relied on balanced on balanced accuracy using logistic regression on features derived from wavelet coefficients.

Why we're posting: This filter is still in beta and we'd love feedback —especially if you try it on your own datasets or devices. The current goal is to support rapid, adaptive, and physics-informed filtering for real-time systems and multi-sensor neurotech platforms.

If you find it useful or want future updates (e.g., universal DLL, long-term/offline licenses), you can subscribe here:

* 🔗 [https://www.minds-applied.com/contact](https://www.minds-applied.com/contact)

https://preview.redd.it/o3xqckeiaeaf1.png?width=594&format=png&auto=webp&s=0fb1860d8af85fa516cb705c096427a32977a522

https://preview.redd.it/95lbzd8jaeaf1.png?width=589&format=png&auto=webp&s=39984d0e8f75f27ab0a71e7e5ca09bba25f6ffb4

https://preview.redd.it/x9iyc4kjaeaf1.png?width=1372&format=png&auto=webp&s=ef70703c892727318688b7472778cb5658a899ee

",1,0,2025-07-02T05:16:35+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lpnkj0/beta_release_minds_ai_filter_for_eeg/,"Beta release: Minds AI Filter for EEG — Physics-informed preprocessing for real-time BCI (+17% gain on noisy data from commercial headsets, 0.2s latency) We at MindsApplied specialize in the development of machine learning models for the enhancement of EEG signal quality and emotional state classification. We're excited to share our latest model—the Minds AI Filter—and would love your feedback.

* [👉 Download the Python package here](https://drive.google.com/drive/folders/1_4Q9voe5j88G_EMF8YanoeEPVoUt_D2B?usp=drive_link)
* 🔑Use key: ''REDDIT-KEY-VRG44S' to initialize
* 📄 Includes setup instructions

The Minds AI Filter is a physics-informed, real-time EEG preprocessing tool that relies on sensor fusion for low-latency noise and artifact removal. It's built to improve signal quality before feature extraction or classification, especially for online systems. To dive (very briefly) into the details, it works in part by **reducing high-frequency noise (\~40 Hz) and sharpening low-frequency activity (\~3–7 Hz)**.

We tested it alongside standard bandpass filtering, using both:

* Commercial EEG hardware (OpenBCI Mark IV, BrainBit Dragon)
* The public DEAP dataset, a 32-participant benchmark for emotional state classification

Here are our experimental results:

* Commercial Devices (OpenBCI Mark IV, BrainBit Dragon)
   * \+15% average improvement in balanced accuracy using only 12 trials of 60 seconds per subject per device
   * Improvement attributed to higher baseline noise in these systems
* DEAP Dataset
   * \+6% average improvement across 32 subjects and 32 channels
   * Maximum individual gain: +35%
   * Average gain in classification accuracy was 17% for cases where the filter led to improvement.
   * No decline in accuracy for any participant
* Performance
   * \~0.2 seconds to filter 60 seconds of data

Note: Comparisons were made between bandpass-only and bandpass + Minds AI Filter. Filtering occurred before bandpass.

Methodology:

To generate these experimental results, we used 2-fold stratified cross-validation grid search to tune the filter's key hyperparameter (λ). Classification relied on balanced on balanced accuracy using logistic regression on features derived from wavelet coefficients.

Why we're posting: This filter is still in beta and we'd love feedback —especially if you try it on your own datasets or devices. The current goal is to support rapid, adaptive, and physics-informed filtering for real-time systems and multi-sensor neurotech platforms.

If you find it useful or want future updates (e.g., universal DLL, long-term/offline licenses), you can subscribe here:

* 🔗 [https://www.minds-applied.com/contact](https://www.minds-applied.com/contact)

https://preview.redd.it/o3xqckeiaeaf1.png?width=594&format=png&auto=webp&s=0fb1860d8af85fa516cb705c096427a32977a522

https://preview.redd.it/95lbzd8jaeaf1.png?width=589&format=png&auto=webp&s=39984d0e8f75f27ab0a71e7e5ca09bba25f6ffb4

https://preview.redd.it/x9iyc4kjaeaf1.png?width=1372&format=png&auto=webp&s=ef70703c892727318688b7472778cb5658a899ee

",beta release minds ai filter for eeg physicsinformed preprocessing for realtime bci gain on noisy data from commercial headsets s latency we at mindsapplied specialize in the development of machine learning models for the enhancement of eeg signal quality and emotional state classification were excited to share our latest modelthe minds ai filterand would love your feedback keyuse key redditkeyvrgs to initialize pagefacingup includes setup instructions the minds ai filter is a physicsinformed realtime eeg preprocessing tool that relies on sensor fusion for lowlatency noise and artifact removal its built to improve signal quality before feature extraction or classification especially for online systems to dive very briefly into the details it works in part by reducing highfrequency noise hz and sharpening lowfrequency activity hz we tested it alongside standard bandpass filtering using both commercial eeg hardware openbci mark iv brainbit dragon the public deap dataset a participant benchmark for emotional state classification here are our experimental results commercial devices openbci mark iv brainbit dragon average improvement in balanced accuracy using only trials of seconds per subject per device improvement attributed to higher baseline noise in these systems deap dataset average improvement across subjects and channels maximum individual gain average gain in classification accuracy was for cases where the filter led to improvement no decline in accuracy for any participant performance seconds to filter seconds of data note comparisons were made between bandpassonly and bandpass minds ai filter filtering occurred before bandpass methodology to generate these experimental results we used fold stratified crossvalidation grid search to tune the filters key hyperparameter classification relied on balanced on balanced accuracy using logistic regression on features derived from wavelet coefficients why were posting this filter is still in beta and wed love feedback especially if you try it on your own datasets or devices the current goal is to support rapid adaptive and physicsinformed filtering for realtime systems and multisensor neurotech platforms if you find it useful or want future updates eg universal dll longtermoffline licenses you can subscribe here link,beta release mind ai filter eeg physicsinformed preprocessing realtime bci gain noisy datum commercial headset s latency mindsapplie specialize development machine learning model enhancement eeg signal quality emotional state classification excited share late modelthe mind ai filterand love feedback keyuse key redditkeyvrg initialize pagefacingup include setup instruction mind ai filter physicsinformed realtime eeg preprocessing tool rely sensor fusion lowlatency noise artifact removal build improve signal quality feature extraction classification especially online system dive briefly detail work reduce highfrequency noise hz sharpen lowfrequency activity hz test alongside standard bandpass filtering commercial eeg hardware openbci mark iv brainbit dragon public deap dataset participant benchmark emotional state classification experimental result commercial device openbci mark iv brainbit dragon average improvement balanced accuracy trial second subject device improvement attribute high baseline noise system deap dataset average improvement subject channel maximum individual gain average gain classification accuracy case filter lead improvement decline accuracy participant performance second filter second datum note comparison bandpassonly bandpass mind ai filter filtering occur bandpass methodology generate experimental result fold stratified crossvalidation grid search tune filter key hyperparameter classification rely balanced balanced accuracy logistic regression feature derive wavelet coefficient post filter beta d love feedback especially try dataset device current goal support rapid adaptive physicsinforme filter realtime system multisensor neurotech platform find useful want future update eg universal dll longtermoffline license subscribe link
1loo3eh,Does DB normalization worth it?,"Hi, I have 6 months as a Jr Data Analyst and I have been working with Power BI since I begin. At the beginning I watched a lot of dashboards on PBI and when I checked the Data Model was disgusting, it doesn't seems as something well designed. 

On my the few opportunities that I have developed some dashboards I have seen a lot of redundancies on them, but I keep quiet due it's my first analytic role and my role using PBI so I couldn't compare with anything else.

I ask here because I don't know many people who use PBI or has experience on Data related jobs and I've been dealing with query limit reaching (more than 10M rows to process).

So I watched some courses that normalization could solve many issues, but I wanted to know:
1 - If it could really help to solve that issue.
2 - How could I normalize the data when, not the data, the data Model is so messy? 

Thanks in advance.",25,32,2025-07-01T00:36:08+00:00,datascience,https://www.reddit.com/r/datascience/comments/1loo3eh/does_db_normalization_worth_it/,"Does DB normalization worth it? Hi, I have 6 months as a Jr Data Analyst and I have been working with Power BI since I begin. At the beginning I watched a lot of dashboards on PBI and when I checked the Data Model was disgusting, it doesn't seems as something well designed. 

On my the few opportunities that I have developed some dashboards I have seen a lot of redundancies on them, but I keep quiet due it's my first analytic role and my role using PBI so I couldn't compare with anything else.

I ask here because I don't know many people who use PBI or has experience on Data related jobs and I've been dealing with query limit reaching (more than 10M rows to process).

So I watched some courses that normalization could solve many issues, but I wanted to know:
1 - If it could really help to solve that issue.
2 - How could I normalize the data when, not the data, the data Model is so messy? 

Thanks in advance.",does db normalization worth it hi i have months as a jr data analyst and i have been working with power bi since i begin at the beginning i watched a lot of dashboards on pbi and when i checked the data model was disgusting it doesnt seems as something well designed on my the few opportunities that i have developed some dashboards i have seen a lot of redundancies on them but i keep quiet due its my first analytic role and my role using pbi so i couldnt compare with anything else i ask here because i dont know many people who use pbi or has experience on data related jobs and ive been dealing with query limit reaching more than m rows to process so i watched some courses that normalization could solve many issues but i wanted to know if it could really help to solve that issue how could i normalize the data when not the data the data model is so messy thanks in advance,db normalization worth hi month jr data analyst work power bi begin beginning watch lot dashboard pbi check data model disgusting not design opportunity develop dashboard see lot redundancy quiet analytic role role pbi not compare ask not know people use pbi experience datum relate job ve deal query limit reach m row process watch course normalization solve issue want know help solve issue normalize datum datum data model messy thank advance
1lohjp4,No reason to complicate things.,"There's absolutely validity in doing more complex visuals.  But, sometimes simple is better if the audience is more likely to use it/understand it.",1206,75,2025-06-30T19:59:00+00:00,datascience,https://i.redd.it/fygwmz26e4af1.png,"No reason to complicate things. There's absolutely validity in doing more complex visuals.  But, sometimes simple is better if the audience is more likely to use it/understand it.",no reason to complicate things theres absolutely validity in doing more complex visuals but sometimes simple is better if the audience is more likely to use itunderstand it,reason complicate thing s absolutely validity complex visual simple well audience likely use itunderstand
1lo4xao,Model Context Protocol (MCP) tutorials playlist for beginners,"This playlist comprises of numerous tutorials on MCP servers including

1. Install Blender-MCP for Claude AI on Windows
2. Design a Room with Blender-MCP + Claude
3. Connect SQL to Claude AI via MCP
4. Run MCP Servers with Cursor AI
5. Local LLMs with Ollama MCP Server
6. Build Custom MCP Servers (Free)
7. Control Docker via MCP
8. Control WhatsApp with MCP
9. GitHub Automation via MCP
10. Control Chrome using MCP
11. Figma with AI using MCP
12. AI for PowerPoint via MCP
13. Notion Automation with MCP
14. File System Control via MCP
15. AI in Jupyter using MCP
16. Browser Automation with Playwright MCP
17. Excel Automation via MCP
18. Discord + MCP Integration
19. Google Calendar MCP
20. Gmail Automation with MCP
21. Intro to MCP Servers for Beginners
22. Slack + AI via MCP
23. Use Any LLM API with MCP
24. Is Model Context Protocol Dangerous?
25. LangChain with MCP Servers
26. Best Starter MCP Servers
27. YouTube Automation via MCP
28. Zapier + AI using MCP
29. MCP with Gemini 2.5 Pro
30. PyCharm IDE + MCP
31. ElevenLabs Audio with Claude AI via MCP
32. LinkedIn Auto-Posting via MCP
33. Twitter Auto-Posting with MCP
34. Facebook Automation using MCP
35. Top MCP Servers for Data Science
36. Best MCPs for Productivity
37. Social Media MCPs for Content Creation
38. MCP Course for Beginners
39. Create n8n Workflows with MCP
40. RAG MCP Server Guide
41. Multi-File RAG via MCP
42. Use MCP with ChatGPT
43. ChatGPT + PowerPoint (Free, Unlimited)
44. ChatGPT RAG MCP
45. ChatGPT + Excel via MCP
46. Use MCP with Grok AI
47. Vibe Coding in Blender with MCP
48. Perplexity AI + MCP Integration
49. ChatGPT + Figma Integration
50. ChatGPT + Blender MCP
51. ChatGPT + Gmail via MCP
52. ChatGPT + Google Calendar MCP
53. MCP vs Traditional AI Agents

Hope this is useful !!

Playlist : [https://www.youtube.com/playlist?list=PLnH2pfPCPZsJ5aJaHdTW7to2tZkYtzIwp](https://www.youtube.com/playlist?list=PLnH2pfPCPZsJ5aJaHdTW7to2tZkYtzIwp)",25,1,2025-06-30T11:19:26+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lo4xao/model_context_protocol_mcp_tutorials_playlist_for/,"Model Context Protocol (MCP) tutorials playlist for beginners This playlist comprises of numerous tutorials on MCP servers including

1. Install Blender-MCP for Claude AI on Windows
2. Design a Room with Blender-MCP + Claude
3. Connect SQL to Claude AI via MCP
4. Run MCP Servers with Cursor AI
5. Local LLMs with Ollama MCP Server
6. Build Custom MCP Servers (Free)
7. Control Docker via MCP
8. Control WhatsApp with MCP
9. GitHub Automation via MCP
10. Control Chrome using MCP
11. Figma with AI using MCP
12. AI for PowerPoint via MCP
13. Notion Automation with MCP
14. File System Control via MCP
15. AI in Jupyter using MCP
16. Browser Automation with Playwright MCP
17. Excel Automation via MCP
18. Discord + MCP Integration
19. Google Calendar MCP
20. Gmail Automation with MCP
21. Intro to MCP Servers for Beginners
22. Slack + AI via MCP
23. Use Any LLM API with MCP
24. Is Model Context Protocol Dangerous?
25. LangChain with MCP Servers
26. Best Starter MCP Servers
27. YouTube Automation via MCP
28. Zapier + AI using MCP
29. MCP with Gemini 2.5 Pro
30. PyCharm IDE + MCP
31. ElevenLabs Audio with Claude AI via MCP
32. LinkedIn Auto-Posting via MCP
33. Twitter Auto-Posting with MCP
34. Facebook Automation using MCP
35. Top MCP Servers for Data Science
36. Best MCPs for Productivity
37. Social Media MCPs for Content Creation
38. MCP Course for Beginners
39. Create n8n Workflows with MCP
40. RAG MCP Server Guide
41. Multi-File RAG via MCP
42. Use MCP with ChatGPT
43. ChatGPT + PowerPoint (Free, Unlimited)
44. ChatGPT RAG MCP
45. ChatGPT + Excel via MCP
46. Use MCP with Grok AI
47. Vibe Coding in Blender with MCP
48. Perplexity AI + MCP Integration
49. ChatGPT + Figma Integration
50. ChatGPT + Blender MCP
51. ChatGPT + Gmail via MCP
52. ChatGPT + Google Calendar MCP
53. MCP vs Traditional AI Agents

Hope this is useful !!

Playlist : [https://www.youtube.com/playlist?list=PLnH2pfPCPZsJ5aJaHdTW7to2tZkYtzIwp](https://www.youtube.com/playlist?list=PLnH2pfPCPZsJ5aJaHdTW7to2tZkYtzIwp)",model context protocol mcp tutorials playlist for beginners this playlist comprises of numerous tutorials on mcp servers including install blendermcp for claude ai on windows design a room with blendermcp claude connect sql to claude ai via mcp run mcp servers with cursor ai local llms with ollama mcp server build custom mcp servers free control docker via mcp control whatsapp with mcp github automation via mcp control chrome using mcp figma with ai using mcp ai for powerpoint via mcp notion automation with mcp file system control via mcp ai in jupyter using mcp browser automation with playwright mcp excel automation via mcp discord mcp integration google calendar mcp gmail automation with mcp intro to mcp servers for beginners slack ai via mcp use any llm api with mcp is model context protocol dangerous langchain with mcp servers best starter mcp servers youtube automation via mcp zapier ai using mcp mcp with gemini pro pycharm ide mcp elevenlabs audio with claude ai via mcp linkedin autoposting via mcp twitter autoposting with mcp facebook automation using mcp top mcp servers for data science best mcps for productivity social media mcps for content creation mcp course for beginners create nn workflows with mcp rag mcp server guide multifile rag via mcp use mcp with chatgpt chatgpt powerpoint free unlimited chatgpt rag mcp chatgpt excel via mcp use mcp with grok ai vibe coding in blender with mcp perplexity ai mcp integration chatgpt figma integration chatgpt blender mcp chatgpt gmail via mcp chatgpt google calendar mcp mcp vs traditional ai agents hope this is useful playlist,model context protocol mcp tutorial playlist beginner playlist comprise numerous tutorial mcp server include install blendermcp claude ai windows design room blendermcp claude connect sql claude ai mcp run mcp server cursor ai local llm ollama mcp server build custom mcp server free control docker mcp control whatsapp mcp github automation mcp control chrome mcp figma ai mcp ai powerpoint mcp notion automation mcp file system control mcp ai jupyter mcp browser automation playwright mcp excel automation mcp discord mcp integration google calendar mcp gmail automation mcp intro mcp server beginner slack ai mcp use llm api mcp model context protocol dangerous langchain mcp server well starter mcp server youtube automation mcp zapier ai mcp mcp gemini pro pycharm ide mcp elevenlabs audio claude ai mcp linkedin autoposte mcp twitter autoposte mcp facebook automation mcp mcp server datum science good mcp productivity social medium mcp content creation mcp course beginner create nn workflow mcp rag mcp server guide multifile rag mcp use mcp chatgpt chatgpt powerpoint free unlimited chatgpt rag mcp chatgpt excel mcp use mcp grok ai vibe code blender mcp perplexity ai mcp integration chatgpt figma integration chatgpt blender mcp chatgpt gmail mcp chatgpt google calendar mcp mcp vs traditional ai agent hope useful playlist
1lny1dk,"Weekly Entering & Transitioning - Thread 30 Jun, 2025 - 07 Jul, 2025"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",10,63,2025-06-30T04:01:14+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lny1dk/weekly_entering_transitioning_thread_30_jun_2025/,"Weekly Entering & Transitioning - Thread 30 Jun, 2025 - 07 Jul, 2025  

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",weekly entering transitioning thread jun jul welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the and resources pages on our wiki you can also search for answers in,weekly enter transition thread jun jul welcome week enter transition thread thread question getting start study transition data science field topic include learn resource eg book tutorial video traditional education eg schools degree elective alternative education eg online course bootcamp job search question eg resume apply career prospect elementary question eg start wait answer community check resource page wiki search answer
1lntegl,ICs who pivoted: did you go engineering or management?,"Hitting that point where I feel like I need to pick a lane.

Curious what others did. Did you double down on technical stuff (data engineering/MLE/SWE), switched to the product side, or did you move into people management?",58,39,2025-06-29T23:57:36+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lntegl/ics_who_pivoted_did_you_go_engineering_or/,"ICs who pivoted: did you go engineering or management? Hitting that point where I feel like I need to pick a lane.

Curious what others did. Did you double down on technical stuff (data engineering/MLE/SWE), switched to the product side, or did you move into people management?",ics who pivoted did you go engineering or management hitting that point where i feel like i need to pick a lane curious what others did did you double down on technical stuff data engineeringmleswe switched to the product side or did you move into people management,ics pivot engineering management hit point feel like need pick lane curious double technical stuff datum engineeringmleswe switch product people management
1lnct9i,Using Claude Code in notebook,"At work I use jupyter notebooks for experimentation and prototyping of data products. So far, I’ve been leveraging AI code completion type of functionality within a Python cell for finishing a line of code, writing the next few lines or writing a function altogether. 

But I’m curious about the next level: using something like Claude Code open side-by side with my notebook. 

Just wondering if anyone is currently using this type of workflow and if you have any tips & tricks or specific use cases you could share. ",0,9,2025-06-29T11:50:32+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lnct9i/using_claude_code_in_notebook/,"Using Claude Code in notebook At work I use jupyter notebooks for experimentation and prototyping of data products. So far, I’ve been leveraging AI code completion type of functionality within a Python cell for finishing a line of code, writing the next few lines or writing a function altogether. 

But I’m curious about the next level: using something like Claude Code open side-by side with my notebook. 

Just wondering if anyone is currently using this type of workflow and if you have any tips & tricks or specific use cases you could share. ",using claude code in notebook at work i use jupyter notebooks for experimentation and prototyping of data products so far ive been leveraging ai code completion type of functionality within a python cell for finishing a line of code writing the next few lines or writing a function altogether but im curious about the next level using something like claude code open sideby side with my notebook just wondering if anyone is currently using this type of workflow and if you have any tips tricks or specific use cases you could share,claude code notebook work use jupyt notebook experimentation prototyping datum product far ve leverage ai code completion type functionality python cell finish line code write line write function altogether m curious level like claude code open sideby notebook wonder currently type workflow tip trick specific use case share
1lnbgna,Not sure what certifications to attain to increase my chances of getting an internship after third year,"Context: I am planning to go into data science as a career. Im currently about to go into my third year and I need to secure an internship agter my third year during my coop year. To increade my chances, I want to obtain AWS certifications. The problem I am seeing is that the AWS SAA certificate seems to specific to AWS. Would the MLEA or DEA increade my chance of getting data scientist/mle internships significantly? Assume I have knowledge and projects to showcase knowledge of theoretical ML, python, sql, etc. Also assume I have cloud practitioner and AI practitioner certs but no experience with AWS whatsoever, but experience in data analysis. I would really appreciate in depth responses. Please avoid stupid comments like ""certifications are useless"" because they obv arent and can set you apart from someone with similar skill sets in other areas. ",0,8,2025-06-29T10:28:01+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lnbgna/not_sure_what_certifications_to_attain_to/,"Not sure what certifications to attain to increase my chances of getting an internship after third year Context: I am planning to go into data science as a career. Im currently about to go into my third year and I need to secure an internship agter my third year during my coop year. To increade my chances, I want to obtain AWS certifications. The problem I am seeing is that the AWS SAA certificate seems to specific to AWS. Would the MLEA or DEA increade my chance of getting data scientist/mle internships significantly? Assume I have knowledge and projects to showcase knowledge of theoretical ML, python, sql, etc. Also assume I have cloud practitioner and AI practitioner certs but no experience with AWS whatsoever, but experience in data analysis. I would really appreciate in depth responses. Please avoid stupid comments like ""certifications are useless"" because they obv arent and can set you apart from someone with similar skill sets in other areas. ",not sure what certifications to attain to increase my chances of getting an internship after third year context i am planning to go into data science as a career im currently about to go into my third year and i need to secure an internship agter my third year during my coop year to increade my chances i want to obtain aws certifications the problem i am seeing is that the aws saa certificate seems to specific to aws would the mlea or dea increade my chance of getting data scientistmle internships significantly assume i have knowledge and projects to showcase knowledge of theoretical ml python sql etc also assume i have cloud practitioner and ai practitioner certs but no experience with aws whatsoever but experience in data analysis i would really appreciate in depth responses please avoid stupid comments like certifications are useless because they obv arent and can set you apart from someone with similar skill sets in other areas,sure certification attain increase chance get internship year context plan data science career m currently year need secure internship agter year coop year increade chance want obtain aws certification problem see aw saa certificate specific aw mlea dea increade chance get datum scientistmle internship significantly assume knowledge project showcase knowledge theoretical ml python sql etc assume cloud practitioner ai practitioner cert experience aw whatsoever experience data analysis appreciate depth response avoid stupid comment like certification useless obv not set apart similar skill set area
1ln9cf0,Advice on feature selection process,"**Hi everyone,**

I have a question regarding the feature selection process for a credit risk model I'm building as part of my internship. I've collected raw data and conducted feature engineering with the help of a domain expert in credit risk. Now I have a list of around 2000 features.

For the feature selection part, based on what I've learned, the typical approach is to use a tree-based model (like Random Forest or XGBoost) to rank feature importance, and then shortlist it down to about 15–20 features. After that, I would use those selected features to train my final model (CatBoost in this case), perform hyperparameter tuning, and then use that model for inference.

Am I doing it correctly? It feels a bit too straightforward — like once I have the 2000 features, I just plug them into a tree model, get the top features, and that's it. I noticed that some of my colleagues do multiple rounds of feature selection — for example, narrowing it down from 2000 to 200, then to 80, and finally to 20 — using multiple tree models and iterations.

Also, where do SHAP values fit into this process? I usually use SHAP to visualize feature effects in the final model for interpretability, but I'm wondering if it can or should be used during the feature selection stage as well.

I’d really appreciate your advice!",29,19,2025-06-29T08:05:12+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ln9cf0/advice_on_feature_selection_process/,"Advice on feature selection process **Hi everyone,**

I have a question regarding the feature selection process for a credit risk model I'm building as part of my internship. I've collected raw data and conducted feature engineering with the help of a domain expert in credit risk. Now I have a list of around 2000 features.

For the feature selection part, based on what I've learned, the typical approach is to use a tree-based model (like Random Forest or XGBoost) to rank feature importance, and then shortlist it down to about 15–20 features. After that, I would use those selected features to train my final model (CatBoost in this case), perform hyperparameter tuning, and then use that model for inference.

Am I doing it correctly? It feels a bit too straightforward — like once I have the 2000 features, I just plug them into a tree model, get the top features, and that's it. I noticed that some of my colleagues do multiple rounds of feature selection — for example, narrowing it down from 2000 to 200, then to 80, and finally to 20 — using multiple tree models and iterations.

Also, where do SHAP values fit into this process? I usually use SHAP to visualize feature effects in the final model for interpretability, but I'm wondering if it can or should be used during the feature selection stage as well.

I’d really appreciate your advice!",advice on feature selection process hi everyone i have a question regarding the feature selection process for a credit risk model im building as part of my internship ive collected raw data and conducted feature engineering with the help of a domain expert in credit risk now i have a list of around features for the feature selection part based on what ive learned the typical approach is to use a treebased model like random forest or xgboost to rank feature importance and then shortlist it down to about features after that i would use those selected features to train my final model catboost in this case perform hyperparameter tuning and then use that model for inference am i doing it correctly it feels a bit too straightforward like once i have the features i just plug them into a tree model get the top features and thats it i noticed that some of my colleagues do multiple rounds of feature selection for example narrowing it down from to then to and finally to using multiple tree models and iterations also where do shap values fit into this process i usually use shap to visualize feature effects in the final model for interpretability but im wondering if it can or should be used during the feature selection stage as well id really appreciate your advice,advice feature selection process hi question feature selection process credit risk model m build internship ve collect raw datum conduct feature engineer help domain expert credit risk list feature feature selection base ve learn typical approach use treebase model like random forest xgboost rank feature importance shortlist feature use select feature train final model catboost case perform hyperparameter tuning use model inference correctly feel bit straightforward like feature plug tree model feature s notice colleague multiple round feature selection example narrow finally multiple tree model iteration shap value fit process usually use shap visualize feature effect final model interpretability m wonder feature selection stage d appreciate advice
1ln8f2b,How do you deal with data scientists with big pay check and title but no domain knowledge?,"A tech illiterate Director at my org hired a data couple of data scientists 18 months ago. He has tasked them with nothing specific. And their job was solely to observe and find uses-cases themselves. The only reason they were hired was for the Director to gain brownie points of creating a data-driven team for themself, despite there being several other such teams.

Cut to today, the Director has realized that there is very little ROI from his hires because they lack domain knowledge. He conveniently moved them to another team where ML is an overkill. The data scientists however, have found some problems they thought they'll solve with ""data science"". They have been vibe coding and building PPTs for months now. But their attempts are hardly successful because of their lack of domain knowledge. To compensate for their lack of domain knowledge, they create beautiful presentations with lots of buzzwords such as LLMs, but again, lack domain substance.

Now, their proposals seem unnecessary and downright obnoxious to many domain SMEs. But the SMEs don't have the courage to say it to the leadership and be percevied as a roadblock to the data-driven strategy. The constant interference of these data scientists is destabilizing the existing processes for the worst and the team is incurring additional costs.

This is a very peculiar situation where the data scientists, lacking domain knowledge, are just shooting project proposals in the dark hoping to hit something. I know this doesn't typically happen in most organizations. But have you ever seen such a situation around you? How did you or others deal with the situation?

EDIT: This post is not to shit on the data scientists. They are probably good in their areas. The problem is not the domain SME support. The problem is that these data scientists seem to be too high on their titles and paychecks to collaborate with SMEs. Most SMEs want to support them and tell them nicely that ML/AI is an overkill for their usecases, and the efforts required are too big. There are other data science and analytics teams that are working seamlesly with SMEs.",0,17,2025-06-29T07:02:58+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ln8f2b/how_do_you_deal_with_data_scientists_with_big_pay/,"How do you deal with data scientists with big pay check and title but no domain knowledge? A tech illiterate Director at my org hired a data couple of data scientists 18 months ago. He has tasked them with nothing specific. And their job was solely to observe and find uses-cases themselves. The only reason they were hired was for the Director to gain brownie points of creating a data-driven team for themself, despite there being several other such teams.

Cut to today, the Director has realized that there is very little ROI from his hires because they lack domain knowledge. He conveniently moved them to another team where ML is an overkill. The data scientists however, have found some problems they thought they'll solve with ""data science"". They have been vibe coding and building PPTs for months now. But their attempts are hardly successful because of their lack of domain knowledge. To compensate for their lack of domain knowledge, they create beautiful presentations with lots of buzzwords such as LLMs, but again, lack domain substance.

Now, their proposals seem unnecessary and downright obnoxious to many domain SMEs. But the SMEs don't have the courage to say it to the leadership and be percevied as a roadblock to the data-driven strategy. The constant interference of these data scientists is destabilizing the existing processes for the worst and the team is incurring additional costs.

This is a very peculiar situation where the data scientists, lacking domain knowledge, are just shooting project proposals in the dark hoping to hit something. I know this doesn't typically happen in most organizations. But have you ever seen such a situation around you? How did you or others deal with the situation?

EDIT: This post is not to shit on the data scientists. They are probably good in their areas. The problem is not the domain SME support. The problem is that these data scientists seem to be too high on their titles and paychecks to collaborate with SMEs. Most SMEs want to support them and tell them nicely that ML/AI is an overkill for their usecases, and the efforts required are too big. There are other data science and analytics teams that are working seamlesly with SMEs.",how do you deal with data scientists with big pay check and title but no domain knowledge a tech illiterate director at my org hired a data couple of data scientists months ago he has tasked them with nothing specific and their job was solely to observe and find usescases themselves the only reason they were hired was for the director to gain brownie points of creating a datadriven team for themself despite there being several other such teams cut to today the director has realized that there is very little roi from his hires because they lack domain knowledge he conveniently moved them to another team where ml is an overkill the data scientists however have found some problems they thought theyll solve with data science they have been vibe coding and building ppts for months now but their attempts are hardly successful because of their lack of domain knowledge to compensate for their lack of domain knowledge they create beautiful presentations with lots of buzzwords such as llms but again lack domain substance now their proposals seem unnecessary and downright obnoxious to many domain smes but the smes dont have the courage to say it to the leadership and be percevied as a roadblock to the datadriven strategy the constant interference of these data scientists is destabilizing the existing processes for the worst and the team is incurring additional costs this is a very peculiar situation where the data scientists lacking domain knowledge are just shooting project proposals in the dark hoping to hit something i know this doesnt typically happen in most organizations but have you ever seen such a situation around you how did you or others deal with the situation edit this post is not to shit on the data scientists they are probably good in their areas the problem is not the domain sme support the problem is that these data scientists seem to be too high on their titles and paychecks to collaborate with smes most smes want to support them and tell them nicely that mlai is an overkill for their usecases and the efforts required are too big there are other data science and analytics teams that are working seamlesly with smes,deal data scientist big pay check title domain knowledge tech illiterate director org hire data couple datum scientist month ago task specific job solely observe find usescase reason hire director gain brownie point create datadriven team themself despite team cut today director realize little roi hire lack domain knowledge conveniently move team ml overkill data scientist find problem think ll solve datum science vibe code build ppt month attempt hardly successful lack domain knowledge compensate lack domain knowledge create beautiful presentation lot buzzword llm lack domain substance proposal unnecessary downright obnoxious domain sme sme not courage leadership percevie roadblock datadriven strategy constant interference data scientist destabilize exist process bad team incur additional cost peculiar situation data scientist lack domain knowledge shoot project proposal dark hope hit know not typically happen organization see situation deal situation edit post shit data scientist probably good area problem domain sme support problem datum scientist high title paycheck collaborate sme sme want support tell nicely mlai overkill usecase effort require big datum science analytic team work seamlesly sme
1ln6aeq,How’s the job market for Bayesian statistics?,"I’m a data scientist with 1 YOE. mostly worked on credit scoring models, sql, and Power BI. Lately, I’ve been thinking of going deeper into bayesian statistics and I’m currently going through the s*tatistical rethinking* book.

But I’m wondering. is it worth focusing heavily on bayesian stats? Or should I pivot toward something that opens up more job opportunities?

Would love to hear your thoughts or experiences!",138,72,2025-06-29T04:47:53+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ln6aeq/hows_the_job_market_for_bayesian_statistics/,"How’s the job market for Bayesian statistics? I’m a data scientist with 1 YOE. mostly worked on credit scoring models, sql, and Power BI. Lately, I’ve been thinking of going deeper into bayesian statistics and I’m currently going through the s*tatistical rethinking* book.

But I’m wondering. is it worth focusing heavily on bayesian stats? Or should I pivot toward something that opens up more job opportunities?

Would love to hear your thoughts or experiences!",hows the job market for bayesian statistics im a data scientist with yoe mostly worked on credit scoring models sql and power bi lately ive been thinking of going deeper into bayesian statistics and im currently going through the statistical rethinking book but im wondering is it worth focusing heavily on bayesian stats or should i pivot toward something that opens up more job opportunities would love to hear your thoughts or experiences,s job market bayesian statistic m data scientist yoe work credit scoring model sql power bi lately ve think go deeply bayesian statistic m currently go statistical rethinking book m wonder worth focus heavily bayesian stat pivot open job opportunity love hear thought experience
1ln3zyk,Is ML/AI engineering increasingly becoming less focused on model training and more focused on integrating LLMs to build web apps?,"One thing I've noticed recently is that increasingly, a lot of AI/ML roles seem to be focused on ways to integrate LLMs to build web apps that automate some kind of task, e.g. chatbot with RAG or using agent to automate some task in a consumer-facing software with tools like langchain, llamaindex, Claude, etc. I feel like there's less and less of the ""classical"" ML training and building models.

I am not saying that ""classical"" ML training will go away. I think model building/training non-LLMs will always have some place in data science. But in a way, I feel like ""AI engineering"" seems increasingly converging to something closer to back-end engineering you typically see in full-stack. What I mean is that rather than focusing on building or training models, it seems that the bulk of the work now seems to be about how to take LLMs from model providers like OpenAI and Anthropic, and use it to build some software that automates some work with Langchain/Llamaindex.

Is this a reasonable take? I know we can never predict the future, but the trends I see seem to be increasingly heading towards that.",159,40,2025-06-29T02:35:38+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ln3zyk/is_mlai_engineering_increasingly_becoming_less/,"Is ML/AI engineering increasingly becoming less focused on model training and more focused on integrating LLMs to build web apps? One thing I've noticed recently is that increasingly, a lot of AI/ML roles seem to be focused on ways to integrate LLMs to build web apps that automate some kind of task, e.g. chatbot with RAG or using agent to automate some task in a consumer-facing software with tools like langchain, llamaindex, Claude, etc. I feel like there's less and less of the ""classical"" ML training and building models.

I am not saying that ""classical"" ML training will go away. I think model building/training non-LLMs will always have some place in data science. But in a way, I feel like ""AI engineering"" seems increasingly converging to something closer to back-end engineering you typically see in full-stack. What I mean is that rather than focusing on building or training models, it seems that the bulk of the work now seems to be about how to take LLMs from model providers like OpenAI and Anthropic, and use it to build some software that automates some work with Langchain/Llamaindex.

Is this a reasonable take? I know we can never predict the future, but the trends I see seem to be increasingly heading towards that.",is mlai engineering increasingly becoming less focused on model training and more focused on integrating llms to build web apps one thing ive noticed recently is that increasingly a lot of aiml roles seem to be focused on ways to integrate llms to build web apps that automate some kind of task eg chatbot with rag or using agent to automate some task in a consumerfacing software with tools like langchain llamaindex claude etc i feel like theres less and less of the classical ml training and building models i am not saying that classical ml training will go away i think model buildingtraining nonllms will always have some place in data science but in a way i feel like ai engineering seems increasingly converging to something closer to backend engineering you typically see in fullstack what i mean is that rather than focusing on building or training models it seems that the bulk of the work now seems to be about how to take llms from model providers like openai and anthropic and use it to build some software that automates some work with langchainllamaindex is this a reasonable take i know we can never predict the future but the trends i see seem to be increasingly heading towards that,mlai engineering increasingly focused model training focused integrate llm build web app thing ve notice recently increasingly lot aiml role focus way integrate llm build web app automate kind task eg chatbot rag agent automate task consumerfacing software tool like langchain llamaindex claude etc feel like s classical ml training building model say classical ml training away think model buildingtraine nonllm place data science way feel like ai engineering increasingly converge close backend engineering typically fullstack mean focus building training model bulk work llm model provider like openai anthropic use build software automate work langchainllamaindex reasonable know predict future trend increasingly head
1lmxkq8,"Pleased to share the ""SimPy Simulation Playground"" - examples of simulations in Python from different industries","Just put the finishing touches to the first version of this web page where you can run SimPy examples from different industries, including parameterising the sim, editing the code if you wish, running and viewing the results.

Runs entirely in your browser.

Here's the link: [https://www.schoolofsimulation.com/simpy\_simulations](https://www.schoolofsimulation.com/simpy_simulations)

My goal with this is to help provide education and informationa around how discrete-event simulation with SimPy can be applied to different industry contexts.

If you have any suggestions for other examples to add, I'd be happy to consider expanding the list!

Feedback, as ever, is most welcome!",15,6,2025-06-28T21:14:48+00:00,datascience,https://i.redd.it/qm0yh3nxhq9f1.png,"Pleased to share the ""SimPy Simulation Playground"" - examples of simulations in Python from different industries Just put the finishing touches to the first version of this web page where you can run SimPy examples from different industries, including parameterising the sim, editing the code if you wish, running and viewing the results.

Runs entirely in your browser.

Here's the link: [https://www.schoolofsimulation.com/simpy\_simulations](https://www.schoolofsimulation.com/simpy_simulations)

My goal with this is to help provide education and informationa around how discrete-event simulation with SimPy can be applied to different industry contexts.

If you have any suggestions for other examples to add, I'd be happy to consider expanding the list!

Feedback, as ever, is most welcome!",pleased to share the simpy simulation playground examples of simulations in python from different industries just put the finishing touches to the first version of this web page where you can run simpy examples from different industries including parameterising the sim editing the code if you wish running and viewing the results runs entirely in your browser heres the link my goal with this is to help provide education and informationa around how discreteevent simulation with simpy can be applied to different industry contexts if you have any suggestions for other examples to add id be happy to consider expanding the list feedback as ever is most welcome,pleased share simpy simulation playground example simulation python different industry finishing touch version web page run simpy example different industry include parameterise sim edit code wish run view result run entirely browser here link goal help provide education informationa discreteevent simulation simpy apply different industry context suggestion example add d happy consider expand list feedback welcome
1lmv5uf,Unpopular Opinion: These are the most useless posters on LinkedIn,"LinkedIn influencers love to treat the two roles as different species. In most enterprises, especially in mid to small orgs, these roles are largely overlapping. ",1292,109,2025-06-28T19:27:04+00:00,datascience,https://i.redd.it/flntff9gwp9f1.jpeg,"Unpopular Opinion: These are the most useless posters on LinkedIn LinkedIn influencers love to treat the two roles as different species. In most enterprises, especially in mid to small orgs, these roles are largely overlapping. ",unpopular opinion these are the most useless posters on linkedin linkedin influencers love to treat the two roles as different species in most enterprises especially in mid to small orgs these roles are largely overlapping,unpopular opinion useless poster linkedin linkedin influencer love treat role different specie enterprise especially mid small org role largely overlap
1lmsf8b,HuggingFace transformers API reference: How do you navigate it?,"This might be a me problem, but I have some difficulty navigating HF transformers API documentation. It's sometimes easier to use Gemini or Claude to get the relevant information than from the official HF transformers API reference. 

How do you all do it? Any best practices? 

TY.",3,4,2025-06-28T17:30:08+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lmsf8b/huggingface_transformers_api_reference_how_do_you/,"HuggingFace transformers API reference: How do you navigate it? This might be a me problem, but I have some difficulty navigating HF transformers API documentation. It's sometimes easier to use Gemini or Claude to get the relevant information than from the official HF transformers API reference. 

How do you all do it? Any best practices? 

TY.",huggingface transformers api reference how do you navigate it this might be a me problem but i have some difficulty navigating hf transformers api documentation its sometimes easier to use gemini or claude to get the relevant information than from the official hf transformers api reference how do you all do it any best practices ty,huggingface transformer api reference navigate problem difficulty navigate hf transformer api documentation easy use gemini claude relevant information official hf transformer api reference good practice ty
1lmneo7,I built a self-hosted Databricks,"Hey everyone, I'm an ML Engineer who spearheaded the adoption of Databricks at work. I love the agency it affords me because I can own projects end-to-end and do everything in one place.

However, the platform adds a lot of overhead and has a wide array of data-features I just don't care about. So many problems can be solved with a simple data pipeline and basic model (e.g. XGBoost.) Not only is there technical overhead, but systems and process overhead; bureaucracy and red-tap significantly slow delivery. Right now at work we are undertaking a ""migration"" to Databricks and man, it is such a PITA to get anything moving it isn't even funny...

Anyway, I decided to try and address this myself by developing [FlintML](https://github.com/flintml/flintml), a self-hosted, all-in-one MLOps stack. Basically, Polars, Delta Lake, unified catalog, Aim experiment tracking, notebook IDE and orchestration (still working on this) fully spun up with Docker Compose.

I'm hoping to get some feedback from this subreddit. I've spent a couple of months developing this and want to know whether I would be wasting time by continuing or if this might actually be useful. I am using it for my personal research projects and find it very helpful.

Thanks heaps",78,20,2025-06-28T13:55:44+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lmneo7/i_built_a_selfhosted_databricks/,"I built a self-hosted Databricks Hey everyone, I'm an ML Engineer who spearheaded the adoption of Databricks at work. I love the agency it affords me because I can own projects end-to-end and do everything in one place.

However, the platform adds a lot of overhead and has a wide array of data-features I just don't care about. So many problems can be solved with a simple data pipeline and basic model (e.g. XGBoost.) Not only is there technical overhead, but systems and process overhead; bureaucracy and red-tap significantly slow delivery. Right now at work we are undertaking a ""migration"" to Databricks and man, it is such a PITA to get anything moving it isn't even funny...

Anyway, I decided to try and address this myself by developing [FlintML](https://github.com/flintml/flintml), a self-hosted, all-in-one MLOps stack. Basically, Polars, Delta Lake, unified catalog, Aim experiment tracking, notebook IDE and orchestration (still working on this) fully spun up with Docker Compose.

I'm hoping to get some feedback from this subreddit. I've spent a couple of months developing this and want to know whether I would be wasting time by continuing or if this might actually be useful. I am using it for my personal research projects and find it very helpful.

Thanks heaps",i built a selfhosted databricks hey everyone im an ml engineer who spearheaded the adoption of databricks at work i love the agency it affords me because i can own projects endtoend and do everything in one place however the platform adds a lot of overhead and has a wide array of datafeatures i just dont care about so many problems can be solved with a simple data pipeline and basic model eg xgboost not only is there technical overhead but systems and process overhead bureaucracy and redtap significantly slow delivery right now at work we are undertaking a migration to databricks and man it is such a pita to get anything moving it isnt even funny anyway i decided to try and address this myself by developing a selfhosted allinone mlops stack basically polars delta lake unified catalog aim experiment tracking notebook ide and orchestration still working on this fully spun up with docker compose im hoping to get some feedback from this subreddit ive spent a couple of months developing this and want to know whether i would be wasting time by continuing or if this might actually be useful i am using it for my personal research projects and find it very helpful thanks heaps,build selfhoste databrick hey m ml engineer spearhead adoption databrick work love agency afford project endtoend place platform add lot overhead wide array datafeature not care problem solve simple data pipeline basic model eg xgboost technical overhead system process overhead bureaucracy redtap significantly slow delivery right work undertake migration databrick man pita move not funny decide try address develop selfhoste allinone mlop stack basically polar delta lake unify catalog aim experiment track notebook ide orchestration work fully spin docker compose m hope feedback subreddit ve spend couple month develop want know waste time continue actually useful personal research project find helpful thank heap
1lmi8j8,"The ""Unicorn"" is Dead: A Four-Era History of the Data Scientist Role and Why We're All Engineers Now","Hey everyone,

I’ve been in this field for a while now, starting back when ""Big Data"" was the big buzzword, and I've been thinking a lot about how drastically our roles have changed. It feels like the job description for a ""Data Scientist"" has been rewritten three or four times over. The ""unicorn"" we all talked about a decade ago feels like a fossil today.

I wanted to map out this evolution, partly to make sense of it for myself, but also to see if it resonates with your experiences. I see it as four distinct eras.

---

### **Era 1: The BI & Stats Age (The ""Before Times,"" Pre-2010)**

Remember this? Before ""Data Scientist"" was a thing, we were all in our separate corners.

*   **Who we were:** BI Analysts, Statisticians, Database Admins, Quants.
*   **What we did:** Our world revolved around historical reporting. We lived in SQL, wrestling with relational databases and using tools like Business Objects or good old Excel to build reports. The core question was always, **""What happened last quarter?""**
*   **The ""advanced"" stuff:** If you were a true statistician, maybe you were building logistic regression models in SAS, but that felt very separate from the day-to-day business analytics. It was more academic, less integrated.

The mindset was purely descriptive. We were the historians of the company's data.

### **Era 2: The Golden Age of the ""Unicorn"" (Roughly 2011-2018)**

This is when everything changed. *HBR* called our job the ""sexiest"" of the century, and the hype was real.

*   **The trigger:** Hadoop and Spark made ""Big Data"" accessible, and Python with Scikit-learn became an absolute powerhouse. Suddenly, you could do serious modeling on your own machine.
*   **The mission:** The game changed from ""What happened?"" to **""What's *going* to happen?""** We were all building churn models, recommendation engines, and trying to predict the future. The Jupyter Notebook was our kingdom.
*   **The ""unicorn"" expectation:** This was the peak of the ""full-stack"" ideal. One person was supposed to understand the business, wrangle the data, build the model, and then explain it all in a PowerPoint deck. The *insight* from the model was the final product. It was an incredibly fun, creative, and exploratory time.

### **Era 3: The Industrial Age & The Great Bifurcation (Roughly 2019-2023)**

This is where, in my opinion, the ""unicorn"" myth started to crack. Companies realized a model sitting in a notebook doesn't actually *do* anything for the business. The focus shifted from *building models* to *deploying systems*.

*   **The trigger:** The cloud matured. AWS, GCP, and Azure became the standard, and the discipline of MLOps was born. The problem wasn't ""can we predict it?"" anymore. It was, **""Can we serve these predictions reliably to millions of users with low latency?""**
*   **The splintering:** The generalist ""Data Scientist"" role started to fracture into specialists because no single person could master it all:
    *   **ML Engineers:** The software engineers who actually productionized the models.
    *   **Data Engineers:** The unsung heroes who built the reliable data pipelines with tools like Airflow and dbt.
    *   **Analytics Engineers:** The new role that owned the data modeling layer for BI.
*   The mindset became engineering-first. We were building factories, not just artisanal products.

### **Era 4: The Autonomous Age (2023 - Today and Beyond)**

And then, everything changed again. The arrival of truly powerful LLMs completely upended the landscape.

*   **The trigger:** ChatGPT went public, GPT-4 was released, and frameworks like LangChain gave us the tools to build on top of this new paradigm.
*   **The mission:** The core question has evolved again. It's not just about prediction anymore; it's about **action and orchestration**. The question is, **""How do we build a system that can understand a goal, create a plan, and execute it?""**
*   **The new reality:**
    *   **Prediction becomes a feature, not the product.** An AI *agent* doesn't just predict churn; it takes an *action* to prevent it.
    *   **We are all systems architects now.** We're not just building a model; we're building an intelligent, multi-step workflow. We're integrating vector databases, multiple APIs, and complex reasoning loops.
    *   **The engineering rigor from Era 3 is now the mandatory foundation.** You can't build a reliable agent without solid MLOps and real-time data engineering (Kafka, Flink, etc.).

It feels like the ""science"" part of our job is now less about statistical analysis (AI can do a lot of that for us) and more about the rigorous, empirical science of architecting and evaluating these incredibly complex, often non-deterministic systems.

So, that's my take. The ""Data Scientist"" title isn't dead, but the ""unicorn"" generalist ideal of 2015 certainly is. We've been pushed to become deeper specialists, and for most of us on the building side, that specialty looks a lot more like engineering than anything else.

Curious to hear if this matches up with what you're all seeing in your roles. Did I miss an era? Is your experience different?

EDIT: In response to comments asking if this was written by AI: The underlying ideas are based on my own experience.

However, I want to be transparent that I would not have been able to articulate my vague, intuitive thoughts about the changes in this field with such precision. 

I used AI specifically for the structurization and organization of the content.",601,111,2025-06-28T08:56:59+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lmi8j8/the_unicorn_is_dead_a_fourera_history_of_the_data/,"The ""Unicorn"" is Dead: A Four-Era History of the Data Scientist Role and Why We're All Engineers Now Hey everyone,

I’ve been in this field for a while now, starting back when ""Big Data"" was the big buzzword, and I've been thinking a lot about how drastically our roles have changed. It feels like the job description for a ""Data Scientist"" has been rewritten three or four times over. The ""unicorn"" we all talked about a decade ago feels like a fossil today.

I wanted to map out this evolution, partly to make sense of it for myself, but also to see if it resonates with your experiences. I see it as four distinct eras.

---

### **Era 1: The BI & Stats Age (The ""Before Times,"" Pre-2010)**

Remember this? Before ""Data Scientist"" was a thing, we were all in our separate corners.

*   **Who we were:** BI Analysts, Statisticians, Database Admins, Quants.
*   **What we did:** Our world revolved around historical reporting. We lived in SQL, wrestling with relational databases and using tools like Business Objects or good old Excel to build reports. The core question was always, **""What happened last quarter?""**
*   **The ""advanced"" stuff:** If you were a true statistician, maybe you were building logistic regression models in SAS, but that felt very separate from the day-to-day business analytics. It was more academic, less integrated.

The mindset was purely descriptive. We were the historians of the company's data.

### **Era 2: The Golden Age of the ""Unicorn"" (Roughly 2011-2018)**

This is when everything changed. *HBR* called our job the ""sexiest"" of the century, and the hype was real.

*   **The trigger:** Hadoop and Spark made ""Big Data"" accessible, and Python with Scikit-learn became an absolute powerhouse. Suddenly, you could do serious modeling on your own machine.
*   **The mission:** The game changed from ""What happened?"" to **""What's *going* to happen?""** We were all building churn models, recommendation engines, and trying to predict the future. The Jupyter Notebook was our kingdom.
*   **The ""unicorn"" expectation:** This was the peak of the ""full-stack"" ideal. One person was supposed to understand the business, wrangle the data, build the model, and then explain it all in a PowerPoint deck. The *insight* from the model was the final product. It was an incredibly fun, creative, and exploratory time.

### **Era 3: The Industrial Age & The Great Bifurcation (Roughly 2019-2023)**

This is where, in my opinion, the ""unicorn"" myth started to crack. Companies realized a model sitting in a notebook doesn't actually *do* anything for the business. The focus shifted from *building models* to *deploying systems*.

*   **The trigger:** The cloud matured. AWS, GCP, and Azure became the standard, and the discipline of MLOps was born. The problem wasn't ""can we predict it?"" anymore. It was, **""Can we serve these predictions reliably to millions of users with low latency?""**
*   **The splintering:** The generalist ""Data Scientist"" role started to fracture into specialists because no single person could master it all:
    *   **ML Engineers:** The software engineers who actually productionized the models.
    *   **Data Engineers:** The unsung heroes who built the reliable data pipelines with tools like Airflow and dbt.
    *   **Analytics Engineers:** The new role that owned the data modeling layer for BI.
*   The mindset became engineering-first. We were building factories, not just artisanal products.

### **Era 4: The Autonomous Age (2023 - Today and Beyond)**

And then, everything changed again. The arrival of truly powerful LLMs completely upended the landscape.

*   **The trigger:** ChatGPT went public, GPT-4 was released, and frameworks like LangChain gave us the tools to build on top of this new paradigm.
*   **The mission:** The core question has evolved again. It's not just about prediction anymore; it's about **action and orchestration**. The question is, **""How do we build a system that can understand a goal, create a plan, and execute it?""**
*   **The new reality:**
    *   **Prediction becomes a feature, not the product.** An AI *agent* doesn't just predict churn; it takes an *action* to prevent it.
    *   **We are all systems architects now.** We're not just building a model; we're building an intelligent, multi-step workflow. We're integrating vector databases, multiple APIs, and complex reasoning loops.
    *   **The engineering rigor from Era 3 is now the mandatory foundation.** You can't build a reliable agent without solid MLOps and real-time data engineering (Kafka, Flink, etc.).

It feels like the ""science"" part of our job is now less about statistical analysis (AI can do a lot of that for us) and more about the rigorous, empirical science of architecting and evaluating these incredibly complex, often non-deterministic systems.

So, that's my take. The ""Data Scientist"" title isn't dead, but the ""unicorn"" generalist ideal of 2015 certainly is. We've been pushed to become deeper specialists, and for most of us on the building side, that specialty looks a lot more like engineering than anything else.

Curious to hear if this matches up with what you're all seeing in your roles. Did I miss an era? Is your experience different?

EDIT: In response to comments asking if this was written by AI: The underlying ideas are based on my own experience.

However, I want to be transparent that I would not have been able to articulate my vague, intuitive thoughts about the changes in this field with such precision. 

I used AI specifically for the structurization and organization of the content.",the unicorn is dead a fourera history of the data scientist role and why were all engineers now hey everyone ive been in this field for a while now starting back when big data was the big buzzword and ive been thinking a lot about how drastically our roles have changed it feels like the job description for a data scientist has been rewritten three or four times over the unicorn we all talked about a decade ago feels like a fossil today i wanted to map out this evolution partly to make sense of it for myself but also to see if it resonates with your experiences i see it as four distinct eras era the bi stats age the before times pre remember this before data scientist was a thing we were all in our separate corners who we were bi analysts statisticians database admins quants what we did our world revolved around historical reporting we lived in sql wrestling with relational databases and using tools like business objects or good old excel to build reports the core question was always what happened last quarter the advanced stuff if you were a true statistician maybe you were building logistic regression models in sas but that felt very separate from the daytoday business analytics it was more academic less integrated the mindset was purely descriptive we were the historians of the companys data era the golden age of the unicorn roughly this is when everything changed hbr called our job the sexiest of the century and the hype was real the trigger hadoop and spark made big data accessible and python with scikitlearn became an absolute powerhouse suddenly you could do serious modeling on your own machine the mission the game changed from what happened to whats going to happen we were all building churn models recommendation engines and trying to predict the future the jupyter notebook was our kingdom the unicorn expectation this was the peak of the fullstack ideal one person was supposed to understand the business wrangle the data build the model and then explain it all in a powerpoint deck the insight from the model was the final product it was an incredibly fun creative and exploratory time era the industrial age the great bifurcation roughly this is where in my opinion the unicorn myth started to crack companies realized a model sitting in a notebook doesnt actually do anything for the business the focus shifted from building models to deploying systems the trigger the cloud matured aws gcp and azure became the standard and the discipline of mlops was born the problem wasnt can we predict it anymore it was can we serve these predictions reliably to millions of users with low latency the splintering the generalist data scientist role started to fracture into specialists because no single person could master it all ml engineers the software engineers who actually productionized the models data engineers the unsung heroes who built the reliable data pipelines with tools like airflow and dbt analytics engineers the new role that owned the data modeling layer for bi the mindset became engineeringfirst we were building factories not just artisanal products era the autonomous age today and beyond and then everything changed again the arrival of truly powerful llms completely upended the landscape the trigger chatgpt went public gpt was released and frameworks like langchain gave us the tools to build on top of this new paradigm the mission the core question has evolved again its not just about prediction anymore its about action and orchestration the question is how do we build a system that can understand a goal create a plan and execute it the new reality prediction becomes a feature not the product an ai agent doesnt just predict churn it takes an action to prevent it we are all systems architects now were not just building a model were building an intelligent multistep workflow were integrating vector databases multiple apis and complex reasoning loops the engineering rigor from era is now the mandatory foundation you cant build a reliable agent without solid mlops and realtime data engineering kafka flink etc it feels like the science part of our job is now less about statistical analysis ai can do a lot of that for us and more about the rigorous empirical science of architecting and evaluating these incredibly complex often nondeterministic systems so thats my take the data scientist title isnt dead but the unicorn generalist ideal of certainly is weve been pushed to become deeper specialists and for most of us on the building side that specialty looks a lot more like engineering than anything else curious to hear if this matches up with what youre all seeing in your roles did i miss an era is your experience different edit in response to comments asking if this was written by ai the underlying ideas are based on my own experience however i want to be transparent that i would not have been able to articulate my vague intuitive thoughts about the changes in this field with such precision i used ai specifically for the structurization and organization of the content,unicorn dead fourera history data scientist role engineer hey ve field start big datum big buzzword ve think lot drastically role change feel like job description data scientist rewrite time unicorn talk decade ago feel like fossil today want map evolution partly sense resonate experience distinct era era bi stat age time pre remember datum scientist thing separate corner bi analyst statistician database admin quant world revolve historical reporting live sql wrestling relational database tool like business object good old excel build report core question happen quarter advanced stuff true statistician maybe build logistic regression model sas feel separate daytoday business analytic academic integrated mindset purely descriptive historian company datum era golden age unicorn roughly change hbr call job sexiest century hype real trigger hadoop spark big datum accessible python scikitlearn absolute powerhouse suddenly modeling machine mission game change happen s go happen build churn model recommendation engine try predict future jupyter notebook kingdom unicorn expectation peak fullstack ideal person suppose understand business wrangle datum build model explain powerpoint deck insight model final product incredibly fun creative exploratory time era industrial age great bifurcation roughly opinion unicorn myth start crack company realize model sit notebook not actually business focus shift building model deploy system trigger cloud mature aw gcp azure standard discipline mlop bear problem not predict anymore serve prediction reliably million user low latency splinter generalist data scientist role start fracture specialist single person master ml engineer software engineer actually productionize model datum engineer unsung hero build reliable data pipeline tool like airflow dbt analytic engineer new role own datum modeling layer bi mindset engineeringfirst build factory artisanal product era autonomous age today change arrival truly powerful llm completely upend landscape trigger chatgpt go public gpt release framework like langchain give tool build new paradigm mission core question evolve prediction anymore action orchestration question build system understand goal create plan execute new reality prediction feature product ai agent not predict churn take action prevent system architect build model build intelligent multistep workflow integrate vector database multiple apis complex reasoning loop engineering rigor era mandatory foundation not build reliable agent solid mlop realtime datum engineering kafka flink etc feel like science job statistical analysis ai lot rigorous empirical science architecte evaluate incredibly complex nondeterministic system s data scientist title not dead unicorn generalist ideal certainly ve push deep specialist building specialty look lot like engineering curious hear match see role miss era experience different edit response comment ask write ai underlie idea base experience want transparent able articulate vague intuitive thought change field precision ai specifically structurization organization content
1lmaxr4,Using LLMs to Extract Stock Picks from YouTube,"For anyone interested in NLP or the application of data science in finance and media, we just released a dataset + paper on extracting **stock recommendations from YouTube financial influencer videos**.

This is a real-world task that combines signals across audio, video, and transcripts. We used expert annotations and benchmarked both LLMs and multimodal models to see how well they can extract structured recommendation data (like ticker and action) from messy, informal content.

If you're interested in working with unstructured media, financial data, or evaluating model performance in noisy settings, this might be interesting.

Paper: [https://papers.ssrn.com/sol3/papers.cfm?abstract\_id=5315526](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5315526)  
Dataset: [https://huggingface.co/datasets/gtfintechlab/VideoConviction](https://huggingface.co/datasets/gtfintechlab/VideoConviction)

Happy to discuss the challenges we ran into or potential applications beyond finance!

[Betting against finfluencer recommendations outperformed the S&P 500 by +6.8&#37; in annual returns, but at higher risk \(Sharpe ratio 0.41 vs 0.65\). QQQ wins in Sharpe ratio. ](https://preview.redd.it/3n861nuhnk9f1.png?width=4764&format=png&auto=webp&s=aa010ae695934b5520df5e82d8158201750cb3a4)

",94,24,2025-06-28T01:36:04+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lmaxr4/using_llms_to_extract_stock_picks_from_youtube/,"Using LLMs to Extract Stock Picks from YouTube For anyone interested in NLP or the application of data science in finance and media, we just released a dataset + paper on extracting **stock recommendations from YouTube financial influencer videos**.

This is a real-world task that combines signals across audio, video, and transcripts. We used expert annotations and benchmarked both LLMs and multimodal models to see how well they can extract structured recommendation data (like ticker and action) from messy, informal content.

If you're interested in working with unstructured media, financial data, or evaluating model performance in noisy settings, this might be interesting.

Paper: [https://papers.ssrn.com/sol3/papers.cfm?abstract\_id=5315526](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5315526)  
Dataset: [https://huggingface.co/datasets/gtfintechlab/VideoConviction](https://huggingface.co/datasets/gtfintechlab/VideoConviction)

Happy to discuss the challenges we ran into or potential applications beyond finance!

[Betting against finfluencer recommendations outperformed the S&P 500 by +6.8&#37; in annual returns, but at higher risk \(Sharpe ratio 0.41 vs 0.65\). QQQ wins in Sharpe ratio. ](https://preview.redd.it/3n861nuhnk9f1.png?width=4764&format=png&auto=webp&s=aa010ae695934b5520df5e82d8158201750cb3a4)

",using llms to extract stock picks from youtube for anyone interested in nlp or the application of data science in finance and media we just released a dataset paper on extracting stock recommendations from youtube financial influencer videos this is a realworld task that combines signals across audio video and transcripts we used expert annotations and benchmarked both llms and multimodal models to see how well they can extract structured recommendation data like ticker and action from messy informal content if youre interested in working with unstructured media financial data or evaluating model performance in noisy settings this might be interesting paper dataset happy to discuss the challenges we ran into or potential applications beyond finance,llm extract stock pick youtube interested nlp application datum science finance medium release dataset paper extract stock recommendation youtube financial influencer video realworld task combine signal audio video transcript expert annotation benchmarke llm multimodal model extract structured recommendation datum like ticker action messy informal content interested work unstructured medium financial datum evaluate model performance noisy setting interesting paper dataset happy discuss challenge run potential application finance
1lm0dc9,"I built a ""virtual simulation engineer"" tool that designs, build, executes and displays the results of Python SimPy simulations entirely in a single browser window","New tool I built to design, build and execute a discrete-event simulation in Python entirely using natural language in a single browser window. 

You can use it here, 100% free: [https://gemini.google.com/share/ad9d3a205479](https://gemini.google.com/share/ad9d3a205479)

Version 2 uses SimPy under the hood. Pyodide to execute Python in the front end.

This is a proof of concept, I am keen for feedback please.

I made a video overview of it here: [https://www.youtube.com/watch?v=BF-1F-kqvL4](https://www.youtube.com/watch?v=BF-1F-kqvL4) ",12,9,2025-06-27T17:51:09+00:00,datascience,https://i.redd.it/4g1jooknci9f1.png,"I built a ""virtual simulation engineer"" tool that designs, build, executes and displays the results of Python SimPy simulations entirely in a single browser window New tool I built to design, build and execute a discrete-event simulation in Python entirely using natural language in a single browser window. 

You can use it here, 100% free: [https://gemini.google.com/share/ad9d3a205479](https://gemini.google.com/share/ad9d3a205479)

Version 2 uses SimPy under the hood. Pyodide to execute Python in the front end.

This is a proof of concept, I am keen for feedback please.

I made a video overview of it here: [https://www.youtube.com/watch?v=BF-1F-kqvL4](https://www.youtube.com/watch?v=BF-1F-kqvL4) ",i built a virtual simulation engineer tool that designs build executes and displays the results of python simpy simulations entirely in a single browser window new tool i built to design build and execute a discreteevent simulation in python entirely using natural language in a single browser window you can use it here free version uses simpy under the hood pyodide to execute python in the front end this is a proof of concept i am keen for feedback please i made a video overview of it here,build virtual simulation engineer tool design build execute display result python simpy simulation entirely single browser window new tool build design build execute discreteevent simulation python entirely natural language single browser window use free version use simpy hood pyodide execute python end proof concept keen feedback video overview
1llvtfl,CVS Heath vs JPM,Thank you all for the support. This is a really helpful group. Cheers!,32,38,2025-06-27T14:50:08+00:00,datascience,https://www.reddit.com/r/datascience/comments/1llvtfl/cvs_heath_vs_jpm/,CVS Heath vs JPM Thank you all for the support. This is a really helpful group. Cheers!,cvs heath vs jpm thank you all for the support this is a really helpful group cheers,cvs heath vs jpm thank support helpful group cheer
1lluwlv,Data Science Has Become a Pseudo-Science,"I’ve been working in data science for the last ten years, both in industry and academia, having pursued a master’s and PhD in Europe. My experience in the industry, overall, has been very positive. I’ve had the opportunity to work with brilliant people on exciting, high-impact projects. Of course, there were the usual high-stress situations, nonsense PowerPoints, and impossible deadlines, but the work largely felt meaningful.

However, over the past two years or so, it feels like the field has taken a sharp turn. Just yesterday, I attended a technical presentation from the analytics team. The project aimed to identify anomalies in a dataset composed of multiple time series, each containing a clear inflection point. The team’s hypothesis was that these trajectories might indicate entities engaged in some sort of fraud.

The team claimed to have solved the task using “generative AI”. They didn’t go into methodological details but presented results that, according to them, were amazing. Curious, nespecially since the project was heading toward deployment, i asked about validation, performance metrics, or baseline comparisons. None were presented.

Later, I found out that “generative AI” meant asking ChatGPT to generate a code. The code simply computed the mean of each series before and after the inflection point, then calculated the z-score of the difference. No model evaluation. No metrics. No baselines. Absolutely no model criticism. Just a naive approach, packaged and executed very, very quickly under the label of generative AI.

The moment I understood the proposed solution, my immediate thought was ""I need to get as far away from this company as possible"". I share this anecdote because it summarizes much of what I’ve witnessed in the field over the past two years. It feels like data science is drifting toward a kind of pseudo-science where we consult a black-box oracle for answers, and questioning its outputs is treated as anti-innovation, while no one really understand how the outputs were generated.

After several experiences like this, I’m seriously considering focusing on academia. Working on projects like these is eroding any hope I have in the field. I know this won’t work and yet, the label generative AI seems to make it unquestionable. So I came here to ask if is this experience shared among other DSs?

",2605,327,2025-06-27T14:11:44+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lluwlv/data_science_has_become_a_pseudoscience/,"Data Science Has Become a Pseudo-Science I’ve been working in data science for the last ten years, both in industry and academia, having pursued a master’s and PhD in Europe. My experience in the industry, overall, has been very positive. I’ve had the opportunity to work with brilliant people on exciting, high-impact projects. Of course, there were the usual high-stress situations, nonsense PowerPoints, and impossible deadlines, but the work largely felt meaningful.

However, over the past two years or so, it feels like the field has taken a sharp turn. Just yesterday, I attended a technical presentation from the analytics team. The project aimed to identify anomalies in a dataset composed of multiple time series, each containing a clear inflection point. The team’s hypothesis was that these trajectories might indicate entities engaged in some sort of fraud.

The team claimed to have solved the task using “generative AI”. They didn’t go into methodological details but presented results that, according to them, were amazing. Curious, nespecially since the project was heading toward deployment, i asked about validation, performance metrics, or baseline comparisons. None were presented.

Later, I found out that “generative AI” meant asking ChatGPT to generate a code. The code simply computed the mean of each series before and after the inflection point, then calculated the z-score of the difference. No model evaluation. No metrics. No baselines. Absolutely no model criticism. Just a naive approach, packaged and executed very, very quickly under the label of generative AI.

The moment I understood the proposed solution, my immediate thought was ""I need to get as far away from this company as possible"". I share this anecdote because it summarizes much of what I’ve witnessed in the field over the past two years. It feels like data science is drifting toward a kind of pseudo-science where we consult a black-box oracle for answers, and questioning its outputs is treated as anti-innovation, while no one really understand how the outputs were generated.

After several experiences like this, I’m seriously considering focusing on academia. Working on projects like these is eroding any hope I have in the field. I know this won’t work and yet, the label generative AI seems to make it unquestionable. So I came here to ask if is this experience shared among other DSs?

",data science has become a pseudoscience ive been working in data science for the last ten years both in industry and academia having pursued a masters and phd in europe my experience in the industry overall has been very positive ive had the opportunity to work with brilliant people on exciting highimpact projects of course there were the usual highstress situations nonsense powerpoints and impossible deadlines but the work largely felt meaningful however over the past two years or so it feels like the field has taken a sharp turn just yesterday i attended a technical presentation from the analytics team the project aimed to identify anomalies in a dataset composed of multiple time series each containing a clear inflection point the teams hypothesis was that these trajectories might indicate entities engaged in some sort of fraud the team claimed to have solved the task using generative ai they didnt go into methodological details but presented results that according to them were amazing curious nespecially since the project was heading toward deployment i asked about validation performance metrics or baseline comparisons none were presented later i found out that generative ai meant asking chatgpt to generate a code the code simply computed the mean of each series before and after the inflection point then calculated the zscore of the difference no model evaluation no metrics no baselines absolutely no model criticism just a naive approach packaged and executed very very quickly under the label of generative ai the moment i understood the proposed solution my immediate thought was i need to get as far away from this company as possible i share this anecdote because it summarizes much of what ive witnessed in the field over the past two years it feels like data science is drifting toward a kind of pseudoscience where we consult a blackbox oracle for answers and questioning its outputs is treated as antiinnovation while no one really understand how the outputs were generated after several experiences like this im seriously considering focusing on academia working on projects like these is eroding any hope i have in the field i know this wont work and yet the label generative ai seems to make it unquestionable so i came here to ask if is this experience shared among other dss,data science pseudoscience ve work data science year industry academia having pursue master phd europe experience industry overall positive ve opportunity work brilliant people exciting highimpact project course usual highstress situation nonsense powerpoint impossible deadline work largely feel meaningful past year feel like field take sharp turn yesterday attend technical presentation analytic team project aim identify anomaly dataset compose multiple time series contain clear inflection point team hypothesis trajectory indicate entity engage sort fraud team claim solve task generative ai not methodological detail present result accord amazing curious nespecially project head deployment ask validation performance metric baseline comparison present later find generative ai mean ask chatgpt generate code code simply compute mean series inflection point calculate zscore difference model evaluation metric baseline absolutely model criticism naive approach package execute quickly label generative ai moment understand propose solution immediate thought need far away company possible share anecdote summarize ve witness field past year feel like data science drift kind pseudoscience consult blackbox oracle answer question output treat antiinnovation understand output generate experience like m seriously consider focus academia work project like erode hope field know will not work label generative ai unquestionable come ask experience share dss
1llnbwq,Causal Inference in Sports,"For all curious on Causal Inference, and anyone interested in the application of DS in Sport. I’ve written this blog with the aim of providing a taste for how Causal Inference techniques are used practically, as well as some examples to get people thinking.

I do believe upskilling in Causal Inference is quite valuable, despite the learning curve I think it’s quite cool identifying cause-and -effect without having to do RCTs.

Enjoy!",70,17,2025-06-27T06:55:48+00:00,datascience,https://medium.com/@joshamayo7/causal-inference-in-sports-7d911a248375,"Causal Inference in Sports For all curious on Causal Inference, and anyone interested in the application of DS in Sport. I’ve written this blog with the aim of providing a taste for how Causal Inference techniques are used practically, as well as some examples to get people thinking.

I do believe upskilling in Causal Inference is quite valuable, despite the learning curve I think it’s quite cool identifying cause-and -effect without having to do RCTs.

Enjoy!",causal inference in sports for all curious on causal inference and anyone interested in the application of ds in sport ive written this blog with the aim of providing a taste for how causal inference techniques are used practically as well as some examples to get people thinking i do believe upskilling in causal inference is quite valuable despite the learning curve i think its quite cool identifying causeand effect without having to do rcts enjoy,causal inference sport curious causal inference interested application ds sport ve write blog aim provide taste causal inference technique practically example people think believe upskille causal inference valuable despite learn curve think cool identify causeand effect have rct enjoy
1lliwit,SEAL:Self-Adapting Language Models (self learning LLMs),"MIT has recently released a new research paper where they have introduced a new framework SEAL which introduces a concept of self-learning LLMs that means LLMs can now generate their own fine-tuning data set optimized for the strategy and fine tune themselves on the given context. 

Full summary ; [https://www.youtube.com/watch?v=MLUh9b8nN2U](https://www.youtube.com/watch?v=MLUh9b8nN2U)

Paper : [https://arxiv.org/abs/2506.10943](https://arxiv.org/abs/2506.10943)",9,1,2025-06-27T02:40:50+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lliwit/sealselfadapting_language_models_self_learning/,"SEAL:Self-Adapting Language Models (self learning LLMs) MIT has recently released a new research paper where they have introduced a new framework SEAL which introduces a concept of self-learning LLMs that means LLMs can now generate their own fine-tuning data set optimized for the strategy and fine tune themselves on the given context. 

Full summary ; [https://www.youtube.com/watch?v=MLUh9b8nN2U](https://www.youtube.com/watch?v=MLUh9b8nN2U)

Paper : [https://arxiv.org/abs/2506.10943](https://arxiv.org/abs/2506.10943)",sealselfadapting language models self learning llms mit has recently released a new research paper where they have introduced a new framework seal which introduces a concept of selflearning llms that means llms can now generate their own finetuning data set optimized for the strategy and fine tune themselves on the given context full summary paper,sealselfadapte language model self learn llm mit recently release new research paper introduce new framework seal introduce concept selflearning llm mean llm generate finetuning datum set optimize strategy fine tune give context summary paper
1ll7or7,"When applying internally, do you reach out to the hiring manager?","I work at a relatively large company, and I've always reached out to hiring managers for internal positions, setting up a brief introductory meeting to ask specific questions about the role. However, during a recent HR session for new employees, it was recommended that we avoid this approach, as it could ""create bias"" and that managers are often too busy.

Now I'm rethinking my strategy for internal applications, I feel like it's highly dependent on the manager themselves but in most cases, asking for a quick intro meeting wouldn't hurt right? I feel like HR was way too broad with this statement. What are people's experiences on this.",52,34,2025-06-26T18:27:04+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ll7or7/when_applying_internally_do_you_reach_out_to_the/,"When applying internally, do you reach out to the hiring manager? I work at a relatively large company, and I've always reached out to hiring managers for internal positions, setting up a brief introductory meeting to ask specific questions about the role. However, during a recent HR session for new employees, it was recommended that we avoid this approach, as it could ""create bias"" and that managers are often too busy.

Now I'm rethinking my strategy for internal applications, I feel like it's highly dependent on the manager themselves but in most cases, asking for a quick intro meeting wouldn't hurt right? I feel like HR was way too broad with this statement. What are people's experiences on this.",when applying internally do you reach out to the hiring manager i work at a relatively large company and ive always reached out to hiring managers for internal positions setting up a brief introductory meeting to ask specific questions about the role however during a recent hr session for new employees it was recommended that we avoid this approach as it could create bias and that managers are often too busy now im rethinking my strategy for internal applications i feel like its highly dependent on the manager themselves but in most cases asking for a quick intro meeting wouldnt hurt right i feel like hr was way too broad with this statement what are peoples experiences on this,apply internally reach hire manager work relatively large company ve reach hire manager internal position set brief introductory meeting ask specific question role recent hr session new employee recommend avoid approach create bias manager busy m rethink strategy internal application feel like highly dependent manager case ask quick intro meeting not hurt right feel like hr way broad statement people experience
1ll5dv2,I have two amazing job offers. I want to build my own company in the near future. At a loss.,"Hi!

I have two offers. One from a big tech company as a data scientist. I deem it easily the best tech company in my country. I would have killed for this offer just 1 year ago.

Another offer is from a robotics startup. I would be a founding engineer doing ML, and I think I would learn a lot. However, I'm not interested in this company in the long run. I would jump out after 2 years at the latest to build my own. So my equity would not even vest, and I would feel like I'm backstabbing the founders. They probably would not hire me if I told them this. But I think I would (maybe) learn more in this position.

I just can't decide what to do... My ultimate goal is to build my own company in 1-2 years. What to do?",73,41,2025-06-26T16:59:08+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ll5dv2/i_have_two_amazing_job_offers_i_want_to_build_my/,"I have two amazing job offers. I want to build my own company in the near future. At a loss. Hi!

I have two offers. One from a big tech company as a data scientist. I deem it easily the best tech company in my country. I would have killed for this offer just 1 year ago.

Another offer is from a robotics startup. I would be a founding engineer doing ML, and I think I would learn a lot. However, I'm not interested in this company in the long run. I would jump out after 2 years at the latest to build my own. So my equity would not even vest, and I would feel like I'm backstabbing the founders. They probably would not hire me if I told them this. But I think I would (maybe) learn more in this position.

I just can't decide what to do... My ultimate goal is to build my own company in 1-2 years. What to do?",i have two amazing job offers i want to build my own company in the near future at a loss hi i have two offers one from a big tech company as a data scientist i deem it easily the best tech company in my country i would have killed for this offer just year ago another offer is from a robotics startup i would be a founding engineer doing ml and i think i would learn a lot however im not interested in this company in the long run i would jump out after years at the latest to build my own so my equity would not even vest and i would feel like im backstabbing the founders they probably would not hire me if i told them this but i think i would maybe learn more in this position i just cant decide what to do my ultimate goal is to build my own company in years what to do,amazing job offer want build company near future loss hi offer big tech company data scientist deem easily good tech company country kill offer year ago offer robotic startup found engineer ml think learn lot m interested company long run jump year late build equity vest feel like m backstabbe founder probably hire tell think maybe learn position not decide ultimate goal build company year
1ll56bo,Gemini CLI: Google's free coding AI Agent,Google's Gemini CLI is a terminal based AI Agent mostly for coding and easy to install with free access to Gemini 2.5 Pro. Check demo here : https://youtu.be/Diib3vKblBM?si=DDtnlHqAhn_kHbiP,24,4,2025-06-26T16:50:48+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ll56bo/gemini_cli_googles_free_coding_ai_agent/,Gemini CLI: Google's free coding AI Agent Google's Gemini CLI is a terminal based AI Agent mostly for coding and easy to install with free access to Gemini 2.5 Pro. Check demo here : https://youtu.be/Diib3vKblBM?si=DDtnlHqAhn_kHbiP,gemini cli googles free coding ai agent googles gemini cli is a terminal based ai agent mostly for coding and easy to install with free access to gemini pro check demo here,gemini cli google free code ai agent google gemini cli terminal base ai agent code easy install free access gemini pro check demo
1lkpnkk,Pre-Expedition Weather Conditions and Success Rates: Seasonal Pattern Analysis of Himalayan Expedition Data,"After someone posted Himalayan expedition data on Kaggle: [Himalayan Expeditions](https://www.kaggle.com/datasets/siddharth0935/himalayan-expeditions), I decided to start a personal project and expand on this data by adding ERA5 historical reanalysis weather data to it. Some of my preliminary findings have been interesting so far and I thought I would share them.  
  
I expanded on the expedition data by creating multiple different weather windows:

* Full expedition from basecamp date until termination either following summit or termination of attempt.
* Pre-expedition weather - 14 days prior to official expedition start at basecamp.
* Termination or Summit approach - the day before termination or summit.
* Early phase - the first 14 days at basecamp.
* Late phase - 7 days prior to termination date (either after summit or on failed attempt.)
* Decision window - 2 days prior to summit window

The first weather that I have focused on analyzing is the pre-expedition weather window. After cleaning the data and adding the weather windows, I also added a few other features using simple operations and created a few target variables for later modelling like expedition success score, expedition failure score, and an overall expedition score. For this analysis, though, I only focused on success being either True or False. After creating the features and targets, I then ran t-tests on success being True or False to determine their statistical significance. 

When looking at all the features related to the pre-expedition weather window, the findings seem to suggest that pre-expedition weather conditions play a significant role in Himalayan expedition success or failure in spring/summer expeditions. The graphs and correlation heatmap below summarize the variables that have the highest significance in either success or failure:  


[This diagram shows how the different attributes either contribute to success or failure.](https://preview.redd.it/6nbr99uzu69f1.png?width=1904&format=png&auto=webp&s=f84e3cb76b2d61d3b3e68dc3fdd0eec2608cd586)

[This diagram highlights the key attributes over or under of a significance of 0.2 or -0.2 respectively. ](https://preview.redd.it/bzj3uxu2v69f1.png?width=1889&format=png&auto=webp&s=5287852c5a90ae75b251826e1a9668db0ca34d80)

[This is a correlation heatmap diagram associating the attributes to success or failure.](https://preview.redd.it/dd5g6ly4v69f1.png?width=1904&format=png&auto=webp&s=a6925405bc7b5a9930fa9265adc3f425129579d8)

Although these findings alone do not paint an over-all picture of Himalayan expedition success or failure, I believe they play a significant part and could be used practically to assess conditions going into spring/summer expeditions. 

I hope this is interesting and feel free to provide any feedback. I am not a data scientist by professional and still learning. This analysis was done in Python using a jupyter notebook.",13,10,2025-06-26T03:17:02+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lkpnkk/preexpedition_weather_conditions_and_success/,"Pre-Expedition Weather Conditions and Success Rates: Seasonal Pattern Analysis of Himalayan Expedition Data After someone posted Himalayan expedition data on Kaggle: [Himalayan Expeditions](https://www.kaggle.com/datasets/siddharth0935/himalayan-expeditions), I decided to start a personal project and expand on this data by adding ERA5 historical reanalysis weather data to it. Some of my preliminary findings have been interesting so far and I thought I would share them.  
  
I expanded on the expedition data by creating multiple different weather windows:

* Full expedition from basecamp date until termination either following summit or termination of attempt.
* Pre-expedition weather - 14 days prior to official expedition start at basecamp.
* Termination or Summit approach - the day before termination or summit.
* Early phase - the first 14 days at basecamp.
* Late phase - 7 days prior to termination date (either after summit or on failed attempt.)
* Decision window - 2 days prior to summit window

The first weather that I have focused on analyzing is the pre-expedition weather window. After cleaning the data and adding the weather windows, I also added a few other features using simple operations and created a few target variables for later modelling like expedition success score, expedition failure score, and an overall expedition score. For this analysis, though, I only focused on success being either True or False. After creating the features and targets, I then ran t-tests on success being True or False to determine their statistical significance. 

When looking at all the features related to the pre-expedition weather window, the findings seem to suggest that pre-expedition weather conditions play a significant role in Himalayan expedition success or failure in spring/summer expeditions. The graphs and correlation heatmap below summarize the variables that have the highest significance in either success or failure:  


[This diagram shows how the different attributes either contribute to success or failure.](https://preview.redd.it/6nbr99uzu69f1.png?width=1904&format=png&auto=webp&s=f84e3cb76b2d61d3b3e68dc3fdd0eec2608cd586)

[This diagram highlights the key attributes over or under of a significance of 0.2 or -0.2 respectively. ](https://preview.redd.it/bzj3uxu2v69f1.png?width=1889&format=png&auto=webp&s=5287852c5a90ae75b251826e1a9668db0ca34d80)

[This is a correlation heatmap diagram associating the attributes to success or failure.](https://preview.redd.it/dd5g6ly4v69f1.png?width=1904&format=png&auto=webp&s=a6925405bc7b5a9930fa9265adc3f425129579d8)

Although these findings alone do not paint an over-all picture of Himalayan expedition success or failure, I believe they play a significant part and could be used practically to assess conditions going into spring/summer expeditions. 

I hope this is interesting and feel free to provide any feedback. I am not a data scientist by professional and still learning. This analysis was done in Python using a jupyter notebook.",preexpedition weather conditions and success rates seasonal pattern analysis of himalayan expedition data after someone posted himalayan expedition data on kaggle i decided to start a personal project and expand on this data by adding era historical reanalysis weather data to it some of my preliminary findings have been interesting so far and i thought i would share them i expanded on the expedition data by creating multiple different weather windows full expedition from basecamp date until termination either following summit or termination of attempt preexpedition weather days prior to official expedition start at basecamp termination or summit approach the day before termination or summit early phase the first days at basecamp late phase days prior to termination date either after summit or on failed attempt decision window days prior to summit window the first weather that i have focused on analyzing is the preexpedition weather window after cleaning the data and adding the weather windows i also added a few other features using simple operations and created a few target variables for later modelling like expedition success score expedition failure score and an overall expedition score for this analysis though i only focused on success being either true or false after creating the features and targets i then ran ttests on success being true or false to determine their statistical significance when looking at all the features related to the preexpedition weather window the findings seem to suggest that preexpedition weather conditions play a significant role in himalayan expedition success or failure in springsummer expeditions the graphs and correlation heatmap below summarize the variables that have the highest significance in either success or failure although these findings alone do not paint an overall picture of himalayan expedition success or failure i believe they play a significant part and could be used practically to assess conditions going into springsummer expeditions i hope this is interesting and feel free to provide any feedback i am not a data scientist by professional and still learning this analysis was done in python using a jupyter notebook,preexpedition weather condition success rate seasonal pattern analysis himalayan expedition datum post himalayan expedition datum kaggle decide start personal project expand datum add era historical reanalysis weather datum preliminary finding interesting far think share expand expedition datum create multiple different weather window expedition basecamp date termination follow summit termination attempt preexpedition weather day prior official expedition start basecamp termination summit approach day termination summit early phase day basecamp late phase day prior termination date summit fail attempt decision window day prior summit window weather focus analyze preexpedition weather window clean datum add weather window add feature simple operation create target variable later modelling like expedition success score expedition failure score overall expedition score analysis focus success true false create feature target run ttest success true false determine statistical significance look feature relate preexpedition weather window finding suggest preexpedition weather condition play significant role himalayan expedition success failure springsummer expedition graph correlation heatmap summarize variable high significance success failure finding paint overall picture himalayan expedition success failure believe play significant practically assess condition go springsummer expedition hope interesting feel free provide feedback data scientist professional learn analysis python jupyt notebook
1lkjxmr,Steam Recommender using Vectors! (Student Project),"Hello Data Enjoyers!

I have recently created a steam game finder that helps users find games similar to their own favorite game,

I pulled reviews form multiple sources then used sentiment with some regex to help me find insightful ones then with some procedural tag generation along with a hierarchical genre umbrella tree i created game vectors in category trees, to traverse my db I use vector similarity and walk up my hierarchical tree.

my goal is to create a tool to help me and hopefully many others find games not by relevancy but purely by similarity. Ideally as I work on it finding hidden gems will be easy.

I created this project to prepare for my software engineering final in undergrad so its **very rough**, this is not a finished product at all by any means. **Let me know** if there are any features you would like to see or suggest some algorithms to incorporate.

check it out on : [https://nextsteamgame.com/](https://nextsteamgame.com/)",143,40,2025-06-25T22:44:09+00:00,datascience,https://www.reddit.com/gallery/1lkjxmr,"Steam Recommender using Vectors! (Student Project) Hello Data Enjoyers!

I have recently created a steam game finder that helps users find games similar to their own favorite game,

I pulled reviews form multiple sources then used sentiment with some regex to help me find insightful ones then with some procedural tag generation along with a hierarchical genre umbrella tree i created game vectors in category trees, to traverse my db I use vector similarity and walk up my hierarchical tree.

my goal is to create a tool to help me and hopefully many others find games not by relevancy but purely by similarity. Ideally as I work on it finding hidden gems will be easy.

I created this project to prepare for my software engineering final in undergrad so its **very rough**, this is not a finished product at all by any means. **Let me know** if there are any features you would like to see or suggest some algorithms to incorporate.

check it out on : [https://nextsteamgame.com/](https://nextsteamgame.com/)",steam recommender using vectors student project hello data enjoyers i have recently created a steam game finder that helps users find games similar to their own favorite game i pulled reviews form multiple sources then used sentiment with some regex to help me find insightful ones then with some procedural tag generation along with a hierarchical genre umbrella tree i created game vectors in category trees to traverse my db i use vector similarity and walk up my hierarchical tree my goal is to create a tool to help me and hopefully many others find games not by relevancy but purely by similarity ideally as i work on it finding hidden gems will be easy i created this project to prepare for my software engineering final in undergrad so its very rough this is not a finished product at all by any means let me know if there are any features you would like to see or suggest some algorithms to incorporate check it out on,steam recommender vector student project hello data enjoyer recently create steam game finder help user find game similar favorite game pull review form multiple source sentiment regex help find insightful one procedural tag generation hierarchical genre umbrella tree create game vector category tree traverse db use vector similarity walk hierarchical tree goal create tool help hopefully find game relevancy purely similarity ideally work find hide gem easy create project prepare software engineering final undergrad rough finished product mean let know feature like suggest algorithm incorporate check
1lkfg6w,How long/which things as a HM you would expect a candidate to speak for in Behavioral interviews?,"How long/which things as a HM you would expect a candidate to speak for in Behavioral interviews?  Anything important you want them to share or things that they share make them stand out from other candidates for offer? Also things they mention/not mention make them on rejection list? 


Also, is 2-3 minutes stories good enough? Or are they too short?  (For me STAR method complete stories in 2 minutes unless i add unnecessary details that are not asked) 

i tend to be person who answer only things you asked, should I change this method?. Like if you ask whether i did project on worked on stake holders t


Any other things you would like to share for DS behavioral interviews",9,7,2025-06-25T19:43:38+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lkfg6w/how_longwhich_things_as_a_hm_you_would_expect_a/,"How long/which things as a HM you would expect a candidate to speak for in Behavioral interviews? How long/which things as a HM you would expect a candidate to speak for in Behavioral interviews?  Anything important you want them to share or things that they share make them stand out from other candidates for offer? Also things they mention/not mention make them on rejection list? 


Also, is 2-3 minutes stories good enough? Or are they too short?  (For me STAR method complete stories in 2 minutes unless i add unnecessary details that are not asked) 

i tend to be person who answer only things you asked, should I change this method?. Like if you ask whether i did project on worked on stake holders t


Any other things you would like to share for DS behavioral interviews",how longwhich things as a hm you would expect a candidate to speak for in behavioral interviews how longwhich things as a hm you would expect a candidate to speak for in behavioral interviews anything important you want them to share or things that they share make them stand out from other candidates for offer also things they mentionnot mention make them on rejection list also is minutes stories good enough or are they too short for me star method complete stories in minutes unless i add unnecessary details that are not asked i tend to be person who answer only things you asked should i change this method like if you ask whether i did project on worked on stake holders t any other things you would like to share for ds behavioral interviews,longwhich thing hm expect candidate speak behavioral interview longwhich thing hm expect candidate speak behavioral interview important want share thing share stand candidate offer thing mentionnot mention rejection list minute story good short star method complete story minute add unnecessary detail ask tend person answer thing ask change method like ask project work stake holder t thing like share ds behavioral interview
1ljsd1j,Graduating Soon — Any Tips for Landing an Entry-Level Data Science Job?,"Hey everyone — I'm finishing up my MSc in Data Science this fall (Fall 2025). I also have a BSc in Computer Science and completed 2–3 relevant tech internships.

I’m starting to plan my job hunt and would love to hear from working data scientists or others in the field:

* Should I be applying in bulk to everything I qualify for, or focus on tailoring my resume with ATS keywords?
* Are there other strategies that helped you break into the field?
* What do you wish someone had told you when you were job hunting?
* Is it even heard of fresh graduates landing data roles?

I know the market’s tough right now, so I want to be as strategic as possible. Any advice is appreciated — thanks!",179,99,2025-06-25T00:59:41+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ljsd1j/graduating_soon_any_tips_for_landing_an/,"Graduating Soon — Any Tips for Landing an Entry-Level Data Science Job? Hey everyone — I'm finishing up my MSc in Data Science this fall (Fall 2025). I also have a BSc in Computer Science and completed 2–3 relevant tech internships.

I’m starting to plan my job hunt and would love to hear from working data scientists or others in the field:

* Should I be applying in bulk to everything I qualify for, or focus on tailoring my resume with ATS keywords?
* Are there other strategies that helped you break into the field?
* What do you wish someone had told you when you were job hunting?
* Is it even heard of fresh graduates landing data roles?

I know the market’s tough right now, so I want to be as strategic as possible. Any advice is appreciated — thanks!",graduating soon any tips for landing an entrylevel data science job hey everyone im finishing up my msc in data science this fall fall i also have a bsc in computer science and completed relevant tech internships im starting to plan my job hunt and would love to hear from working data scientists or others in the field should i be applying in bulk to everything i qualify for or focus on tailoring my resume with ats keywords are there other strategies that helped you break into the field what do you wish someone had told you when you were job hunting is it even heard of fresh graduates landing data roles i know the markets tough right now so i want to be as strategic as possible any advice is appreciated thanks,graduate soon tip land entrylevel datum science job hey m finish msc data science fall fall bsc computer science complete relevant tech internship m start plan job hunt love hear work datum scientist field apply bulk qualify focus tailor resume at keyword strategy help break field wish tell job hunting hear fresh graduate land datum role know market tough right want strategic possible advice appreciate thank
1ljs8wq,Masters in DS/CS/ML/AI inquiry,"For those of you that had a BS in CS then went to pursue a masters degree in CS, Ai, ML or similar how much was the benefit of this masters? 

Were there things you learned besides ML theory and application that you could not have learned in the industry?

Did this open additional doors for you versus just working as a data scientist or ML engineer without a masters?

Thanks",10,10,2025-06-25T00:54:04+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ljs8wq/masters_in_dscsmlai_inquiry/,"Masters in DS/CS/ML/AI inquiry For those of you that had a BS in CS then went to pursue a masters degree in CS, Ai, ML or similar how much was the benefit of this masters? 

Were there things you learned besides ML theory and application that you could not have learned in the industry?

Did this open additional doors for you versus just working as a data scientist or ML engineer without a masters?

Thanks",masters in dscsmlai inquiry for those of you that had a bs in cs then went to pursue a masters degree in cs ai ml or similar how much was the benefit of this masters were there things you learned besides ml theory and application that you could not have learned in the industry did this open additional doors for you versus just working as a data scientist or ml engineer without a masters thanks,master dscsmlai inquiry bs cs go pursue masters degree cs ai ml similar benefit master thing learn ml theory application learn industry open additional door versus work data scientist ml engineer master thank
1ljp64t,How much time do you spend designing your ML/DS problems before starting?,"Not sure if this is a low effort question but working in the industry I am starting to think I am not spending enough time designing the problem by addressing how I will build training, validation, test sets. Identifying the model candidates. Identifying sources of data to build features. Designing end to end pipeline for my end result to be consumed.

In my opinion this is not spoken about enough and I am curious how much time some of you spend and what you focus to address?

Thanks",19,22,2025-06-24T22:34:41+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ljp64t/how_much_time_do_you_spend_designing_your_mlds/,"How much time do you spend designing your ML/DS problems before starting? Not sure if this is a low effort question but working in the industry I am starting to think I am not spending enough time designing the problem by addressing how I will build training, validation, test sets. Identifying the model candidates. Identifying sources of data to build features. Designing end to end pipeline for my end result to be consumed.

In my opinion this is not spoken about enough and I am curious how much time some of you spend and what you focus to address?

Thanks",how much time do you spend designing your mlds problems before starting not sure if this is a low effort question but working in the industry i am starting to think i am not spending enough time designing the problem by addressing how i will build training validation test sets identifying the model candidates identifying sources of data to build features designing end to end pipeline for my end result to be consumed in my opinion this is not spoken about enough and i am curious how much time some of you spend and what you focus to address thanks,time spend design mld problem start sure low effort question work industry start think spend time design problem address build training validation test set identify model candidate identify source datum build feature designing end end pipeline end result consume opinion speak curious time spend focus address thank
1ljiuzx,A Breakdown of RAG vs CAG,"I work at a company that does a lot of RAG work, and a lot of our customers have been asking us about CAG. I thought I might break down the difference of the two approaches.

RAG (retrieval augmented generation) Includes the following general steps:

* retrieve context based on a users prompt
* construct an augmented prompt by combining the users question with retrieved context (basically just string formatting)
* generate a response by passing the augmented prompt to the LLM

We know it, we love it. While RAG can get fairly complex (document parsing, different methods of retrieval source assignment, etc), it's conceptually pretty straight forward.

[A conceptual diagram of RAG, from an article I wrote on the subject \(IAEE RAG\).](https://preview.redd.it/izh2zrta0x8f1.png?width=800&format=png&auto=webp&s=2beb6557c45ffc3221a6d0cda78d5674ffddb487)

CAG, on the other hand, is a bit more complex. It uses the idea of LLM caching to pre-process references such that they can be injected into a language model at minimal cost.

First, you feed the context into the model:

[Feed context into the model. From an article I wrote on CAG \(IAEE CAG\).](https://preview.redd.it/5zw54o9j1x8f1.png?width=1500&format=png&auto=webp&s=27e46efa7ef7a467834558c511954f603b94f224)

Then, you can store the internal representation of the context as a cache, which can then be used to answer a query.

[pre-computed internal representations of context can be saved, allowing the model to more efficiently leverage that data when answering queries. From an article I wrote on CAG \(IAEE CAG\).](https://preview.redd.it/jfznfh2p1x8f1.png?width=1456&format=png&auto=webp&s=da7c17029235ca3fceaa2880a14f095badef9bb3)

So, while the names are similar, CAG really only concerns the augmentation and generation pipeline, not the entire RAG pipeline. If you have a relatively small knowledge base you may be able to cache the entire thing in the context window of an LLM, or you might not.

Personally, I would say CAG is compelling if:

* The context can always be at the beginning of the prompt
* The information presented in the context is static
* The entire context can fit in the context window of the LLM, with room to spare.

Otherwise, I think RAG makes more sense.

If you pass all your chunks through the LLM prior, you can use CAG as caching layer on top of a RAG pipeline, allowing you to get the best of both worlds (admittedly, with increased complexity).

[From the RAG vs CAG article.](https://preview.redd.it/lc6ku69g3x8f1.png?width=1880&format=png&auto=webp&s=01c59fae3b9daf0b1554a5cb139375fed353d570)

I filmed a [video](https://www.youtube.com/watch?v=HqJ-KDPE6PY) recently on the differences of RAG vs CAG if you want to know more.

Sources:  
\- [RAG vs CAG video](https://www.youtube.com/watch?v=HqJ-KDPE6PY)  
\- [RAG vs CAG Article](https://www.eyelevel.ai/post/rag-vs-cag)  
\- [RAG IAEE](https://iaee.substack.com/p/retrieval-augmented-generation-intuitively-and-exhaustively-explain-6a39d6fe6fc9?utm_source=publication-search)  
\- [CAG IAEE](https://iaee.substack.com/p/cache-augmented-generation-intuitively?utm_source=publication-search)",44,7,2025-06-24T18:25:57+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ljiuzx/a_breakdown_of_rag_vs_cag/,"A Breakdown of RAG vs CAG I work at a company that does a lot of RAG work, and a lot of our customers have been asking us about CAG. I thought I might break down the difference of the two approaches.

RAG (retrieval augmented generation) Includes the following general steps:

* retrieve context based on a users prompt
* construct an augmented prompt by combining the users question with retrieved context (basically just string formatting)
* generate a response by passing the augmented prompt to the LLM

We know it, we love it. While RAG can get fairly complex (document parsing, different methods of retrieval source assignment, etc), it's conceptually pretty straight forward.

[A conceptual diagram of RAG, from an article I wrote on the subject \(IAEE RAG\).](https://preview.redd.it/izh2zrta0x8f1.png?width=800&format=png&auto=webp&s=2beb6557c45ffc3221a6d0cda78d5674ffddb487)

CAG, on the other hand, is a bit more complex. It uses the idea of LLM caching to pre-process references such that they can be injected into a language model at minimal cost.

First, you feed the context into the model:

[Feed context into the model. From an article I wrote on CAG \(IAEE CAG\).](https://preview.redd.it/5zw54o9j1x8f1.png?width=1500&format=png&auto=webp&s=27e46efa7ef7a467834558c511954f603b94f224)

Then, you can store the internal representation of the context as a cache, which can then be used to answer a query.

[pre-computed internal representations of context can be saved, allowing the model to more efficiently leverage that data when answering queries. From an article I wrote on CAG \(IAEE CAG\).](https://preview.redd.it/jfznfh2p1x8f1.png?width=1456&format=png&auto=webp&s=da7c17029235ca3fceaa2880a14f095badef9bb3)

So, while the names are similar, CAG really only concerns the augmentation and generation pipeline, not the entire RAG pipeline. If you have a relatively small knowledge base you may be able to cache the entire thing in the context window of an LLM, or you might not.

Personally, I would say CAG is compelling if:

* The context can always be at the beginning of the prompt
* The information presented in the context is static
* The entire context can fit in the context window of the LLM, with room to spare.

Otherwise, I think RAG makes more sense.

If you pass all your chunks through the LLM prior, you can use CAG as caching layer on top of a RAG pipeline, allowing you to get the best of both worlds (admittedly, with increased complexity).

[From the RAG vs CAG article.](https://preview.redd.it/lc6ku69g3x8f1.png?width=1880&format=png&auto=webp&s=01c59fae3b9daf0b1554a5cb139375fed353d570)

I filmed a [video](https://www.youtube.com/watch?v=HqJ-KDPE6PY) recently on the differences of RAG vs CAG if you want to know more.

Sources:  
\- [RAG vs CAG video](https://www.youtube.com/watch?v=HqJ-KDPE6PY)  
\- [RAG vs CAG Article](https://www.eyelevel.ai/post/rag-vs-cag)  
\- [RAG IAEE](https://iaee.substack.com/p/retrieval-augmented-generation-intuitively-and-exhaustively-explain-6a39d6fe6fc9?utm_source=publication-search)  
\- [CAG IAEE](https://iaee.substack.com/p/cache-augmented-generation-intuitively?utm_source=publication-search)",a breakdown of rag vs cag i work at a company that does a lot of rag work and a lot of our customers have been asking us about cag i thought i might break down the difference of the two approaches rag retrieval augmented generation includes the following general steps retrieve context based on a users prompt construct an augmented prompt by combining the users question with retrieved context basically just string formatting generate a response by passing the augmented prompt to the llm we know it we love it while rag can get fairly complex document parsing different methods of retrieval source assignment etc its conceptually pretty straight forward cag on the other hand is a bit more complex it uses the idea of llm caching to preprocess references such that they can be injected into a language model at minimal cost first you feed the context into the model then you can store the internal representation of the context as a cache which can then be used to answer a query so while the names are similar cag really only concerns the augmentation and generation pipeline not the entire rag pipeline if you have a relatively small knowledge base you may be able to cache the entire thing in the context window of an llm or you might not personally i would say cag is compelling if the context can always be at the beginning of the prompt the information presented in the context is static the entire context can fit in the context window of the llm with room to spare otherwise i think rag makes more sense if you pass all your chunks through the llm prior you can use cag as caching layer on top of a rag pipeline allowing you to get the best of both worlds admittedly with increased complexity i filmed a recently on the differences of rag vs cag if you want to know more sources,breakdown rag vs cag work company lot rag work lot customer ask cag think break difference approach rag retrieval augmented generation include follow general step retrieve context base user prompt construct augmented prompt combine user question retrieve context basically stre format generate response pass augmented prompt llm know love rag fairly complex document parse different method retrieval source assignment etc conceptually pretty straight forward cag hand bit complex use idea llm cache preprocess reference inject language model minimal cost feed context model store internal representation context cache answer query name similar cag concern augmentation generation pipeline entire rag pipeline relatively small knowledge base able cache entire thing context window llm personally cag compelling context beginning prompt information present context static entire context fit context window llm room spare think rag make sense pass chunk llm prior use cag cache layer rag pipeline allow good world admittedly increase complexity film recently difference rag vs cag want know source
1ljhuda,How to tell the difference between whether managers are embracing reality of AI or buying into hype?,"I work in data science with a skillset that comprises of data science, data engineering and analytics. My team seems to want to eventually make my role completely non-technical (I'm not sure what a non-technical role would entail). The reason is because there's a feeling all the technical aspects will be completely eliminated by AI. The rationale, in theory, makes sense - we focus on the human aspects of our work, which is to develop solutions that can clearly be transferred to a fully technical team or AI to do the job for us. 

The reality in my experience is that this makes a strong assumptions data processes have the capacity to fit cleanly and neatly into something like a written prompt that can easily be given to somebody or AI with no 'context' to develop. I don't feel like in my work, our processes are there yet....like at all. Some things, maybe, but most things no. I also feel I'm navigating a lot of ever evolving priorities, stakeholder needs, conflicting advice (do this, no revert this, do this, rinse, repeat). This is making my job honestly frustrating and burning me out FAST. I'm working 12 hour days, sometimes up to 3 AM. My technical skills are deteriorating and I feel like my mind is becoming into a fried egg. Don't have time or energy to do anything to upskill.

On one hand, I'm not sure if management has a point - if I let go of the 'technical' parts that I like b/c of AI and instead just focus on more of the 'other stuff', would I have more growth, opportunity and salary increase in my career? Or is it better off to have a balance between those skills and the technical aspects? In an ideal world, I want to be able to have a good compromise between subject matter and technical skills and have a job where I get to do a bit of both. I'm not sure if the narrative I'm hearing is one of hype or reality. Would be interested in hearing thoughts. ",25,23,2025-06-24T17:47:58+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ljhuda/how_to_tell_the_difference_between_whether/,"How to tell the difference between whether managers are embracing reality of AI or buying into hype? I work in data science with a skillset that comprises of data science, data engineering and analytics. My team seems to want to eventually make my role completely non-technical (I'm not sure what a non-technical role would entail). The reason is because there's a feeling all the technical aspects will be completely eliminated by AI. The rationale, in theory, makes sense - we focus on the human aspects of our work, which is to develop solutions that can clearly be transferred to a fully technical team or AI to do the job for us. 

The reality in my experience is that this makes a strong assumptions data processes have the capacity to fit cleanly and neatly into something like a written prompt that can easily be given to somebody or AI with no 'context' to develop. I don't feel like in my work, our processes are there yet....like at all. Some things, maybe, but most things no. I also feel I'm navigating a lot of ever evolving priorities, stakeholder needs, conflicting advice (do this, no revert this, do this, rinse, repeat). This is making my job honestly frustrating and burning me out FAST. I'm working 12 hour days, sometimes up to 3 AM. My technical skills are deteriorating and I feel like my mind is becoming into a fried egg. Don't have time or energy to do anything to upskill.

On one hand, I'm not sure if management has a point - if I let go of the 'technical' parts that I like b/c of AI and instead just focus on more of the 'other stuff', would I have more growth, opportunity and salary increase in my career? Or is it better off to have a balance between those skills and the technical aspects? In an ideal world, I want to be able to have a good compromise between subject matter and technical skills and have a job where I get to do a bit of both. I'm not sure if the narrative I'm hearing is one of hype or reality. Would be interested in hearing thoughts. ",how to tell the difference between whether managers are embracing reality of ai or buying into hype i work in data science with a skillset that comprises of data science data engineering and analytics my team seems to want to eventually make my role completely nontechnical im not sure what a nontechnical role would entail the reason is because theres a feeling all the technical aspects will be completely eliminated by ai the rationale in theory makes sense we focus on the human aspects of our work which is to develop solutions that can clearly be transferred to a fully technical team or ai to do the job for us the reality in my experience is that this makes a strong assumptions data processes have the capacity to fit cleanly and neatly into something like a written prompt that can easily be given to somebody or ai with no context to develop i dont feel like in my work our processes are there yetlike at all some things maybe but most things no i also feel im navigating a lot of ever evolving priorities stakeholder needs conflicting advice do this no revert this do this rinse repeat this is making my job honestly frustrating and burning me out fast im working hour days sometimes up to am my technical skills are deteriorating and i feel like my mind is becoming into a fried egg dont have time or energy to do anything to upskill on one hand im not sure if management has a point if i let go of the technical parts that i like bc of ai and instead just focus on more of the other stuff would i have more growth opportunity and salary increase in my career or is it better off to have a balance between those skills and the technical aspects in an ideal world i want to be able to have a good compromise between subject matter and technical skills and have a job where i get to do a bit of both im not sure if the narrative im hearing is one of hype or reality would be interested in hearing thoughts,tell difference manager embrace reality ai buy hype work datum science skillset comprise datum science datum engineering analytic team want eventually role completely nontechnical m sure nontechnical role entail reason s feeling technical aspect completely eliminate ai rationale theory make sense focus human aspect work develop solution clearly transfer fully technical team ai job reality experience make strong assumption data process capacity fit cleanly neatly like write prompt easily give somebody ai context develop not feel like work process yetlike thing maybe thing feel m navigate lot evolve priority stakeholder need conflict advice revert rinse repeat make job honestly frustrating burn fast m work hour day technical skill deteriorate feel like mind fried egg not time energy upskill hand m sure management point let technical part like bc ai instead focus stuff growth opportunity salary increase career well balance skill technical aspect ideal world want able good compromise subject matter technical skill job bit m sure narrative m hear hype reality interested hear thought
1ljhav8,Has anyone prepared for Doordash DS interview? Looking for tips and resources,"I have phone screen coming up in 2 weeks. I feel okay about SQL part, but I am quite worried about the product case study, particularly the questions that may include A/B testing. 

Do you have any resources for studying A/B testing to crack the interview?",40,17,2025-06-24T17:27:54+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ljhav8/has_anyone_prepared_for_doordash_ds_interview/,"Has anyone prepared for Doordash DS interview? Looking for tips and resources I have phone screen coming up in 2 weeks. I feel okay about SQL part, but I am quite worried about the product case study, particularly the questions that may include A/B testing. 

Do you have any resources for studying A/B testing to crack the interview?",has anyone prepared for doordash ds interview looking for tips and resources i have phone screen coming up in weeks i feel okay about sql part but i am quite worried about the product case study particularly the questions that may include ab testing do you have any resources for studying ab testing to crack the interview,prepare doordash ds interview look tip resource phone screen come week feel okay sql worried product case study particularly question include ab testing resource study ab testing crack interview
1ljg8dx,Why would anyone try to win Kaggle's challenges?,"Per title. Go to Kaggle right now and look at the top competitions featuring monetary prizes. Like you have to predict folded protein structures and polymers properties within 3 months? Those are ground breaking problems which to me would probably require years of academic effort without any guarantee of success. And IF you win you get what, 50000$, not even a year salary in most positions, and you have to split it with your team? Like even if you are capable of actually solving some of these challenges why would you ever share them as Kaggle public notebook or give IP to the challenge sponsor?",388,77,2025-06-24T16:47:46+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ljg8dx/why_would_anyone_try_to_win_kaggles_challenges/,"Why would anyone try to win Kaggle's challenges? Per title. Go to Kaggle right now and look at the top competitions featuring monetary prizes. Like you have to predict folded protein structures and polymers properties within 3 months? Those are ground breaking problems which to me would probably require years of academic effort without any guarantee of success. And IF you win you get what, 50000$, not even a year salary in most positions, and you have to split it with your team? Like even if you are capable of actually solving some of these challenges why would you ever share them as Kaggle public notebook or give IP to the challenge sponsor?",why would anyone try to win kaggles challenges per title go to kaggle right now and look at the top competitions featuring monetary prizes like you have to predict folded protein structures and polymers properties within months those are ground breaking problems which to me would probably require years of academic effort without any guarantee of success and if you win you get what not even a year salary in most positions and you have to split it with your team like even if you are capable of actually solving some of these challenges why would you ever share them as kaggle public notebook or give ip to the challenge sponsor,try win kaggle challenge title kaggle right look competition feature monetary prize like predict fold protein structure polymer property month grind break problem probably require year academic effort guarantee success win year salary position split team like capable actually solve challenge share kaggle public notebook ip challenge sponsor
1lirxxw,"Does anybody remember the old Python logo?  Honestly, I've only been using Python since 2018, so I didn't recall that this ever existed.",,206,17,2025-06-23T20:46:06+00:00,datascience,https://i.redd.it/v3elvap9oq8f1.png,"Does anybody remember the old Python logo?  Honestly, I've only been using Python since 2018, so I didn't recall that this ever existed. ",does anybody remember the old python logo honestly ive only been using python since so i didnt recall that this ever existed,anybody remember old python logo honestly ve python not recall exist
1libni7,Which workflow to avoid using notebooks?,"I have always used notebooks for data science.
I often do EDA and experiments in notebooks before refactoring it properly to module, api etc.

Recently my manager is pushing the team to move away from notebook because it favor bad code practice and take more time to rewrite the code.

But I am quite confused how to proceed without using notebook. 

How are you doing a data science project from eda, analysis, data viz etc to final api/reports without using notebook?

Thanks a lot for your advice.",94,61,2025-06-23T08:55:43+00:00,datascience,https://www.reddit.com/r/datascience/comments/1libni7/which_workflow_to_avoid_using_notebooks/,"Which workflow to avoid using notebooks? I have always used notebooks for data science.
I often do EDA and experiments in notebooks before refactoring it properly to module, api etc.

Recently my manager is pushing the team to move away from notebook because it favor bad code practice and take more time to rewrite the code.

But I am quite confused how to proceed without using notebook. 

How are you doing a data science project from eda, analysis, data viz etc to final api/reports without using notebook?

Thanks a lot for your advice.",which workflow to avoid using notebooks i have always used notebooks for data science i often do eda and experiments in notebooks before refactoring it properly to module api etc recently my manager is pushing the team to move away from notebook because it favor bad code practice and take more time to rewrite the code but i am quite confused how to proceed without using notebook how are you doing a data science project from eda analysis data viz etc to final apireports without using notebook thanks a lot for your advice,workflow avoid notebook notebook data science eda experiment notebook refactore properly module api etc recently manager push team away notebook favor bad code practice time rewrite code confused proceed notebook data science project eda analysis datum viz etc final apireport notebook thank lot advice
1li722k,"Weekly Entering & Transitioning - Thread 23 Jun, 2025 - 30 Jun, 2025"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",12,57,2025-06-23T04:01:34+00:00,datascience,https://www.reddit.com/r/datascience/comments/1li722k/weekly_entering_transitioning_thread_23_jun_2025/,"Weekly Entering & Transitioning - Thread 23 Jun, 2025 - 30 Jun, 2025  

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",weekly entering transitioning thread jun jun welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the and resources pages on our wiki you can also search for answers in,weekly enter transition thread jun jun welcome week enter transition thread thread question getting start study transition data science field topic include learn resource eg book tutorial video traditional education eg schools degree elective alternative education eg online course bootcamp job search question eg resume apply career prospect elementary question eg start wait answer community check resource page wiki search answer
1li6e4v,Would you do this job if you were rich enough to retire?,"Curious your perspective on this. Many of us got into the field because it was lucrative and ensures a stable living,

But it also is intrinsically interesting to study and challenge yourself. The personalities attracted to tech are often fun and make work not so bad. It’s fun to build, experiment, and be in a role where that is expected!

But what if you had enough money to retire? What would you do? Quit and do something else? Keep doing it? Consult? Curious your reasons and thoughts here!",94,98,2025-06-23T03:24:36+00:00,datascience,https://www.reddit.com/r/datascience/comments/1li6e4v/would_you_do_this_job_if_you_were_rich_enough_to/,"Would you do this job if you were rich enough to retire? Curious your perspective on this. Many of us got into the field because it was lucrative and ensures a stable living,

But it also is intrinsically interesting to study and challenge yourself. The personalities attracted to tech are often fun and make work not so bad. It’s fun to build, experiment, and be in a role where that is expected!

But what if you had enough money to retire? What would you do? Quit and do something else? Keep doing it? Consult? Curious your reasons and thoughts here!",would you do this job if you were rich enough to retire curious your perspective on this many of us got into the field because it was lucrative and ensures a stable living but it also is intrinsically interesting to study and challenge yourself the personalities attracted to tech are often fun and make work not so bad its fun to build experiment and be in a role where that is expected but what if you had enough money to retire what would you do quit and do something else keep doing it consult curious your reasons and thoughts here,job rich retire curious perspective get field lucrative ensure stable living intrinsically interesting study challenge personality attract tech fun work bad fun build experiment role expect money retire quit consult curious reason thought
1lhuk01,I have run DS interviews and wow!,"Hey all,
I have been responsible for technical interviews for a Data Scientist position and the experience was quite surprising to me. I thought some of you may appreciate some insights.

A few disclaimers: I have no previous experience running interviews and have had no training at all so I have just gone with my intuition and any input from the hiring manager. As for my own competencies, I do hold a Master’s degree that I only just graduated from and have no full-time work experience, so I went into this with severe imposter syndrome as I do just holding a DS title myself. But after all, as the only data scientist, I was the most qualified for the task.

For the interviews I was basically just tasked with getting a feeling of the technical skills of the candidates. I decided to write a simple predictive modeling case with no real requirements besides the solution being a notebook. I expected to see some simple solutions that would focus on well-structured modeling and sound generalization. No crazy accuracy or super sophisticated models.

For all interviews the candidate would run through his/her solution from data being loaded to test accuracy. I would then shoot some questions related to the decisions that were made. This is what stood out to me:

1. Very few candidates really knew of other approaches to sorting out missing values than whatever approach they had taken. They also didn’t really know what the pros/cons are of imputing rather than dropping data. Also, only a single candidate could explain why it is problematic to make the imputation before splitting the data.

2. Very few candidates were familiar with the concept of class imbalance.

3. For encoding of categorical variables, most candidates would either know of label or one-hot and no alternatives, they also didn’t know of any potential drawbacks of either one.

4. Not all candidates were familiar with cross-validation

5. For model training very few candidates could really explain how they made their choice on optimization metric, what exactly it measured, or how different ones could be used for different tasks.

Overall the vast majority of candidates had an extremely superficial understanding of ML fundamentals and didn’t really seem to have any sense for their lack of knowledge.
I am not entirely sure what went wrong. My guesses are that either the recruiter that sent candidates my way did a poor job with the screening. Perhaps my expectations are just too unrealistic, however I really hope that is not the case. My best guess is that the Data Scientist title is rapidly being diluted to a state where it is perfectly fine to not really know any ML.
I am not joking - only two candidates could confidently explain all of their decisions to me and demonstrate knowledge of alternative approaches while not leaking data.

Would love to hear some perspectives. Is this a common experience?
",820,280,2025-06-22T18:13:21+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lhuk01/i_have_run_ds_interviews_and_wow/,"I have run DS interviews and wow! Hey all,
I have been responsible for technical interviews for a Data Scientist position and the experience was quite surprising to me. I thought some of you may appreciate some insights.

A few disclaimers: I have no previous experience running interviews and have had no training at all so I have just gone with my intuition and any input from the hiring manager. As for my own competencies, I do hold a Master’s degree that I only just graduated from and have no full-time work experience, so I went into this with severe imposter syndrome as I do just holding a DS title myself. But after all, as the only data scientist, I was the most qualified for the task.

For the interviews I was basically just tasked with getting a feeling of the technical skills of the candidates. I decided to write a simple predictive modeling case with no real requirements besides the solution being a notebook. I expected to see some simple solutions that would focus on well-structured modeling and sound generalization. No crazy accuracy or super sophisticated models.

For all interviews the candidate would run through his/her solution from data being loaded to test accuracy. I would then shoot some questions related to the decisions that were made. This is what stood out to me:

1. Very few candidates really knew of other approaches to sorting out missing values than whatever approach they had taken. They also didn’t really know what the pros/cons are of imputing rather than dropping data. Also, only a single candidate could explain why it is problematic to make the imputation before splitting the data.

2. Very few candidates were familiar with the concept of class imbalance.

3. For encoding of categorical variables, most candidates would either know of label or one-hot and no alternatives, they also didn’t know of any potential drawbacks of either one.

4. Not all candidates were familiar with cross-validation

5. For model training very few candidates could really explain how they made their choice on optimization metric, what exactly it measured, or how different ones could be used for different tasks.

Overall the vast majority of candidates had an extremely superficial understanding of ML fundamentals and didn’t really seem to have any sense for their lack of knowledge.
I am not entirely sure what went wrong. My guesses are that either the recruiter that sent candidates my way did a poor job with the screening. Perhaps my expectations are just too unrealistic, however I really hope that is not the case. My best guess is that the Data Scientist title is rapidly being diluted to a state where it is perfectly fine to not really know any ML.
I am not joking - only two candidates could confidently explain all of their decisions to me and demonstrate knowledge of alternative approaches while not leaking data.

Would love to hear some perspectives. Is this a common experience?
",i have run ds interviews and wow hey all i have been responsible for technical interviews for a data scientist position and the experience was quite surprising to me i thought some of you may appreciate some insights a few disclaimers i have no previous experience running interviews and have had no training at all so i have just gone with my intuition and any input from the hiring manager as for my own competencies i do hold a masters degree that i only just graduated from and have no fulltime work experience so i went into this with severe imposter syndrome as i do just holding a ds title myself but after all as the only data scientist i was the most qualified for the task for the interviews i was basically just tasked with getting a feeling of the technical skills of the candidates i decided to write a simple predictive modeling case with no real requirements besides the solution being a notebook i expected to see some simple solutions that would focus on wellstructured modeling and sound generalization no crazy accuracy or super sophisticated models for all interviews the candidate would run through hisher solution from data being loaded to test accuracy i would then shoot some questions related to the decisions that were made this is what stood out to me very few candidates really knew of other approaches to sorting out missing values than whatever approach they had taken they also didnt really know what the proscons are of imputing rather than dropping data also only a single candidate could explain why it is problematic to make the imputation before splitting the data very few candidates were familiar with the concept of class imbalance for encoding of categorical variables most candidates would either know of label or onehot and no alternatives they also didnt know of any potential drawbacks of either one not all candidates were familiar with crossvalidation for model training very few candidates could really explain how they made their choice on optimization metric what exactly it measured or how different ones could be used for different tasks overall the vast majority of candidates had an extremely superficial understanding of ml fundamentals and didnt really seem to have any sense for their lack of knowledge i am not entirely sure what went wrong my guesses are that either the recruiter that sent candidates my way did a poor job with the screening perhaps my expectations are just too unrealistic however i really hope that is not the case my best guess is that the data scientist title is rapidly being diluted to a state where it is perfectly fine to not really know any ml i am not joking only two candidates could confidently explain all of their decisions to me and demonstrate knowledge of alternative approaches while not leaking data would love to hear some perspectives is this a common experience,run ds interview wow hey responsible technical interview data scientist position experience surprising think appreciate insight disclaimer previous experience run interview training go intuition input hire manager competency hold masters degree graduate fulltime work experience go severe impost syndrome hold ds title data scientist qualified task interview basically tasked get feeling technical skill candidate decide write simple predictive modeling case real requirement solution notebook expect simple solution focus wellstructure modeling sound generalization crazy accuracy super sophisticated model interview candidate run hisher solution datum load test accuracy shoot question relate decision stand candidate know approach sort miss value approach take not know proscon impute drop datum single candidate explain problematic imputation split datum candidate familiar concept class imbalance encoding categorical variable candidate know label onehot alternative not know potential drawback candidate familiar crossvalidation model training candidate explain choice optimization metric exactly measure different one different task overall vast majority candidate extremely superficial understanding ml fundamental not sense lack knowledge entirely sure go wrong guess recruiter send candidate way poor job screening expectation unrealistic hope case good guess data scientist title rapidly dilute state perfectly fine know ml joke candidate confidently explain decision demonstrate knowledge alternative approach leak datum love hear perspective common experience
1lhn2sb,I talked to a DS professional who told me Gen AI is going to take up the DE job,,0,14,2025-06-22T12:47:54+00:00,datascience,/r/dataengineering/comments/1lhn1x9/i_talked_to_someone_telling_gen_ai_is_going_to/,I talked to a DS professional who told me Gen AI is going to take up the DE job ,i talked to a ds professional who told me gen ai is going to take up the de job,talk ds professional tell gen ai go de job
1lgvh62,ML case study rounds,"I am asking this from context of interview. In almost every company these days, there is an ML case study round where the focus is on solving a real world case study. Idk if this is somewhat similar to ML system design or not (I think ML system design rounds are different or maybe part of case study round). Can anyone help me with resources to prepare from for this round? I am well-versed with ML theories, but never worked on solving an end to end solution from interview context. ",56,16,2025-06-21T12:32:30+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lgvh62/ml_case_study_rounds/,"ML case study rounds I am asking this from context of interview. In almost every company these days, there is an ML case study round where the focus is on solving a real world case study. Idk if this is somewhat similar to ML system design or not (I think ML system design rounds are different or maybe part of case study round). Can anyone help me with resources to prepare from for this round? I am well-versed with ML theories, but never worked on solving an end to end solution from interview context. ",ml case study rounds i am asking this from context of interview in almost every company these days there is an ml case study round where the focus is on solving a real world case study idk if this is somewhat similar to ml system design or not i think ml system design rounds are different or maybe part of case study round can anyone help me with resources to prepare from for this round i am wellversed with ml theories but never worked on solving an end to end solution from interview context,ml case study round ask context interview company day ml case study round focus solve real world case study idk somewhat similar ml system design think ml system design round different maybe case study round help resource prepare round wellverse ml theory work solve end end solution interview context
1lgt6nn,Feature Interaction Constraints in GBMs,"Hi everyone,

  
I'm curious if anyone here uses the `interaction_constraints` parameter in [XGBoost](https://xgboost.readthedocs.io/en/stable/tutorials/feature_interaction_constraint.html) or [LightGBM](https://lightgbm.readthedocs.io/en/latest/Parameters.html#interaction_constraints). In what scenarios do you find it useful and how do you typically set it up? Any real-world examples or tips would be appreciated, thanks in advance.",18,6,2025-06-21T10:12:57+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lgt6nn/feature_interaction_constraints_in_gbms/,"Feature Interaction Constraints in GBMs Hi everyone,

  
I'm curious if anyone here uses the `interaction_constraints` parameter in [XGBoost](https://xgboost.readthedocs.io/en/stable/tutorials/feature_interaction_constraint.html) or [LightGBM](https://lightgbm.readthedocs.io/en/latest/Parameters.html#interaction_constraints). In what scenarios do you find it useful and how do you typically set it up? Any real-world examples or tips would be appreciated, thanks in advance.",feature interaction constraints in gbms hi everyone im curious if anyone here uses the interactionconstraints parameter in or in what scenarios do you find it useful and how do you typically set it up any realworld examples or tips would be appreciated thanks in advance,feature interaction constraint gbms hi m curious use interactionconstraint parameter scenario find useful typically set realworld example tip appreciate thank advance
1lggtm2,What is your opinion on Julius and other ai first data science tools?,"I’m wondering what people’s opinions are on Julius and similar tools (https://julius.ai/)

Have people tried them? Are they useful or end up causing more work?",0,37,2025-06-20T22:22:05+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lggtm2/what_is_your_opinion_on_julius_and_other_ai_first/,"What is your opinion on Julius and other ai first data science tools? I’m wondering what people’s opinions are on Julius and similar tools (https://julius.ai/)

Have people tried them? Are they useful or end up causing more work?",what is your opinion on julius and other ai first data science tools im wondering what peoples opinions are on julius and similar tools have people tried them are they useful or end up causing more work,opinion julius ai datum science tool m wonder people opinion julius similar tool people try useful end cause work
1lgfmli,Toolkit to move from junior to senior data analyst (data science track),"I would like to move from data analyst to senior data analyst (SDA) in the next year or so. I have a background in marketing, but pivoted to data science four years ago, and have been learning python since then. Most of my work nowadays is either data wrangling or dashboards, with more senior people doing advanced data science thingies like PCA.

This is a list of tools I think I would need to move from junior data analyst to senior data analyst. Any feedback on if SDA is the right person for these tools is much appreciated.

Extraction
- general pandas read (csv, parquet, json)
- gzip
- iterating through directories
- hosting on AWS / Google Cloud
- various other python packages like sqlite

Wrangling
- cleaning
- merging
- regex / search
- masking
- dtype conversion
- bucketing
- ML preprocessing (hash encoding, standardizing, feature selection)

Segmentation
- PCA / SVD / ICA
- k-means / DBSCAN
- itertools segmentation

Statistics
- descriptive statistics
- AB testing: t tests, ANOVAs, chi squared
- confidence intervals

Machine learning
- model selection
- hyperparameter tuning
- scoring
- inference

Visualization
- EDA visualizations in Jupyter Lab / Colab
- final visualizations in dashboards

Deployment
- deploy and host on AWS / Google Cloud

———

Things I think are simply out of the realm of any DA, senior or not:
- recommendation systems
- neural networks
- setting up an AB test on the back end

Curious what the community would bucket into data analyst, senior data analyst, or data scientist responsibilities.",55,24,2025-06-20T21:29:24+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lgfmli/toolkit_to_move_from_junior_to_senior_data/,"Toolkit to move from junior to senior data analyst (data science track) I would like to move from data analyst to senior data analyst (SDA) in the next year or so. I have a background in marketing, but pivoted to data science four years ago, and have been learning python since then. Most of my work nowadays is either data wrangling or dashboards, with more senior people doing advanced data science thingies like PCA.

This is a list of tools I think I would need to move from junior data analyst to senior data analyst. Any feedback on if SDA is the right person for these tools is much appreciated.

Extraction
- general pandas read (csv, parquet, json)
- gzip
- iterating through directories
- hosting on AWS / Google Cloud
- various other python packages like sqlite

Wrangling
- cleaning
- merging
- regex / search
- masking
- dtype conversion
- bucketing
- ML preprocessing (hash encoding, standardizing, feature selection)

Segmentation
- PCA / SVD / ICA
- k-means / DBSCAN
- itertools segmentation

Statistics
- descriptive statistics
- AB testing: t tests, ANOVAs, chi squared
- confidence intervals

Machine learning
- model selection
- hyperparameter tuning
- scoring
- inference

Visualization
- EDA visualizations in Jupyter Lab / Colab
- final visualizations in dashboards

Deployment
- deploy and host on AWS / Google Cloud

———

Things I think are simply out of the realm of any DA, senior or not:
- recommendation systems
- neural networks
- setting up an AB test on the back end

Curious what the community would bucket into data analyst, senior data analyst, or data scientist responsibilities.",toolkit to move from junior to senior data analyst data science track i would like to move from data analyst to senior data analyst sda in the next year or so i have a background in marketing but pivoted to data science four years ago and have been learning python since then most of my work nowadays is either data wrangling or dashboards with more senior people doing advanced data science thingies like pca this is a list of tools i think i would need to move from junior data analyst to senior data analyst any feedback on if sda is the right person for these tools is much appreciated extraction general pandas read csv parquet json gzip iterating through directories hosting on aws google cloud various other python packages like sqlite wrangling cleaning merging regex search masking dtype conversion bucketing ml preprocessing hash encoding standardizing feature selection segmentation pca svd ica kmeans dbscan itertools segmentation statistics descriptive statistics ab testing t tests anovas chi squared confidence intervals machine learning model selection hyperparameter tuning scoring inference visualization eda visualizations in jupyter lab colab final visualizations in dashboards deployment deploy and host on aws google cloud things i think are simply out of the realm of any da senior or not recommendation systems neural networks setting up an ab test on the back end curious what the community would bucket into data analyst senior data analyst or data scientist responsibilities,toolkit junior senior datum analyst datum science track like datum analyst senior datum analyst sda year background marketing pivot datum science year ago learn python work nowadays datum wrangle dashboard senior people advanced data science thingie like pca list tool think need junior datum analyst senior datum analyst feedback sda right person tool appreciated extraction general panda read csv parquet json gzip iterate directory host aws google cloud python package like sqlite wrangling cleaning merge regex search masking dtype conversion bucket ml preprocesse hash encoding standardize feature selection segmentation pca svd ica kmeans dbscan itertool segmentation statistic descriptive statistic ab testing t test anovas chi square confidence interval machine learning model selection hyperparameter tuning scoring inference visualization eda visualization jupyter lab colab final visualization dashboard deployment deploy host aws google cloud thing think simply realm da senior recommendation system neural network set ab test end curious community bucket datum analyst senior datum analyst data scientist responsibility
1lgdg9j,Has anyone seen research or articles proving that code quality matters in data science projects?,"Hi all,

I'm looking for articles, studies, or real-world examples backed by data that demonstrate the value of code quality specifically in data science projects.

Most of the literature I’ve found focuses on large-scale software projects, where the codebase is big (tens of thousands of lines), the team is large (10+ developers) the expected lifetime of the product is long (10+ years).

Examples: https://arxiv.org/pdf/2203.04374

In those cases the long-term ROI of clean code and testing is clearly proven. But data science is often different: small teams, high-level languages like Python or R, and project lifespans that can be quite short.

Alternatively, I found interesting recommandations like https://martinfowler.com/articles/is-quality-worth-cost.html (article is old, but recommandations still apply) but without a lot of data backing up the claims.


Has anyone come across evidence (academic or otherwise) showing that investing in code quality, no matter how we define it, pays off in typical data science workflows?



",20,53,2025-06-20T19:57:40+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lgdg9j/has_anyone_seen_research_or_articles_proving_that/,"Has anyone seen research or articles proving that code quality matters in data science projects? Hi all,

I'm looking for articles, studies, or real-world examples backed by data that demonstrate the value of code quality specifically in data science projects.

Most of the literature I’ve found focuses on large-scale software projects, where the codebase is big (tens of thousands of lines), the team is large (10+ developers) the expected lifetime of the product is long (10+ years).

Examples: https://arxiv.org/pdf/2203.04374

In those cases the long-term ROI of clean code and testing is clearly proven. But data science is often different: small teams, high-level languages like Python or R, and project lifespans that can be quite short.

Alternatively, I found interesting recommandations like https://martinfowler.com/articles/is-quality-worth-cost.html (article is old, but recommandations still apply) but without a lot of data backing up the claims.


Has anyone come across evidence (academic or otherwise) showing that investing in code quality, no matter how we define it, pays off in typical data science workflows?



",has anyone seen research or articles proving that code quality matters in data science projects hi all im looking for articles studies or realworld examples backed by data that demonstrate the value of code quality specifically in data science projects most of the literature ive found focuses on largescale software projects where the codebase is big tens of thousands of lines the team is large developers the expected lifetime of the product is long years examples in those cases the longterm roi of clean code and testing is clearly proven but data science is often different small teams highlevel languages like python or r and project lifespans that can be quite short alternatively i found interesting recommandations like article is old but recommandations still apply but without a lot of data backing up the claims has anyone come across evidence academic or otherwise showing that investing in code quality no matter how we define it pays off in typical data science workflows,see research article prove code quality matter datum science project hi m look article study realworld example back datum demonstrate value code quality specifically datum science project literature ve find focus largescale software project codebase big ten thousand line team large developer expect lifetime product long year example case longterm roi clean code testing clearly prove data science different small team highlevel language like python r project lifespan short alternatively find interesting recommandation like article old recommandation apply lot datum back claim come evidence academic show invest code quality matter define pay typical datum science workflow
1lg60ju,"How to build a usability metric that is ""normalized"" across flows?","Hey all, kind of a specific question here, but I've been trying to research approaches to this question and haven't found a reasonable solution. Basically, I work for a tech company with a user-facing product, and we want to build a metric which measures the usability of all our different flows.

I have a good sense of what metrics might represent usability (funnel conversion rate, time, survey scores, etc) but one request made is that the metric must be ""normalized"" (not sure if that's the right word). In other words, the usability score must be comparable across different flows. For example, conversion rate in an ""add payment"" section is always going to be lower than a ""learn about our features"" section - so to prioritize usability efforts we should have a score which accounts for this difference and measures usability on an ""objective"" scale that accounts for the expected gap between different flows.

Does anyone have any experience in building this kind of metric? Are there public analyses or papers I can read up on to understand how to approach this problem, or am I doomed? Thanks in advance!",3,8,2025-06-20T14:54:37+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lg60ju/how_to_build_a_usability_metric_that_is/,"How to build a usability metric that is ""normalized"" across flows? Hey all, kind of a specific question here, but I've been trying to research approaches to this question and haven't found a reasonable solution. Basically, I work for a tech company with a user-facing product, and we want to build a metric which measures the usability of all our different flows.

I have a good sense of what metrics might represent usability (funnel conversion rate, time, survey scores, etc) but one request made is that the metric must be ""normalized"" (not sure if that's the right word). In other words, the usability score must be comparable across different flows. For example, conversion rate in an ""add payment"" section is always going to be lower than a ""learn about our features"" section - so to prioritize usability efforts we should have a score which accounts for this difference and measures usability on an ""objective"" scale that accounts for the expected gap between different flows.

Does anyone have any experience in building this kind of metric? Are there public analyses or papers I can read up on to understand how to approach this problem, or am I doomed? Thanks in advance!",how to build a usability metric that is normalized across flows hey all kind of a specific question here but ive been trying to research approaches to this question and havent found a reasonable solution basically i work for a tech company with a userfacing product and we want to build a metric which measures the usability of all our different flows i have a good sense of what metrics might represent usability funnel conversion rate time survey scores etc but one request made is that the metric must be normalized not sure if thats the right word in other words the usability score must be comparable across different flows for example conversion rate in an add payment section is always going to be lower than a learn about our features section so to prioritize usability efforts we should have a score which accounts for this difference and measures usability on an objective scale that accounts for the expected gap between different flows does anyone have any experience in building this kind of metric are there public analyses or papers i can read up on to understand how to approach this problem or am i doomed thanks in advance,build usability metric normalize flow hey kind specific question ve try research approach question not find reasonable solution basically work tech company userface product want build metric measure usability different flow good sense metric represent usability funnel conversion rate time survey score etc request metric normalize sure s right word word usability score comparable different flow example conversion rate add payment section go low learn feature section prioritize usability effort score account difference measure usability objective scale account expect gap different flow experience build kind metric public analysis paper read understand approach problem doom thank advance
1lg5mrg,"Ridiculous offer, how to proceed?","Hello All, after a very long struggle with landing my first data science job, I got a ridiculous offer and would like to know how to proceed. For context, I have 7 years of medtech experience, not specifically in data science but similar and an undergrad in stats and now a masters in data science. I am located in the US.

I've been talking with a company for months now and had several interviews even without a specific position available. Well they finally opened two positions, one associate and one senior with salary ranges of 66-99k and 130k-180k respectively. I applied for both and when HR got involved for the offer they said they could probably just split the difference for 110k. Sure that's fine. However, a couple days later, they called again and offered 60-70k, below even the lower limit of the associate range. So my question is has this happened to anyone else? Is this HR's way of trying to get me to just go away?

Maybe I'm just frustrated since HR said the salary range listed on the job req isn't actually what they are willing to pay",267,120,2025-06-20T14:38:34+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lg5mrg/ridiculous_offer_how_to_proceed/,"Ridiculous offer, how to proceed? Hello All, after a very long struggle with landing my first data science job, I got a ridiculous offer and would like to know how to proceed. For context, I have 7 years of medtech experience, not specifically in data science but similar and an undergrad in stats and now a masters in data science. I am located in the US.

I've been talking with a company for months now and had several interviews even without a specific position available. Well they finally opened two positions, one associate and one senior with salary ranges of 66-99k and 130k-180k respectively. I applied for both and when HR got involved for the offer they said they could probably just split the difference for 110k. Sure that's fine. However, a couple days later, they called again and offered 60-70k, below even the lower limit of the associate range. So my question is has this happened to anyone else? Is this HR's way of trying to get me to just go away?

Maybe I'm just frustrated since HR said the salary range listed on the job req isn't actually what they are willing to pay",ridiculous offer how to proceed hello all after a very long struggle with landing my first data science job i got a ridiculous offer and would like to know how to proceed for context i have years of medtech experience not specifically in data science but similar and an undergrad in stats and now a masters in data science i am located in the us ive been talking with a company for months now and had several interviews even without a specific position available well they finally opened two positions one associate and one senior with salary ranges of k and kk respectively i applied for both and when hr got involved for the offer they said they could probably just split the difference for k sure thats fine however a couple days later they called again and offered k below even the lower limit of the associate range so my question is has this happened to anyone else is this hrs way of trying to get me to just go away maybe im just frustrated since hr said the salary range listed on the job req isnt actually what they are willing to pay,ridiculous offer proceed hello long struggle land data science job get ridiculous offer like know proceed context year medtech experience specifically datum science similar undergrad stat master data science locate ve talk company month interview specific position available finally open position associate senior salary range k kk respectively apply hr get involve offer say probably split difference k sure s fine couple day later call offer k low limit associate range question happen hrs way try away maybe m frustrated hr say salary range list job req not actually willing pay
1lg5043,Problem identification & specification in Data Science (a metacognitive deep dive),"Hey r/datascience,

I've found that one of the impactful parts of our work is the initial phase of **problem identification and specification**. It's crucial for project success, yet often feels more like an art than a structured science.

I've been thinking about the **metacognition** involved: *how* do we find the right problems, and *how* do we translate them into clear, actionable data science objectives? I'd love to kick off a discussion to gain a more structured understanding of this process.

**Problem Identification**

1. What triggers your initial recognition of a problem that wasn't explicitly assigned?
2. How much is proactive observation versus reacting to a stakeholder's vague need?

**The Interplay of Domain Expertise & Data**

Domain expertise and data go hand-in-hand. Deep domain knowledge can spot issues data alone might miss, while data exploration can reveal patterns demanding domain context.

1. How do these two elements come together in your initial problem framing? Is it sequential or iterative?

**Problem Specification**

1. What critical steps do you take to define a problem clearly?
2. Who are the key players, and what frameworks or tools do you use for nailing down success metrics and scope?

**The ""Systems Model"" of Problem Formulation (A Conceptual Idea)**

This is a bit more abstract, but I'm trying to visualize the process itself. I'm thinking about a 'Systems Model' for problem formulation: *how a problem gets identified and specified*.

If we mapped this process, what would the nodes, edges, and feedback loops look like? Are there common pathways or anti-patterns that lead to poorly defined problems?

\--

I'm curious in how you navigate this foundational aspect of our work. What are your insights into problem identification and specification in data science?

Thank you!",11,4,2025-06-20T14:12:10+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lg5043/problem_identification_specification_in_data/,"Problem identification & specification in Data Science (a metacognitive deep dive) Hey r/datascience,

I've found that one of the impactful parts of our work is the initial phase of **problem identification and specification**. It's crucial for project success, yet often feels more like an art than a structured science.

I've been thinking about the **metacognition** involved: *how* do we find the right problems, and *how* do we translate them into clear, actionable data science objectives? I'd love to kick off a discussion to gain a more structured understanding of this process.

**Problem Identification**

1. What triggers your initial recognition of a problem that wasn't explicitly assigned?
2. How much is proactive observation versus reacting to a stakeholder's vague need?

**The Interplay of Domain Expertise & Data**

Domain expertise and data go hand-in-hand. Deep domain knowledge can spot issues data alone might miss, while data exploration can reveal patterns demanding domain context.

1. How do these two elements come together in your initial problem framing? Is it sequential or iterative?

**Problem Specification**

1. What critical steps do you take to define a problem clearly?
2. Who are the key players, and what frameworks or tools do you use for nailing down success metrics and scope?

**The ""Systems Model"" of Problem Formulation (A Conceptual Idea)**

This is a bit more abstract, but I'm trying to visualize the process itself. I'm thinking about a 'Systems Model' for problem formulation: *how a problem gets identified and specified*.

If we mapped this process, what would the nodes, edges, and feedback loops look like? Are there common pathways or anti-patterns that lead to poorly defined problems?

\--

I'm curious in how you navigate this foundational aspect of our work. What are your insights into problem identification and specification in data science?

Thank you!",problem identification specification in data science a metacognitive deep dive hey rdatascience ive found that one of the impactful parts of our work is the initial phase of problem identification and specification its crucial for project success yet often feels more like an art than a structured science ive been thinking about the metacognition involved how do we find the right problems and how do we translate them into clear actionable data science objectives id love to kick off a discussion to gain a more structured understanding of this process problem identification what triggers your initial recognition of a problem that wasnt explicitly assigned how much is proactive observation versus reacting to a stakeholders vague need the interplay of domain expertise data domain expertise and data go handinhand deep domain knowledge can spot issues data alone might miss while data exploration can reveal patterns demanding domain context how do these two elements come together in your initial problem framing is it sequential or iterative problem specification what critical steps do you take to define a problem clearly who are the key players and what frameworks or tools do you use for nailing down success metrics and scope the systems model of problem formulation a conceptual idea this is a bit more abstract but im trying to visualize the process itself im thinking about a systems model for problem formulation how a problem gets identified and specified if we mapped this process what would the nodes edges and feedback loops look like are there common pathways or antipatterns that lead to poorly defined problems im curious in how you navigate this foundational aspect of our work what are your insights into problem identification and specification in data science thank you,problem identification specification data science metacognitive deep dive hey rdatascience ve find impactful part work initial phase problem identification specification crucial project success feel like art structured science ve think metacognition involve find right problem translate clear actionable datum science objective d love kick discussion gain structured understanding process problem identification trigger initial recognition problem not explicitly assign proactive observation versus react stakeholder vague need interplay domain expertise datum domain expertise datum handinhand deep domain knowledge spot issue datum miss data exploration reveal pattern demand domain context element come initial problem frame sequential iterative problem specification critical step define problem clearly key player framework tool use nail success metric scope system model problem formulation conceptual idea bit abstract m try visualize process m think system model problem formulation problem get identify specify map process node edge feedback loop look like common pathway antipattern lead poorly define problem m curious navigate foundational aspect work insight problem identification specification datum science thank
1lg4t92,How are you making AI applications in settings where no external APIs are allowed?,"I've seen a lot of people build plenty of AI applications that interface with a litany of external APIs, but in environments where you can't send data to a third party, what are your biggest challenges of building LLM powered systems and how do you tackle them?

In my experience LLMs can be complex to serve efficiently, LLM APIs have useful abstractions like output parsing and tool use definitions which on-prem implementations can't use, RAG Processes usually rely on sophisticated embedding models which, when deployed locally, require the creation of hosting, provisioning, scaling, storing and querying vector representations. Then, you have document parsing, which is a whole other can of worms, and is usually critical when interfacing with knowledge bases in a regulated industry.

I'm curious, especially if you're doing On-Prem RAG for applications with large numbers of complex documents, what were the big issues you experienced and how did you solve them?",32,18,2025-06-20T14:04:02+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lg4t92/how_are_you_making_ai_applications_in_settings/,"How are you making AI applications in settings where no external APIs are allowed? I've seen a lot of people build plenty of AI applications that interface with a litany of external APIs, but in environments where you can't send data to a third party, what are your biggest challenges of building LLM powered systems and how do you tackle them?

In my experience LLMs can be complex to serve efficiently, LLM APIs have useful abstractions like output parsing and tool use definitions which on-prem implementations can't use, RAG Processes usually rely on sophisticated embedding models which, when deployed locally, require the creation of hosting, provisioning, scaling, storing and querying vector representations. Then, you have document parsing, which is a whole other can of worms, and is usually critical when interfacing with knowledge bases in a regulated industry.

I'm curious, especially if you're doing On-Prem RAG for applications with large numbers of complex documents, what were the big issues you experienced and how did you solve them?",how are you making ai applications in settings where no external apis are allowed ive seen a lot of people build plenty of ai applications that interface with a litany of external apis but in environments where you cant send data to a third party what are your biggest challenges of building llm powered systems and how do you tackle them in my experience llms can be complex to serve efficiently llm apis have useful abstractions like output parsing and tool use definitions which onprem implementations cant use rag processes usually rely on sophisticated embedding models which when deployed locally require the creation of hosting provisioning scaling storing and querying vector representations then you have document parsing which is a whole other can of worms and is usually critical when interfacing with knowledge bases in a regulated industry im curious especially if youre doing onprem rag for applications with large numbers of complex documents what were the big issues you experienced and how did you solve them,make ai application setting external apis allow ve see lot people build plenty ai application interface litany external apis environment not send datum party big challenge build llm power system tackle experience llm complex serve efficiently llm apis useful abstraction like output parsing tool use definition onprem implementation not use rag process usually rely sophisticated embedding model deploy locally require creation host provision scale store query vector representation document parsing worm usually critical interface knowledge basis regulated industry m curious especially onprem rag application large number complex document big issue experience solve
1lfp3ge,Confidence interval width vs training MAPE,"Hi, can anyone with strong background in estimation please help me out here? I am performing price elasticity estimation. I am trying out various levels to calculate elasticities on - calculating elasticity for individual item level, calculating elasticity for each subcategory (after grouping by subcategory) and each category level. The data is very sparse in the lower levels, hence I want to check how reliable the coefficient estimates are at each level, so I am measuring median Confidence interval width and MAPE. at each level. The lower the category, the lower the number of samples in each group for which we are calculating an elasticity. Now, the confidence interval width is decreasing for it as we go for higher grouping level i.e. more number of different types of items in each group, but training mape is increasing with group size/grouping level. So much so, if we compute a single elasticity for all items (containing all sorts of items) without any grouping, I am getting the lowest confidence interval width but high mape.

But what I am confused by is - shouldn't a lower confidence interval width indicate a more precise fit and hence a better training MAPE? I know that the CI width is decreasing because sample size is increasing for larger group size, but so should the residual variance and balance out the CI width, right (because larger group contains many type of items with high variance in price behaviour)? And if the residual variance due to difference between different type of items within the group is unable to balance out the effect of the increased sample size, doesn't it indicate that the inter item variability within different types of items isn't significant enough for us to benefit from modelling them separately and we should compute a single elasticity for all items (which doesn't make sense from common sense pov)?",9,8,2025-06-19T23:20:01+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lfp3ge/confidence_interval_width_vs_training_mape/,"Confidence interval width vs training MAPE Hi, can anyone with strong background in estimation please help me out here? I am performing price elasticity estimation. I am trying out various levels to calculate elasticities on - calculating elasticity for individual item level, calculating elasticity for each subcategory (after grouping by subcategory) and each category level. The data is very sparse in the lower levels, hence I want to check how reliable the coefficient estimates are at each level, so I am measuring median Confidence interval width and MAPE. at each level. The lower the category, the lower the number of samples in each group for which we are calculating an elasticity. Now, the confidence interval width is decreasing for it as we go for higher grouping level i.e. more number of different types of items in each group, but training mape is increasing with group size/grouping level. So much so, if we compute a single elasticity for all items (containing all sorts of items) without any grouping, I am getting the lowest confidence interval width but high mape.

But what I am confused by is - shouldn't a lower confidence interval width indicate a more precise fit and hence a better training MAPE? I know that the CI width is decreasing because sample size is increasing for larger group size, but so should the residual variance and balance out the CI width, right (because larger group contains many type of items with high variance in price behaviour)? And if the residual variance due to difference between different type of items within the group is unable to balance out the effect of the increased sample size, doesn't it indicate that the inter item variability within different types of items isn't significant enough for us to benefit from modelling them separately and we should compute a single elasticity for all items (which doesn't make sense from common sense pov)?",confidence interval width vs training mape hi can anyone with strong background in estimation please help me out here i am performing price elasticity estimation i am trying out various levels to calculate elasticities on calculating elasticity for individual item level calculating elasticity for each subcategory after grouping by subcategory and each category level the data is very sparse in the lower levels hence i want to check how reliable the coefficient estimates are at each level so i am measuring median confidence interval width and mape at each level the lower the category the lower the number of samples in each group for which we are calculating an elasticity now the confidence interval width is decreasing for it as we go for higher grouping level ie more number of different types of items in each group but training mape is increasing with group sizegrouping level so much so if we compute a single elasticity for all items containing all sorts of items without any grouping i am getting the lowest confidence interval width but high mape but what i am confused by is shouldnt a lower confidence interval width indicate a more precise fit and hence a better training mape i know that the ci width is decreasing because sample size is increasing for larger group size but so should the residual variance and balance out the ci width right because larger group contains many type of items with high variance in price behaviour and if the residual variance due to difference between different type of items within the group is unable to balance out the effect of the increased sample size doesnt it indicate that the inter item variability within different types of items isnt significant enough for us to benefit from modelling them separately and we should compute a single elasticity for all items which doesnt make sense from common sense pov,confidence interval width vs training mape hi strong background estimation help perform price elasticity estimation try level calculate elasticity calculate elasticity individual item level calculate elasticity subcategory group subcategory category level data sparse low level want check reliable coefficient estimate level measure median confidence interval width mape level low category low number sample group calculate elasticity confidence interval width decrease high grouping level ie number different type item group training mape increase group sizegrouping level compute single elasticity item contain sort item grouping get low confidence interval width high mape confuse not low confidence interval width indicate precise fit well training mape know ci width decrease sample size increase large group size residual variance balance ci width right large group contain type item high variance price behaviour residual variance difference different type item group unable balance effect increase sample size not indicate inter item variability different type item not significant benefit model separately compute single elasticity item not sense common sense pov
1lfdkws,What are good resources to learn MLE/SWE concepts?,I'm struggling adapting my code and was wondering if there were any (preferably free) resources to further my understanding of the engineering way of creating ML pipelines.,25,10,2025-06-19T15:24:38+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lfdkws/what_are_good_resources_to_learn_mleswe_concepts/,What are good resources to learn MLE/SWE concepts? I'm struggling adapting my code and was wondering if there were any (preferably free) resources to further my understanding of the engineering way of creating ML pipelines.,what are good resources to learn mleswe concepts im struggling adapting my code and was wondering if there were any preferably free resources to further my understanding of the engineering way of creating ml pipelines,good resource learn mleswe concept m struggle adapt code wonder preferably free resource understanding engineering way create ml pipeline
1leyh9g,Splitting Up Modeling in Project Amongst DS Team,"Hi! When it comes to modeling portion of a DS project, how does your team divy that part of the project among all the data scientist in your team?

I've been part of different teams and they've each done something different and I'm curious about how other teams have gone about it. I've had a boss who would have us all make one model and we just work off one model together. I've also had other managers who had us all work on our own models and we decide which one to go with based off RMSE.

Thanks!",15,8,2025-06-19T01:33:41+00:00,datascience,https://www.reddit.com/r/datascience/comments/1leyh9g/splitting_up_modeling_in_project_amongst_ds_team/,"Splitting Up Modeling in Project Amongst DS Team Hi! When it comes to modeling portion of a DS project, how does your team divy that part of the project among all the data scientist in your team?

I've been part of different teams and they've each done something different and I'm curious about how other teams have gone about it. I've had a boss who would have us all make one model and we just work off one model together. I've also had other managers who had us all work on our own models and we decide which one to go with based off RMSE.

Thanks!",splitting up modeling in project amongst ds team hi when it comes to modeling portion of a ds project how does your team divy that part of the project among all the data scientist in your team ive been part of different teams and theyve each done something different and im curious about how other teams have gone about it ive had a boss who would have us all make one model and we just work off one model together ive also had other managers who had us all work on our own models and we decide which one to go with based off rmse thanks,split modeling project ds team hi come modeling portion ds project team divy project data scientist team ve different team ve different m curious team go ve boss model work model ve manager work model decide base rmse thank
1lewya2,What tasks don’t you trust zero-shot LLMs to handle reliably?,"For some context I’ve been working on a number of NLP projects lately (classifying textual conversation data). Many of our use cases are classification tasks that align with our niche objectives. I’ve found in this setting that structured output from LLMs can often outperform traditional methods.

That said, my boss is now asking for likelihoods instead of just classifications. I haven’t implemented this yet, but my gut says this could be pushing LLMs into the “lying machine” zone. I mean, how exactly would an LLM independently rank documents and do so accurately and consistently? 

So I’m curious:

* What kinds of tasks have you found to be unreliable or risky for zero-shot LLM use?
* And on the flip side, what types of tasks have worked surprisingly well for you? ",67,38,2025-06-19T00:18:12+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lewya2/what_tasks_dont_you_trust_zeroshot_llms_to_handle/,"What tasks don’t you trust zero-shot LLMs to handle reliably? For some context I’ve been working on a number of NLP projects lately (classifying textual conversation data). Many of our use cases are classification tasks that align with our niche objectives. I’ve found in this setting that structured output from LLMs can often outperform traditional methods.

That said, my boss is now asking for likelihoods instead of just classifications. I haven’t implemented this yet, but my gut says this could be pushing LLMs into the “lying machine” zone. I mean, how exactly would an LLM independently rank documents and do so accurately and consistently? 

So I’m curious:

* What kinds of tasks have you found to be unreliable or risky for zero-shot LLM use?
* And on the flip side, what types of tasks have worked surprisingly well for you? ",what tasks dont you trust zeroshot llms to handle reliably for some context ive been working on a number of nlp projects lately classifying textual conversation data many of our use cases are classification tasks that align with our niche objectives ive found in this setting that structured output from llms can often outperform traditional methods that said my boss is now asking for likelihoods instead of just classifications i havent implemented this yet but my gut says this could be pushing llms into the lying machine zone i mean how exactly would an llm independently rank documents and do so accurately and consistently so im curious what kinds of tasks have you found to be unreliable or risky for zeroshot llm use and on the flip side what types of tasks have worked surprisingly well for you,task not trust zeroshot llm handle reliably context ve work number nlp project lately classify textual conversation datum use case classification task align niche objective ve find setting structure output llm outperform traditional method say boss ask likelihood instead classification not implement gut say push llm lie machine zone mean exactly llm independently rank document accurately consistently m curious kind task find unreliable risky zeroshot llm use flip type task work surprisingly
1leucnm,Does anyone here do predictive modeling with scenario planning?,"I've been asked to look into this at my DS job, but I'm the only DS so I'd love to get the thoughts of others in the field. I get the business value of making predictions under a range of possible futures, but it feels like this would have to be the last step after several:

1. Thorough exploration of your data to understand feature-level relationships. If you change something about a feature that's correlated with other features you need to be able to model that.

2. Just having a working predictive model. We don't have any actual models in production yet. An EDA would be part of this as well, accomplishing step 1.

3. Then scenario planning is something you can use simulations for assuming you have enough to work with in 1 and 2.

My other thought has been to explore what approaches causal inference and things like DAGs might offer. Not where my background is, but it sounds like the company wants to make casual statements so it seems worth considering.

I'm just wondering what anyone else who works in this space does and if there's anything I'm missing that I should be exploring. I'm excited to be working on something like this but it also feels like there's so much that success depends on. 

",27,14,2025-06-18T22:18:23+00:00,datascience,https://www.reddit.com/r/datascience/comments/1leucnm/does_anyone_here_do_predictive_modeling_with/,"Does anyone here do predictive modeling with scenario planning? I've been asked to look into this at my DS job, but I'm the only DS so I'd love to get the thoughts of others in the field. I get the business value of making predictions under a range of possible futures, but it feels like this would have to be the last step after several:

1. Thorough exploration of your data to understand feature-level relationships. If you change something about a feature that's correlated with other features you need to be able to model that.

2. Just having a working predictive model. We don't have any actual models in production yet. An EDA would be part of this as well, accomplishing step 1.

3. Then scenario planning is something you can use simulations for assuming you have enough to work with in 1 and 2.

My other thought has been to explore what approaches causal inference and things like DAGs might offer. Not where my background is, but it sounds like the company wants to make casual statements so it seems worth considering.

I'm just wondering what anyone else who works in this space does and if there's anything I'm missing that I should be exploring. I'm excited to be working on something like this but it also feels like there's so much that success depends on. 

",does anyone here do predictive modeling with scenario planning ive been asked to look into this at my ds job but im the only ds so id love to get the thoughts of others in the field i get the business value of making predictions under a range of possible futures but it feels like this would have to be the last step after several thorough exploration of your data to understand featurelevel relationships if you change something about a feature thats correlated with other features you need to be able to model that just having a working predictive model we dont have any actual models in production yet an eda would be part of this as well accomplishing step then scenario planning is something you can use simulations for assuming you have enough to work with in and my other thought has been to explore what approaches causal inference and things like dags might offer not where my background is but it sounds like the company wants to make casual statements so it seems worth considering im just wondering what anyone else who works in this space does and if theres anything im missing that i should be exploring im excited to be working on something like this but it also feels like theres so much that success depends on,predictive modeling scenario planning ve ask look ds job m ds d love thought field business value make prediction range possible future feel like step thorough exploration datum understand featurelevel relationship change feature s correlate feature need able model have work predictive model not actual model production eda accomplish step scenario planning use simulation assume work thought explore approach causal inference thing like dag offer background sound like company want casual statement worth consider m wonder work space s m miss explore m excited work like feel like s success depend
1let4dl,[Side Project] How I built a website that uses ML to find you ML jobs,"**Link:** [**filtrjobs.com**](https://www.filtrjobs.com/)

I was frustrated with irrelevant postings relying on keyword matching. so i built my own job search engine for fun

I'm doing a semantic search with your resume against embeddings of job postings prioritizing things like working on similar problems/domains

It's also **100% free with no signup needed** for ever

",0,11,2025-06-18T21:26:25+00:00,datascience,https://www.reddit.com/r/datascience/comments/1let4dl/side_project_how_i_built_a_website_that_uses_ml/,"[Side Project] How I built a website that uses ML to find you ML jobs **Link:** [**filtrjobs.com**](https://www.filtrjobs.com/)

I was frustrated with irrelevant postings relying on keyword matching. so i built my own job search engine for fun

I'm doing a semantic search with your resume against embeddings of job postings prioritizing things like working on similar problems/domains

It's also **100% free with no signup needed** for ever

",i was frustrated with irrelevant postings relying on keyword matching so i built my own job search engine for fun im doing a semantic search with your resume against embeddings of job postings prioritizing things like working on similar problemsdomains its also free with no signup needed for ever,frustrate irrelevant posting rely keyword matching build job search engine fun m semantic search resume embedding job posting prioritize thing like work similar problemsdomain free signup need
1lenpta,I got ghosted after 8 interviews. Why do companies do this?,"I went through 7 rounds of interviews with a company, followed by a month of complete silence. Then the recruiter reached out asking me to do an additional round because of an organizational change — the role now had a new hiring manager. Since I had already invested so much time, I agreed to go through the 8th round.

After that, they kept stringing me along and eventually just ghosted me.

Not to make this a therapy session, but this whole experience has left me feeling really sad this past week. I spent months in this process, and they couldn’t even send a simple rejection email? How hard is that? I believe I was one of their top candidates — why else would they 
circle back a month after the initial rounds? How to get over this?

Edit: One more detail, they have been trying to fill this role for the last 6 months.",382,121,2025-06-18T17:51:26+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lenpta/i_got_ghosted_after_8_interviews_why_do_companies/,"I got ghosted after 8 interviews. Why do companies do this? I went through 7 rounds of interviews with a company, followed by a month of complete silence. Then the recruiter reached out asking me to do an additional round because of an organizational change — the role now had a new hiring manager. Since I had already invested so much time, I agreed to go through the 8th round.

After that, they kept stringing me along and eventually just ghosted me.

Not to make this a therapy session, but this whole experience has left me feeling really sad this past week. I spent months in this process, and they couldn’t even send a simple rejection email? How hard is that? I believe I was one of their top candidates — why else would they 
circle back a month after the initial rounds? How to get over this?

Edit: One more detail, they have been trying to fill this role for the last 6 months.",i got ghosted after interviews why do companies do this i went through rounds of interviews with a company followed by a month of complete silence then the recruiter reached out asking me to do an additional round because of an organizational change the role now had a new hiring manager since i had already invested so much time i agreed to go through the th round after that they kept stringing me along and eventually just ghosted me not to make this a therapy session but this whole experience has left me feeling really sad this past week i spent months in this process and they couldnt even send a simple rejection email how hard is that i believe i was one of their top candidates why else would they circle back a month after the initial rounds how to get over this edit one more detail they have been trying to fill this role for the last months,get ghost interview company go round interview company follow month complete silence recruiter reach ask additional round organizational change role new hire manager invest time agree th round keep string eventually ghost therapy session experience leave feel sad past week spend month process not send simple rejection email hard believe candidate circle month initial round edit detail try fill role month
1leh4wm,My data science dream is slowly dying,"
I am currently studying Data Science and really fell in love with the field, but the more i progress the more depressed i become.

Over the past year, after watching job postings especially in tech I’ve realized most Data Scientist roles are basically advanced data analysts, focused on dashboards, metrics, A/B tests. (It is not a bad job dont get me wrong, but it is not the direction i want to take)

The actual ML work seems to be done by ML Engineers, which often requires deep software engineering skills which something I’m not passionate about.

Right now, I feel stuck. I don’t think I’d enjoy spending most of my time on product analytics, but I also don’t see many roles focused on ML unless you’re already a software engineer (not talking about research but training models to solve business problems).

Do you have any advice?                                      

**Also will there ever be more space for Data Scientists to work hands on with ML or is that firmly in the engineer’s domain now? I mean which is your idea about the field?**",795,199,2025-06-18T13:29:00+00:00,datascience,https://www.reddit.com/r/datascience/comments/1leh4wm/my_data_science_dream_is_slowly_dying/,"My data science dream is slowly dying 
I am currently studying Data Science and really fell in love with the field, but the more i progress the more depressed i become.

Over the past year, after watching job postings especially in tech I’ve realized most Data Scientist roles are basically advanced data analysts, focused on dashboards, metrics, A/B tests. (It is not a bad job dont get me wrong, but it is not the direction i want to take)

The actual ML work seems to be done by ML Engineers, which often requires deep software engineering skills which something I’m not passionate about.

Right now, I feel stuck. I don’t think I’d enjoy spending most of my time on product analytics, but I also don’t see many roles focused on ML unless you’re already a software engineer (not talking about research but training models to solve business problems).

Do you have any advice?                                      

**Also will there ever be more space for Data Scientists to work hands on with ML or is that firmly in the engineer’s domain now? I mean which is your idea about the field?**",my data science dream is slowly dying i am currently studying data science and really fell in love with the field but the more i progress the more depressed i become over the past year after watching job postings especially in tech ive realized most data scientist roles are basically advanced data analysts focused on dashboards metrics ab tests it is not a bad job dont get me wrong but it is not the direction i want to take the actual ml work seems to be done by ml engineers which often requires deep software engineering skills which something im not passionate about right now i feel stuck i dont think id enjoy spending most of my time on product analytics but i also dont see many roles focused on ml unless youre already a software engineer not talking about research but training models to solve business problems do you have any advice also will there ever be more space for data scientists to work hands on with ml or is that firmly in the engineers domain now i mean which is your idea about the field,data science dream slowly die currently study datum science fall love field progress depressed past year watch job posting especially tech ve realize datum scientist role basically advanced datum analyst focus dashboard metric ab test bad job not wrong direction want actual ml work ml engineer require deep software engineering skill m passionate right feel stuck not think d enjoy spend time product analytic not role focus ml software engineer talk research training model solve business problem advice space datum scientist work hand ml firmly engineer domain mean idea field
1le3whp,How would you categorize this DS skill?,"I am DS with several YOE. My company had a problem with the billing system. Several people tried fixing it for a few months but couldn’t fix it.

I met with a few people and took notes. I wrote a few basic sql queries and threw the data into excel then had the solution after a few hours. This saved the company a lot of money.

I didn’t use ML or AI or any other fancy word that gets you interviews. I just used my brain. Anyone can use their brain but all those other smart people couldn’t figure it out so what is the “thing” I have that I can sell to employers.",65,31,2025-06-18T00:47:49+00:00,datascience,https://www.reddit.com/r/datascience/comments/1le3whp/how_would_you_categorize_this_ds_skill/,"How would you categorize this DS skill? I am DS with several YOE. My company had a problem with the billing system. Several people tried fixing it for a few months but couldn’t fix it.

I met with a few people and took notes. I wrote a few basic sql queries and threw the data into excel then had the solution after a few hours. This saved the company a lot of money.

I didn’t use ML or AI or any other fancy word that gets you interviews. I just used my brain. Anyone can use their brain but all those other smart people couldn’t figure it out so what is the “thing” I have that I can sell to employers.",how would you categorize this ds skill i am ds with several yoe my company had a problem with the billing system several people tried fixing it for a few months but couldnt fix it i met with a few people and took notes i wrote a few basic sql queries and threw the data into excel then had the solution after a few hours this saved the company a lot of money i didnt use ml or ai or any other fancy word that gets you interviews i just used my brain anyone can use their brain but all those other smart people couldnt figure it out so what is the thing i have that i can sell to employers,categorize ds skill ds yoe company problem billing system people try fix month not fix meet people take note write basic sql query throw datum excel solution hour save company lot money not use ml ai fancy word get interview brain use brain smart people not figure thing sell employer
1ldqozx,"We are back with many Data science jobs in Soccer, NFL, NHL, Formula1 and more sports! 2025-06","Hey guys,

I've been silent here lately but many opportunities keep appearing and being posted.

These are a few from the last 10 days or so

* [Lead/Senior Quantitative Analyst, Predictive Modeling - Philadelphia Phillies](http://www.sportsjobs.online/jobs/8268-lead-senior-quantitative-analyst-predictive-modeling)
* [Vice President, Business Strategy & Analytics - Detroit Pistons](http://www.sportsjobs.online/jobs/8294-vice-president-business-strategy-analytics)
* [Data Scientist - Los Angeles Rams](http://www.sportsjobs.online/jobs/8288-data-scientist)
* [Data Engineer - Houston Texans](http://www.sportsjobs.online/jobs/8299-data-engineer)

A few Internships (hard to find!)

* [Software Engineer Intern - Dallas Mavericks](https://www.sportsjobs.online/jobs/8107-software-engineer-intern)
* [Business Strategy Internship - Nashville Predators](https://www.sportsjobs.online/jobs/8212-nashville-predators-business-strategy-internship-fall-2025-nhl)
* [Business Analytics Intern - Carolina Panthers](http://www.sportsjobs.online/jobs/8197-business-analytics-intern)

NBA Great jobs that were open (and closed applications quickly) but they appear !

* [Data Analyst - Miami Heat](http://www.sportsjobs.online/jobs/8255-data-analyst) \[Sold out\]
* [Applied Scientist, Basketball Analytics - Phoenix Suns](http://www.sportsjobs.online/jobs/8243-applied-scientist-basketball-analytics) \[Sold out\]

I run www.sportsjobs(.)online, a job board in that niche. In the last month I added around 300 jobs.

For the ones that already saw my posts before, I've added more sources of jobs lately. I'm open to suggestions to prioritize the next batch.

It's a niche, there aren't thousands of jobs as in Software in general but my commitment is to **keep improving a simple metric, jobs per month.** We always need some metric in DS..

I run also a newsletter to receive emails with jobs and interesting content on sports analytics (next edition tomorrow!)  
[https://sportsjobs-online.beehiiv.com/subscribe](https://sportsjobs-online.beehiiv.com/subscribe)

Finally, I've created also a [reddit community](https://www.reddit.com/r/sports_jobs/) where I post recurrently the openings if that's easier to check for you.

I hope this helps someone!",90,28,2025-06-17T15:50:25+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ldqozx/we_are_back_with_many_data_science_jobs_in_soccer/,"We are back with many Data science jobs in Soccer, NFL, NHL, Formula1 and more sports! 2025-06 Hey guys,

I've been silent here lately but many opportunities keep appearing and being posted.

These are a few from the last 10 days or so

* [Lead/Senior Quantitative Analyst, Predictive Modeling - Philadelphia Phillies](http://www.sportsjobs.online/jobs/8268-lead-senior-quantitative-analyst-predictive-modeling)
* [Vice President, Business Strategy & Analytics - Detroit Pistons](http://www.sportsjobs.online/jobs/8294-vice-president-business-strategy-analytics)
* [Data Scientist - Los Angeles Rams](http://www.sportsjobs.online/jobs/8288-data-scientist)
* [Data Engineer - Houston Texans](http://www.sportsjobs.online/jobs/8299-data-engineer)

A few Internships (hard to find!)

* [Software Engineer Intern - Dallas Mavericks](https://www.sportsjobs.online/jobs/8107-software-engineer-intern)
* [Business Strategy Internship - Nashville Predators](https://www.sportsjobs.online/jobs/8212-nashville-predators-business-strategy-internship-fall-2025-nhl)
* [Business Analytics Intern - Carolina Panthers](http://www.sportsjobs.online/jobs/8197-business-analytics-intern)

NBA Great jobs that were open (and closed applications quickly) but they appear !

* [Data Analyst - Miami Heat](http://www.sportsjobs.online/jobs/8255-data-analyst) \[Sold out\]
* [Applied Scientist, Basketball Analytics - Phoenix Suns](http://www.sportsjobs.online/jobs/8243-applied-scientist-basketball-analytics) \[Sold out\]

I run www.sportsjobs(.)online, a job board in that niche. In the last month I added around 300 jobs.

For the ones that already saw my posts before, I've added more sources of jobs lately. I'm open to suggestions to prioritize the next batch.

It's a niche, there aren't thousands of jobs as in Software in general but my commitment is to **keep improving a simple metric, jobs per month.** We always need some metric in DS..

I run also a newsletter to receive emails with jobs and interesting content on sports analytics (next edition tomorrow!)  
[https://sportsjobs-online.beehiiv.com/subscribe](https://sportsjobs-online.beehiiv.com/subscribe)

Finally, I've created also a [reddit community](https://www.reddit.com/r/sports_jobs/) where I post recurrently the openings if that's easier to check for you.

I hope this helps someone!",we are back with many data science jobs in soccer nfl nhl formula and more sports hey guys ive been silent here lately but many opportunities keep appearing and being posted these are a few from the last days or so a few internships hard to find nba great jobs that were open and closed applications quickly but they appear sold out sold out i run a job board in that niche in the last month i added around jobs for the ones that already saw my posts before ive added more sources of jobs lately im open to suggestions to prioritize the next batch its a niche there arent thousands of jobs as in software in general but my commitment is to keep improving a simple metric jobs per month we always need some metric in ds i run also a newsletter to receive emails with jobs and interesting content on sports analytics next edition tomorrow finally ive created also a where i post recurrently the openings if thats easier to check for you i hope this helps someone,datum science job soccer nfl nhl formula sport hey guy ve silent lately opportunity appear post day internship hard find nba great job open closed application quickly appear sell sell run job board niche month add job one see post ve add source job lately m open suggestion prioritize batch niche not thousand job software general commitment improve simple metric job month need metric ds run newsletter receive email job interesting content sport analytic edition tomorrow finally ve create post recurrently opening s easy check hope help
1ld1nf6,Just tell them you work with models.  Let them figure out the rest on their own.,,654,15,2025-06-16T19:06:27+00:00,datascience,https://i.redd.it/wyx0k1xu7c7f1.png,Just tell them you work with models.  Let them figure out the rest on their own. ,just tell them you work with models let them figure out the rest on their own,tell work model let figure rest
1ld06j0,"The Illusion of ""The Illusion of Thinking""","Recently, Apple released a paper called ""The Illusion of Thinking"", which suggested that LLMs may not be reasoning at all, but rather are pattern matching:

[https://arxiv.org/abs/2506.06941](https://arxiv.org/abs/2506.06941)

A few days later, A paper written by two authors (one of them being the LLM Claude Opus model) released a paper called ""The Illusion of the Illusion of thinking"", which heavily criticised the paper.

[https://arxiv.org/html/2506.09250v1](https://arxiv.org/html/2506.09250v1)

A major issue of ""The Illusion of Thinking"" paper was that the authors asked LLMs to do excessively tedious and sometimes impossible tasks; citing The ""Illusion of the Illusion of thinking"" paper:

>Shojaee et al.’s results demonstrate that models cannot output more tokens than their context limits allow, that programmatic evaluation can miss both model capabilities and puzzle impossibilities, and that solution length poorly predicts problem difficulty. These are valuable engineering insights, but they do not support claims about fundamental reasoning limitations.

>Future work should:

>1. Design evaluations that distinguish between reasoning capability and output constraints

>2. Verify puzzle solvability before evaluating model performance

>3. Use complexity metrics that reflect computational difficulty, not just solution length

>4. Consider multiple solution representations to separate algorithmic understanding from execution

>The question isn’t whether LRMs can reason, but whether our evaluations can distinguish reasoning from typing.

This might seem like a silly throw away moment in AI research, an off the cuff paper being quickly torn down, but I don't think that's the case. I think what we're seeing is the growing pains of an industry as it begins to define what reasoning actually is.

This is relevant to application developers, not just researchers. AI powered products are significantly difficult to evaluate, often because it can be very difficult to define what ""performant"" actually means.

(I wrote this, it focuses on RAG but covers evaluation strategies generally. I work for EyeLevel)  
[https://www.eyelevel.ai/post/how-to-test-rag-and-agents-in-the-real-world](https://www.eyelevel.ai/post/how-to-test-rag-and-agents-in-the-real-world)

I've seen this sentiment time and time again: LLMs, LRMs, and AI in general are more powerful than our ability to test is sophisticated. New testing and validation approaches are required moving forward.",24,66,2025-06-16T18:10:48+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ld06j0/the_illusion_of_the_illusion_of_thinking/,"The Illusion of ""The Illusion of Thinking"" Recently, Apple released a paper called ""The Illusion of Thinking"", which suggested that LLMs may not be reasoning at all, but rather are pattern matching:

[https://arxiv.org/abs/2506.06941](https://arxiv.org/abs/2506.06941)

A few days later, A paper written by two authors (one of them being the LLM Claude Opus model) released a paper called ""The Illusion of the Illusion of thinking"", which heavily criticised the paper.

[https://arxiv.org/html/2506.09250v1](https://arxiv.org/html/2506.09250v1)

A major issue of ""The Illusion of Thinking"" paper was that the authors asked LLMs to do excessively tedious and sometimes impossible tasks; citing The ""Illusion of the Illusion of thinking"" paper:

>Shojaee et al.’s results demonstrate that models cannot output more tokens than their context limits allow, that programmatic evaluation can miss both model capabilities and puzzle impossibilities, and that solution length poorly predicts problem difficulty. These are valuable engineering insights, but they do not support claims about fundamental reasoning limitations.

>Future work should:

>1. Design evaluations that distinguish between reasoning capability and output constraints

>2. Verify puzzle solvability before evaluating model performance

>3. Use complexity metrics that reflect computational difficulty, not just solution length

>4. Consider multiple solution representations to separate algorithmic understanding from execution

>The question isn’t whether LRMs can reason, but whether our evaluations can distinguish reasoning from typing.

This might seem like a silly throw away moment in AI research, an off the cuff paper being quickly torn down, but I don't think that's the case. I think what we're seeing is the growing pains of an industry as it begins to define what reasoning actually is.

This is relevant to application developers, not just researchers. AI powered products are significantly difficult to evaluate, often because it can be very difficult to define what ""performant"" actually means.

(I wrote this, it focuses on RAG but covers evaluation strategies generally. I work for EyeLevel)  
[https://www.eyelevel.ai/post/how-to-test-rag-and-agents-in-the-real-world](https://www.eyelevel.ai/post/how-to-test-rag-and-agents-in-the-real-world)

I've seen this sentiment time and time again: LLMs, LRMs, and AI in general are more powerful than our ability to test is sophisticated. New testing and validation approaches are required moving forward.",the illusion of the illusion of thinking recently apple released a paper called the illusion of thinking which suggested that llms may not be reasoning at all but rather are pattern matching a few days later a paper written by two authors one of them being the llm claude opus model released a paper called the illusion of the illusion of thinking which heavily criticised the paper a major issue of the illusion of thinking paper was that the authors asked llms to do excessively tedious and sometimes impossible tasks citing the illusion of the illusion of thinking paper shojaee et als results demonstrate that models cannot output more tokens than their context limits allow that programmatic evaluation can miss both model capabilities and puzzle impossibilities and that solution length poorly predicts problem difficulty these are valuable engineering insights but they do not support claims about fundamental reasoning limitations future work should design evaluations that distinguish between reasoning capability and output constraints verify puzzle solvability before evaluating model performance use complexity metrics that reflect computational difficulty not just solution length consider multiple solution representations to separate algorithmic understanding from execution the question isnt whether lrms can reason but whether our evaluations can distinguish reasoning from typing this might seem like a silly throw away moment in ai research an off the cuff paper being quickly torn down but i dont think thats the case i think what were seeing is the growing pains of an industry as it begins to define what reasoning actually is this is relevant to application developers not just researchers ai powered products are significantly difficult to evaluate often because it can be very difficult to define what performant actually means i wrote this it focuses on rag but covers evaluation strategies generally i work for eyelevel ive seen this sentiment time and time again llms lrms and ai in general are more powerful than our ability to test is sophisticated new testing and validation approaches are required moving forward,illusion illusion thinking recently apple release paper call illusion thinking suggest llm reason pattern match day later paper write author llm claude opus model release paper call illusion illusion thinking heavily criticise paper major issue illusion thinking paper author ask llm excessively tedious impossible task cite illusion illusion think paper shojaee et als result demonstrate model output token context limit allow programmatic evaluation miss model capability puzzle impossibility solution length poorly predict problem difficulty valuable engineering insight support claim fundamental reasoning limitation future work design evaluation distinguish reasoning capability output constraint verify puzzle solvability evaluate model performance use complexity metric reflect computational difficulty solution length consider multiple solution representation separate algorithmic understanding execution question not lrm reason evaluation distinguish reasoning type like silly throw away moment ai research cuff paper quickly tear not think s case think see grow pain industry begin define reasoning actually relevant application developer researcher ai power product significantly difficult evaluate difficult define performant actually mean write focus rag cover evaluation strategy generally work eyelevel ve see sentiment time time llm lrm ai general powerful ability test sophisticated new testing validation approach require move forward
1lcpzzw,"""Yes, I do want to allow this app to make changes to my device!""","DS's in mid-sized firms: do you have to wrestle with the constant “admin approval required” pop-ups? Is this really best practice?

I'm writing this in anger (sorry if that comes across!) but I feel like every time I stumble on anything remotely  cool or new, *BAM -* admin rights. 

I understand the security implication, but surely there's a better way. When I was at a large tech firm, this wasn't a thing - but I'm not sure if my laptop was truly unlocked, or if they had a clever workaround. 

1. Is it reasonable/possible to ask IT to carve out an exception for the data science team. If you've manage this, what arguments or evidence actually worked? 
2. Is there a middle ground I don't know about?",61,20,2025-06-16T11:08:55+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lcpzzw/yes_i_do_want_to_allow_this_app_to_make_changes/,"""Yes, I do want to allow this app to make changes to my device!"" DS's in mid-sized firms: do you have to wrestle with the constant “admin approval required” pop-ups? Is this really best practice?

I'm writing this in anger (sorry if that comes across!) but I feel like every time I stumble on anything remotely  cool or new, *BAM -* admin rights. 

I understand the security implication, but surely there's a better way. When I was at a large tech firm, this wasn't a thing - but I'm not sure if my laptop was truly unlocked, or if they had a clever workaround. 

1. Is it reasonable/possible to ask IT to carve out an exception for the data science team. If you've manage this, what arguments or evidence actually worked? 
2. Is there a middle ground I don't know about?",yes i do want to allow this app to make changes to my device dss in midsized firms do you have to wrestle with the constant admin approval required popups is this really best practice im writing this in anger sorry if that comes across but i feel like every time i stumble on anything remotely cool or new bam admin rights i understand the security implication but surely theres a better way when i was at a large tech firm this wasnt a thing but im not sure if my laptop was truly unlocked or if they had a clever workaround is it reasonablepossible to ask it to carve out an exception for the data science team if youve manage this what arguments or evidence actually worked is there a middle ground i dont know about,yes want allow app change device dss midsized firm wrestle constant admin approval require popup good practice m write anger sorry come feel like time stumble remotely cool new bam admin right understand security implication surely s well way large tech firm not thing m sure laptop truly unlocked clever workaround reasonablepossible ask carve exception data science team ve manage argument evidence actually work middle ground not know
1lcjd6h,"Weekly Entering & Transitioning - Thread 16 Jun, 2025 - 23 Jun, 2025"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",4,27,2025-06-16T04:01:18+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lcjd6h/weekly_entering_transitioning_thread_16_jun_2025/,"Weekly Entering & Transitioning - Thread 16 Jun, 2025 - 23 Jun, 2025  

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",weekly entering transitioning thread jun jun welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the and resources pages on our wiki you can also search for answers in,weekly enter transition thread jun jun welcome week enter transition thread thread question getting start study transition data science field topic include learn resource eg book tutorial video traditional education eg schools degree elective alternative education eg online course bootcamp job search question eg resume apply career prospect elementary question eg start wait answer community check resource page wiki search answer
1lcemw6,"Don’t be the data scientist who’s in love with models, be the one who solves real problems","work at a company with around 100 data scientists, ML and data engineers.

The most frustrating part of working with many data scientists and honestly, I see this on this sub all the time too, is how obsessed some folks are with using ML or whatever the latest SoTA causal inference technique is. Earlier in my career plus during my masters, I was exactly the same, so I get it.

But here’s the best advice I can give you: **don’t be that person.**

Unless you’re literally working on a product where ML is the core feature, **your job is basically being an internal consultant.** That means understanding what stakeholders actually want, challenging their assumptions when needed, and giving them something useful, not just something that will disappear into a slide deck or notebook. 

Always try and make something run in production, don’t do endless proof of concepts. If you’re doing deep dives / analysis, define success criteria of your initiatives, try and measure them (e.g., some of my less technical but awesome DS colleagues made their career of finding drivers of key KPIs, reporting them to key stakeholders and measuring improvement over time). In short, **prove you’re worth it**.

A lot of the time, that means building a dashboard. Or doing proper data/software engineering. Or using GenAI. Or whatever else some of my colleagues (and a loads of people on this sub) roll their eyes at.

Solve the problem. Use whatever gets the job done, not just whatever looks cool on a résumé.",844,99,2025-06-15T23:52:42+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lcemw6/dont_be_the_data_scientist_whos_in_love_with/,"Don’t be the data scientist who’s in love with models, be the one who solves real problems work at a company with around 100 data scientists, ML and data engineers.

The most frustrating part of working with many data scientists and honestly, I see this on this sub all the time too, is how obsessed some folks are with using ML or whatever the latest SoTA causal inference technique is. Earlier in my career plus during my masters, I was exactly the same, so I get it.

But here’s the best advice I can give you: **don’t be that person.**

Unless you’re literally working on a product where ML is the core feature, **your job is basically being an internal consultant.** That means understanding what stakeholders actually want, challenging their assumptions when needed, and giving them something useful, not just something that will disappear into a slide deck or notebook. 

Always try and make something run in production, don’t do endless proof of concepts. If you’re doing deep dives / analysis, define success criteria of your initiatives, try and measure them (e.g., some of my less technical but awesome DS colleagues made their career of finding drivers of key KPIs, reporting them to key stakeholders and measuring improvement over time). In short, **prove you’re worth it**.

A lot of the time, that means building a dashboard. Or doing proper data/software engineering. Or using GenAI. Or whatever else some of my colleagues (and a loads of people on this sub) roll their eyes at.

Solve the problem. Use whatever gets the job done, not just whatever looks cool on a résumé.",dont be the data scientist whos in love with models be the one who solves real problems work at a company with around data scientists ml and data engineers the most frustrating part of working with many data scientists and honestly i see this on this sub all the time too is how obsessed some folks are with using ml or whatever the latest sota causal inference technique is earlier in my career plus during my masters i was exactly the same so i get it but heres the best advice i can give you dont be that person unless youre literally working on a product where ml is the core feature your job is basically being an internal consultant that means understanding what stakeholders actually want challenging their assumptions when needed and giving them something useful not just something that will disappear into a slide deck or notebook always try and make something run in production dont do endless proof of concepts if youre doing deep dives analysis define success criteria of your initiatives try and measure them eg some of my less technical but awesome ds colleagues made their career of finding drivers of key kpis reporting them to key stakeholders and measuring improvement over time in short prove youre worth it a lot of the time that means building a dashboard or doing proper datasoftware engineering or using genai or whatever else some of my colleagues and a loads of people on this sub roll their eyes at solve the problem use whatever gets the job done not just whatever looks cool on a rsum,not data scientist s love model solve real problem work company data scientist ml data engineer frustrating work data scientist honestly sub time obsessed folk ml late sota causal inference technique early career plus master exactly here good advice not person literally work product ml core feature job basically internal consultant mean understand stakeholder actually want challenge assumption need give useful disappear slide deck notebook try run production not endless proof concept deep dive analysis define success criterion initiative try measure eg technical awesome ds colleague career find driver key kpis report key stakeholder measure improvement time short prove worth lot time mean build dashboard proper datasoftware engineering genai colleague load people sub roll eye solve problem use get job look cool rsum
1lccbgj,Books on applied data science for B2B marketing?,"There's this thread from 3 years ago: https://www.reddit.com/r/datascience/comments/ram75g/books_on_applied_data_science_for_b2b_marketing/

Unfortunately, it never got any book recommendations - I'm in pretty much the exact same position as the OP of the linked thread and am looking for resources that explain the best methods and provide practical how-tos for marketing science/data science applied to B2B marketing.",4,2,2025-06-15T22:01:35+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lccbgj/books_on_applied_data_science_for_b2b_marketing/,"Books on applied data science for B2B marketing? There's this thread from 3 years ago: https://www.reddit.com/r/datascience/comments/ram75g/books_on_applied_data_science_for_b2b_marketing/

Unfortunately, it never got any book recommendations - I'm in pretty much the exact same position as the OP of the linked thread and am looking for resources that explain the best methods and provide practical how-tos for marketing science/data science applied to B2B marketing.",books on applied data science for bb marketing theres this thread from years ago unfortunately it never got any book recommendations im in pretty much the exact same position as the op of the linked thread and am looking for resources that explain the best methods and provide practical howtos for marketing sciencedata science applied to bb marketing,book apply data science bb marketing s thread year ago unfortunately get book recommendation m pretty exact position op link thread look resource explain good method provide practical howto marketing sciencedata science apply bb marketing
1lbksb6,creating a deepfake identity on Social media ( for good),"To avoid bullying on SM for my ideas, I want to replace my face with a deepfake ( not a real person, but I don t anyone to take it since i ll be using it all the time), what is the best way to do that? I already have ideas. but someone with deep knowledge will help me a lot. My pc also don t have gpu (amd rysen) so advice on that also will be helpful. thanks!",0,8,2025-06-14T22:22:41+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lbksb6/creating_a_deepfake_identity_on_social_media_for/,"creating a deepfake identity on Social media ( for good) To avoid bullying on SM for my ideas, I want to replace my face with a deepfake ( not a real person, but I don t anyone to take it since i ll be using it all the time), what is the best way to do that? I already have ideas. but someone with deep knowledge will help me a lot. My pc also don t have gpu (amd rysen) so advice on that also will be helpful. thanks!",creating a deepfake identity on social media for good to avoid bullying on sm for my ideas i want to replace my face with a deepfake not a real person but i don t anyone to take it since i ll be using it all the time what is the best way to do that i already have ideas but someone with deep knowledge will help me a lot my pc also don t have gpu amd rysen so advice on that also will be helpful thanks,create deepfake identity social medium good avoid bully sm idea want replace face deepfake real person don t ll time good way idea deep knowledge help lot pc don t gpu amd rysen advice helpful thank
1lare33,"""Data Annotation"" spam","Anyone else's job search site just absolutely spammed by Data Annotation? If I look up Data, ML, AI, or anything similar in my area I get 2-3 pages of there job posting.",139,29,2025-06-13T21:16:50+00:00,datascience,https://www.reddit.com/r/datascience/comments/1lare33/data_annotation_spam/,"""Data Annotation"" spam Anyone else's job search site just absolutely spammed by Data Annotation? If I look up Data, ML, AI, or anything similar in my area I get 2-3 pages of there job posting.",data annotation spam anyone elses job search site just absolutely spammed by data annotation if i look up data ml ai or anything similar in my area i get pages of there job posting,datum annotation spam else job search site absolutely spamme datum annotation look datum ml ai similar area page job posting
1l9w0ln,Significant humor,"Saw this and found it hilarious , thought I’d share it here as this is one of the few places this joke might actually land. 


Datetime.now() + timedelta(days=4) ",2374,62,2025-06-12T19:48:52+00:00,datascience,https://i.redd.it/dztfywc2wj6f1.jpeg,"Significant humor Saw this and found it hilarious , thought I’d share it here as this is one of the few places this joke might actually land. 


Datetime.now() + timedelta(days=4) ",significant humor saw this and found it hilarious thought id share it here as this is one of the few places this joke might actually land datetimenow timedeltadays,significant humor see find hilarious think d share place joke actually land datetimenow timedeltaday
1l9q78x,Do you say day-tah or dah-tah,"Grab the hornets nest, shake it, throw it, run!!!!",135,130,2025-06-12T16:02:08+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l9q78x/do_you_say_daytah_or_dahtah/,"Do you say day-tah or dah-tah Grab the hornets nest, shake it, throw it, run!!!!",do you say daytah or dahtah grab the hornets nest shake it throw it run,daytah dahtah grab hornet nest shake throw run
1l99bfz,Get dozens of messages from new graduates/ former data scientist  about roles at my organization. Is this a sign?,"Everyday I have  been getting more and more LinkedIn messages from people laid off from their analytics roles searching for roles from JPMorgan Chase to CVS, to name a few. Are we in for a downturn? This is making me nervous for my own role. This doesn’t even include all the new students who have just graduated.",224,119,2025-06-12T00:53:52+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l99bfz/get_dozens_of_messages_from_new_graduates_former/,"Get dozens of messages from new graduates/ former data scientist  about roles at my organization. Is this a sign? Everyday I have  been getting more and more LinkedIn messages from people laid off from their analytics roles searching for roles from JPMorgan Chase to CVS, to name a few. Are we in for a downturn? This is making me nervous for my own role. This doesn’t even include all the new students who have just graduated.",get dozens of messages from new graduates former data scientist about roles at my organization is this a sign everyday i have been getting more and more linkedin messages from people laid off from their analytics roles searching for roles from jpmorgan chase to cvs to name a few are we in for a downturn this is making me nervous for my own role this doesnt even include all the new students who have just graduated,dozen message new graduate data scientist role organization sign everyday get linkedin message people lay analytic role search role jpmorgan chase cvs downturn make nervous role not include new student graduate
1l8xqgf,Data scientists need to know about data contracts.,"Data contracts are these things that data engineers write to set up expectations of what the data looks like.

And who understands the expectations better than a data engineer? A data scientist with context about how the business works.

…But, most of us aren’t gonna write YAML files and glue contracts into pipelines.

We don’t do that kind of dirty job…

Still, if you want to stop data quality issues from showing up and impacting your machine learning models, contracts can still be the way to go.

Why? Because a good data contract connects two worlds:

• The business context you understand.

• The technical realities your team builds on.

That’s a perfect match for what great data scientists already do.",0,6,2025-06-11T16:52:05+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l8xqgf/data_scientists_need_to_know_about_data_contracts/,"Data scientists need to know about data contracts. Data contracts are these things that data engineers write to set up expectations of what the data looks like.

And who understands the expectations better than a data engineer? A data scientist with context about how the business works.

…But, most of us aren’t gonna write YAML files and glue contracts into pipelines.

We don’t do that kind of dirty job…

Still, if you want to stop data quality issues from showing up and impacting your machine learning models, contracts can still be the way to go.

Why? Because a good data contract connects two worlds:

• The business context you understand.

• The technical realities your team builds on.

That’s a perfect match for what great data scientists already do.",data scientists need to know about data contracts data contracts are these things that data engineers write to set up expectations of what the data looks like and who understands the expectations better than a data engineer a data scientist with context about how the business works but most of us arent gonna write yaml files and glue contracts into pipelines we dont do that kind of dirty job still if you want to stop data quality issues from showing up and impacting your machine learning models contracts can still be the way to go why because a good data contract connects two worlds the business context you understand the technical realities your team builds on thats a perfect match for what great data scientists already do,data scientist need know datum contract datum contract thing data engineer write set expectation datum look like understand expectation well data engineer data scientist context business work not go to write yaml file glue contract pipeline not kind dirty job want stop datum quality issue show impact machine learning model contract way good data contract connect world business context understand technical reality team build s perfect match great data scientist
1l8vdvk,What do you hates the most as a data scientist,"A bit of a rant here. But sometimes it feels like 90% of the time at my job is not about data science.  
I wonder if it is just me and my job is special or everyone is like this.

If I try to add up a project from end to end, may be there is 10-15% of really interesting modeling work.   
It looks something like this:  
- Go after different sources to get the right data - 20% (lot's of meeting)
- Clean the data - 20% (lot's of meeting to understand the data)
- Wrestling with some code issue, packages installation, old dependencies - 10%
- Data exploration, analysis, modeling - 10%
- validation & documentation - 10%
- Deployment, debugging deployment issues - 20%
- Some regular reporting, maintenance - 10%

How do things look like for you? I wonder if things are different depending on companies, industries etc..",233,129,2025-06-11T15:18:43+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l8vdvk/what_do_you_hates_the_most_as_a_data_scientist/,"What do you hates the most as a data scientist A bit of a rant here. But sometimes it feels like 90% of the time at my job is not about data science.  
I wonder if it is just me and my job is special or everyone is like this.

If I try to add up a project from end to end, may be there is 10-15% of really interesting modeling work.   
It looks something like this:  
- Go after different sources to get the right data - 20% (lot's of meeting)
- Clean the data - 20% (lot's of meeting to understand the data)
- Wrestling with some code issue, packages installation, old dependencies - 10%
- Data exploration, analysis, modeling - 10%
- validation & documentation - 10%
- Deployment, debugging deployment issues - 20%
- Some regular reporting, maintenance - 10%

How do things look like for you? I wonder if things are different depending on companies, industries etc..",what do you hates the most as a data scientist a bit of a rant here but sometimes it feels like of the time at my job is not about data science i wonder if it is just me and my job is special or everyone is like this if i try to add up a project from end to end may be there is of really interesting modeling work it looks something like this go after different sources to get the right data lots of meeting clean the data lots of meeting to understand the data wrestling with some code issue packages installation old dependencies data exploration analysis modeling validation documentation deployment debugging deployment issues some regular reporting maintenance how do things look like for you i wonder if things are different depending on companies industries etc,hate data scientist bit rant feel like time job data science wonder job special like try add project end end interesting modeling work look like different source right data lot meet clean data lot meeting understand datum wrestle code issue package installation old dependency datum exploration analysis model validation documentation deployment debug deployment issue regular reporting maintenance thing look like wonder thing different depend company industry etc
1l8kf9h,I have a training budget of ~250 USD for my own professional development. What would you recommend I spend it on?,"Pretty much the title, but here are some details:

* As far as I know, the budget can be spent on things like books, courses, seminars - things like that (possible also cloud services, haven't found out about that one)
* As far as the skills I currently have, my educational background is in mathematics (master's degree level) and my work today is mainly in classical ML and NLP. In the past I also did some bio-medical modeling with non-linear ODE systems.
* However, the scope of both the budget and my interests are pretty much anything to do with data science, so hit me with anything you've got :). Also, whatever it is doesn't have to fit perfectly into the budget - I'm happy to purchase multiple things, not use all of it or dip into my own pocket if needed.
* I'm based in Melbourne, Australia, in case someone has an in-person thing to recommend

Appreciate all the help!",47,29,2025-06-11T05:14:06+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l8kf9h/i_have_a_training_budget_of_250_usd_for_my_own/,"I have a training budget of ~250 USD for my own professional development. What would you recommend I spend it on? Pretty much the title, but here are some details:

* As far as I know, the budget can be spent on things like books, courses, seminars - things like that (possible also cloud services, haven't found out about that one)
* As far as the skills I currently have, my educational background is in mathematics (master's degree level) and my work today is mainly in classical ML and NLP. In the past I also did some bio-medical modeling with non-linear ODE systems.
* However, the scope of both the budget and my interests are pretty much anything to do with data science, so hit me with anything you've got :). Also, whatever it is doesn't have to fit perfectly into the budget - I'm happy to purchase multiple things, not use all of it or dip into my own pocket if needed.
* I'm based in Melbourne, Australia, in case someone has an in-person thing to recommend

Appreciate all the help!",i have a training budget of usd for my own professional development what would you recommend i spend it on pretty much the title but here are some details as far as i know the budget can be spent on things like books courses seminars things like that possible also cloud services havent found out about that one as far as the skills i currently have my educational background is in mathematics masters degree level and my work today is mainly in classical ml and nlp in the past i also did some biomedical modeling with nonlinear ode systems however the scope of both the budget and my interests are pretty much anything to do with data science so hit me with anything youve got also whatever it is doesnt have to fit perfectly into the budget im happy to purchase multiple things not use all of it or dip into my own pocket if needed im based in melbourne australia in case someone has an inperson thing to recommend appreciate all the help,training budget usd professional development recommend spend pretty title detail far know budget spend thing like book course seminar thing like possible cloud service not find far skill currently educational background mathematic master degree level work today mainly classical ml nlp past biomedical modeling nonlinear ode system scope budget interest pretty data science hit ve get not fit perfectly budget m happy purchase multiple thing use dip pocket need m base melbourne australia case inperson thing recommend appreciate help
1l8gmy0,Lyft vs Pinterest Data Science,"If you have some familiarity with both, how does Lyft compare with Pinterest for career growth both while inside the company and in terms of exit opportunities?",63,41,2025-06-11T01:48:37+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l8gmy0/lyft_vs_pinterest_data_science/,"Lyft vs Pinterest Data Science If you have some familiarity with both, how does Lyft compare with Pinterest for career growth both while inside the company and in terms of exit opportunities?",lyft vs pinterest data science if you have some familiarity with both how does lyft compare with pinterest for career growth both while inside the company and in terms of exit opportunities,lyft vs pinterest datum science familiarity lyft compare pinterest career growth inside company term exit opportunity
1l8e4iq,The higher ups asked me for an analysis and it worked.,"So I totally mean to brag here. Last week a group of directors said, “We suspect X is happening in the market, do we have data that demonstrates it?”

And I thought to myself, here we go again. I’ve got to wade through our data swamp then tell them we don’t have the data that tells the story they want.

Well I waded through the data swamp and the data was there. I made them a graph that definitively demonstrated that yes, X is happening as they suspected. It wasn’t super easy to figure out and it also didn’t require a super complex model to figure out either. ",527,41,2025-06-10T23:44:50+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l8e4iq/the_higher_ups_asked_me_for_an_analysis_and_it/,"The higher ups asked me for an analysis and it worked. So I totally mean to brag here. Last week a group of directors said, “We suspect X is happening in the market, do we have data that demonstrates it?”

And I thought to myself, here we go again. I’ve got to wade through our data swamp then tell them we don’t have the data that tells the story they want.

Well I waded through the data swamp and the data was there. I made them a graph that definitively demonstrated that yes, X is happening as they suspected. It wasn’t super easy to figure out and it also didn’t require a super complex model to figure out either. ",the higher ups asked me for an analysis and it worked so i totally mean to brag here last week a group of directors said we suspect x is happening in the market do we have data that demonstrates it and i thought to myself here we go again ive got to wade through our data swamp then tell them we dont have the data that tells the story they want well i waded through the data swamp and the data was there i made them a graph that definitively demonstrated that yes x is happening as they suspected it wasnt super easy to figure out and it also didnt require a super complex model to figure out either,high up ask analysis work totally mean brag week group director say suspect x happen market datum demonstrate think ve get wade datum swamp tell not datum tell story want wade data swamp datum graph definitively demonstrate yes x happen suspect not super easy figure not require super complex model figure
1l89f9z,no internship as a sophomore,"i have sent hundreds of applications, but wasn't able to land an internship this summer. i think it's my experience, i switched from microbiology to stats/ds  a year ago, but was hoping to get something over the summer which would help me recruit in my junior year. genuinely heartbroken.

can anyone give me advice on what to do in the summer improve my experience? things i can do to add on my cv, i have absolutely no clue.

thank you!

  
edit: thank you guys so so much - actually - i am so grateful for your ideas! i will work on some projects in the summer, i've reached out to some professors for research opportunities (might be late, but no harm in trying ig!) and i will expand on my knowledge. you guys are awesome :)",15,21,2025-06-10T20:27:21+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l89f9z/no_internship_as_a_sophomore/,"no internship as a sophomore i have sent hundreds of applications, but wasn't able to land an internship this summer. i think it's my experience, i switched from microbiology to stats/ds  a year ago, but was hoping to get something over the summer which would help me recruit in my junior year. genuinely heartbroken.

can anyone give me advice on what to do in the summer improve my experience? things i can do to add on my cv, i have absolutely no clue.

thank you!

  
edit: thank you guys so so much - actually - i am so grateful for your ideas! i will work on some projects in the summer, i've reached out to some professors for research opportunities (might be late, but no harm in trying ig!) and i will expand on my knowledge. you guys are awesome :)",no internship as a sophomore i have sent hundreds of applications but wasnt able to land an internship this summer i think its my experience i switched from microbiology to statsds a year ago but was hoping to get something over the summer which would help me recruit in my junior year genuinely heartbroken can anyone give me advice on what to do in the summer improve my experience things i can do to add on my cv i have absolutely no clue thank you edit thank you guys so so much actually i am so grateful for your ideas i will work on some projects in the summer ive reached out to some professors for research opportunities might be late but no harm in trying ig and i will expand on my knowledge you guys are awesome,internship sophomore send hundred application not able land internship summer think experience switch microbiology statsds year ago hope summer help recruit junior year genuinely heartbroken advice summer improve experience thing add cv absolutely clue thank edit thank guy actually grateful idea work project summer ve reach professor research opportunity late harm try ig expand knowledge guy awesome
1l843cd,Vicious circle of misplaced expectations with PMs and stakeholders,"Looking for opinions from experienced folks in DS.

Stuck in a vicious circle of misplaced expectations from stakeholders being agreed for delivery by PMs even without consulting DS to begin with. Then, those come to DS team to build because business stakeholders already know that is the solution they need/are missing - not necessarily true. So, that expectation functions like a feature in a front end application in the mind of a Product Manager - deterministic mode (not sure if it is agile or waterfall type of project management or whatever).

DS tries to do what is best possible but it falls short of what stakeholders expect - they literally say we thought some magic would happen through advanced data science!

PM now tries to do RCA to understand where things went wrong while continuing to play gallery to stakeholders unquestioningly. PM has difficulty understanding DS stuff and keeps telling to keep things non-technical while asking questions that are inherently technical! PM is more comfortable looking at data viz, React applications etc.

DS is to blame for not creating magic.

Meanwhile, users have other problems that could be solved by DA or DS but they lie unutilized because they are attached to Excel and Excel Macros. Not willing to share relevant domain inputs.

On loop.",21,23,2025-06-10T17:02:52+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l843cd/vicious_circle_of_misplaced_expectations_with_pms/,"Vicious circle of misplaced expectations with PMs and stakeholders Looking for opinions from experienced folks in DS.

Stuck in a vicious circle of misplaced expectations from stakeholders being agreed for delivery by PMs even without consulting DS to begin with. Then, those come to DS team to build because business stakeholders already know that is the solution they need/are missing - not necessarily true. So, that expectation functions like a feature in a front end application in the mind of a Product Manager - deterministic mode (not sure if it is agile or waterfall type of project management or whatever).

DS tries to do what is best possible but it falls short of what stakeholders expect - they literally say we thought some magic would happen through advanced data science!

PM now tries to do RCA to understand where things went wrong while continuing to play gallery to stakeholders unquestioningly. PM has difficulty understanding DS stuff and keeps telling to keep things non-technical while asking questions that are inherently technical! PM is more comfortable looking at data viz, React applications etc.

DS is to blame for not creating magic.

Meanwhile, users have other problems that could be solved by DA or DS but they lie unutilized because they are attached to Excel and Excel Macros. Not willing to share relevant domain inputs.

On loop.",vicious circle of misplaced expectations with pms and stakeholders looking for opinions from experienced folks in ds stuck in a vicious circle of misplaced expectations from stakeholders being agreed for delivery by pms even without consulting ds to begin with then those come to ds team to build because business stakeholders already know that is the solution they needare missing not necessarily true so that expectation functions like a feature in a front end application in the mind of a product manager deterministic mode not sure if it is agile or waterfall type of project management or whatever ds tries to do what is best possible but it falls short of what stakeholders expect they literally say we thought some magic would happen through advanced data science pm now tries to do rca to understand where things went wrong while continuing to play gallery to stakeholders unquestioningly pm has difficulty understanding ds stuff and keeps telling to keep things nontechnical while asking questions that are inherently technical pm is more comfortable looking at data viz react applications etc ds is to blame for not creating magic meanwhile users have other problems that could be solved by da or ds but they lie unutilized because they are attached to excel and excel macros not willing to share relevant domain inputs on loop,vicious circle misplaced expectation pm stakeholder look opinion experienced folk ds stick vicious circle misplaced expectation stakeholder agree delivery pm consult ds begin come ds team build business stakeholder know solution needare miss necessarily true expectation function like feature end application mind product manager deterministic mode sure agile waterfall type project management ds try well possible fall short stakeholder expect literally think magic happen advanced data science pm try rca understand thing go wrong continue play gallery stakeholder unquestioningly pm difficulty understand ds stuff keep tell thing nontechnical ask question inherently technical pm comfortable look datum viz react application etc ds blame create magic user problem solve da ds lie unutilized attach excel excel macros willing share relevant domain input loop
1l7spck,What Masters should could be an option after B.Sc Data Science,"Hello,

I recently completed B.Sc Data Science in India. Was wondering which M.Sc should I go for after this.

Someone told me M.Sc Data Science but when I checked the syllabus, a lot of subjects are similar. Would it still be a good option? Or please help with different options as well ",0,26,2025-06-10T07:35:31+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l7spck/what_masters_should_could_be_an_option_after_bsc/,"What Masters should could be an option after B.Sc Data Science Hello,

I recently completed B.Sc Data Science in India. Was wondering which M.Sc should I go for after this.

Someone told me M.Sc Data Science but when I checked the syllabus, a lot of subjects are similar. Would it still be a good option? Or please help with different options as well ",what masters should could be an option after bsc data science hello i recently completed bsc data science in india was wondering which msc should i go for after this someone told me msc data science but when i checked the syllabus a lot of subjects are similar would it still be a good option or please help with different options as well,master option bsc data science hello recently complete bsc datum science india wonder msc tell msc datum science check syllabus lot subject similar good option help different option
1l7knce,Can someone explain to me the difference between Fitting aggregation functions and regular old linear regression?,"They seem like basically the same thing? 
When would one prefer to use fitting aggregation functions?",14,8,2025-06-10T00:03:49+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l7knce/can_someone_explain_to_me_the_difference_between/,"Can someone explain to me the difference between Fitting aggregation functions and regular old linear regression? They seem like basically the same thing? 
When would one prefer to use fitting aggregation functions?",can someone explain to me the difference between fitting aggregation functions and regular old linear regression they seem like basically the same thing when would one prefer to use fitting aggregation functions,explain difference fitting aggregation function regular old linear regression like basically thing prefer use fitting aggregation function
1l7cbkg,"""What if we inverted that chart?""",,978,52,2025-06-09T18:24:27+00:00,datascience,https://i.redd.it/ens3q2p02y5f1.png,"""What if we inverted that chart?"" ",what if we inverted that chart,invert chart
1l77blf,ML monitoring startup NannyML got acquired by Soda Data Quality,,21,13,2025-06-09T15:11:14+00:00,datascience,https://siliconcanals.com/brussels-soda-acquires-nannyml/,ML monitoring startup NannyML got acquired by Soda Data Quality ,ml monitoring startup nannyml got acquired by soda data quality,ml monitor startup nannyml get acquire soda datum quality
1l6vciq,"Weekly Entering & Transitioning - Thread 09 Jun, 2025 - 16 Jun, 2025"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",12,52,2025-06-09T04:01:44+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l6vciq/weekly_entering_transitioning_thread_09_jun_2025/,"Weekly Entering & Transitioning - Thread 09 Jun, 2025 - 16 Jun, 2025  

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",weekly entering transitioning thread jun jun welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the and resources pages on our wiki you can also search for answers in,weekly enter transition thread jun jun welcome week enter transition thread thread question getting start study transition data science field topic include learn resource eg book tutorial video traditional education eg schools degree elective alternative education eg online course bootcamp job search question eg resume apply career prospect elementary question eg start wait answer community check resource page wiki search answer
1l6ac7v,"You can now automate deep dives, with clear actionable recommendations based on data.",,0,8,2025-06-08T11:52:12+00:00,datascience,https://medium.com/firebird-technologies/deep-analysis-your-new-superpower-for-insight-6a9244350a83,"You can now automate deep dives, with clear actionable recommendations based on data. ",you can now automate deep dives with clear actionable recommendations based on data,automate deep dive clear actionable recommendation base datum
1l5tiqg,What is your domain and what are the most important technical skills that help you stand out in your domain?,"Aside from soft skills and domain expertise, ofc those are a given.

I'm manufacturing-adjacent (closer to product development and validation). Design of experiments has been my most useful data-related skill. I'm always being asked ""We are doing test X to validate our process. Can you propose how to do it with less runs?"" Most of the other engineers in our team are familiar with the concept of DoE but aren't confident enough to generate or analyze it themselves, which is where my role typically falls into.",46,37,2025-06-07T19:49:58+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l5tiqg/what_is_your_domain_and_what_are_the_most/,"What is your domain and what are the most important technical skills that help you stand out in your domain? Aside from soft skills and domain expertise, ofc those are a given.

I'm manufacturing-adjacent (closer to product development and validation). Design of experiments has been my most useful data-related skill. I'm always being asked ""We are doing test X to validate our process. Can you propose how to do it with less runs?"" Most of the other engineers in our team are familiar with the concept of DoE but aren't confident enough to generate or analyze it themselves, which is where my role typically falls into.",what is your domain and what are the most important technical skills that help you stand out in your domain aside from soft skills and domain expertise ofc those are a given im manufacturingadjacent closer to product development and validation design of experiments has been my most useful datarelated skill im always being asked we are doing test x to validate our process can you propose how to do it with less runs most of the other engineers in our team are familiar with the concept of doe but arent confident enough to generate or analyze it themselves which is where my role typically falls into,domain important technical skill help stand domain aside soft skill domain expertise ofc give m manufacturingadjacent close product development validation design experiment useful datarelated skill m ask test x validate process propose run engineer team familiar concept doe not confident generate analyze role typically fall
1l5t9af,PhD vs Masters prepared data scientist expectations.,"Is there anything more that you expect from a data scientist with a PhD versus a data scientist with just a master's degree, given the same level of experience?

 For the companies that I've worked with, most data science teams were mixes of folks with master's degrees and folks with PhDs and various disciplines.

That got me thinking. As a manager or team member, do you expect more from your doctorally prepared data scientist then your data scientist with only Master's degrees? If so, what are you looking for?  

Are there any particular skills that data scientists with phds from a variety of disciplines have across the board that the typical Masters prepare data scientist doesn't have?

Is there something common about the research portion of a doctorate that develops in those with a PhD skills that aren't developed during the master's degree program? If so, how are they applicable to what we do as data scientists?",104,66,2025-06-07T19:38:07+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l5t9af/phd_vs_masters_prepared_data_scientist/,"PhD vs Masters prepared data scientist expectations. Is there anything more that you expect from a data scientist with a PhD versus a data scientist with just a master's degree, given the same level of experience?

 For the companies that I've worked with, most data science teams were mixes of folks with master's degrees and folks with PhDs and various disciplines.

That got me thinking. As a manager or team member, do you expect more from your doctorally prepared data scientist then your data scientist with only Master's degrees? If so, what are you looking for?  

Are there any particular skills that data scientists with phds from a variety of disciplines have across the board that the typical Masters prepare data scientist doesn't have?

Is there something common about the research portion of a doctorate that develops in those with a PhD skills that aren't developed during the master's degree program? If so, how are they applicable to what we do as data scientists?",phd vs masters prepared data scientist expectations is there anything more that you expect from a data scientist with a phd versus a data scientist with just a masters degree given the same level of experience for the companies that ive worked with most data science teams were mixes of folks with masters degrees and folks with phds and various disciplines that got me thinking as a manager or team member do you expect more from your doctorally prepared data scientist then your data scientist with only masters degrees if so what are you looking for are there any particular skills that data scientists with phds from a variety of disciplines have across the board that the typical masters prepare data scientist doesnt have is there something common about the research portion of a doctorate that develops in those with a phd skills that arent developed during the masters degree program if so how are they applicable to what we do as data scientists,phd vs master prepare data scientist expectation expect data scientist phd versus data scientist masters degree give level experience company ve work datum science team mix folk master degree folk phds discipline get think manager team member expect doctorally prepare data scientist data scientist master degree look particular skill data scientist phds variety discipline board typical master prepare datum scientist not common research portion doctorate develop phd skill not develop master degree program applicable data scientist
1l51ufd,Data analyst vs. engineer? At non-profit,"Hi all,

I am the only Data Analyst at a medium-sized company related to shared transportation (adjacent to Lime Scooter/Bike). I'm pretty early in my career (grad from college 3 years ago).

My role encompasses a LOT of responsibilities that aren't traditionally under ""data analyst"", the biggest of which being that I build and maintain all the data pipelines from our partner companies via API and webhooks to our own SQL database. This feels very much like the role of Data Engineer. From there, I use the SQL data to build dashboards / do analyses, etc, which is what I usually think of as ""Data Analyst"".

I am trying to argue for a raise (since data engineers are usually paid more than analysts), and I am trying to figure out if I should ask for a title change too. I'd like to have engineering somehow in it, but ""Data Engineer and Analyst"" doesn't sound great.

Does anyone have any experience or advice with this? Thanks!!",94,27,2025-06-06T19:56:35+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l51ufd/data_analyst_vs_engineer_at_nonprofit/,"Data analyst vs. engineer? At non-profit Hi all,

I am the only Data Analyst at a medium-sized company related to shared transportation (adjacent to Lime Scooter/Bike). I'm pretty early in my career (grad from college 3 years ago).

My role encompasses a LOT of responsibilities that aren't traditionally under ""data analyst"", the biggest of which being that I build and maintain all the data pipelines from our partner companies via API and webhooks to our own SQL database. This feels very much like the role of Data Engineer. From there, I use the SQL data to build dashboards / do analyses, etc, which is what I usually think of as ""Data Analyst"".

I am trying to argue for a raise (since data engineers are usually paid more than analysts), and I am trying to figure out if I should ask for a title change too. I'd like to have engineering somehow in it, but ""Data Engineer and Analyst"" doesn't sound great.

Does anyone have any experience or advice with this? Thanks!!",data analyst vs engineer at nonprofit hi all i am the only data analyst at a mediumsized company related to shared transportation adjacent to lime scooterbike im pretty early in my career grad from college years ago my role encompasses a lot of responsibilities that arent traditionally under data analyst the biggest of which being that i build and maintain all the data pipelines from our partner companies via api and webhooks to our own sql database this feels very much like the role of data engineer from there i use the sql data to build dashboards do analyses etc which is what i usually think of as data analyst i am trying to argue for a raise since data engineers are usually paid more than analysts and i am trying to figure out if i should ask for a title change too id like to have engineering somehow in it but data engineer and analyst doesnt sound great does anyone have any experience or advice with this thanks,datum analyst vs engineer nonprofit hi data analyst mediumsize company relate share transportation adjacent lime scooterbike m pretty early career grad college year ago role encompass lot responsibility not traditionally datum analyst big build maintain data pipeline partner company api webhook sql database feel like role datum engineer use sql datum build dashboard analysis etc usually think datum analyst try argue raise data engineer usually pay analyst try figure ask title change d like engineer data engineer analyst not sound great experience advice thank
1l51gfr,Understanding Regression Discontinuity Design,"In my latest blog post I break-down **regression discontinuity design** \- then I build it up again in an intuition-first manner. It will become clear why you really want to understand this technique (but, that there is never really free lunch)

[Here it is](https://towardsdatascience.com/regression-discontinuity-design-how-it-works-and-when-to-use-it/) @ Towards Data Science

**My own takeaways:**

1. Assumptions make it or break it - with RDD more than ever
2. LATE might be not what we need, but it'll be what we get
3. RDD and instrumental variables have lots in common. At least both are very ""elegant"".
4. Sprinkle covariates into your model very, very delicately or you'll do more harm than good
5. Never lose track of the question you're trying to answer, and never pick it up if it did not matter to begin with

I get it; you really can't imagine how you're going to read straight on for 40 minutes; no worries, you don't have to. Just make sure you don't miss part where I leverage results page cutoff (max. 30 items per page) to recover the causal effect of top-positions on conversion — for them e-commerce / online marketplace DS out there.",19,9,2025-06-06T19:39:44+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l51gfr/understanding_regression_discontinuity_design/,"Understanding Regression Discontinuity Design In my latest blog post I break-down **regression discontinuity design** \- then I build it up again in an intuition-first manner. It will become clear why you really want to understand this technique (but, that there is never really free lunch)

[Here it is](https://towardsdatascience.com/regression-discontinuity-design-how-it-works-and-when-to-use-it/) @ Towards Data Science

**My own takeaways:**

1. Assumptions make it or break it - with RDD more than ever
2. LATE might be not what we need, but it'll be what we get
3. RDD and instrumental variables have lots in common. At least both are very ""elegant"".
4. Sprinkle covariates into your model very, very delicately or you'll do more harm than good
5. Never lose track of the question you're trying to answer, and never pick it up if it did not matter to begin with

I get it; you really can't imagine how you're going to read straight on for 40 minutes; no worries, you don't have to. Just make sure you don't miss part where I leverage results page cutoff (max. 30 items per page) to recover the causal effect of top-positions on conversion — for them e-commerce / online marketplace DS out there.",understanding regression discontinuity design in my latest blog post i breakdown regression discontinuity design then i build it up again in an intuitionfirst manner it will become clear why you really want to understand this technique but that there is never really free lunch towards data science my own takeaways assumptions make it or break it with rdd more than ever late might be not what we need but itll be what we get rdd and instrumental variables have lots in common at least both are very elegant sprinkle covariates into your model very very delicately or youll do more harm than good never lose track of the question youre trying to answer and never pick it up if it did not matter to begin with i get it you really cant imagine how youre going to read straight on for minutes no worries you dont have to just make sure you dont miss part where i leverage results page cutoff max items per page to recover the causal effect of toppositions on conversion for them ecommerce online marketplace ds out there,understand regression discontinuity design late blog post breakdown regression discontinuity design build intuitionfirst manner clear want understand technique free lunch datum science takeaway assumption break rdd late need ll rdd instrumental variable lot common elegant sprinkle covariate model delicately ll harm good lose track question try answer pick matter begin not imagine go read straight minute worry not sure not miss leverage result page cutoff max item page recover causal effect topposition conversion ecommerce online marketplace ds
1l4txpv,BI and Predictive Analytics on SaaS Data Sources,"Hi guys,

Seeking advice on a best practices in data management using data from SaaS sources (e.g., CRM, accounting software). 

The goal is to establish robust business intelligence (BI) and potentially incorporate predictive analytics while keeping the approach lean, avoiding unnecessary bloating of components.

1. For data integration, would you use tools like Airbyte or Stitch to extract data from SaaS sources and load it into a data warehouse like Google BigQuery? Would you use Looker for BI and EDA, or is there another stack you’d suggest to gather all data in one place?

2. For predictive analytics, would you use BigQuery’s built-in ML modeling features to keep the solution simple or opt for custom modeling in Python? 

Appreciate your feedback and recommendations!",7,3,2025-06-06T14:33:04+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l4txpv/bi_and_predictive_analytics_on_saas_data_sources/,"BI and Predictive Analytics on SaaS Data Sources Hi guys,

Seeking advice on a best practices in data management using data from SaaS sources (e.g., CRM, accounting software). 

The goal is to establish robust business intelligence (BI) and potentially incorporate predictive analytics while keeping the approach lean, avoiding unnecessary bloating of components.

1. For data integration, would you use tools like Airbyte or Stitch to extract data from SaaS sources and load it into a data warehouse like Google BigQuery? Would you use Looker for BI and EDA, or is there another stack you’d suggest to gather all data in one place?

2. For predictive analytics, would you use BigQuery’s built-in ML modeling features to keep the solution simple or opt for custom modeling in Python? 

Appreciate your feedback and recommendations!",bi and predictive analytics on saas data sources hi guys seeking advice on a best practices in data management using data from saas sources eg crm accounting software the goal is to establish robust business intelligence bi and potentially incorporate predictive analytics while keeping the approach lean avoiding unnecessary bloating of components for data integration would you use tools like airbyte or stitch to extract data from saas sources and load it into a data warehouse like google bigquery would you use looker for bi and eda or is there another stack youd suggest to gather all data in one place for predictive analytics would you use bigquerys builtin ml modeling features to keep the solution simple or opt for custom modeling in python appreciate your feedback and recommendations,bi predictive analytic saas datum source hi guy seek advice good practice datum management datum saas source eg crm accounting software goal establish robust business intelligence bi potentially incorporate predictive analytic keep approach lean avoid unnecessary bloating component datum integration use tool like airbyte stitch extract datum saas source load data warehouse like google bigquery use looker bi eda stack d suggest gather datum place predictive analytic use bigquerys builtin ml modeling feature solution simple opt custom modeling python appreciate feedback recommendation
1l4b3t7,"Need help sorting my thoughts about current ""contract""","Just reaching out to industry veterans to see if anyone can offer me some level-headed advice. Maybe you've been in a similar situation and can tell me how you approached the issue. Maybe you've been on the other side of my situation and can offer me that perspective.

For context:  
I'm a new grad who has been struggling to find work for a while now. My fiancée mentioned my power BI experience to her boss (general manager) at work and that got the ball rolling on a small contract. I was thrilled. I would be reporting to the ops manager and she had plans for a solid 4 month contract. She takes her plan off to the owner who says he wants to start off with 1 BI report done in 35 hours as a test run as a sort of feasibility thing. I do up a solid report in 32 hours. Ops manager loves it. General manager likes it. Owner thinks I missed the mark. Damn. His feedback is that he doesn't like that he has to filter to get some of the information. He'd like pieces of it to be readily available and visible without having to click anything. I take this feedback and quickly add cards with the wanted measures. Not good enough, now he wants to see more without having to filter. Oh also, he wants all the info to be on one page and all viewable without having to scroll. I tried to tell him that's not the best way to use power BI multiple times, but he just kinda brushed me off and kept moving along every time. We get to a point where he's finally happy with this report. Now he wants to see the small approach we agreed upon applied to a new report so he can verify it from scratch without me needing to take more time to implement feedback after. So I get a new report to work on, and only 20 hours this time. It's an easier data set, so I'm able to blast through it pretty quick and I do it up with his own requested measures shown prominently all on one page, with some visuals for some more complex relationships. Nope. Somehow this one isn't good enough either, but now they have this document that they just keep adding little requests to. I've gone at this thing like 4 or 5 times now. It'll be good, so we move on to the next phase, but then I somehow miss the mark on that and have to go back to the first phase and incorporate new measures?!?!?

Now he keeps giving me these tiny 3 hour micro contracts and moving the goal posts while dangling a longer contract in front of me at the end of a long stick. It's gotten to the point that literally everything on the page is being fed by a measure so that he doesn't have to filter. Am I overreacting and is this a normal use of power BI? They're paying me dog shit too (bottom 1% for my area). I feel like telling them to all fuck off, but I need to navigate things appropriately so that it doesn't negatively impact my fiancée. I'm feeling massively disrespected and played, though. I feel like it goes against everything I've learned about the tool. I'm trying to be cooperative so I can land this contract while also trying to avoid being taken advantage of because I'm a new grad. 

Oh! Also, this dude said to the ops manager that he thought I was going to use up any extra safety time he gives me because I just want the hours. This is after I saved 3 hours on my first sprint and 6 hours on my second sprint. I don't understand what his issue is. Ops manager thinks he should just give me a solid contract but keeps making excuses for why we should just try one more time to meet his unrealistic wants. 

Typing all this out has helped me realize just how much I'm being screwed. I'm going to post it anyway cause I still want other people's feedback, but yeah, I see how spineless I'm being. It's just hard to walk away when I could really use the contract that they keep dangling, but I don't think it's ever coming.

Sorry if this reads like a scatterbrained mess of words. I'm just kinda shot gunning my thoughts out. Anything constructive you can offer is appreciated. Apologies if this is a topic that has been answered 1000 times.",13,10,2025-06-05T21:25:21+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l4b3t7/need_help_sorting_my_thoughts_about_current/,"Need help sorting my thoughts about current ""contract"" Just reaching out to industry veterans to see if anyone can offer me some level-headed advice. Maybe you've been in a similar situation and can tell me how you approached the issue. Maybe you've been on the other side of my situation and can offer me that perspective.

For context:  
I'm a new grad who has been struggling to find work for a while now. My fiancée mentioned my power BI experience to her boss (general manager) at work and that got the ball rolling on a small contract. I was thrilled. I would be reporting to the ops manager and she had plans for a solid 4 month contract. She takes her plan off to the owner who says he wants to start off with 1 BI report done in 35 hours as a test run as a sort of feasibility thing. I do up a solid report in 32 hours. Ops manager loves it. General manager likes it. Owner thinks I missed the mark. Damn. His feedback is that he doesn't like that he has to filter to get some of the information. He'd like pieces of it to be readily available and visible without having to click anything. I take this feedback and quickly add cards with the wanted measures. Not good enough, now he wants to see more without having to filter. Oh also, he wants all the info to be on one page and all viewable without having to scroll. I tried to tell him that's not the best way to use power BI multiple times, but he just kinda brushed me off and kept moving along every time. We get to a point where he's finally happy with this report. Now he wants to see the small approach we agreed upon applied to a new report so he can verify it from scratch without me needing to take more time to implement feedback after. So I get a new report to work on, and only 20 hours this time. It's an easier data set, so I'm able to blast through it pretty quick and I do it up with his own requested measures shown prominently all on one page, with some visuals for some more complex relationships. Nope. Somehow this one isn't good enough either, but now they have this document that they just keep adding little requests to. I've gone at this thing like 4 or 5 times now. It'll be good, so we move on to the next phase, but then I somehow miss the mark on that and have to go back to the first phase and incorporate new measures?!?!?

Now he keeps giving me these tiny 3 hour micro contracts and moving the goal posts while dangling a longer contract in front of me at the end of a long stick. It's gotten to the point that literally everything on the page is being fed by a measure so that he doesn't have to filter. Am I overreacting and is this a normal use of power BI? They're paying me dog shit too (bottom 1% for my area). I feel like telling them to all fuck off, but I need to navigate things appropriately so that it doesn't negatively impact my fiancée. I'm feeling massively disrespected and played, though. I feel like it goes against everything I've learned about the tool. I'm trying to be cooperative so I can land this contract while also trying to avoid being taken advantage of because I'm a new grad. 

Oh! Also, this dude said to the ops manager that he thought I was going to use up any extra safety time he gives me because I just want the hours. This is after I saved 3 hours on my first sprint and 6 hours on my second sprint. I don't understand what his issue is. Ops manager thinks he should just give me a solid contract but keeps making excuses for why we should just try one more time to meet his unrealistic wants. 

Typing all this out has helped me realize just how much I'm being screwed. I'm going to post it anyway cause I still want other people's feedback, but yeah, I see how spineless I'm being. It's just hard to walk away when I could really use the contract that they keep dangling, but I don't think it's ever coming.

Sorry if this reads like a scatterbrained mess of words. I'm just kinda shot gunning my thoughts out. Anything constructive you can offer is appreciated. Apologies if this is a topic that has been answered 1000 times.",need help sorting my thoughts about current contract just reaching out to industry veterans to see if anyone can offer me some levelheaded advice maybe youve been in a similar situation and can tell me how you approached the issue maybe youve been on the other side of my situation and can offer me that perspective for context im a new grad who has been struggling to find work for a while now my fiance mentioned my power bi experience to her boss general manager at work and that got the ball rolling on a small contract i was thrilled i would be reporting to the ops manager and she had plans for a solid month contract she takes her plan off to the owner who says he wants to start off with bi report done in hours as a test run as a sort of feasibility thing i do up a solid report in hours ops manager loves it general manager likes it owner thinks i missed the mark damn his feedback is that he doesnt like that he has to filter to get some of the information hed like pieces of it to be readily available and visible without having to click anything i take this feedback and quickly add cards with the wanted measures not good enough now he wants to see more without having to filter oh also he wants all the info to be on one page and all viewable without having to scroll i tried to tell him thats not the best way to use power bi multiple times but he just kinda brushed me off and kept moving along every time we get to a point where hes finally happy with this report now he wants to see the small approach we agreed upon applied to a new report so he can verify it from scratch without me needing to take more time to implement feedback after so i get a new report to work on and only hours this time its an easier data set so im able to blast through it pretty quick and i do it up with his own requested measures shown prominently all on one page with some visuals for some more complex relationships nope somehow this one isnt good enough either but now they have this document that they just keep adding little requests to ive gone at this thing like or times now itll be good so we move on to the next phase but then i somehow miss the mark on that and have to go back to the first phase and incorporate new measures now he keeps giving me these tiny hour micro contracts and moving the goal posts while dangling a longer contract in front of me at the end of a long stick its gotten to the point that literally everything on the page is being fed by a measure so that he doesnt have to filter am i overreacting and is this a normal use of power bi theyre paying me dog shit too bottom for my area i feel like telling them to all fuck off but i need to navigate things appropriately so that it doesnt negatively impact my fiance im feeling massively disrespected and played though i feel like it goes against everything ive learned about the tool im trying to be cooperative so i can land this contract while also trying to avoid being taken advantage of because im a new grad oh also this dude said to the ops manager that he thought i was going to use up any extra safety time he gives me because i just want the hours this is after i saved hours on my first sprint and hours on my second sprint i dont understand what his issue is ops manager thinks he should just give me a solid contract but keeps making excuses for why we should just try one more time to meet his unrealistic wants typing all this out has helped me realize just how much im being screwed im going to post it anyway cause i still want other peoples feedback but yeah i see how spineless im being its just hard to walk away when i could really use the contract that they keep dangling but i dont think its ever coming sorry if this reads like a scatterbrained mess of words im just kinda shot gunning my thoughts out anything constructive you can offer is appreciated apologies if this is a topic that has been answered times,need help sort thought current contract reach industry veteran offer levelheade advice maybe ve similar situation tell approach issue maybe ve situation offer perspective context m new grad struggle find work fiance mention power bi experience boss general manager work get ball roll small contract thrill report op manager plan solid month contract take plan owner say want start bi report hour test run sort feasibility thing solid report hour op manager love general manager like owner think miss mark damn feedback not like filter information d like piece readily available visible have click feedback quickly add card want measure good want have filter oh want info page viewable have scroll try tell s good way use power bi multiple time kinda brush keep move time point s finally happy report want small approach agree apply new report verify scratch need time implement feedback new report work hour time easy datum set m able blast pretty quick request measure show prominently page visual complex relationship nope not good document add little request ve go thing like time ll good phase miss mark phase incorporate new measure keep give tiny hour micro contract move goal post dangle long contract end long stick get point literally page feed measure not filter overreact normal use power bi pay dog shit area feel like tell fuck need navigate thing appropriately not negatively impact fiance m feel massively disrespected play feel like go ve learn tool m try cooperative land contract try avoid take advantage m new grad oh dude say op manager think go use extra safety time give want hour save hour sprint hour second sprint not understand issue op manager think solid contract keep make excuse try time meet unrealistic want type help realize m screw m go post cause want people feedback yeah spineless m hard walk away use contract dangle not think come sorry read like scatterbrained mess word m kinda shot gun thought constructive offer appreciated apology topic answer time
1l49208,"Humble Bundle: ML, GenAI and more from O'Reilly",This 'pay what you want' [Humble Bundle](https://www.humblebundle.com/books/machine-learning-ai-and-bots-oreilly-2025-books) from O'Reilly is very GenAI leaning,83,16,2025-06-05T20:02:09+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l49208/humble_bundle_ml_genai_and_more_from_oreilly/,"Humble Bundle: ML, GenAI and more from O'Reilly This 'pay what you want' [Humble Bundle](https://www.humblebundle.com/books/machine-learning-ai-and-bots-oreilly-2025-books) from O'Reilly is very GenAI leaning",humble bundle ml genai and more from oreilly this pay what you want from oreilly is very genai leaning,humble bundle ml genai oreilly pay want oreilly genai lean
1l40tho,What is the best IDE for data science in 2025?,"Hi all,  
I am a ""old"" data scientists looking to renew my stacks. Looking for opinions on what is the best IDE in 2025.   
The other discussion I found was 1 year ago and some even older. 

So what do you use as IDE for data science (data extraction, cleaning, modeling to deployment)? What do you like and what you don't like about it? 

Currently, I am using JupyterLab:  
**What I like:**  
\- Native compatible with notebook, I still find notebook the right format to explore and share results  
\- %magic command  
\- Widget and compatible with all sorts of dataviz (plotly, etc)  
\- Export in HTML

**What I feel missing (but I wonder whether it is mostly because I don't know how to use it):**  
\- Debugging  
\- Autocomplete doesn't seems to work most of the time.   
\- Tree view of file and folder  
\- Comment out block of code ? (I remember it used to work but I don't know why it don't work anymore)  
\- Great integration of AI like Github Copilot

Thanks in advance and looking forward to read your thoughts.",162,274,2025-06-05T14:37:30+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l40tho/what_is_the_best_ide_for_data_science_in_2025/,"What is the best IDE for data science in 2025? Hi all,  
I am a ""old"" data scientists looking to renew my stacks. Looking for opinions on what is the best IDE in 2025.   
The other discussion I found was 1 year ago and some even older. 

So what do you use as IDE for data science (data extraction, cleaning, modeling to deployment)? What do you like and what you don't like about it? 

Currently, I am using JupyterLab:  
**What I like:**  
\- Native compatible with notebook, I still find notebook the right format to explore and share results  
\- %magic command  
\- Widget and compatible with all sorts of dataviz (plotly, etc)  
\- Export in HTML

**What I feel missing (but I wonder whether it is mostly because I don't know how to use it):**  
\- Debugging  
\- Autocomplete doesn't seems to work most of the time.   
\- Tree view of file and folder  
\- Comment out block of code ? (I remember it used to work but I don't know why it don't work anymore)  
\- Great integration of AI like Github Copilot

Thanks in advance and looking forward to read your thoughts.",what is the best ide for data science in hi all i am a old data scientists looking to renew my stacks looking for opinions on what is the best ide in the other discussion i found was year ago and some even older so what do you use as ide for data science data extraction cleaning modeling to deployment what do you like and what you dont like about it currently i am using jupyterlab what i like native compatible with notebook i still find notebook the right format to explore and share results magic command widget and compatible with all sorts of dataviz plotly etc export in html what i feel missing but i wonder whether it is mostly because i dont know how to use it debugging autocomplete doesnt seems to work most of the time tree view of file and folder comment out block of code i remember it used to work but i dont know why it dont work anymore great integration of ai like github copilot thanks in advance and looking forward to read your thoughts,good ide datum science hi old data scientist look renew stack look opinion good ide discussion find year ago old use ide datum science datum extraction clean modeling deployment like not like currently jupyterlab like native compatible notebook find notebook right format explore share result magic command widget compatible sort dataviz plotly etc export html feel missing wonder not know use debug autocomplete not work time tree view file folder comment block code remember work not know not work anymore great integration ai like github copilot thank advance look forward read thought
1l3y3sd,Introducing the MLSYNTH App,"Presumably most people here know Python, but either way, [here's an app](https://mlsynthapp.streamlit.app/about) for my mlsynth library. Now, you can run impact analysis models without needing to know Python, all you need to know is econometrics.",6,9,2025-06-05T12:37:23+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l3y3sd/introducing_the_mlsynth_app/,"Introducing the MLSYNTH App Presumably most people here know Python, but either way, [here's an app](https://mlsynthapp.streamlit.app/about) for my mlsynth library. Now, you can run impact analysis models without needing to know Python, all you need to know is econometrics.",introducing the mlsynth app presumably most people here know python but either way for my mlsynth library now you can run impact analysis models without needing to know python all you need to know is econometrics,introduce mlsynth app presumably people know python way mlsynth library run impact analysis model need know python need know econometric
1l2lqs3,Follow up question to my previous post.,"Previous post: https://www.reddit.com/r/datascience/comments/1l1pm5w/am_i_walking_into_a_trap/


Hello everyone! Thank you so much for the comments on the previous post. It was very helpful to understand your view. I have a follow up question and want to hear your opinion:

I also have an offer to study computer science at University of Bristol. 

Would you rather:

Take the data science job with no direct mentoring for £33,000 pay

OR

Study an MSc for Computer Science (Conversion) at Bristol University
",0,6,2025-06-03T20:01:17+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l2lqs3/follow_up_question_to_my_previous_post/,"Follow up question to my previous post. Previous post: https://www.reddit.com/r/datascience/comments/1l1pm5w/am_i_walking_into_a_trap/


Hello everyone! Thank you so much for the comments on the previous post. It was very helpful to understand your view. I have a follow up question and want to hear your opinion:

I also have an offer to study computer science at University of Bristol. 

Would you rather:

Take the data science job with no direct mentoring for £33,000 pay

OR

Study an MSc for Computer Science (Conversion) at Bristol University
",follow up question to my previous post previous post hello everyone thank you so much for the comments on the previous post it was very helpful to understand your view i have a follow up question and want to hear your opinion i also have an offer to study computer science at university of bristol would you rather take the data science job with no direct mentoring for pay or study an msc for computer science conversion at bristol university,follow question previous post previous post hello thank comment previous post helpful understand view follow question want hear opinion offer study computer science university bristol data science job direct mentoring pay study msc computer science conversion bristol university
1l2i3p2,What projects are in high demand?,"I have 15 YOE. Looking for new job after 7 years. I mostly do anomaly detection and data engineering. I have all the normal skills (ML, Spark, etc). All the postings say something like use giant list of tech skills to drive value but they don’t mention the actual projects.

What type of projects are you doing which are in high demand?",131,49,2025-06-03T17:34:19+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l2i3p2/what_projects_are_in_high_demand/,"What projects are in high demand? I have 15 YOE. Looking for new job after 7 years. I mostly do anomaly detection and data engineering. I have all the normal skills (ML, Spark, etc). All the postings say something like use giant list of tech skills to drive value but they don’t mention the actual projects.

What type of projects are you doing which are in high demand?",what projects are in high demand i have yoe looking for new job after years i mostly do anomaly detection and data engineering i have all the normal skills ml spark etc all the postings say something like use giant list of tech skills to drive value but they dont mention the actual projects what type of projects are you doing which are in high demand,project high demand yoe look new job year anomaly detection data engineering normal skill ml spark etc posting like use giant list tech skill drive value not mention actual project type project high demand
1l2g1rh,Why am I not getting interviews?,,782,399,2025-06-03T16:15:04+00:00,datascience,https://i.redd.it/gh451zoplq4f1.png,Why am I not getting interviews? ,why am i not getting interviews,get interview
1l2f2ph,DuckLake: This is your Data Lake on ACID,,32,9,2025-06-03T15:36:50+00:00,datascience,https://www.definite.app/blog/ducklake,DuckLake: This is your Data Lake on ACID ,ducklake this is your data lake on acid,ducklake data lake acid
1l2bmqx,First Hitting Time in ARIMA models,"Hi everybody. I am learning about time series, starting from the simple ideas of autoregressive models. I kinda understand, intuitively, how these models define the conditional distribution of the value at the next timestep X\_t given all previous values, but I'm struggling to understand how can I use these models to estimate the day at which my time series crosses a certain threshold, or in other words the probability distribution of the random variable τ i.e. the first day at which the value X\_τ exceeds a certain threshold.

So far I've been following some well known online sources such as [https://otexts.com/fpp3/](https://otexts.com/fpp3/) and lots of google searches but I struggle to find a walkthrough of this specific problem with ARIMA models. Is it that uncommon? Or am I just stupid",34,8,2025-06-03T13:16:25+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l2bmqx/first_hitting_time_in_arima_models/,"First Hitting Time in ARIMA models Hi everybody. I am learning about time series, starting from the simple ideas of autoregressive models. I kinda understand, intuitively, how these models define the conditional distribution of the value at the next timestep X\_t given all previous values, but I'm struggling to understand how can I use these models to estimate the day at which my time series crosses a certain threshold, or in other words the probability distribution of the random variable τ i.e. the first day at which the value X\_τ exceeds a certain threshold.

So far I've been following some well known online sources such as [https://otexts.com/fpp3/](https://otexts.com/fpp3/) and lots of google searches but I struggle to find a walkthrough of this specific problem with ARIMA models. Is it that uncommon? Or am I just stupid",first hitting time in arima models hi everybody i am learning about time series starting from the simple ideas of autoregressive models i kinda understand intuitively how these models define the conditional distribution of the value at the next timestep xt given all previous values but im struggling to understand how can i use these models to estimate the day at which my time series crosses a certain threshold or in other words the probability distribution of the random variable ie the first day at which the value x exceeds a certain threshold so far ive been following some well known online sources such as and lots of google searches but i struggle to find a walkthrough of this specific problem with arima models is it that uncommon or am i just stupid,hit time arima model hi everybody learn time series start simple idea autoregressive model kinda understand intuitively model define conditional distribution value timestep xt give previous value m struggle understand use model estimate day time series cross certain threshold word probability distribution random variable ie day value x exceed certain threshold far ve follow know online source lot google search struggle find walkthrough specific problem arima model uncommon stupid
1l21w10,"Your first job matters more than you know, and sometimes it matters more than an advanced degree","Your first job matters more than you know, and sometimes it matters more than a masters degree.

This is something myself and a few others have mentioned here however I find that this discussion still doesn't occur enough.

I'm in a position and have been for the last few years where I get to define the hiring pipeline.

Generally speaking, I pay way more attention to what someone has been doing for the last 4 years than what they have a degree in. If someone studied a BS in geoscience then did predictive analytics for GIS and environmental services and I just happen to be working at a financial firm that's interested in environment / services then when it comes to that person or the guy with a PhD in Industrial Engineering I'm taking the BS in geoscience.

Same thing in a less niche space, if I'm looking for someone who can come up with initiatives and drive them with business leaders then I'm generally looking for someone who did analytics at a supply chain / distribution company because they know how to stand up for themself, they're willing to work more / take ownership, etc.

It doesn't matter if you got an MS from Stanford if you do compliance analytics or data governance at a bank, you're now less desirable for many applied data science positions. This being said, many smaller companies are now getting to the point where they need data governance and there is a space for you to be a leader there.

Saying this because outside of research positions, the field you work in does impact how easy it is to tranistion to other roles.",332,60,2025-06-03T03:30:27+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l21w10/your_first_job_matters_more_than_you_know_and/,"Your first job matters more than you know, and sometimes it matters more than an advanced degree Your first job matters more than you know, and sometimes it matters more than a masters degree.

This is something myself and a few others have mentioned here however I find that this discussion still doesn't occur enough.

I'm in a position and have been for the last few years where I get to define the hiring pipeline.

Generally speaking, I pay way more attention to what someone has been doing for the last 4 years than what they have a degree in. If someone studied a BS in geoscience then did predictive analytics for GIS and environmental services and I just happen to be working at a financial firm that's interested in environment / services then when it comes to that person or the guy with a PhD in Industrial Engineering I'm taking the BS in geoscience.

Same thing in a less niche space, if I'm looking for someone who can come up with initiatives and drive them with business leaders then I'm generally looking for someone who did analytics at a supply chain / distribution company because they know how to stand up for themself, they're willing to work more / take ownership, etc.

It doesn't matter if you got an MS from Stanford if you do compliance analytics or data governance at a bank, you're now less desirable for many applied data science positions. This being said, many smaller companies are now getting to the point where they need data governance and there is a space for you to be a leader there.

Saying this because outside of research positions, the field you work in does impact how easy it is to tranistion to other roles.",your first job matters more than you know and sometimes it matters more than an advanced degree your first job matters more than you know and sometimes it matters more than a masters degree this is something myself and a few others have mentioned here however i find that this discussion still doesnt occur enough im in a position and have been for the last few years where i get to define the hiring pipeline generally speaking i pay way more attention to what someone has been doing for the last years than what they have a degree in if someone studied a bs in geoscience then did predictive analytics for gis and environmental services and i just happen to be working at a financial firm thats interested in environment services then when it comes to that person or the guy with a phd in industrial engineering im taking the bs in geoscience same thing in a less niche space if im looking for someone who can come up with initiatives and drive them with business leaders then im generally looking for someone who did analytics at a supply chain distribution company because they know how to stand up for themself theyre willing to work more take ownership etc it doesnt matter if you got an ms from stanford if you do compliance analytics or data governance at a bank youre now less desirable for many applied data science positions this being said many smaller companies are now getting to the point where they need data governance and there is a space for you to be a leader there saying this because outside of research positions the field you work in does impact how easy it is to tranistion to other roles,job matter know matter advanced degree job matter know matter masters degree mention find discussion not occur m position year define hire pipeline generally speak pay way attention year degree study bs geoscience predictive analytic gis environmental service happen work financial firm s interested environment service come person guy phd industrial engineering m take bs geoscience thing niche space m look come initiative drive business leader m generally look analytic supply chain distribution company know stand themself willing work ownership etc not matter get ms stanford compliance analytic datum governance bank desirable apply datum science position say small company get point need datum governance space leader say outside research position field work impact easy tranistion role
1l1uzi1,How do I manage expectations for my career as a prospective data scientist,"Hey all,

I'm a recent MS Statistics graduate (Fall '24), who just finished undergrad (Spring '23) with no working and internship experience. Fortunately, I was able to land a data analyst position at a nonprofit company in March this year, but I am kind of missing the hands-on modeling (Bayesian Statistics, Econometrics, ML, Statistical Regression) and theoretical math (stochastic calculus/processes, ML, probability, Real Analysis) during my master's program.

I understand that given my lack of experience and entry level position, I am very luck to have a job, especially in this economy. However, I also do harbor disappointment in my outcomes, as I did apply for \~1000 jobs, and had more than 40 interviews for all types of positions (quant, data scientist, model validation analyst, data analyst, etc.) this year, but was beat out by people who probably have more relevant experience and technical skills.

I am thinking of applying this Fall/beginning of next year for some more modeling-heavy positions, but I am also wondering whether given the current economy and my unproven track record, I should realistically lower my expectations and evaluate other options (personal projects to sharpen my skills, PhD in a STEM field, working on a research project), and what I should focus on with my projects to improve myself as a candidate (domain knowledge, sound coding skills, implementation of new models). I would like to hear your thoughts and opinions about my future career goals.

Thanks",49,30,2025-06-02T21:57:51+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l1uzi1/how_do_i_manage_expectations_for_my_career_as_a/,"How do I manage expectations for my career as a prospective data scientist Hey all,

I'm a recent MS Statistics graduate (Fall '24), who just finished undergrad (Spring '23) with no working and internship experience. Fortunately, I was able to land a data analyst position at a nonprofit company in March this year, but I am kind of missing the hands-on modeling (Bayesian Statistics, Econometrics, ML, Statistical Regression) and theoretical math (stochastic calculus/processes, ML, probability, Real Analysis) during my master's program.

I understand that given my lack of experience and entry level position, I am very luck to have a job, especially in this economy. However, I also do harbor disappointment in my outcomes, as I did apply for \~1000 jobs, and had more than 40 interviews for all types of positions (quant, data scientist, model validation analyst, data analyst, etc.) this year, but was beat out by people who probably have more relevant experience and technical skills.

I am thinking of applying this Fall/beginning of next year for some more modeling-heavy positions, but I am also wondering whether given the current economy and my unproven track record, I should realistically lower my expectations and evaluate other options (personal projects to sharpen my skills, PhD in a STEM field, working on a research project), and what I should focus on with my projects to improve myself as a candidate (domain knowledge, sound coding skills, implementation of new models). I would like to hear your thoughts and opinions about my future career goals.

Thanks",how do i manage expectations for my career as a prospective data scientist hey all im a recent ms statistics graduate fall who just finished undergrad spring with no working and internship experience fortunately i was able to land a data analyst position at a nonprofit company in march this year but i am kind of missing the handson modeling bayesian statistics econometrics ml statistical regression and theoretical math stochastic calculusprocesses ml probability real analysis during my masters program i understand that given my lack of experience and entry level position i am very luck to have a job especially in this economy however i also do harbor disappointment in my outcomes as i did apply for jobs and had more than interviews for all types of positions quant data scientist model validation analyst data analyst etc this year but was beat out by people who probably have more relevant experience and technical skills i am thinking of applying this fallbeginning of next year for some more modelingheavy positions but i am also wondering whether given the current economy and my unproven track record i should realistically lower my expectations and evaluate other options personal projects to sharpen my skills phd in a stem field working on a research project and what i should focus on with my projects to improve myself as a candidate domain knowledge sound coding skills implementation of new models i would like to hear your thoughts and opinions about my future career goals thanks,manage expectation career prospective data scientist hey m recent ms statistic graduate fall finish undergrad spring working internship experience fortunately able land data analyst position nonprofit company march year kind miss handson model bayesian statistic econometrics ml statistical regression theoretical math stochastic calculusprocesse ml probability real analysis master program understand give lack experience entry level position luck job especially economy harbor disappointment outcome apply job interview type position quant datum scientist model validation analyst datum analyst etc year beat people probably relevant experience technical skill think apply fallbeginning year modelingheavy position wonder give current economy unproven track record realistically lower expectation evaluate option personal project sharpen skill phd stem field work research project focus project improve candidate domain knowledge sound code skill implementation new model like hear thought opinion future career goal thank
1l1qvz5,Real or fake pattern?,"I am doing some data analysis/engineering to uncover highly pure subnodes in a dataset, but am having trouble understanding something.

In this graph, each point represents a pandas mask, which is linked to a small subsample of the data. Subsamples range from 30-300 in size (overall dataset was just 2500). The x axis is the size of the sample, and the y axis is %pure, cutoff at 80% and rounded to 4 decimals. Average purity for the overall dataset is just under 29%. There is jitter on the x axis, as it’s an integrated with multiple values per label.

I cannot tell if these “ribbons”relationship is strictly due to integer division (?), as Claude would suggest, or if this is a pattern commonly found in segmentation, and each ribbon is some sub-cohort of a segment.

Has anyone seen these curved ribbons in their data before?",89,28,2025-06-02T19:15:58+00:00,datascience,https://i.redd.it/6eeqoat3dk4f1.jpeg,"Real or fake pattern? I am doing some data analysis/engineering to uncover highly pure subnodes in a dataset, but am having trouble understanding something.

In this graph, each point represents a pandas mask, which is linked to a small subsample of the data. Subsamples range from 30-300 in size (overall dataset was just 2500). The x axis is the size of the sample, and the y axis is %pure, cutoff at 80% and rounded to 4 decimals. Average purity for the overall dataset is just under 29%. There is jitter on the x axis, as it’s an integrated with multiple values per label.

I cannot tell if these “ribbons”relationship is strictly due to integer division (?), as Claude would suggest, or if this is a pattern commonly found in segmentation, and each ribbon is some sub-cohort of a segment.

Has anyone seen these curved ribbons in their data before?",real or fake pattern i am doing some data analysisengineering to uncover highly pure subnodes in a dataset but am having trouble understanding something in this graph each point represents a pandas mask which is linked to a small subsample of the data subsamples range from in size overall dataset was just the x axis is the size of the sample and the y axis is pure cutoff at and rounded to decimals average purity for the overall dataset is just under there is jitter on the x axis as its an integrated with multiple values per label i cannot tell if these ribbonsrelationship is strictly due to integer division as claude would suggest or if this is a pattern commonly found in segmentation and each ribbon is some subcohort of a segment has anyone seen these curved ribbons in their data before,real fake pattern datum analysisengineere uncover highly pure subnode dataset have trouble understand graph point represent panda mask link small subsample data subsample range size overall dataset x axis size sample y axis pure cutoff round decimal average purity overall dataset jitter x axis integrate multiple value label tell ribbonsrelationship strictly integer division claude suggest pattern commonly find segmentation ribbon subcohort segment see curved ribbon datum
1l1pm5w,Am I walking into a trap?,I have a job offer from a small company (UK based) under 50 employees. It's a data science job. However there is no direct mentoring involved and I would be the only data scientist in the company. I need a job but don't know if this is safe or not. ,85,42,2025-06-02T18:27:11+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l1pm5w/am_i_walking_into_a_trap/,Am I walking into a trap? I have a job offer from a small company (UK based) under 50 employees. It's a data science job. However there is no direct mentoring involved and I would be the only data scientist in the company. I need a job but don't know if this is safe or not. ,am i walking into a trap i have a job offer from a small company uk based under employees its a data science job however there is no direct mentoring involved and i would be the only data scientist in the company i need a job but dont know if this is safe or not,walk trap job offer small company uk base employee data science job direct mentoring involve data scientist company need job not know safe
1l1nm9m,How do you teach business common sense?,"Really not the best way to start the week by finding out a colleague of mine CC'ed our internal-only model run reports to downstream team, which then triggered a chain of ppl requesting to be CC'ed for any future delivery.

We have an external report for that which said colleague has been sending out for an extended period of time.

Said colleague would also pull up code base and go line-by-line in a meeting with director-level business people. Different directors had, on multiple occasions, asked to not do that and give an abstraction only. This affects his perception despite the work underneath being solid. We're not toxic but you really can't expect high management to read your SQL code without them feeling like you're wasting their time.

This person works hard, has good intention, and can deliver if correctly understanding the task (which is in itself another battle). I'm not his manager, but he takes over the processes/pipelines I established so I'm still on the hook if things don't work.

I trust his work on the technical side but this corporate thing is really not clicking for him, and I really have no idea how do you put these ""common sense"" into someone's head.",63,31,2025-06-02T17:10:57+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l1nm9m/how_do_you_teach_business_common_sense/,"How do you teach business common sense? Really not the best way to start the week by finding out a colleague of mine CC'ed our internal-only model run reports to downstream team, which then triggered a chain of ppl requesting to be CC'ed for any future delivery.

We have an external report for that which said colleague has been sending out for an extended period of time.

Said colleague would also pull up code base and go line-by-line in a meeting with director-level business people. Different directors had, on multiple occasions, asked to not do that and give an abstraction only. This affects his perception despite the work underneath being solid. We're not toxic but you really can't expect high management to read your SQL code without them feeling like you're wasting their time.

This person works hard, has good intention, and can deliver if correctly understanding the task (which is in itself another battle). I'm not his manager, but he takes over the processes/pipelines I established so I'm still on the hook if things don't work.

I trust his work on the technical side but this corporate thing is really not clicking for him, and I really have no idea how do you put these ""common sense"" into someone's head.",how do you teach business common sense really not the best way to start the week by finding out a colleague of mine cced our internalonly model run reports to downstream team which then triggered a chain of ppl requesting to be cced for any future delivery we have an external report for that which said colleague has been sending out for an extended period of time said colleague would also pull up code base and go linebyline in a meeting with directorlevel business people different directors had on multiple occasions asked to not do that and give an abstraction only this affects his perception despite the work underneath being solid were not toxic but you really cant expect high management to read your sql code without them feeling like youre wasting their time this person works hard has good intention and can deliver if correctly understanding the task which is in itself another battle im not his manager but he takes over the processespipelines i established so im still on the hook if things dont work i trust his work on the technical side but this corporate thing is really not clicking for him and i really have no idea how do you put these common sense into someones head,teach business common sense good way start week find colleague cce internalonly model run report downstream team trigger chain ppl request cce future delivery external report say colleague send extended period time say colleague pull code base linebyline meeting directorlevel business people different director multiple occasion ask abstraction affect perception despite work underneath solid toxic not expect high management read sql code feel like waste time person work hard good intention deliver correctly understand task battle m manager take processespipeline establish m hook thing not work trust work technical corporate thing click idea common sense someone head
1l1iud0,"Well, that’s one way to waste the budget on tools that nobody will use...","AI Tools Deployed with Purpose = Great  
AI Tools Deployed without anyone Asking Why or What it's for = Useless",457,30,2025-06-02T14:03:04+00:00,datascience,https://i.redd.it/lgtrvc63ti4f1.png,"Well, that’s one way to waste the budget on tools that nobody will use... AI Tools Deployed with Purpose = Great  
AI Tools Deployed without anyone Asking Why or What it's for = Useless",well thats one way to waste the budget on tools that nobody will use ai tools deployed with purpose great ai tools deployed without anyone asking why or what its for useless,s way waste budget tool use ai tool deploy purpose great ai tool deploy ask useless
1l18ji8,"Weekly Entering & Transitioning - Thread 02 Jun, 2025 - 09 Jun, 2025"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",5,23,2025-06-02T04:02:21+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l18ji8/weekly_entering_transitioning_thread_02_jun_2025/,"Weekly Entering & Transitioning - Thread 02 Jun, 2025 - 09 Jun, 2025  

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",weekly entering transitioning thread jun jun welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the and resources pages on our wiki you can also search for answers in,weekly enter transition thread jun jun welcome week enter transition thread thread question getting start study transition data science field topic include learn resource eg book tutorial video traditional education eg schools degree elective alternative education eg online course bootcamp job search question eg resume apply career prospect elementary question eg start wait answer community check resource page wiki search answer
1l10fes,How I scraped 4.1 million jobs with GPT4o-mini,"**Background**: During my PhD in Data Science at Stanford, I got sick and tired of ghost jobs & 3rd party offshore agencies on LinkedIn & Indeed. So I wrote a script that fetches jobs from 100k+ company websites' career pages and uses GPT4o-mini to extract relevant information (ex salary, remote, etc.) from job descriptions. I made it publicly available here [https://hiring.cafe](https://hiring.cafe) and you can follow my progress and give me feedback at r/hiringcafe

**Tech details (from a DS perspective)**

1. Verifying legit companies. This I did manually, but it was crucial that I exclude any recruiting firms, 3rd party offshore agencies, etc. I manually sorted through the \~100,000 company career pages (this took several weeks) and picked the ones that looked legit. At Stanford, we call this technique ""occular regression"" :) 
2. Removing ghost jobs. I discovered that a strong predictor of if a job is a ghost job is that if it keeps being reposted. I was able to identify reposting by doing a embedding text similarity search for jobs from the same company. If 2 job descriptions overlap too much, I only show the date posted for the *earliest* listing. This allowed me to weed out most ghost jobs simply by using a date filter (for example, excluding any jobs posted over a month ago). 
3. Scraping fresh jobs 3x/day. To ensure that my database is reflective of the company career page, I check each company career page 3x/day. To avoid rate-limits, I used a rotating proxy from Oxylabs for now.
4. Building advanced NLP text filters. After playing with GPT4o-mini API, I realized I could can effectively dump raw job descriptions (in HTML) and ask it to give me back formatted information back in JSON (ex salary, yoe, etc). I used this technique to extract a variety of information, including technical keywords, job industry, required licenses & security clearance, if the company sponsors visa, etc.

**Question for the DS community:** Beyond job search, one thing I'm really excited about this 4.1 million job dataset is to be able to do a yearly or quarterly trend report. For instance, to look at what technical skills are growing in demand. What kinds of cool job trends analyses would you do if you had access to this data.

**Edit:** A few folks DMed asking to explore the data for job searching. I put together a minimal frontend to make the scraped jobs searchable: [https://hiring.cafe](https://hiring.cafe) — note that it's currently non-commercial, unsupported, just a PhD side-project at the moment until I gradute.

**Edit 2::** thank you for all the super positive comments. you can follow my progress on scraping more jobs on r/hiringcafe .Aalso to comments saying this is an ad, my full-time job is my phd, this is just a fun side project beofore I get an actual job haha",539,67,2025-06-01T21:27:39+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l10fes/how_i_scraped_41_million_jobs_with_gpt4omini/,"How I scraped 4.1 million jobs with GPT4o-mini **Background**: During my PhD in Data Science at Stanford, I got sick and tired of ghost jobs & 3rd party offshore agencies on LinkedIn & Indeed. So I wrote a script that fetches jobs from 100k+ company websites' career pages and uses GPT4o-mini to extract relevant information (ex salary, remote, etc.) from job descriptions. I made it publicly available here [https://hiring.cafe](https://hiring.cafe) and you can follow my progress and give me feedback at r/hiringcafe

**Tech details (from a DS perspective)**

1. Verifying legit companies. This I did manually, but it was crucial that I exclude any recruiting firms, 3rd party offshore agencies, etc. I manually sorted through the \~100,000 company career pages (this took several weeks) and picked the ones that looked legit. At Stanford, we call this technique ""occular regression"" :) 
2. Removing ghost jobs. I discovered that a strong predictor of if a job is a ghost job is that if it keeps being reposted. I was able to identify reposting by doing a embedding text similarity search for jobs from the same company. If 2 job descriptions overlap too much, I only show the date posted for the *earliest* listing. This allowed me to weed out most ghost jobs simply by using a date filter (for example, excluding any jobs posted over a month ago). 
3. Scraping fresh jobs 3x/day. To ensure that my database is reflective of the company career page, I check each company career page 3x/day. To avoid rate-limits, I used a rotating proxy from Oxylabs for now.
4. Building advanced NLP text filters. After playing with GPT4o-mini API, I realized I could can effectively dump raw job descriptions (in HTML) and ask it to give me back formatted information back in JSON (ex salary, yoe, etc). I used this technique to extract a variety of information, including technical keywords, job industry, required licenses & security clearance, if the company sponsors visa, etc.

**Question for the DS community:** Beyond job search, one thing I'm really excited about this 4.1 million job dataset is to be able to do a yearly or quarterly trend report. For instance, to look at what technical skills are growing in demand. What kinds of cool job trends analyses would you do if you had access to this data.

**Edit:** A few folks DMed asking to explore the data for job searching. I put together a minimal frontend to make the scraped jobs searchable: [https://hiring.cafe](https://hiring.cafe) — note that it's currently non-commercial, unsupported, just a PhD side-project at the moment until I gradute.

**Edit 2::** thank you for all the super positive comments. you can follow my progress on scraping more jobs on r/hiringcafe .Aalso to comments saying this is an ad, my full-time job is my phd, this is just a fun side project beofore I get an actual job haha",how i scraped million jobs with gptomini background during my phd in data science at stanford i got sick and tired of ghost jobs rd party offshore agencies on linkedin indeed so i wrote a script that fetches jobs from k company websites career pages and uses gptomini to extract relevant information ex salary remote etc from job descriptions i made it publicly available here and you can follow my progress and give me feedback at rhiringcafe tech details from a ds perspective verifying legit companies this i did manually but it was crucial that i exclude any recruiting firms rd party offshore agencies etc i manually sorted through the company career pages this took several weeks and picked the ones that looked legit at stanford we call this technique occular regression removing ghost jobs i discovered that a strong predictor of if a job is a ghost job is that if it keeps being reposted i was able to identify reposting by doing a embedding text similarity search for jobs from the same company if job descriptions overlap too much i only show the date posted for the earliest listing this allowed me to weed out most ghost jobs simply by using a date filter for example excluding any jobs posted over a month ago scraping fresh jobs xday to ensure that my database is reflective of the company career page i check each company career page xday to avoid ratelimits i used a rotating proxy from oxylabs for now building advanced nlp text filters after playing with gptomini api i realized i could can effectively dump raw job descriptions in html and ask it to give me back formatted information back in json ex salary yoe etc i used this technique to extract a variety of information including technical keywords job industry required licenses security clearance if the company sponsors visa etc question for the ds community beyond job search one thing im really excited about this million job dataset is to be able to do a yearly or quarterly trend report for instance to look at what technical skills are growing in demand what kinds of cool job trends analyses would you do if you had access to this data edit a few folks dmed asking to explore the data for job searching i put together a minimal frontend to make the scraped jobs searchable note that its currently noncommercial unsupported just a phd sideproject at the moment until i gradute edit thank you for all the super positive comments you can follow my progress on scraping more jobs on rhiringcafe aalso to comments saying this is an ad my fulltime job is my phd this is just a fun side project beofore i get an actual job haha,scrape million job gptomini background phd datum science stanford get sick tired ghost job rd party offshore agency linkedin write script fetch job k company website career page use gptomini extract relevant information ex salary remote etc job description publicly available follow progress feedback rhiringcafe tech detail ds perspective verify legit company manually crucial exclude recruiting firm rd party offshore agency etc manually sort company career page take week pick one look legit stanford technique occular regression remove ghost job discover strong predictor job ghost job keep reposte able identify reposte embed text similarity search job company job description overlap date post early listing allow weed ghost job simply date filter example exclude job post month ago scrape fresh job xday ensure database reflective company career page check company career page xday avoid ratelimit rotate proxy oxylab build advanced nlp text filter play gptomini api realize effectively dump raw job description html ask format information json ex salary yoe etc technique extract variety information include technical keyword job industry require license security clearance company sponsor visa etc question ds community job search thing m excited million job dataset able yearly quarterly trend report instance look technical skill grow demand kind cool job trend analyse access datum edit folk dme ask explore datum job search minimal frontend scrape job searchable note currently noncommercial unsupported phd sideproject moment gradute edit thank super positive comment follow progress scrape job rhiringcafe aalso comment say ad fulltime job phd fun project beofore actual job haha
1l0y4zo,Advice on processing ~1M jobs/month with LLaMA for cost savings,"I'm using GPT-4o-mini to process \~1 million jobs/month. It's doing things like deduplication, classification, title normalization, and enrichment.

This setup is fast and easy, but the cost is starting to hurt. I'm considering distilling this pipeline into an open-source LLM, like LLaMA 3 or Mistral, to reduce inference costs, most likely self-hosted on GPU on Google Coud. 

Questions:

\* Has anyone done a similar migration? What were your real-world cost savings (e.g., from GPT-4o to self-hosted LLaMA/Mistral)

\* Any recommended distillation workflows? I'd be fine using GPT-4o to fine-tune an open model on our own tasks.

\* Are there best practices for reducing inference costs even further (e.g., batching, quantization, routing tasks through smaller models first)?

\* Is anyone running LLM inference on consumer GPUs for light-to-medium workloads successfully?

Right now, our GPT-4o-mini usage is costing me thousands/month (I'm paying for it out of pocket, no investors). Would love to hear what’s worked for others!



",10,5,2025-06-01T19:52:46+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l0y4zo/advice_on_processing_1m_jobsmonth_with_llama_for/,"Advice on processing ~1M jobs/month with LLaMA for cost savings I'm using GPT-4o-mini to process \~1 million jobs/month. It's doing things like deduplication, classification, title normalization, and enrichment.

This setup is fast and easy, but the cost is starting to hurt. I'm considering distilling this pipeline into an open-source LLM, like LLaMA 3 or Mistral, to reduce inference costs, most likely self-hosted on GPU on Google Coud. 

Questions:

\* Has anyone done a similar migration? What were your real-world cost savings (e.g., from GPT-4o to self-hosted LLaMA/Mistral)

\* Any recommended distillation workflows? I'd be fine using GPT-4o to fine-tune an open model on our own tasks.

\* Are there best practices for reducing inference costs even further (e.g., batching, quantization, routing tasks through smaller models first)?

\* Is anyone running LLM inference on consumer GPUs for light-to-medium workloads successfully?

Right now, our GPT-4o-mini usage is costing me thousands/month (I'm paying for it out of pocket, no investors). Would love to hear what’s worked for others!



",advice on processing m jobsmonth with llama for cost savings im using gptomini to process million jobsmonth its doing things like deduplication classification title normalization and enrichment this setup is fast and easy but the cost is starting to hurt im considering distilling this pipeline into an opensource llm like llama or mistral to reduce inference costs most likely selfhosted on gpu on google coud questions has anyone done a similar migration what were your realworld cost savings eg from gpto to selfhosted llamamistral any recommended distillation workflows id be fine using gpto to finetune an open model on our own tasks are there best practices for reducing inference costs even further eg batching quantization routing tasks through smaller models first is anyone running llm inference on consumer gpus for lighttomedium workloads successfully right now our gptomini usage is costing me thousandsmonth im paying for it out of pocket no investors would love to hear whats worked for others,advice process m jobsmonth llama cost saving m gptomini process million jobsmonth thing like deduplication classification title normalization enrichment setup fast easy cost start hurt m consider distil pipeline opensource llm like llama mistral reduce inference cost likely selfhoste gpu google coud question similar migration realworld cost saving eg gpto selfhoste llamamistral recommend distillation workflow d fine gpto finetune open model task good practice reduce inference cost eg batch quantization route task small model run llm inference consumer gpu lighttomedium workload successfully right gptomini usage cost thousandsmonth m pay pocket investor love hear s work
1l0wx56,Can data science be used in computer networking (if not can it be used in cybersecurity)?,"Hi, I’m a high schooler (junior year) who is extremely interested in data science to the point where it is the main career field I want to go into. However, I got enrolled in a program where we train and study for the CCNA and Network+, two prominent computer networking certifications that even adults in the field dont have. I’m taking the certifications next week so hopefully I pass both, but my heart is still in data science although i rlly dont want to waste these newly acquired skills. I know data science is a wide ranging topic that can be extended to multiple different fields, and the use of automation and AI being used in stuff like SDNs are increasing. I guess my question is if theres a solid career in data science with a computer networking background.

Additional question: I gotta start thinking of college so would I, if there is a possible path, major in data science and minor in computer networking?",14,9,2025-06-01T19:01:46+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l0wx56/can_data_science_be_used_in_computer_networking/,"Can data science be used in computer networking (if not can it be used in cybersecurity)? Hi, I’m a high schooler (junior year) who is extremely interested in data science to the point where it is the main career field I want to go into. However, I got enrolled in a program where we train and study for the CCNA and Network+, two prominent computer networking certifications that even adults in the field dont have. I’m taking the certifications next week so hopefully I pass both, but my heart is still in data science although i rlly dont want to waste these newly acquired skills. I know data science is a wide ranging topic that can be extended to multiple different fields, and the use of automation and AI being used in stuff like SDNs are increasing. I guess my question is if theres a solid career in data science with a computer networking background.

Additional question: I gotta start thinking of college so would I, if there is a possible path, major in data science and minor in computer networking?",can data science be used in computer networking if not can it be used in cybersecurity hi im a high schooler junior year who is extremely interested in data science to the point where it is the main career field i want to go into however i got enrolled in a program where we train and study for the ccna and network two prominent computer networking certifications that even adults in the field dont have im taking the certifications next week so hopefully i pass both but my heart is still in data science although i rlly dont want to waste these newly acquired skills i know data science is a wide ranging topic that can be extended to multiple different fields and the use of automation and ai being used in stuff like sdns are increasing i guess my question is if theres a solid career in data science with a computer networking background additional question i gotta start thinking of college so would i if there is a possible path major in data science and minor in computer networking,datum science computer network cybersecurity hi m high schooler junior year extremely interested data science point main career field want get enrol program train study ccna network prominent computer network certification adult field not m take certification week hopefully pass heart datum science rlly not want waste newly acquire skill know datum science wide ranging topic extend multiple different field use automation ai stuff like sdns increase guess question s solid career datum science computer network background additional question get to start think college possible path major data science minor computer network
1l0fa7t,What is your functional area?,"I don’t mean industry. I mean product, operations, etc. I work in operations. I don’t grow the business. I keep the business alive.",38,55,2025-06-01T03:32:11+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l0fa7t/what_is_your_functional_area/,"What is your functional area? I don’t mean industry. I mean product, operations, etc. I work in operations. I don’t grow the business. I keep the business alive.",what is your functional area i dont mean industry i mean product operations etc i work in operations i dont grow the business i keep the business alive,functional area not mean industry mean product operation etc work operation not grow business business alive
1l0dsfl,About MCP servers,Do anyone have tried MCP server with llm and rag? If anyone done please share the code ,1,5,2025-06-01T02:11:05+00:00,datascience,https://www.reddit.com/r/datascience/comments/1l0dsfl/about_mcp_servers/,About MCP servers Do anyone have tried MCP server with llm and rag? If anyone done please share the code ,about mcp servers do anyone have tried mcp server with llm and rag if anyone done please share the code,mcp server try mcp server llm rag share code
1l03bjn,Help choosing a book for learning bayesian statistics in python,,22,15,2025-05-31T17:59:03+00:00,datascience,/r/statistics/comments/1l02phw/d_help_choosing_a_book_for_learning_bayesian/,Help choosing a book for learning bayesian statistics in python ,help choosing a book for learning bayesian statistics in python,help choose book learn bayesian statistic python
1kzpdnv,"Infra DA/DS, guidance to ramp up?","Hello!

Just stepped into a new role as Lead DS for a team focused on infra analytics and data science. We'll be analyzing model training jobs/runs (I don't know what the data set is yet but assume it's resource usage, cost, and system logs) to find efficiency wins (think speed, cost, and even sustainability). We'll also explore automation opportunities down the line as subsequent projects.

This is my first time working at the infrastructure layer, and I’m looking to ramp up fast.

What I’m looking for:

- Go-to resources (books, papers, vids) for ML infra analytics

- What data you typically analyze (training logs, GPU usage, queue times, etc.)

- Examples of quick wins, useful dashboards, KPIs?

If you’ve done this kind of work I’d love to hear what helped you get sharp. Thanks!

Ps - I'm a 8 yr DS at this company. Company size, data, number of models, etc, is absolutely massive. Lmk what other info and I can amend this post. Thank you!",17,3,2025-05-31T05:22:28+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kzpdnv/infra_dads_guidance_to_ramp_up/,"Infra DA/DS, guidance to ramp up? Hello!

Just stepped into a new role as Lead DS for a team focused on infra analytics and data science. We'll be analyzing model training jobs/runs (I don't know what the data set is yet but assume it's resource usage, cost, and system logs) to find efficiency wins (think speed, cost, and even sustainability). We'll also explore automation opportunities down the line as subsequent projects.

This is my first time working at the infrastructure layer, and I’m looking to ramp up fast.

What I’m looking for:

- Go-to resources (books, papers, vids) for ML infra analytics

- What data you typically analyze (training logs, GPU usage, queue times, etc.)

- Examples of quick wins, useful dashboards, KPIs?

If you’ve done this kind of work I’d love to hear what helped you get sharp. Thanks!

Ps - I'm a 8 yr DS at this company. Company size, data, number of models, etc, is absolutely massive. Lmk what other info and I can amend this post. Thank you!",infra dads guidance to ramp up hello just stepped into a new role as lead ds for a team focused on infra analytics and data science well be analyzing model training jobsruns i dont know what the data set is yet but assume its resource usage cost and system logs to find efficiency wins think speed cost and even sustainability well also explore automation opportunities down the line as subsequent projects this is my first time working at the infrastructure layer and im looking to ramp up fast what im looking for goto resources books papers vids for ml infra analytics what data you typically analyze training logs gpu usage queue times etc examples of quick wins useful dashboards kpis if youve done this kind of work id love to hear what helped you get sharp thanks ps im a yr ds at this company company size data number of models etc is absolutely massive lmk what other info and i can amend this post thank you,infra dad guidance ramp hello step new role lead ds team focus infra analytic datum science analyze model training jobsrun not know datum set assume resource usage cost system log find efficiency win think speed cost sustainability explore automation opportunity line subsequent project time work infrastructure layer m look ramp fast m look goto resource book paper vid ml infra analytic datum typically analyze training log gpu usage queue time etc example quick win useful dashboard kpi ve kind work d love hear help sharp thank ps m yr ds company company size datum number model etc absolutely massive lmk info amend post thank
1kzkwcg,Validation of Statistical Tooling Packages,"Hey all,

I was wondering if anyone has any experience on how to properly validating statistical packages for numerical accuracy?

Some context: I've developed a Python package for internal use that can undertake all the statistics we require in our field for our company. The statistics are used to ensure compliance to regulatory guidelines. 

The industry standard is a globally shared maceo-free Excel sheet, that relies heavily on approximations to bypass VBA requirements. Because of this, edge cases will give different reaults. Examples include use of non-central t-distrubtion, MLE, infinite series calcuations, Shapiro-wilk. The sheet is also limited to 50 samples as the approximations end here.

Packages exist in R that do most of it (NADA, EnvStats, STAND, Tolerance). I could (and probably should have) make a package from these, but I'd still need to modify and develop some statistics from scratch, and my R skills are abysmal compared to Python.

From a software engineering point, for more math heavy code, is there best practices for validating the outputs? The issue is this Excel sheet is considered the ""gold standard"" and I'll need to justify differences.

I currently have two validation passes, one is a dedicated unit test with a small dataset that I have cross referenced and checked by hand, with exisiting R packages and with the existing notebook. This dataset I've picked tries to cover extremes at either side of the data ranges we get (Geo standard deviations > 5, massive skews, zero range, heavily censored datasets).

The second is a bulk run of a large datatset to tease out weird edge cases, but I haven't done the cross validations by hand unless I notice weird results.

Is there anything else that I should be doing, or need to consider?",13,6,2025-05-31T01:12:57+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kzkwcg/validation_of_statistical_tooling_packages/,"Validation of Statistical Tooling Packages Hey all,

I was wondering if anyone has any experience on how to properly validating statistical packages for numerical accuracy?

Some context: I've developed a Python package for internal use that can undertake all the statistics we require in our field for our company. The statistics are used to ensure compliance to regulatory guidelines. 

The industry standard is a globally shared maceo-free Excel sheet, that relies heavily on approximations to bypass VBA requirements. Because of this, edge cases will give different reaults. Examples include use of non-central t-distrubtion, MLE, infinite series calcuations, Shapiro-wilk. The sheet is also limited to 50 samples as the approximations end here.

Packages exist in R that do most of it (NADA, EnvStats, STAND, Tolerance). I could (and probably should have) make a package from these, but I'd still need to modify and develop some statistics from scratch, and my R skills are abysmal compared to Python.

From a software engineering point, for more math heavy code, is there best practices for validating the outputs? The issue is this Excel sheet is considered the ""gold standard"" and I'll need to justify differences.

I currently have two validation passes, one is a dedicated unit test with a small dataset that I have cross referenced and checked by hand, with exisiting R packages and with the existing notebook. This dataset I've picked tries to cover extremes at either side of the data ranges we get (Geo standard deviations > 5, massive skews, zero range, heavily censored datasets).

The second is a bulk run of a large datatset to tease out weird edge cases, but I haven't done the cross validations by hand unless I notice weird results.

Is there anything else that I should be doing, or need to consider?",validation of statistical tooling packages hey all i was wondering if anyone has any experience on how to properly validating statistical packages for numerical accuracy some context ive developed a python package for internal use that can undertake all the statistics we require in our field for our company the statistics are used to ensure compliance to regulatory guidelines the industry standard is a globally shared maceofree excel sheet that relies heavily on approximations to bypass vba requirements because of this edge cases will give different reaults examples include use of noncentral tdistrubtion mle infinite series calcuations shapirowilk the sheet is also limited to samples as the approximations end here packages exist in r that do most of it nada envstats stand tolerance i could and probably should have make a package from these but id still need to modify and develop some statistics from scratch and my r skills are abysmal compared to python from a software engineering point for more math heavy code is there best practices for validating the outputs the issue is this excel sheet is considered the gold standard and ill need to justify differences i currently have two validation passes one is a dedicated unit test with a small dataset that i have cross referenced and checked by hand with exisiting r packages and with the existing notebook this dataset ive picked tries to cover extremes at either side of the data ranges we get geo standard deviations massive skews zero range heavily censored datasets the second is a bulk run of a large datatset to tease out weird edge cases but i havent done the cross validations by hand unless i notice weird results is there anything else that i should be doing or need to consider,validation statistical tooling package hey wonder experience properly validate statistical package numerical accuracy context ve develop python package internal use undertake statistic require field company statistic ensure compliance regulatory guideline industry standard globally share maceofree excel sheet rely heavily approximation bypass vba requirement edge case different reault example include use noncentral tdistrubtion mle infinite series calcuation shapirowilk sheet limit sample approximation end package exist r nada envstat stand tolerance probably package d need modify develop statistic scratch r skill abysmal compare python software engineering point math heavy code good practice validate output issue excel sheet consider gold standard ill need justify difference currently validation pass dedicated unit test small dataset cross reference check hand exisite r package exist notebook dataset ve pick try cover extreme datum range geo standard deviation massive skew zero range heavily censor dataset second bulk run large datatset tease weird edge case not cross validation hand notice weird result need consider
1kzjr30,Two‑stage model filter for web‑scale document triage?,"I am crawling roughly **20 billion** web pages, and trying to triage for the ones that are only job descriptions. Only about **5%** contain actual job advertisements. Running a Transformer over the whole corpus feels prohibitively expensive, so I am debating whether a **two‑stage pipeline** is the right move:

1. **Stage 1:** ultra‑cheap lexical model (hashing TF‑IDF plus Naive Bayes or logistic regression) on CPUs to toss out the obviously non‑job pages while keeping recall very high.
2. **Stage 2:** small fine‑tuned Transformer such as DistilBERT on a much smaller candidate pool to recover precision.

My questions for teams that have done large‑scale extraction or classification:

* Does the two‑stage approach really save enough money and wall‑clock time to justify the engineering complexity compared with just scaling out a single Transformer model on lots of GPUs?
* Any unexpected pitfalls with maintaining two models in production, feature drift between stages, or tokenization bottlenecks?
* If you tried both single‑stage and two‑stage setups, how did total cost per billion documents compare?
* Would you recommend any open‑source libraries or managed services that made the cascade easier?

",7,1,2025-05-31T00:15:39+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kzjr30/twostage_model_filter_for_webscale_document_triage/,"Two‑stage model filter for web‑scale document triage? I am crawling roughly **20 billion** web pages, and trying to triage for the ones that are only job descriptions. Only about **5%** contain actual job advertisements. Running a Transformer over the whole corpus feels prohibitively expensive, so I am debating whether a **two‑stage pipeline** is the right move:

1. **Stage 1:** ultra‑cheap lexical model (hashing TF‑IDF plus Naive Bayes or logistic regression) on CPUs to toss out the obviously non‑job pages while keeping recall very high.
2. **Stage 2:** small fine‑tuned Transformer such as DistilBERT on a much smaller candidate pool to recover precision.

My questions for teams that have done large‑scale extraction or classification:

* Does the two‑stage approach really save enough money and wall‑clock time to justify the engineering complexity compared with just scaling out a single Transformer model on lots of GPUs?
* Any unexpected pitfalls with maintaining two models in production, feature drift between stages, or tokenization bottlenecks?
* If you tried both single‑stage and two‑stage setups, how did total cost per billion documents compare?
* Would you recommend any open‑source libraries or managed services that made the cascade easier?

",twostage model filter for webscale document triage i am crawling roughly billion web pages and trying to triage for the ones that are only job descriptions only about contain actual job advertisements running a transformer over the whole corpus feels prohibitively expensive so i am debating whether a twostage pipeline is the right move stage ultracheap lexical model hashing tfidf plus naive bayes or logistic regression on cpus to toss out the obviously nonjob pages while keeping recall very high stage small finetuned transformer such as distilbert on a much smaller candidate pool to recover precision my questions for teams that have done largescale extraction or classification does the twostage approach really save enough money and wallclock time to justify the engineering complexity compared with just scaling out a single transformer model on lots of gpus any unexpected pitfalls with maintaining two models in production feature drift between stages or tokenization bottlenecks if you tried both singlestage and twostage setups how did total cost per billion documents compare would you recommend any opensource libraries or managed services that made the cascade easier,twostage model filter webscale document triage crawl roughly billion web page try triage one job description contain actual job advertisement run transformer corpus feel prohibitively expensive debate twostage pipeline right stage ultracheap lexical model hash tfidf plus naive baye logistic regression cpus toss obviously nonjob page keep recall high stage small finetune transformer distilbert small candidate pool recover precision question team largescale extraction classification twostage approach save money wallclock time justify engineering complexity compare scale single transformer model lot gpu unexpected pitfall maintain model production feature drift stage tokenization bottleneck try singlestage twostage setup total cost billion document compare recommend opensource library manage service cascade easy
1kzgvz0,Bored and underutilized - how to prep for the next gig?,"DS/BI team has had 4 different leaders in the past year and our company seems to have lost any sense of analytics strategy. Two years ago we had 16 total, BI devs and data scientists including ML specialists and ML app builders. We are now down to 7 after attrition and I know three more are actively interviewing. Last model put into production was in 2024 and there are no requests for ML work this fiscal year. Our project plans are now less than a sprint ahead and it is not unusual to get an analytical request in the morning only to be told by noon ""that's no longer a priority"".

It's been this way for long enough that I'm questioning whether I want to continue in DS or move to a related field. I have a background in databases and data engineering. i have done some work in Gen AI with prompt engineering and automation but it for my company because there is a zero trust policy on all Gen AI (thanks to an idiot who loaded the transcript from a VPs disciplinary call to chatGPT to get a summary). I am much more interested in probabilistic modeling and forecasting but again no experience outside of online classes. For all intensive purposes I have been a SQL dev with some Python for the last 4 years. The last model I put into production was an unsupervised model of workers by productivity at different roles, which was in 2022. 

Where should I go next? Seriously thinking about enrolling in a masters just to look fresh again.",30,20,2025-05-30T22:04:55+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kzgvz0/bored_and_underutilized_how_to_prep_for_the_next/,"Bored and underutilized - how to prep for the next gig? DS/BI team has had 4 different leaders in the past year and our company seems to have lost any sense of analytics strategy. Two years ago we had 16 total, BI devs and data scientists including ML specialists and ML app builders. We are now down to 7 after attrition and I know three more are actively interviewing. Last model put into production was in 2024 and there are no requests for ML work this fiscal year. Our project plans are now less than a sprint ahead and it is not unusual to get an analytical request in the morning only to be told by noon ""that's no longer a priority"".

It's been this way for long enough that I'm questioning whether I want to continue in DS or move to a related field. I have a background in databases and data engineering. i have done some work in Gen AI with prompt engineering and automation but it for my company because there is a zero trust policy on all Gen AI (thanks to an idiot who loaded the transcript from a VPs disciplinary call to chatGPT to get a summary). I am much more interested in probabilistic modeling and forecasting but again no experience outside of online classes. For all intensive purposes I have been a SQL dev with some Python for the last 4 years. The last model I put into production was an unsupervised model of workers by productivity at different roles, which was in 2022. 

Where should I go next? Seriously thinking about enrolling in a masters just to look fresh again.",bored and underutilized how to prep for the next gig dsbi team has had different leaders in the past year and our company seems to have lost any sense of analytics strategy two years ago we had total bi devs and data scientists including ml specialists and ml app builders we are now down to after attrition and i know three more are actively interviewing last model put into production was in and there are no requests for ml work this fiscal year our project plans are now less than a sprint ahead and it is not unusual to get an analytical request in the morning only to be told by noon thats no longer a priority its been this way for long enough that im questioning whether i want to continue in ds or move to a related field i have a background in databases and data engineering i have done some work in gen ai with prompt engineering and automation but it for my company because there is a zero trust policy on all gen ai thanks to an idiot who loaded the transcript from a vps disciplinary call to chatgpt to get a summary i am much more interested in probabilistic modeling and forecasting but again no experience outside of online classes for all intensive purposes i have been a sql dev with some python for the last years the last model i put into production was an unsupervised model of workers by productivity at different roles which was in where should i go next seriously thinking about enrolling in a masters just to look fresh again,bored underutilize prep gig dsbi team different leader past year company lose sense analytic strategy year ago total bi devs datum scientist include ml specialist ml app builder attrition know actively interview model production request ml work fiscal year project plan sprint ahead unusual analytical request morning tell noon s long priority way long m question want continue ds related field background database datum engineering work gen ai prompt engineering automation company zero trust policy gen ai thank idiot load transcript vps disciplinary chatgpt summary interested probabilistic modeling forecasting experience outside online class intensive purpose sql dev python year model production unsupervised model worker productivity different role seriously think enrol master look fresh
1kz8mmn,President Taps Palantir to Compile Data on Americans,No words,298,49,2025-05-30T16:28:10+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kz8mmn/president_taps_palantir_to_compile_data_on/,President Taps Palantir to Compile Data on Americans No words,president taps palantir to compile data on americans no words,president taps palantir compile datum americans word
1kz6tnh,Perfect job for me suffering from Imposter Syndrome,,1743,55,2025-05-30T15:16:17+00:00,datascience,https://i.redd.it/geogp5wlrx3f1.jpeg,Perfect job for me suffering from Imposter Syndrome ,perfect job for me suffering from imposter syndrome,perfect job suffer impost syndrome
1kyr1va,Regularization=magic?,"Everyone knows that regularization prevents overfitting when model is over-parametrized and it makes sense. But how is it possible that a regularized model performs better even when the model family is fully specified?

I generated data y=2+5x+eps, eps~N(0, 5) and I fit a model y=mx+b (so I fit the same model family as was used for data generation). Somehow ridge regression still fits better than OLS.

I run 10k experiments with 5 training and 5 testing data points. OLS achieved mean MSE 42.74, median MSE 31.79. Ridge with alpha=5 achieved mean MSE 40.56 and median 31.51.

I cannot comprehend how it's possible - I seemingly introduce bias without an upside because I shouldn't be able to overfit. What is going on? Is it some Stein's paradox type of deal? Is there a counterexample where unregularized model would perform better than model with any ridge_alpha?

Edit: well of course this is due to small sample and large error variance. That's not my question. I'm not looking for a ""this is a bias-variance tradeoff"" answer either. Im asking for intuition (proof?) why would a biased model ever work better in such case. Penalizing high b instead of high m would also introduce a bias but it won't lower the test error. But penalizing high m does lower the error. Why?",49,33,2025-05-30T00:44:23+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kyr1va/regularizationmagic/,"Regularization=magic? Everyone knows that regularization prevents overfitting when model is over-parametrized and it makes sense. But how is it possible that a regularized model performs better even when the model family is fully specified?

I generated data y=2+5x+eps, eps~N(0, 5) and I fit a model y=mx+b (so I fit the same model family as was used for data generation). Somehow ridge regression still fits better than OLS.

I run 10k experiments with 5 training and 5 testing data points. OLS achieved mean MSE 42.74, median MSE 31.79. Ridge with alpha=5 achieved mean MSE 40.56 and median 31.51.

I cannot comprehend how it's possible - I seemingly introduce bias without an upside because I shouldn't be able to overfit. What is going on? Is it some Stein's paradox type of deal? Is there a counterexample where unregularized model would perform better than model with any ridge_alpha?

Edit: well of course this is due to small sample and large error variance. That's not my question. I'm not looking for a ""this is a bias-variance tradeoff"" answer either. Im asking for intuition (proof?) why would a biased model ever work better in such case. Penalizing high b instead of high m would also introduce a bias but it won't lower the test error. But penalizing high m does lower the error. Why?",regularizationmagic everyone knows that regularization prevents overfitting when model is overparametrized and it makes sense but how is it possible that a regularized model performs better even when the model family is fully specified i generated data yxeps epsn and i fit a model ymxb so i fit the same model family as was used for data generation somehow ridge regression still fits better than ols i run k experiments with training and testing data points ols achieved mean mse median mse ridge with alpha achieved mean mse and median i cannot comprehend how its possible i seemingly introduce bias without an upside because i shouldnt be able to overfit what is going on is it some steins paradox type of deal is there a counterexample where unregularized model would perform better than model with any ridgealpha edit well of course this is due to small sample and large error variance thats not my question im not looking for a this is a biasvariance tradeoff answer either im asking for intuition proof why would a biased model ever work better in such case penalizing high b instead of high m would also introduce a bias but it wont lower the test error but penalizing high m does lower the error why,regularizationmagic know regularization prevent overfitte model overparametrize make sense possible regularized model perform well model family fully specify generate datum yxep epsn fit model ymxb fit model family datum generation ridge regression fit well ol run k experiment training testing datum point ol achieve mean mse median mse ridge alpha achieve mean mse median comprehend possible seemingly introduce bias upside not able overfit go stein paradox type deal counterexample unregularized model perform well model ridgealpha edit course small sample large error variance s question m look biasvariance tradeoff answer m ask intuition proof biased model work well case penalize high b instead high m introduce bias will not lower test error penalize high m lower error
1kymajf,Anyone working for public organizations publish open data?,"Hello everyone,

I'm conducting research on how public sector organizations manage and share data with the public. I'm particularly interested in understanding:

* **Which platforms or repositories do you use to publish open data?**
* **What types of data are you sharing with the public?**
* **What challenges have you faced in publishing and managing open data?**
* **Are there specific policies or regulations that guide your open data practices?**

Your insights will be invaluable in understanding the current landscape of open data practices in public organizations. Feel free to share as much or as little as you're comfortable with.

Thank you in advance for your contributions!",4,17,2025-05-29T21:09:13+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kymajf/anyone_working_for_public_organizations_publish/,"Anyone working for public organizations publish open data? Hello everyone,

I'm conducting research on how public sector organizations manage and share data with the public. I'm particularly interested in understanding:

* **Which platforms or repositories do you use to publish open data?**
* **What types of data are you sharing with the public?**
* **What challenges have you faced in publishing and managing open data?**
* **Are there specific policies or regulations that guide your open data practices?**

Your insights will be invaluable in understanding the current landscape of open data practices in public organizations. Feel free to share as much or as little as you're comfortable with.

Thank you in advance for your contributions!",anyone working for public organizations publish open data hello everyone im conducting research on how public sector organizations manage and share data with the public im particularly interested in understanding which platforms or repositories do you use to publish open data what types of data are you sharing with the public what challenges have you faced in publishing and managing open data are there specific policies or regulations that guide your open data practices your insights will be invaluable in understanding the current landscape of open data practices in public organizations feel free to share as much or as little as youre comfortable with thank you in advance for your contributions,work public organization publish open datum hello m conduct research public sector organization manage share datum public m particularly interested understanding platform repository use publish open datum type datum share public challenge face publishing manage open datum specific policy regulation guide open data practice insight invaluable understand current landscape open data practice public organization feel free share little comfortable thank advance contribution
1kyesak,Did any certifications or courses actually make a difference or were great investments financially?,"Howdy folks,

Looking for some insights and feedback. Ive been working a new job for the last two months that pays me more than I was previously making, after being out of work for about 8 months. 

Nonetheless, I feel a bit funky as despite it being the best paying job Ive ever had-I also feel insanely disengaged from my job and not really all that engaged by my manager AT ALL and dont feel secure in it either. Its not nearly as kinetic and innovative of a role as I was sold.

So I wanted some feedback while I still had money coming in just in case something happens. 

**Were there or have there been any particular certifications or courses that you paid for, that REALLY made a difference for you in career opportunities at all? Just trying to make smart investments and money moves now in case anything happens and trying to think ahead.**",63,46,2025-05-29T16:11:39+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kyesak/did_any_certifications_or_courses_actually_make_a/,"Did any certifications or courses actually make a difference or were great investments financially? Howdy folks,

Looking for some insights and feedback. Ive been working a new job for the last two months that pays me more than I was previously making, after being out of work for about 8 months. 

Nonetheless, I feel a bit funky as despite it being the best paying job Ive ever had-I also feel insanely disengaged from my job and not really all that engaged by my manager AT ALL and dont feel secure in it either. Its not nearly as kinetic and innovative of a role as I was sold.

So I wanted some feedback while I still had money coming in just in case something happens. 

**Were there or have there been any particular certifications or courses that you paid for, that REALLY made a difference for you in career opportunities at all? Just trying to make smart investments and money moves now in case anything happens and trying to think ahead.**",did any certifications or courses actually make a difference or were great investments financially howdy folks looking for some insights and feedback ive been working a new job for the last two months that pays me more than i was previously making after being out of work for about months nonetheless i feel a bit funky as despite it being the best paying job ive ever hadi also feel insanely disengaged from my job and not really all that engaged by my manager at all and dont feel secure in it either its not nearly as kinetic and innovative of a role as i was sold so i wanted some feedback while i still had money coming in just in case something happens were there or have there been any particular certifications or courses that you paid for that really made a difference for you in career opportunities at all just trying to make smart investments and money moves now in case anything happens and trying to think ahead,certification course actually difference great investment financially howdy folk look insight feedback ve work new job month pay previously make work month nonetheless feel bit funky despite good pay job ve hadi feel insanely disengage job engage manager not feel secure nearly kinetic innovative role sell want feedback money come case happen particular certification course pay difference career opportunity try smart investment money move case happen try think ahead
1kydj2t,I turned a real machine learning project into a children's book,,64,16,2025-05-29T15:21:23+00:00,datascience,https://i.redd.it/fsc08wqugq3f1.jpeg,I turned a real machine learning project into a children's book ,i turned a real machine learning project into a childrens book,turn real machine learn project children book
1ky9jlz,Seeking help in choosing between two offers.,"Hey Y'all,

Needed some inputs in choosing between two offers. I have tried to read similar thread before. 

**Company 1**: Some Fintech

**Position**: Senior Data Scientist

**Role**: Taking care of their models on databricks. Models like ARR modelling. Churn modelling etc.

**Other Important Factors**: Company 1 has 5 days in office. This is a new mandate to prevent previous misuse. You also have to be very social person. They have had rounds of layoffs and had hiring freeze and have started to hiring again. My interview experience was great and I can see myself being successful in this role. However, I havent practiced classic machine learning for a while. I surely can pick it up. I am only worried that this role will have no engineering work at all. No productionsining of models. I am not sure how this will be for my future roles.



**Company 2**: Some company which is actively using LLMs and Agentic approaches

**Position**: Senior Machine Learning Engineer

**Role**: Work with agentic AI and productionise and update LLMs

**My Preference** \- Work with a company with stability and in a position where I can grow long term.


**Other Important Factors**: This role is in line with my last role, my PhD and LLM experience. I have read tonnes of literature so I sort of feel prepared for this role but I feel worthless when I have to spend weeks to improve latency without touching LLMs. My technical round was also okayish in this company. They are doubling the team. They are a well established company too. 


-------------------------------

My last position was of a ML engineer and I think what I disliked is -- the position slowly slipping into too much backend work. I am a stronger data scientist by training but have a PhD in NLP application so know the other bit too. I do struggle a bit when it comes to productinising things but I have improved a lot and in a better place.

I guess what I want to ask is for folks who work at companies that have not yet implemented AI -- do you feel behind the industry or you have satisfied with the current trajectory ?

I honestly don't care about whether I work in NLP / AI or not, All I want is a peaceful job where I can do my best and grow. On one hand the ML engineer position seems to be very on the cutting edge of technology but I know at the end its going to be API call to some LLM with much boiler plate code and many tools. The data scientist position looks like something I have done in the past and now should leave and do progress to ML engineering. 

Advice ?",18,8,2025-05-29T12:29:33+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ky9jlz/seeking_help_in_choosing_between_two_offers/,"Seeking help in choosing between two offers. Hey Y'all,

Needed some inputs in choosing between two offers. I have tried to read similar thread before. 

**Company 1**: Some Fintech

**Position**: Senior Data Scientist

**Role**: Taking care of their models on databricks. Models like ARR modelling. Churn modelling etc.

**Other Important Factors**: Company 1 has 5 days in office. This is a new mandate to prevent previous misuse. You also have to be very social person. They have had rounds of layoffs and had hiring freeze and have started to hiring again. My interview experience was great and I can see myself being successful in this role. However, I havent practiced classic machine learning for a while. I surely can pick it up. I am only worried that this role will have no engineering work at all. No productionsining of models. I am not sure how this will be for my future roles.



**Company 2**: Some company which is actively using LLMs and Agentic approaches

**Position**: Senior Machine Learning Engineer

**Role**: Work with agentic AI and productionise and update LLMs

**My Preference** \- Work with a company with stability and in a position where I can grow long term.


**Other Important Factors**: This role is in line with my last role, my PhD and LLM experience. I have read tonnes of literature so I sort of feel prepared for this role but I feel worthless when I have to spend weeks to improve latency without touching LLMs. My technical round was also okayish in this company. They are doubling the team. They are a well established company too. 


-------------------------------

My last position was of a ML engineer and I think what I disliked is -- the position slowly slipping into too much backend work. I am a stronger data scientist by training but have a PhD in NLP application so know the other bit too. I do struggle a bit when it comes to productinising things but I have improved a lot and in a better place.

I guess what I want to ask is for folks who work at companies that have not yet implemented AI -- do you feel behind the industry or you have satisfied with the current trajectory ?

I honestly don't care about whether I work in NLP / AI or not, All I want is a peaceful job where I can do my best and grow. On one hand the ML engineer position seems to be very on the cutting edge of technology but I know at the end its going to be API call to some LLM with much boiler plate code and many tools. The data scientist position looks like something I have done in the past and now should leave and do progress to ML engineering. 

Advice ?",seeking help in choosing between two offers hey yall needed some inputs in choosing between two offers i have tried to read similar thread before company some fintech position senior data scientist role taking care of their models on databricks models like arr modelling churn modelling etc other important factors company has days in office this is a new mandate to prevent previous misuse you also have to be very social person they have had rounds of layoffs and had hiring freeze and have started to hiring again my interview experience was great and i can see myself being successful in this role however i havent practiced classic machine learning for a while i surely can pick it up i am only worried that this role will have no engineering work at all no productionsining of models i am not sure how this will be for my future roles company some company which is actively using llms and agentic approaches position senior machine learning engineer role work with agentic ai and productionise and update llms my preference work with a company with stability and in a position where i can grow long term other important factors this role is in line with my last role my phd and llm experience i have read tonnes of literature so i sort of feel prepared for this role but i feel worthless when i have to spend weeks to improve latency without touching llms my technical round was also okayish in this company they are doubling the team they are a well established company too my last position was of a ml engineer and i think what i disliked is the position slowly slipping into too much backend work i am a stronger data scientist by training but have a phd in nlp application so know the other bit too i do struggle a bit when it comes to productinising things but i have improved a lot and in a better place i guess what i want to ask is for folks who work at companies that have not yet implemented ai do you feel behind the industry or you have satisfied with the current trajectory i honestly dont care about whether i work in nlp ai or not all i want is a peaceful job where i can do my best and grow on one hand the ml engineer position seems to be very on the cutting edge of technology but i know at the end its going to be api call to some llm with much boiler plate code and many tools the data scientist position looks like something i have done in the past and now should leave and do progress to ml engineering advice,seek help choose offer hey you need input choose offer try read similar thread company fintech position senior data scientist role take care model databrick model like arr modelling churn modelling etc important factor company day office new mandate prevent previous misuse social person round layoff hire freeze start hire interview experience great successful role not practice classic machine learning surely pick worried role engineering work productionsining model sure future role company company actively llm agentic approach position senior machine learn engineer role work agentic ai productionise update llm preference work company stability position grow long term important factor role line role phd llm experience read tonne literature sort feel prepared role feel worthless spend week improve latency touch llm technical round okayish company double team establish company position ml engineer think dislike position slowly slip backend work strong datum scientist training phd nlp application know bit struggle bit come productinise thing improve lot well place guess want ask folk work company implement ai feel industry satisfy current trajectory honestly not care work nlp ai want peaceful job good grow hand ml engineer position cutting edge technology know end go api llm boiler plate code tool data scientist position look like past leave progress ml engineering advice
1kxkne5,Does anyone knows a nice course for Streamlit Apps?,"What's in the title, I wanna learn how to create a deploy apps using Streamlit and I wanted to know which courses do you suggest for it?",0,27,2025-05-28T15:53:14+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kxkne5/does_anyone_knows_a_nice_course_for_streamlit_apps/,"Does anyone knows a nice course for Streamlit Apps? What's in the title, I wanna learn how to create a deploy apps using Streamlit and I wanted to know which courses do you suggest for it?",does anyone knows a nice course for streamlit apps whats in the title i wanna learn how to create a deploy apps using streamlit and i wanted to know which courses do you suggest for it,know nice course streamlit app s title wanna learn create deploy app streamlit want know course suggest
1kxk5m1,Best youtube playlists for learning causal inference with Python?,"Hey folks,

Im starting to learn causal inference and want to understand both the theory and how to apply it using python. I’m comfortable with classical ML, but causal inference is new to me.

Looking for youtube playlists or videos that explain concepts like DAGs, DID, double ML, propensity scores, IPTW, etc., and ideally show practical examples using libraries like DoWhy, EconML, or CausalML.

im not very comfortable with books.

Also, is it even worth spending time learning causal inference in depth? Im planning to dig into Bayesian inference next, so curious if this is a good path.

Would really appreciate any suggestions. thanks!",73,18,2025-05-28T15:33:47+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kxk5m1/best_youtube_playlists_for_learning_causal/,"Best youtube playlists for learning causal inference with Python? Hey folks,

Im starting to learn causal inference and want to understand both the theory and how to apply it using python. I’m comfortable with classical ML, but causal inference is new to me.

Looking for youtube playlists or videos that explain concepts like DAGs, DID, double ML, propensity scores, IPTW, etc., and ideally show practical examples using libraries like DoWhy, EconML, or CausalML.

im not very comfortable with books.

Also, is it even worth spending time learning causal inference in depth? Im planning to dig into Bayesian inference next, so curious if this is a good path.

Would really appreciate any suggestions. thanks!",best youtube playlists for learning causal inference with python hey folks im starting to learn causal inference and want to understand both the theory and how to apply it using python im comfortable with classical ml but causal inference is new to me looking for youtube playlists or videos that explain concepts like dags did double ml propensity scores iptw etc and ideally show practical examples using libraries like dowhy econml or causalml im not very comfortable with books also is it even worth spending time learning causal inference in depth im planning to dig into bayesian inference next so curious if this is a good path would really appreciate any suggestions thanks,good youtube playlist learn causal inference python hey folk m start learn causal inference want understand theory apply python m comfortable classical ml causal inference new look youtube playlist video explain concept like dag double ml propensity score iptw etc ideally practical example library like dowhy econml causalml m comfortable book worth spend time learn causal inference depth m plan dig bayesian inference curious good path appreciate suggestion thank
1kxjfgz,How to stay motivated in a job where my salary has remained flat for last 4 years and there’s no promotion in sight?,"I joined my current company 3.5 years ago during a hiring boom. I was excited about the role and contributed heavily, leading process improvements with real financial impact. Despite this, I’ve received 0% raises year after year, which has been discouraging.

I stayed motivated, hoping the role would benefit my long-term career. But since the last performance cycle, my enthusiasm has dropped. I don’t feel appreciated, and it worries me that I could be the first to go if layoffs happen.

I’ve asked for a promotion twice in the past two years, but only received vague feedback like “We haven’t set you up for success yet” or “Promotion isn’t just about performance.”

It’s frustrating to feel stuck in a job I once loved. I’ve started interviewing, though the market is tough — but I’ll keep at it. In the meantime, I’m not sure what to do next. Any advice?",193,77,2025-05-28T15:04:52+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kxjfgz/how_to_stay_motivated_in_a_job_where_my_salary/,"How to stay motivated in a job where my salary has remained flat for last 4 years and there’s no promotion in sight? I joined my current company 3.5 years ago during a hiring boom. I was excited about the role and contributed heavily, leading process improvements with real financial impact. Despite this, I’ve received 0% raises year after year, which has been discouraging.

I stayed motivated, hoping the role would benefit my long-term career. But since the last performance cycle, my enthusiasm has dropped. I don’t feel appreciated, and it worries me that I could be the first to go if layoffs happen.

I’ve asked for a promotion twice in the past two years, but only received vague feedback like “We haven’t set you up for success yet” or “Promotion isn’t just about performance.”

It’s frustrating to feel stuck in a job I once loved. I’ve started interviewing, though the market is tough — but I’ll keep at it. In the meantime, I’m not sure what to do next. Any advice?",how to stay motivated in a job where my salary has remained flat for last years and theres no promotion in sight i joined my current company years ago during a hiring boom i was excited about the role and contributed heavily leading process improvements with real financial impact despite this ive received raises year after year which has been discouraging i stayed motivated hoping the role would benefit my longterm career but since the last performance cycle my enthusiasm has dropped i dont feel appreciated and it worries me that i could be the first to go if layoffs happen ive asked for a promotion twice in the past two years but only received vague feedback like we havent set you up for success yet or promotion isnt just about performance its frustrating to feel stuck in a job i once loved ive started interviewing though the market is tough but ill keep at it in the meantime im not sure what to do next any advice,stay motivated job salary remain flat year s promotion sight join current company year ago hiring boom excited role contribute heavily lead process improvement real financial impact despite ve receive raise year year discourage stay motivated hope role benefit longterm career performance cycle enthusiasm drop not feel appreciated worry layoff happen ve ask promotion twice past year receive vague feedback like not set success promotion not performance frustrating feel stuck job love ve start interview market tough ill meantime m sure advice
1kwycfm,The DS industry is turning into the investment banking industry,"Seems like the DS industry is essentially becoming a reflection of investment banking at places like Goldman Sachs or JP Mo. To get a job in the investment banking world you need to either: know someone high up at the company, have gone to a prestigious school, have experience at a different prestigious institution or transfer into the role internally.

How is this different from the current state of DS? Sure, it’s still possible to get a job based purely off skills, experience and raw dogging a job application, but it’s unlikely considering you are battling against ~800 resumes filled with exaggerations and lies for each job posting. Some companies don’t even put out job positions and choose to hire from their network instead, similar to IB. Merit based hiring seems like a thing of the past at this point.",0,12,2025-05-27T20:46:09+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kwycfm/the_ds_industry_is_turning_into_the_investment/,"The DS industry is turning into the investment banking industry Seems like the DS industry is essentially becoming a reflection of investment banking at places like Goldman Sachs or JP Mo. To get a job in the investment banking world you need to either: know someone high up at the company, have gone to a prestigious school, have experience at a different prestigious institution or transfer into the role internally.

How is this different from the current state of DS? Sure, it’s still possible to get a job based purely off skills, experience and raw dogging a job application, but it’s unlikely considering you are battling against ~800 resumes filled with exaggerations and lies for each job posting. Some companies don’t even put out job positions and choose to hire from their network instead, similar to IB. Merit based hiring seems like a thing of the past at this point.",the ds industry is turning into the investment banking industry seems like the ds industry is essentially becoming a reflection of investment banking at places like goldman sachs or jp mo to get a job in the investment banking world you need to either know someone high up at the company have gone to a prestigious school have experience at a different prestigious institution or transfer into the role internally how is this different from the current state of ds sure its still possible to get a job based purely off skills experience and raw dogging a job application but its unlikely considering you are battling against resumes filled with exaggerations and lies for each job posting some companies dont even put out job positions and choose to hire from their network instead similar to ib merit based hiring seems like a thing of the past at this point,ds industry turn investment banking industry like ds industry essentially reflection investment banking place like goldman sachs jp mo job investment banking world need know high company go prestigious school experience different prestigious institution transfer role internally different current state ds sure possible job base purely skill experience raw dog job application unlikely consider battle resume fill exaggeration lie job post company not job position choose hire network instead similar ib merit base hiring like thing past point
1kwh7bw,Seeking Advice: How To Scale AI Models Without Huge Upfront Investment?,"Hey folks,  
Our startup is exploring AI-powered features but building and managing GPU clusters is way beyond our current budget and expertise. Are there good cloud services that provide ready-to-use AI models via API?Anyone here used similar “model APIs” to speed up AI deployment and avoid heavy infrastructure? Insights appreciated!",11,8,2025-05-27T07:25:02+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kwh7bw/seeking_advice_how_to_scale_ai_models_without/,"Seeking Advice: How To Scale AI Models Without Huge Upfront Investment? Hey folks,  
Our startup is exploring AI-powered features but building and managing GPU clusters is way beyond our current budget and expertise. Are there good cloud services that provide ready-to-use AI models via API?Anyone here used similar “model APIs” to speed up AI deployment and avoid heavy infrastructure? Insights appreciated!",seeking advice how to scale ai models without huge upfront investment hey folks our startup is exploring aipowered features but building and managing gpu clusters is way beyond our current budget and expertise are there good cloud services that provide readytouse ai models via apianyone here used similar model apis to speed up ai deployment and avoid heavy infrastructure insights appreciated,seek advice scale ai model huge upfront investment hey folk startup explore aipowere feature build manage gpu cluster way current budget expertise good cloud service provide readytouse ai model apianyone similar model apis speed ai deployment avoid heavy infrastructure insight appreciate
1kwd8vj,"With DS layoffs happening everyday,what’s the future ?",I am a freelancer Data Scientist and finding it extremely hard to get projects. I understand the current environment in DS space with layoffs happening all over the place and even the Director of AI @ Microsoft was laid off. I would love to hear from other Redditors about it. I’m currently extremely scared about my future as I don’t know if I’ll get projects. ,174,66,2025-05-27T03:18:51+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kwd8vj/with_ds_layoffs_happening_everydaywhats_the_future/,"With DS layoffs happening everyday,what’s the future ? I am a freelancer Data Scientist and finding it extremely hard to get projects. I understand the current environment in DS space with layoffs happening all over the place and even the Director of AI @ Microsoft was laid off. I would love to hear from other Redditors about it. I’m currently extremely scared about my future as I don’t know if I’ll get projects. ",with ds layoffs happening everydaywhats the future i am a freelancer data scientist and finding it extremely hard to get projects i understand the current environment in ds space with layoffs happening all over the place and even the director of ai microsoft was laid off i would love to hear from other redditors about it im currently extremely scared about my future as i dont know if ill get projects,ds layoff happen everydaywhat future freelancer datum scientist find extremely hard project understand current environment ds space layoff happen place director ai microsoft lay love hear redditor m currently extremely scared future not know ill project
1kw1cik,Am i the only one who truly love this field? It sounds like everyone here is in for the money and hate their jobs,it's funny because in real life most of the people i know in the field love it,1892,145,2025-05-26T18:13:38+00:00,datascience,https://i.redd.it/1cgu2smi363f1.jpeg,Am i the only one who truly love this field? It sounds like everyone here is in for the money and hate their jobs it's funny because in real life most of the people i know in the field love it,am i the only one who truly love this field it sounds like everyone here is in for the money and hate their jobs its funny because in real life most of the people i know in the field love it,truly love field sound like money hate job funny real life people know field love
1kvzd73,Thinking of switching from Data Scientist to Data Product Owner — need advice,"Hey everyone,
I’ve been working as a Data Scientist for the past 5 years, currently at a bank. I’ll be honest — this might sound a bit harsh, but it’s just how I personally feel: this job is slowly draining me.

Most of the models I build never make it to production. A big chunk of my time is spent doing analysis that feels more like trying to impress higher-ups than solving real problems. And with AI evolving so rapidly, there’s this growing pressure to “level up” to a senior role — but the bar is so high now, and the opportunities seem fewer and harder to reach. It’s honestly demotivating.

So, I’m thinking about pivoting into a Data Product Owner (or Product Manager) role. I feel like my experience could bridge the gap between business and technical teams — I can speak the language of data engineers, ML engineers, and data scientists. Plus, I’d love to be in a role that’s more collaborative and human-facing. It also feels like a safer long-term path in this AI-driven world.

Has anyone made a similar transition? Or is anyone here feeling the same way? I’d really appreciate any advice, feedback, or even just hearing your story. Totally open to different perspectives.

Thanks!
",98,25,2025-05-26T16:55:15+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kvzd73/thinking_of_switching_from_data_scientist_to_data/,"Thinking of switching from Data Scientist to Data Product Owner — need advice Hey everyone,
I’ve been working as a Data Scientist for the past 5 years, currently at a bank. I’ll be honest — this might sound a bit harsh, but it’s just how I personally feel: this job is slowly draining me.

Most of the models I build never make it to production. A big chunk of my time is spent doing analysis that feels more like trying to impress higher-ups than solving real problems. And with AI evolving so rapidly, there’s this growing pressure to “level up” to a senior role — but the bar is so high now, and the opportunities seem fewer and harder to reach. It’s honestly demotivating.

So, I’m thinking about pivoting into a Data Product Owner (or Product Manager) role. I feel like my experience could bridge the gap between business and technical teams — I can speak the language of data engineers, ML engineers, and data scientists. Plus, I’d love to be in a role that’s more collaborative and human-facing. It also feels like a safer long-term path in this AI-driven world.

Has anyone made a similar transition? Or is anyone here feeling the same way? I’d really appreciate any advice, feedback, or even just hearing your story. Totally open to different perspectives.

Thanks!
",thinking of switching from data scientist to data product owner need advice hey everyone ive been working as a data scientist for the past years currently at a bank ill be honest this might sound a bit harsh but its just how i personally feel this job is slowly draining me most of the models i build never make it to production a big chunk of my time is spent doing analysis that feels more like trying to impress higherups than solving real problems and with ai evolving so rapidly theres this growing pressure to level up to a senior role but the bar is so high now and the opportunities seem fewer and harder to reach its honestly demotivating so im thinking about pivoting into a data product owner or product manager role i feel like my experience could bridge the gap between business and technical teams i can speak the language of data engineers ml engineers and data scientists plus id love to be in a role thats more collaborative and humanfacing it also feels like a safer longterm path in this aidriven world has anyone made a similar transition or is anyone here feeling the same way id really appreciate any advice feedback or even just hearing your story totally open to different perspectives thanks,thinking switch datum scientist datum product owner need advice hey ve work data scientist past year currently bank ill honest sound bit harsh personally feel job slowly drain model build production big chunk time spend analysis feel like try impress higherup solve real problem ai evolve rapidly s grow pressure level senior role bar high opportunity few hard reach honestly demotivate m think pivot data product owner product manager role feel like experience bridge gap business technical team speak language data engineer ml engineer data scientist plus d love role s collaborative humanface feel like safe longterm path aidriven world similar transition feel way d appreciate advice feedback hear story totally open different perspective thank
1kvqn1s,How can I address wild expectations about Gen AI and Agentic AI?,"Following what the title says, people in my company have gone ballistic on Agentic AI and Gen AI more broadly as of late. This sadly includes some of the IT management that should know better/temper out expectations on what these can/cannot do.

To be clear, I am not a hater either, I see them as useful techonologies that unlock new opportunities within my work. At the same time, I feel like all the non-experts (and in this case even my management which is supposed to be more knowledgeable but has been carried away from the hype and is not hands-on) have completely non-realistic expectations of what these tools can do.

Do any of you have experience with educating people on what is reasonable to expect in this context? I am a bit tired of having to debunk use case by use.",99,44,2025-05-26T10:00:26+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kvqn1s/how_can_i_address_wild_expectations_about_gen_ai/,"How can I address wild expectations about Gen AI and Agentic AI? Following what the title says, people in my company have gone ballistic on Agentic AI and Gen AI more broadly as of late. This sadly includes some of the IT management that should know better/temper out expectations on what these can/cannot do.

To be clear, I am not a hater either, I see them as useful techonologies that unlock new opportunities within my work. At the same time, I feel like all the non-experts (and in this case even my management which is supposed to be more knowledgeable but has been carried away from the hype and is not hands-on) have completely non-realistic expectations of what these tools can do.

Do any of you have experience with educating people on what is reasonable to expect in this context? I am a bit tired of having to debunk use case by use.",how can i address wild expectations about gen ai and agentic ai following what the title says people in my company have gone ballistic on agentic ai and gen ai more broadly as of late this sadly includes some of the it management that should know bettertemper out expectations on what these cancannot do to be clear i am not a hater either i see them as useful techonologies that unlock new opportunities within my work at the same time i feel like all the nonexperts and in this case even my management which is supposed to be more knowledgeable but has been carried away from the hype and is not handson have completely nonrealistic expectations of what these tools can do do any of you have experience with educating people on what is reasonable to expect in this context i am a bit tired of having to debunk use case by use,address wild expectation gen ai agentic ai follow title say people company go ballistic agentic ai gen ai broadly late sadly include management know bettertemper expectation cancannot clear hater useful techonologie unlock new opportunity work time feel like nonexpert case management suppose knowledgeable carry away hype handson completely nonrealistic expectation tool experience educate people reasonable expect context bit tired have debunk use case use
1kvl43y,"Weekly Entering & Transitioning - Thread 26 May, 2025 - 02 Jun, 2025"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",3,32,2025-05-26T04:01:44+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kvl43y/weekly_entering_transitioning_thread_26_may_2025/,"Weekly Entering & Transitioning - Thread 26 May, 2025 - 02 Jun, 2025  

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",weekly entering transitioning thread may jun welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the and resources pages on our wiki you can also search for answers in,weekly enter transition thread jun welcome week enter transition thread thread question getting start study transition data science field topic include learn resource eg book tutorial video traditional education eg schools degree elective alternative education eg online course bootcamp job search question eg resume apply career prospect elementary question eg start wait answer community check resource page wiki search answer
1kv3smi,Can you explain to me the product analytics job?,"I ve watched videos about Data Scientist Product Analytics but i still dont understand if the job would excite me. 

Can someone explain it more in depth so that i can understand if i like it? I like the data science job (i am pursuing a master in DS) but it seems that product analytics is very different in the sense that it is very focused on SQL.

Also is it interesting and does it involve a lot of problem solving?
Does it have a sort of path to PM?",11,14,2025-05-25T14:24:48+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kv3smi/can_you_explain_to_me_the_product_analytics_job/,"Can you explain to me the product analytics job? I ve watched videos about Data Scientist Product Analytics but i still dont understand if the job would excite me. 

Can someone explain it more in depth so that i can understand if i like it? I like the data science job (i am pursuing a master in DS) but it seems that product analytics is very different in the sense that it is very focused on SQL.

Also is it interesting and does it involve a lot of problem solving?
Does it have a sort of path to PM?",can you explain to me the product analytics job i ve watched videos about data scientist product analytics but i still dont understand if the job would excite me can someone explain it more in depth so that i can understand if i like it i like the data science job i am pursuing a master in ds but it seems that product analytics is very different in the sense that it is very focused on sql also is it interesting and does it involve a lot of problem solving does it have a sort of path to pm,explain product analytic job ve watch video data scientist product analytic not understand job excite explain depth understand like like data science job pursue master ds product analytic different sense focused sql interesting involve lot problem solve sort path pm
1kuxcok,2025 stack check: which DS/ML tools am I missing?,"**Hi all,**

I work in ad-tech, where my job is to improve the product with data-driven algorithms, mostly on tabular datasets (CTR models, bidding, attribution, the usual).

Current work stack (quite classic I guess)

* pandas, numpy, scikit-learn, xgboost, statsmodels 
* PyTorch (light use) 
* JupyterLab & notebooks 
* matplotlib, seaborn, plotly for viz 
* Infra: everything runs on AWS (code is hosted on Github)

The news cycle is overflowing with LLM tools, I do use ChatGPT / Claude / Aider as helpers, but my main concern right now is the core DS/ML tooling that powers production pipelines.

So,  
What *genuinely awesome* 2024-25 libraries, frameworks, or services should I try, so I don’t get left behind? :)  
Any recommendations greatly appreciated, thanks!",139,52,2025-05-25T08:05:25+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kuxcok/2025_stack_check_which_dsml_tools_am_i_missing/,"2025 stack check: which DS/ML tools am I missing? **Hi all,**

I work in ad-tech, where my job is to improve the product with data-driven algorithms, mostly on tabular datasets (CTR models, bidding, attribution, the usual).

Current work stack (quite classic I guess)

* pandas, numpy, scikit-learn, xgboost, statsmodels 
* PyTorch (light use) 
* JupyterLab & notebooks 
* matplotlib, seaborn, plotly for viz 
* Infra: everything runs on AWS (code is hosted on Github)

The news cycle is overflowing with LLM tools, I do use ChatGPT / Claude / Aider as helpers, but my main concern right now is the core DS/ML tooling that powers production pipelines.

So,  
What *genuinely awesome* 2024-25 libraries, frameworks, or services should I try, so I don’t get left behind? :)  
Any recommendations greatly appreciated, thanks!",stack check which dsml tools am i missing hi all i work in adtech where my job is to improve the product with datadriven algorithms mostly on tabular datasets ctr models bidding attribution the usual current work stack quite classic i guess pandas numpy scikitlearn xgboost statsmodels pytorch light use jupyterlab notebooks matplotlib seaborn plotly for viz infra everything runs on aws code is hosted on github the news cycle is overflowing with llm tools i do use chatgpt claude aider as helpers but my main concern right now is the core dsml tooling that powers production pipelines so what genuinely awesome libraries frameworks or services should i try so i dont get left behind any recommendations greatly appreciated thanks,stack check dsml tool miss hi work adtech job improve product datadriven algorithm tabular dataset ctr model bid attribution usual current work stack classic guess panda numpy scikitlearn xgboost statsmodels pytorch light use jupyterlab notebooks matplotlib seaborn plotly viz infra run aws code host github news cycle overflow llm tool use chatgpt claude aider helper main concern right core dsml tool power production pipeline genuinely awesome library framework service try not leave recommendation greatly appreciate thank
1kuu5g2,Is it worth to waste a year to do CS?,"_(Yesterday i posted “is studying DS worth it” and it seemed that DS nowadays leads to product analytics which i dont enjoy. So i am considering to switch, it is a tough decision that is giving me troubles sleeping and concentrating on other stuff so i’d really like an helping hand from you guys)_
 
Guys I’m currently doing a 2 years Master in Business Analytics (Management + Data Science), but I’m considering switching to a Master in CS and ML. The downside is that I’d lose a year.

Here are some thoughts I’ve had so far:
With Business Analytics, I can access roles like:
- Data Scientist (but nowadays Data Scientists mostly do Product Analytics rather than ML, which doesn’t excite me)
- Management roles (but in tech it means mainly Sales, Marketing… less interesting to me. The exception is PM but it is very hard as a graduate)

So my questions are:

1) Does it make sense to lose a year to switch to CS+ML? My biggest fear is how AI is evolving and impacting the field. **This is the biggest fear i have, should i switch in the era of AI?**

 2) Am I undervaluing the opportunities from the Business Analytics Master? Especially regarding management roles, are there interesting options I’m missing?",0,34,2025-05-25T04:32:03+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kuu5g2/is_it_worth_to_waste_a_year_to_do_cs/,"Is it worth to waste a year to do CS? _(Yesterday i posted “is studying DS worth it” and it seemed that DS nowadays leads to product analytics which i dont enjoy. So i am considering to switch, it is a tough decision that is giving me troubles sleeping and concentrating on other stuff so i’d really like an helping hand from you guys)_
 
Guys I’m currently doing a 2 years Master in Business Analytics (Management + Data Science), but I’m considering switching to a Master in CS and ML. The downside is that I’d lose a year.

Here are some thoughts I’ve had so far:
With Business Analytics, I can access roles like:
- Data Scientist (but nowadays Data Scientists mostly do Product Analytics rather than ML, which doesn’t excite me)
- Management roles (but in tech it means mainly Sales, Marketing… less interesting to me. The exception is PM but it is very hard as a graduate)

So my questions are:

1) Does it make sense to lose a year to switch to CS+ML? My biggest fear is how AI is evolving and impacting the field. **This is the biggest fear i have, should i switch in the era of AI?**

 2) Am I undervaluing the opportunities from the Business Analytics Master? Especially regarding management roles, are there interesting options I’m missing?",is it worth to waste a year to do cs yesterday i posted is studying ds worth it and it seemed that ds nowadays leads to product analytics which i dont enjoy so i am considering to switch it is a tough decision that is giving me troubles sleeping and concentrating on other stuff so id really like an helping hand from you guys guys im currently doing a years master in business analytics management data science but im considering switching to a master in cs and ml the downside is that id lose a year here are some thoughts ive had so far with business analytics i can access roles like data scientist but nowadays data scientists mostly do product analytics rather than ml which doesnt excite me management roles but in tech it means mainly sales marketing less interesting to me the exception is pm but it is very hard as a graduate so my questions are does it make sense to lose a year to switch to csml my biggest fear is how ai is evolving and impacting the field this is the biggest fear i have should i switch in the era of ai am i undervaluing the opportunities from the business analytics master especially regarding management roles are there interesting options im missing,worth waste year cs yesterday post study ds worth ds nowadays lead product analytic not enjoy consider switch tough decision give trouble sleep concentrate stuff d like help hand guy guy m currently year master business analytic management datum science m consider switch master cs ml downside d lose year thought ve far business analytic access role like datum scientist nowadays data scientist product analytic ml not excite management role tech mean mainly sale marketing interesting exception pm hard graduate question sense lose year switch csml big fear ai evolve impact field big fear switch era ai undervalue opportunity business analytic master especially management role interesting option m miss
1kulk1b,"Found a really amazing video , providing context to the breakthrough as well as the misconceived hype around Alphaevolve","I am sure by now most of us would have seen or atleast heard about AlphaEvolve and it's many breakthroughs including the 4*4 MM improvement. While this was a fantastic step forward in constrained optimisation problems , a lot of the commentary around it in media was absolutely garbage.

The original paper is an amazing read, however I was scouring the internet to find videos by people who understood it at a better depth than I did. That's where I came across this gem. 

It's long watch at around 40 mins, but is extremely well structured and not too heavy on math ( grad level at best). Would highly recommend watching this!",18,1,2025-05-24T20:52:59+00:00,datascience,https://www.youtube.com/watch?v=Z3hIHaV0P7w,"Found a really amazing video , providing context to the breakthrough as well as the misconceived hype around Alphaevolve I am sure by now most of us would have seen or atleast heard about AlphaEvolve and it's many breakthroughs including the 4*4 MM improvement. While this was a fantastic step forward in constrained optimisation problems , a lot of the commentary around it in media was absolutely garbage.

The original paper is an amazing read, however I was scouring the internet to find videos by people who understood it at a better depth than I did. That's where I came across this gem. 

It's long watch at around 40 mins, but is extremely well structured and not too heavy on math ( grad level at best). Would highly recommend watching this!",found a really amazing video providing context to the breakthrough as well as the misconceived hype around alphaevolve i am sure by now most of us would have seen or atleast heard about alphaevolve and its many breakthroughs including the mm improvement while this was a fantastic step forward in constrained optimisation problems a lot of the commentary around it in media was absolutely garbage the original paper is an amazing read however i was scouring the internet to find videos by people who understood it at a better depth than i did thats where i came across this gem its long watch at around mins but is extremely well structured and not too heavy on math grad level at best would highly recommend watching this,find amazing video provide context breakthrough misconceived hype alphaevolve sure see atleast hear alphaevolve breakthrough include mm improvement fantastic step forward constrain optimisation problem lot commentary medium absolutely garbage original paper amazing read scour internet find video people understand well depth s come gem long watch min extremely structured heavy math grad level well highly recommend watch
1ku5qsq,FOMO at workplace,Hii All. I have joined as a DS and this is my first job. The DS model which I am tasked  to improve and maintain does not adhere to the modern tech stack. It is just old school classical ML in R. It is not in production. We only maintain it in our local and show the stakeholders necessary numbers in quarterly meetings or whenever it is required. My concern is am I falling behind on skills by doing this. Especially seeing all the fancy tools and MLE buzzwords that is being thrown around in almost every DS application ?? If yes how can I develop those skills despite not having opportunities at my workplace. ,42,21,2025-05-24T07:15:42+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ku5qsq/fomo_at_workplace/,FOMO at workplace Hii All. I have joined as a DS and this is my first job. The DS model which I am tasked  to improve and maintain does not adhere to the modern tech stack. It is just old school classical ML in R. It is not in production. We only maintain it in our local and show the stakeholders necessary numbers in quarterly meetings or whenever it is required. My concern is am I falling behind on skills by doing this. Especially seeing all the fancy tools and MLE buzzwords that is being thrown around in almost every DS application ?? If yes how can I develop those skills despite not having opportunities at my workplace. ,fomo at workplace hii all i have joined as a ds and this is my first job the ds model which i am tasked to improve and maintain does not adhere to the modern tech stack it is just old school classical ml in r it is not in production we only maintain it in our local and show the stakeholders necessary numbers in quarterly meetings or whenever it is required my concern is am i falling behind on skills by doing this especially seeing all the fancy tools and mle buzzwords that is being thrown around in almost every ds application if yes how can i develop those skills despite not having opportunities at my workplace,fomo workplace hii join ds job ds model tasked improve maintain adhere modern tech stack old school classical ml r production maintain local stakeholder necessary number quarterly meeting require concern fall skill especially see fancy tool mle buzzword throw ds application yes develop skill despite have opportunity workplace
1ku31vc,Is studying Data Science still worth it?,"Hi everyone, I’m currently studying data science, but I’ve been hearing that the demand for data scientists is decreasing significantly. I’ve also been told that many data scientists are essentially becoming analysts, while the machine learning side of things is increasingly being handled by engineers.

- Does it still make sense to pursue a career in data science or should i switch to computer science? I mean i dont think i want to do just AB tests for a living

- Also, are machine learning engineers still building models or are they mostly focused on deploying them?
",273,131,2025-05-24T04:19:28+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ku31vc/is_studying_data_science_still_worth_it/,"Is studying Data Science still worth it? Hi everyone, I’m currently studying data science, but I’ve been hearing that the demand for data scientists is decreasing significantly. I’ve also been told that many data scientists are essentially becoming analysts, while the machine learning side of things is increasingly being handled by engineers.

- Does it still make sense to pursue a career in data science or should i switch to computer science? I mean i dont think i want to do just AB tests for a living

- Also, are machine learning engineers still building models or are they mostly focused on deploying them?
",is studying data science still worth it hi everyone im currently studying data science but ive been hearing that the demand for data scientists is decreasing significantly ive also been told that many data scientists are essentially becoming analysts while the machine learning side of things is increasingly being handled by engineers does it still make sense to pursue a career in data science or should i switch to computer science i mean i dont think i want to do just ab tests for a living also are machine learning engineers still building models or are they mostly focused on deploying them,study datum science worth hi m currently study datum science ve hear demand data scientist decrease significantly ve tell datum scientist essentially analyst machine learn thing increasingly handle engineer sense pursue career datum science switch computer science mean not think want ab test living machine learn engineer build model focus deploy
1ktn5xx,6 degrees of separation,,0,3,2025-05-23T15:58:39+00:00,datascience,https://i.redd.it/6wtkow73ie2f1.jpeg,6 degrees of separation ,degrees of separation,degree separation
1ktaq9z,How is the market for senior Data Scientists with research experience?,"With everything that has going on around deepseek and the memes of US and China competing over the lead on AI, with Europe inventing a new bottle of plastic that is eco friendly, I was wandering how is the ML/AI market for experienced data and research scientists in Europe. Besides Misteral, I don’t think I know much. I guess that all the big companies have sites across the continent, but are there other companies that what are other companies that are worth following? 
Also, to the European here, do you actually expect a boom in Europe with the shocks the Trump administration gives the system in the US?",12,26,2025-05-23T04:21:02+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ktaq9z/how_is_the_market_for_senior_data_scientists_with/,"How is the market for senior Data Scientists with research experience? With everything that has going on around deepseek and the memes of US and China competing over the lead on AI, with Europe inventing a new bottle of plastic that is eco friendly, I was wandering how is the ML/AI market for experienced data and research scientists in Europe. Besides Misteral, I don’t think I know much. I guess that all the big companies have sites across the continent, but are there other companies that what are other companies that are worth following? 
Also, to the European here, do you actually expect a boom in Europe with the shocks the Trump administration gives the system in the US?",how is the market for senior data scientists with research experience with everything that has going on around deepseek and the memes of us and china competing over the lead on ai with europe inventing a new bottle of plastic that is eco friendly i was wandering how is the mlai market for experienced data and research scientists in europe besides misteral i dont think i know much i guess that all the big companies have sites across the continent but are there other companies that what are other companies that are worth following also to the european here do you actually expect a boom in europe with the shocks the trump administration gives the system in the us,market senior datum scientist research experience go deepseek meme china compete lead ai europe invent new bottle plastic eco friendly wander mlai market experienced datum research scientist europe misteral not think know guess big company site continent company company worth follow european actually expect boom europe shock trump administration give system
1ksz870,The 80/20 Guide to R You Wish You Read Years Ago,"After years of R programming, I've noticed most intermediate users get stuck writing code that works but isn't optimal. We learn the basics, get comfortable, but miss the workflow improvements that make the biggest difference.

I just wrote up the handful of changes that transformed my R experience - things like:

* Why DuckDB (and data.table) can handle datasets larger than your RAM
* How renv solves reproducibility issues
* When vectorization actually matters (and when it doesn't)
* The native pipe |> vs %>% debate

These aren't advanced techniques - they're small workflow improvements that compound over time. The kind of stuff I wish someone had told me sooner.

Read the [full article here.](https://open.substack.com/pub/borkar/p/the-8020-guide-to-r-you-wish-you?r=2qg9ny&utm_campaign=post&utm_medium=web&showWelcomeOnShare=true)

What workflow changes made the biggest difference for you?

P.S. Posting to help out a friend",289,34,2025-05-22T19:14:24+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ksz870/the_8020_guide_to_r_you_wish_you_read_years_ago/,"The 80/20 Guide to R You Wish You Read Years Ago After years of R programming, I've noticed most intermediate users get stuck writing code that works but isn't optimal. We learn the basics, get comfortable, but miss the workflow improvements that make the biggest difference.

I just wrote up the handful of changes that transformed my R experience - things like:

* Why DuckDB (and data.table) can handle datasets larger than your RAM
* How renv solves reproducibility issues
* When vectorization actually matters (and when it doesn't)
* The native pipe |> vs %>% debate

These aren't advanced techniques - they're small workflow improvements that compound over time. The kind of stuff I wish someone had told me sooner.

Read the [full article here.](https://open.substack.com/pub/borkar/p/the-8020-guide-to-r-you-wish-you?r=2qg9ny&utm_campaign=post&utm_medium=web&showWelcomeOnShare=true)

What workflow changes made the biggest difference for you?

P.S. Posting to help out a friend",the guide to r you wish you read years ago after years of r programming ive noticed most intermediate users get stuck writing code that works but isnt optimal we learn the basics get comfortable but miss the workflow improvements that make the biggest difference i just wrote up the handful of changes that transformed my r experience things like why duckdb and datatable can handle datasets larger than your ram how renv solves reproducibility issues when vectorization actually matters and when it doesnt the native pipe vs debate these arent advanced techniques theyre small workflow improvements that compound over time the kind of stuff i wish someone had told me sooner read the what workflow changes made the biggest difference for you ps posting to help out a friend,guide r wish read year ago year r programming ve notice intermediate user stick write code work not optimal learn basic comfortable miss workflow improvement big difference write handful change transform r experience thing like duckdb datatable handle dataset large ram renv solve reproducibility issue vectorization actually matter not native pipe vs debate not advanced technique small workflow improvement compound time kind stuff wish tell soon read workflow change big difference ps post help friend
1ksvnsk,"""You will help build and deploy scalable solutions... not just prototypes""","Hi everyone,

I’m not exactly sure how to frame this, but I’d like to kick off a discussion that’s been on my mind lately.

I keep seeing data science job descriptions *(E2E) data science,* not just prototypes, but scalable, production-ready solutions. At the same time, they’re asking for an overwhelming tech stack: DL, LLMs, computer vision, etc. On top of that, E2E implies a whole software engineering stack too.

So, what does *E2E* really mean?

For me, the ""left end"" is talking to stakeholders and/or working with the WH. The ""right end"" is delivering three pickle files: one with the model, one with transformations, and one with feature selection. Sometimes, this turns into an API and gets deployed sometimes not. This assumes the data is already clean and available in a single table. Otherwise, you’ve got another automated ETL step to handle. (Just to note: I’ve never had write access to the warehouse. The best I’ve had is an S3 bucket.)

When people say “scalable deployment,” what does that really mean? Let’s say the above API predicts a value based on daily readings. In my view, the model runs daily, stores the outputs in another table in the warehouse, and that gets picked up by the business or an app. Is that considered scalable? If not, what is?

If the data volume is massive, then you’d need parallelism, Lambdas, or something similar. But is that my job? I could do it if I had to, but in a business setting, I’d expect a software  engineer to handle that.

Now, if the model is deployed on the edge, where exactly is the “end” of E2E then?

Some job descriptions also mention API ingestion, dbt, Airflow, basically full-on data engineering responsibilities.

The bottom line: Sometimes I read a JD and what it *really* says is:

“We want you to talk to stakeholders, figure out their problem, find and ingest the data, store it in an optimized medallion-model warehouse using dbt for daily ingestion and Airflow for monitoring. Then build a model, deploy it to 10,000 devices, monitor it for drift, and make sure the pipeline never breaks.

Meanwhile, in real life, I spend weeks hand-holding stakeholders, begging data engineers for read access to a table I should already have access to, and struggling to get an EC2 instance when my model takes more than a few hours to run. Eventually, we store the outputs after  more meetings with the DE.

Often, the stakeholder sees the prototype, gets excited, and then has no idea how to use it. The model ends up in limbo between the data team and the business until it’s forgotten. It just  feels like the ego boost of the week for the C guys.

Now, I’m not the fastest or the smartest. But when I try to do all this E2E in personal projects, it takes ages and that’s without micromanagers breathing down my neck. Just setting up ingestion and figuring out how to optimize the WH took me two weeks.

So... all I am asking am I stupid , am I missing something?  Do you all actually do all of this daily? Is my understanding off?

Really just hoping this kicks off a genuine discussion.

Cheers :)",84,47,2025-05-22T16:51:29+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ksvnsk/you_will_help_build_and_deploy_scalable_solutions/,"""You will help build and deploy scalable solutions... not just prototypes"" Hi everyone,

I’m not exactly sure how to frame this, but I’d like to kick off a discussion that’s been on my mind lately.

I keep seeing data science job descriptions *(E2E) data science,* not just prototypes, but scalable, production-ready solutions. At the same time, they’re asking for an overwhelming tech stack: DL, LLMs, computer vision, etc. On top of that, E2E implies a whole software engineering stack too.

So, what does *E2E* really mean?

For me, the ""left end"" is talking to stakeholders and/or working with the WH. The ""right end"" is delivering three pickle files: one with the model, one with transformations, and one with feature selection. Sometimes, this turns into an API and gets deployed sometimes not. This assumes the data is already clean and available in a single table. Otherwise, you’ve got another automated ETL step to handle. (Just to note: I’ve never had write access to the warehouse. The best I’ve had is an S3 bucket.)

When people say “scalable deployment,” what does that really mean? Let’s say the above API predicts a value based on daily readings. In my view, the model runs daily, stores the outputs in another table in the warehouse, and that gets picked up by the business or an app. Is that considered scalable? If not, what is?

If the data volume is massive, then you’d need parallelism, Lambdas, or something similar. But is that my job? I could do it if I had to, but in a business setting, I’d expect a software  engineer to handle that.

Now, if the model is deployed on the edge, where exactly is the “end” of E2E then?

Some job descriptions also mention API ingestion, dbt, Airflow, basically full-on data engineering responsibilities.

The bottom line: Sometimes I read a JD and what it *really* says is:

“We want you to talk to stakeholders, figure out their problem, find and ingest the data, store it in an optimized medallion-model warehouse using dbt for daily ingestion and Airflow for monitoring. Then build a model, deploy it to 10,000 devices, monitor it for drift, and make sure the pipeline never breaks.

Meanwhile, in real life, I spend weeks hand-holding stakeholders, begging data engineers for read access to a table I should already have access to, and struggling to get an EC2 instance when my model takes more than a few hours to run. Eventually, we store the outputs after  more meetings with the DE.

Often, the stakeholder sees the prototype, gets excited, and then has no idea how to use it. The model ends up in limbo between the data team and the business until it’s forgotten. It just  feels like the ego boost of the week for the C guys.

Now, I’m not the fastest or the smartest. But when I try to do all this E2E in personal projects, it takes ages and that’s without micromanagers breathing down my neck. Just setting up ingestion and figuring out how to optimize the WH took me two weeks.

So... all I am asking am I stupid , am I missing something?  Do you all actually do all of this daily? Is my understanding off?

Really just hoping this kicks off a genuine discussion.

Cheers :)",you will help build and deploy scalable solutions not just prototypes hi everyone im not exactly sure how to frame this but id like to kick off a discussion thats been on my mind lately i keep seeing data science job descriptions ee data science not just prototypes but scalable productionready solutions at the same time theyre asking for an overwhelming tech stack dl llms computer vision etc on top of that ee implies a whole software engineering stack too so what does ee really mean for me the left end is talking to stakeholders andor working with the wh the right end is delivering three pickle files one with the model one with transformations and one with feature selection sometimes this turns into an api and gets deployed sometimes not this assumes the data is already clean and available in a single table otherwise youve got another automated etl step to handle just to note ive never had write access to the warehouse the best ive had is an s bucket when people say scalable deployment what does that really mean lets say the above api predicts a value based on daily readings in my view the model runs daily stores the outputs in another table in the warehouse and that gets picked up by the business or an app is that considered scalable if not what is if the data volume is massive then youd need parallelism lambdas or something similar but is that my job i could do it if i had to but in a business setting id expect a software engineer to handle that now if the model is deployed on the edge where exactly is the end of ee then some job descriptions also mention api ingestion dbt airflow basically fullon data engineering responsibilities the bottom line sometimes i read a jd and what it really says is we want you to talk to stakeholders figure out their problem find and ingest the data store it in an optimized medallionmodel warehouse using dbt for daily ingestion and airflow for monitoring then build a model deploy it to devices monitor it for drift and make sure the pipeline never breaks meanwhile in real life i spend weeks handholding stakeholders begging data engineers for read access to a table i should already have access to and struggling to get an ec instance when my model takes more than a few hours to run eventually we store the outputs after more meetings with the de often the stakeholder sees the prototype gets excited and then has no idea how to use it the model ends up in limbo between the data team and the business until its forgotten it just feels like the ego boost of the week for the c guys now im not the fastest or the smartest but when i try to do all this ee in personal projects it takes ages and thats without micromanagers breathing down my neck just setting up ingestion and figuring out how to optimize the wh took me two weeks so all i am asking am i stupid am i missing something do you all actually do all of this daily is my understanding off really just hoping this kicks off a genuine discussion cheers,help build deploy scalable solution prototype hi m exactly sure frame d like kick discussion s mind lately see datum science job description ee datum science prototype scalable productionready solution time ask overwhelming tech stack dl llm computer vision etc ee imply software engineering stack ee mean left end talk stakeholder andor work wh right end deliver pickle file model transformation feature selection turn api get deploy assume data clean available single table ve get automate etl step handle note ve write access warehouse good ve s bucket people scalable deployment mean let api predict value base daily reading view model run daily store output table warehouse get pick business app consider scalable datum volume massive d need parallelism lambda similar job business set d expect software engineer handle model deploy edge exactly end ee job description mention api ingestion dbt airflow basically fullon datum engineering responsibility line read jd say want talk stakeholder figure problem find ingest datum store optimize medallionmodel warehouse dbt daily ingestion airflow monitoring build model deploy device monitor drift sure pipeline break real life spend week handholde stakeholder beg datum engineer read access table access struggle ec instance model take hour run eventually store output meeting de stakeholder see prototype get excited idea use model end limbo data team business forget feel like ego boost week c guy m fast smart try ee personal project take age s micromanager breathe neck set ingestion figure optimize wh take week ask stupid miss actually daily understanding hope kick genuine discussion cheer
1ksnwds,Hypothesis Testing and Experimental Design,"Sharing my second ever blog post, covering experimental design and Hypothesis testing. 

I shared my first blog post here a few months ago and received valuable feedback, sharing it here so I can hopefully share some value and receive some feedback as well.",27,3,2025-05-22T11:04:00+00:00,datascience,https://medium.com/@joshamayo7/an-introduction-to-hypothesis-testing-bd6da5b3ccaf,"Hypothesis Testing and Experimental Design Sharing my second ever blog post, covering experimental design and Hypothesis testing. 

I shared my first blog post here a few months ago and received valuable feedback, sharing it here so I can hopefully share some value and receive some feedback as well.",hypothesis testing and experimental design sharing my second ever blog post covering experimental design and hypothesis testing i shared my first blog post here a few months ago and received valuable feedback sharing it here so i can hopefully share some value and receive some feedback as well,hypothesis testing experimental design share second blog post cover experimental design hypothesis testing share blog post month ago receive valuable feedback share hopefully share value receive feedback
1ksev5p,Is the traditional Data Scientist role dying out?,"I've been casually browsing job postings lately just to stay informed about the market, and honestly, I'm starting to wonder if the classic ""Data Scientist"" position is becoming a thing of the past.

Most of what I'm seeing falls into these categories:

* Data Analyst/BI roles (lots of SQL, dashboards, basic reporting)
* Data Engineer positions (pipelines, ETL, infrastructure stuff)
* AI/ML Engineer jobs (but these seem more about LLMs and deploying models than actually building them)

What I'm *not* seeing much of anymore is that traditional data scientist role - you know, the one where you actually do statistical modeling, design experiments, and work through complex business problems from start to finish using both programming and solid stats knowledge.

It makes me wonder: are companies just splitting up what used to be one data scientist job into multiple specialized roles? Or has the market just moved on from needing that ""unicorn"" profile that could do everything?

For those of you currently working as data scientists - what does your actual day-to-day look like? Are you still doing the traditional DS work, or has your role evolved into something more specialized?

And for anyone else who's been keeping an eye on the job market - am I just looking in the wrong places, or are others seeing this same trend?

Just curious about where the field is heading and whether that broad, stats-heavy data scientist role still has a place in today's market.",522,157,2025-05-22T01:33:43+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ksev5p/is_the_traditional_data_scientist_role_dying_out/,"Is the traditional Data Scientist role dying out? I've been casually browsing job postings lately just to stay informed about the market, and honestly, I'm starting to wonder if the classic ""Data Scientist"" position is becoming a thing of the past.

Most of what I'm seeing falls into these categories:

* Data Analyst/BI roles (lots of SQL, dashboards, basic reporting)
* Data Engineer positions (pipelines, ETL, infrastructure stuff)
* AI/ML Engineer jobs (but these seem more about LLMs and deploying models than actually building them)

What I'm *not* seeing much of anymore is that traditional data scientist role - you know, the one where you actually do statistical modeling, design experiments, and work through complex business problems from start to finish using both programming and solid stats knowledge.

It makes me wonder: are companies just splitting up what used to be one data scientist job into multiple specialized roles? Or has the market just moved on from needing that ""unicorn"" profile that could do everything?

For those of you currently working as data scientists - what does your actual day-to-day look like? Are you still doing the traditional DS work, or has your role evolved into something more specialized?

And for anyone else who's been keeping an eye on the job market - am I just looking in the wrong places, or are others seeing this same trend?

Just curious about where the field is heading and whether that broad, stats-heavy data scientist role still has a place in today's market.",is the traditional data scientist role dying out ive been casually browsing job postings lately just to stay informed about the market and honestly im starting to wonder if the classic data scientist position is becoming a thing of the past most of what im seeing falls into these categories data analystbi roles lots of sql dashboards basic reporting data engineer positions pipelines etl infrastructure stuff aiml engineer jobs but these seem more about llms and deploying models than actually building them what im not seeing much of anymore is that traditional data scientist role you know the one where you actually do statistical modeling design experiments and work through complex business problems from start to finish using both programming and solid stats knowledge it makes me wonder are companies just splitting up what used to be one data scientist job into multiple specialized roles or has the market just moved on from needing that unicorn profile that could do everything for those of you currently working as data scientists what does your actual daytoday look like are you still doing the traditional ds work or has your role evolved into something more specialized and for anyone else whos been keeping an eye on the job market am i just looking in the wrong places or are others seeing this same trend just curious about where the field is heading and whether that broad statsheavy data scientist role still has a place in todays market,traditional data scientist role die ve casually browse job posting lately stay informed market honestly m start wonder classic data scientist position thing past m see fall category datum analystbi role lot sql dashboard basic reporting datum engineer position pipeline etl infrastructure stuff aiml engineer job llm deploy model actually build m see anymore traditional data scientist role know actually statistical modeling design experiment work complex business problem start finish programming solid stat knowledge make wonder company split data scientist job multiple specialized role market move need unicorn profile currently work datum scientist actual daytoday look like traditional ds work role evolve specialized s keep eye job market look wrong place see trend curious field head broad statsheavy datum scientist role place today market
1ks5jo6,"Those of you who interviewed/working at big tech/finance, how did you prepare for it? Need advice pls.","title. Im a data analyst  with \~3yoe currently work at a bank. lets say i have this golden time period where my work is low stress/pressure and I can put time into preparing for interviews. My goal is to get into FAANG/finance/similar companies in data science roles. How do I prepare for interviews? Did you follow a specific structure for certain companies? How/what did you allocate time into between analytics/sql/python, ML, GenAI(if at all) or other stuff and how did you prepare? Im good w sql, currently practicing ML and GenAI projects on python. I have very basic understanding of data engg from self projects. What metrics you use to determine where you stand?

I get the job market is shit but Im not ready anyway. My aim is to start interviewing by fall, say august/september. I'd highly appreciate any help i can get. thx. ",73,39,2025-05-21T18:40:52+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ks5jo6/those_of_you_who_interviewedworking_at_big/,"Those of you who interviewed/working at big tech/finance, how did you prepare for it? Need advice pls. title. Im a data analyst  with \~3yoe currently work at a bank. lets say i have this golden time period where my work is low stress/pressure and I can put time into preparing for interviews. My goal is to get into FAANG/finance/similar companies in data science roles. How do I prepare for interviews? Did you follow a specific structure for certain companies? How/what did you allocate time into between analytics/sql/python, ML, GenAI(if at all) or other stuff and how did you prepare? Im good w sql, currently practicing ML and GenAI projects on python. I have very basic understanding of data engg from self projects. What metrics you use to determine where you stand?

I get the job market is shit but Im not ready anyway. My aim is to start interviewing by fall, say august/september. I'd highly appreciate any help i can get. thx. ",those of you who interviewedworking at big techfinance how did you prepare for it need advice pls title im a data analyst with yoe currently work at a bank lets say i have this golden time period where my work is low stresspressure and i can put time into preparing for interviews my goal is to get into faangfinancesimilar companies in data science roles how do i prepare for interviews did you follow a specific structure for certain companies howwhat did you allocate time into between analyticssqlpython ml genaiif at all or other stuff and how did you prepare im good w sql currently practicing ml and genai projects on python i have very basic understanding of data engg from self projects what metrics you use to determine where you stand i get the job market is shit but im not ready anyway my aim is to start interviewing by fall say augustseptember id highly appreciate any help i can get thx,interviewedworke big techfinance prepare need advice pls title m data analyst yoe currently work bank let golden time period work low stresspressure time prepare interview goal faangfinancesimilar company datum science role prepare interview follow specific structure certain company howwhat allocate time analyticssqlpython ml genaiif stuff prepare m good w sql currently practice ml genai project python basic understanding datum engg self project metric use determine stand job market shit m ready aim start interview fall augustseptember d highly appreciate help thx
1krl7kx,Question about using the MLE of a distribution as a loss function,"I recently built a model using a Tweedie loss function. It performed really well, but I want to understand it better under the hood. I'd be super grateful if someone could clarify this for me.

I understand that using a ""Tweedie loss"" just means using the negative log likelihood of a Tweedie distribution as the loss function. I also already understand how this works in the simple case of a linear model f(x\_i) = wx\_i, with a normal distribution negative log likelihood (i.e., the RMSE) as the loss function. You simply write out the likelihood of observing the data {(x\_i, y\_i) | i=1, ..., N}, given that the target variable y\_i came from a normal distribution with mean f(x\_i). Then you take the negative log of this, differentiate it with respect to the parameter(s), w in this case, set it equal to zero, and solve for w. This is all basic and makes sense to me; you are finding the w which maximizes the likelihood of observing the data you saw, given the assumption that the data y\_i was drawn from a normal distribution with mean f(x\_i) for each i.

What gets me confused is using a more complex model and loss function, like LightGBM with a Tweedie loss. I figured the exact same principles would apply, but when I try to wrap my head around it, it seems I'm missing something.

In the linear regression example, the ""model"" is y\_i \~ N(f(x\_i), sigma\^2). In other words, you are assuming that the response variable y\_i is a linear function of the independent variable x\_i, plus normally distributed errors. But how do you even write this in the case of LightGBM with Tweedie loss? In my head, the analogous ""model"" would be y\_i \~ Tw(f(x\_i), phi, p), where f(x\_i) is the output of the LightGBM algorithm, and f(x\_i) takes the place of the mean mu in the Tweedie distribution Tw(u, phi, p). Is this correct? Are we always just treating the prediction f(x\_i) as the mean of the distribution we've assumed, or is that only coincidentally true in the special case of a linear model with normal distribution NLL?",7,3,2025-05-21T00:55:46+00:00,datascience,https://www.reddit.com/r/datascience/comments/1krl7kx/question_about_using_the_mle_of_a_distribution_as/,"Question about using the MLE of a distribution as a loss function I recently built a model using a Tweedie loss function. It performed really well, but I want to understand it better under the hood. I'd be super grateful if someone could clarify this for me.

I understand that using a ""Tweedie loss"" just means using the negative log likelihood of a Tweedie distribution as the loss function. I also already understand how this works in the simple case of a linear model f(x\_i) = wx\_i, with a normal distribution negative log likelihood (i.e., the RMSE) as the loss function. You simply write out the likelihood of observing the data {(x\_i, y\_i) | i=1, ..., N}, given that the target variable y\_i came from a normal distribution with mean f(x\_i). Then you take the negative log of this, differentiate it with respect to the parameter(s), w in this case, set it equal to zero, and solve for w. This is all basic and makes sense to me; you are finding the w which maximizes the likelihood of observing the data you saw, given the assumption that the data y\_i was drawn from a normal distribution with mean f(x\_i) for each i.

What gets me confused is using a more complex model and loss function, like LightGBM with a Tweedie loss. I figured the exact same principles would apply, but when I try to wrap my head around it, it seems I'm missing something.

In the linear regression example, the ""model"" is y\_i \~ N(f(x\_i), sigma\^2). In other words, you are assuming that the response variable y\_i is a linear function of the independent variable x\_i, plus normally distributed errors. But how do you even write this in the case of LightGBM with Tweedie loss? In my head, the analogous ""model"" would be y\_i \~ Tw(f(x\_i), phi, p), where f(x\_i) is the output of the LightGBM algorithm, and f(x\_i) takes the place of the mean mu in the Tweedie distribution Tw(u, phi, p). Is this correct? Are we always just treating the prediction f(x\_i) as the mean of the distribution we've assumed, or is that only coincidentally true in the special case of a linear model with normal distribution NLL?",question about using the mle of a distribution as a loss function i recently built a model using a tweedie loss function it performed really well but i want to understand it better under the hood id be super grateful if someone could clarify this for me i understand that using a tweedie loss just means using the negative log likelihood of a tweedie distribution as the loss function i also already understand how this works in the simple case of a linear model fxi wxi with a normal distribution negative log likelihood ie the rmse as the loss function you simply write out the likelihood of observing the data xi yi i n given that the target variable yi came from a normal distribution with mean fxi then you take the negative log of this differentiate it with respect to the parameters w in this case set it equal to zero and solve for w this is all basic and makes sense to me you are finding the w which maximizes the likelihood of observing the data you saw given the assumption that the data yi was drawn from a normal distribution with mean fxi for each i what gets me confused is using a more complex model and loss function like lightgbm with a tweedie loss i figured the exact same principles would apply but when i try to wrap my head around it it seems im missing something in the linear regression example the model is yi nfxi sigma in other words you are assuming that the response variable yi is a linear function of the independent variable xi plus normally distributed errors but how do you even write this in the case of lightgbm with tweedie loss in my head the analogous model would be yi twfxi phi p where fxi is the output of the lightgbm algorithm and fxi takes the place of the mean mu in the tweedie distribution twu phi p is this correct are we always just treating the prediction fxi as the mean of the distribution weve assumed or is that only coincidentally true in the special case of a linear model with normal distribution nll,question mle distribution loss function recently build model tweedie loss function perform want understand well hood d super grateful clarify understand tweedie loss mean negative log likelihood tweedie distribution loss function understand work simple case linear model fxi wxi normal distribution negative log likelihood ie rmse loss function simply write likelihood observe datum xi yi n give target variable yi come normal distribution mean fxi negative log differentiate respect parameter w case set equal zero solve w basic make sense find w maximize likelihood observe datum see give assumption datum yi draw normal distribution mean fxi get confused complex model loss function like lightgbm tweedie loss figure exact principle apply try wrap head m miss linear regression example model yi nfxi sigma word assume response variable yi linear function independent variable xi plus normally distribute error write case lightgbm tweedie loss head analogous model yi twfxi phi p fxi output lightgbm algorithm fxi take place mean mu tweedie distribution twu phi p correct treat prediction fxi mean distribution ve assume coincidentally true special case linear model normal distribution nll
1krkxl4,"Have you ever wondered, what comes next? Once you’ve built the model or finished the analysis, how do you take the next step? Whether it’s turning it into an app, a tool, a product, or something else?","For those of you working on personal data science projects, what comes after the .py script or Jupyter notebook? 

I’m trying to move beyond exploratory work into something more usable or shareable. 

Is building an app the natural next step? 

What paths have you taken to evolve your projects once the core analysis or modeling was done?",28,22,2025-05-21T00:41:08+00:00,datascience,https://www.reddit.com/r/datascience/comments/1krkxl4/have_you_ever_wondered_what_comes_next_once_youve/,"Have you ever wondered, what comes next? Once you’ve built the model or finished the analysis, how do you take the next step? Whether it’s turning it into an app, a tool, a product, or something else? For those of you working on personal data science projects, what comes after the .py script or Jupyter notebook? 

I’m trying to move beyond exploratory work into something more usable or shareable. 

Is building an app the natural next step? 

What paths have you taken to evolve your projects once the core analysis or modeling was done?",have you ever wondered what comes next once youve built the model or finished the analysis how do you take the next step whether its turning it into an app a tool a product or something else for those of you working on personal data science projects what comes after the py script or jupyter notebook im trying to move beyond exploratory work into something more usable or shareable is building an app the natural next step what paths have you taken to evolve your projects once the core analysis or modeling was done,wonder come ve build model finish analysis step turn app tool product work personal datum science project come py script jupyter notebook m try exploratory work usable shareable build app natural step path take evolve project core analysis modeling
1krc89b,No DS job after degree,"Hi everyone, 
This may be a bit of a vent post. I got a few years in DS experience as a data analyst and then got my MSc in well ranked US school. For some reason beyond my knowledge, I’ve never been able to get a DS job after the MS degree. I got a quant job where DS is the furthest thing from it even though some stats is used, and I am now headed to a data engineering fellowship with option to renew for one more year max. I just wonder if any of this effort was worth it sometimes . I’m open to any advice or suggestions because it feels like I can’t get any lower than this.
Thanks everyone 

Edit : thank you everyone for all the insights and kind words!!!",264,115,2025-05-20T18:24:51+00:00,datascience,https://www.reddit.com/r/datascience/comments/1krc89b/no_ds_job_after_degree/,"No DS job after degree Hi everyone, 
This may be a bit of a vent post. I got a few years in DS experience as a data analyst and then got my MSc in well ranked US school. For some reason beyond my knowledge, I’ve never been able to get a DS job after the MS degree. I got a quant job where DS is the furthest thing from it even though some stats is used, and I am now headed to a data engineering fellowship with option to renew for one more year max. I just wonder if any of this effort was worth it sometimes . I’m open to any advice or suggestions because it feels like I can’t get any lower than this.
Thanks everyone 

Edit : thank you everyone for all the insights and kind words!!!",no ds job after degree hi everyone this may be a bit of a vent post i got a few years in ds experience as a data analyst and then got my msc in well ranked us school for some reason beyond my knowledge ive never been able to get a ds job after the ms degree i got a quant job where ds is the furthest thing from it even though some stats is used and i am now headed to a data engineering fellowship with option to renew for one more year max i just wonder if any of this effort was worth it sometimes im open to any advice or suggestions because it feels like i cant get any lower than this thanks everyone edit thank you everyone for all the insights and kind words,ds job degree hi bit vent post get year ds experience data analyst get msc rank school reason knowledge ve able ds job ms degree get quant job ds furth thing stat head data engineering fellowship option renew year max wonder effort worth m open advice suggestion feel like not low thank edit thank insight kind word
1krau6q,Are there any math tests that test mathematical skill for data science?,I am looking for a test which can test one’s math skills that are relevant for data science- that way I can understand which areas I’m weak in and how I measure relative to my peers. Is anybody aware of anything like that?,51,27,2025-05-20T17:30:32+00:00,datascience,https://www.reddit.com/r/datascience/comments/1krau6q/are_there_any_math_tests_that_test_mathematical/,Are there any math tests that test mathematical skill for data science? I am looking for a test which can test one’s math skills that are relevant for data science- that way I can understand which areas I’m weak in and how I measure relative to my peers. Is anybody aware of anything like that?,are there any math tests that test mathematical skill for data science i am looking for a test which can test ones math skills that are relevant for data science that way i can understand which areas im weak in and how i measure relative to my peers is anybody aware of anything like that,math test test mathematical skill datum science look test test one math skill relevant datum science way understand area m weak measure relative peer anybody aware like
1kr41wk,I Scrape FAANG Data Science Jobs from the Last 24h and Email Them to You,"I built a tool that scrapes fresh data science, machine learning, and data engineering roles from FAANG and other top tech companies’ official career pages — no LinkedIn noise or recruiter spam — and emails them straight to you.

What it does:

* Scrapes jobs directly from sites like Google, Apple, Meta, Amazon, Microsoft, Netflix, Stripe, Uber, TikTok, Airbnb, and more
* Sends daily emails with newly scraped jobs
* Helps you find openings faster – before they hit job boards
* Lets you select different countries like USA, Canada, India, European countries, and more

Check it out here:  
[https://topjobstoday.com/data-scientist-jobs](https://topjobstoday.com/data-scientist-jobs)

Would love to hear your thoughts or suggestions!",0,3,2025-05-20T12:50:06+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kr41wk/i_scrape_faang_data_science_jobs_from_the_last/,"I Scrape FAANG Data Science Jobs from the Last 24h and Email Them to You I built a tool that scrapes fresh data science, machine learning, and data engineering roles from FAANG and other top tech companies’ official career pages — no LinkedIn noise or recruiter spam — and emails them straight to you.

What it does:

* Scrapes jobs directly from sites like Google, Apple, Meta, Amazon, Microsoft, Netflix, Stripe, Uber, TikTok, Airbnb, and more
* Sends daily emails with newly scraped jobs
* Helps you find openings faster – before they hit job boards
* Lets you select different countries like USA, Canada, India, European countries, and more

Check it out here:  
[https://topjobstoday.com/data-scientist-jobs](https://topjobstoday.com/data-scientist-jobs)

Would love to hear your thoughts or suggestions!",i scrape faang data science jobs from the last h and email them to you i built a tool that scrapes fresh data science machine learning and data engineering roles from faang and other top tech companies official career pages no linkedin noise or recruiter spam and emails them straight to you what it does scrapes jobs directly from sites like google apple meta amazon microsoft netflix stripe uber tiktok airbnb and more sends daily emails with newly scraped jobs helps you find openings faster before they hit job boards lets you select different countries like usa canada india european countries and more check it out here would love to hear your thoughts or suggestions,scrape faang datum science job h email build tool scrape fresh data science machine learning datum engineering role faang tech company official career page linkedin noise recruiter spam email straight scrape job directly site like google apple meta amazon microsoft netflix stripe uber tiktok airbnb send daily email newly scrape job help find opening fast hit job board let select different country like usa canada india european country check love hear thought suggestion
1kqkszs,"""But, I still put a ton of work into it...""",,505,8,2025-05-19T19:30:59+00:00,datascience,https://i.redd.it/u5jq8q4zis1f1.png,"""But, I still put a ton of work into it..."" ",but i still put a ton of work into it,ton work
1kqgxhb,"I’ve modularized my Jupyter pipeline into .py files, now what? Exploring GUI ideas, monthly comparisons, and next steps!","I have a data pipeline that processes spreadsheets and generates outputs.

What are smart next steps to take this further without overcomplicating it?

I’m thinking of building a simple GUI or dashboard to make it easier to trigger batch processing or explore outputs.

I want to support month-over-month comparisons e.g. how this month’s data differs from last and then generate diffs or trend insights.

Eventually I might want to track changes over time, add basic versioning, or even push summary outputs to a web format or email report.

Have you done something similar? What did you add next that really improved usefulness or usability? And any advice on building GUIs for spreadsheet based workflows?

I’m curious how others have expanded from here",6,11,2025-05-19T17:01:43+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kqgxhb/ive_modularized_my_jupyter_pipeline_into_py_files/,"I’ve modularized my Jupyter pipeline into .py files, now what? Exploring GUI ideas, monthly comparisons, and next steps! I have a data pipeline that processes spreadsheets and generates outputs.

What are smart next steps to take this further without overcomplicating it?

I’m thinking of building a simple GUI or dashboard to make it easier to trigger batch processing or explore outputs.

I want to support month-over-month comparisons e.g. how this month’s data differs from last and then generate diffs or trend insights.

Eventually I might want to track changes over time, add basic versioning, or even push summary outputs to a web format or email report.

Have you done something similar? What did you add next that really improved usefulness or usability? And any advice on building GUIs for spreadsheet based workflows?

I’m curious how others have expanded from here",ive modularized my jupyter pipeline into py files now what exploring gui ideas monthly comparisons and next steps i have a data pipeline that processes spreadsheets and generates outputs what are smart next steps to take this further without overcomplicating it im thinking of building a simple gui or dashboard to make it easier to trigger batch processing or explore outputs i want to support monthovermonth comparisons eg how this months data differs from last and then generate diffs or trend insights eventually i might want to track changes over time add basic versioning or even push summary outputs to a web format or email report have you done something similar what did you add next that really improved usefulness or usability and any advice on building guis for spreadsheet based workflows im curious how others have expanded from here,ve modularize jupyter pipeline py file explore gui idea monthly comparison step data pipeline process spreadsheet generate output smart step overcomplicate m think build simple gui dashboard easy trigger batch processing explore output want support monthovermonth comparison eg month datum differ generate diff trend insight eventually want track change time add basic versioning push summary output web format email report similar add improve usefulness usability advice build guis spreadsheet base workflow m curious expand
1kq2lxu,"Weekly Entering & Transitioning - Thread 19 May, 2025 - 26 May, 2025"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",3,62,2025-05-19T04:01:33+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kq2lxu/weekly_entering_transitioning_thread_19_may_2025/,"Weekly Entering & Transitioning - Thread 19 May, 2025 - 26 May, 2025  

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",weekly entering transitioning thread may may welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the and resources pages on our wiki you can also search for answers in,weekly enter transition thread welcome week enter transition thread thread question getting start study transition data science field topic include learn resource eg book tutorial video traditional education eg schools degree elective alternative education eg online course bootcamp job search question eg resume apply career prospect elementary question eg start wait answer community check resource page wiki search answer
1kpy8ha,"Study looking at AI chatbots in 7,000 workplaces finds ‘no significant impact on earnings or recorded hours in any occupation’",,877,49,2025-05-19T00:03:15+00:00,datascience,https://fortune.com/2025/05/18/ai-chatbots-study-impact-earnings-hours-worked-any-occupation/,"Study looking at AI chatbots in 7,000 workplaces finds ‘no significant impact on earnings or recorded hours in any occupation’ ",study looking at ai chatbots in workplaces finds no significant impact on earnings or recorded hours in any occupation,study look ai chatbot workplace find significant impact earning record hour occupation
1kpj2cw,Are data science professionals primarily statisticians or computer scientists?,"Seems like there's a lot of overlap and maybe different experts do different jobs all within the data science field, but which background would you say is most prevalent in most data science positions?",262,183,2025-05-18T12:41:28+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kpj2cw/are_data_science_professionals_primarily/,"Are data science professionals primarily statisticians or computer scientists? Seems like there's a lot of overlap and maybe different experts do different jobs all within the data science field, but which background would you say is most prevalent in most data science positions?",are data science professionals primarily statisticians or computer scientists seems like theres a lot of overlap and maybe different experts do different jobs all within the data science field but which background would you say is most prevalent in most data science positions,datum science professional primarily statistician computer scientist like s lot overlap maybe different expert different job data science field background prevalent datum science position
1kp0grb,what were your first cloud projects related to DS/ML?,Currently learning GCP. Help me stay motivated by telling me about your first cloud-related DS/ML projects.,6,8,2025-05-17T18:59:24+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kp0grb/what_were_your_first_cloud_projects_related_to/,what were your first cloud projects related to DS/ML? Currently learning GCP. Help me stay motivated by telling me about your first cloud-related DS/ML projects.,what were your first cloud projects related to dsml currently learning gcp help me stay motivated by telling me about your first cloudrelated dsml projects,cloud project relate dsml currently learn gcp help stay motivated tell cloudrelate dsml project
1kowb8p,Prediction flow with Gaussian distributed features,"Hi all,
Just recently started as a data scientist, so I thought I could use the wisdom of this subreddit before I get up to speed and compare methodologies to see what can help my team better.
 
So say I have a dataset for a classification problem with several features (not all) that are normally distributed, and for the sake of numerical stability I’m normalizing those values to their respective Z-values (using the training set’s means and std to prevent leakage).

Now after I train the model and get some results I’m happy with using the test set (that was normalized also with the training’s mean and std), we trigger some of our tests and deploy pipelines (whatever they are) and later on we’ll use that model in production with new unseen data. 

My question is, what is your most popular go to choice to store those mean and std values for when you’ll need to normalize the unseen data’s features prior to the prediction? The same question applies for filling null values.

“Simplest” thing I thought of (with an emphasis on the “”) is a wrapper class that stores all those values as member fields along with the actual model object (or pickle file path) and storing that class also with pickle, but it sounds a bit cumbersome, so maybe you can spread some light with more efficient ideas :)

Cheers.",23,15,2025-05-17T15:57:36+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kowb8p/prediction_flow_with_gaussian_distributed_features/,"Prediction flow with Gaussian distributed features Hi all,
Just recently started as a data scientist, so I thought I could use the wisdom of this subreddit before I get up to speed and compare methodologies to see what can help my team better.
 
So say I have a dataset for a classification problem with several features (not all) that are normally distributed, and for the sake of numerical stability I’m normalizing those values to their respective Z-values (using the training set’s means and std to prevent leakage).

Now after I train the model and get some results I’m happy with using the test set (that was normalized also with the training’s mean and std), we trigger some of our tests and deploy pipelines (whatever they are) and later on we’ll use that model in production with new unseen data. 

My question is, what is your most popular go to choice to store those mean and std values for when you’ll need to normalize the unseen data’s features prior to the prediction? The same question applies for filling null values.

“Simplest” thing I thought of (with an emphasis on the “”) is a wrapper class that stores all those values as member fields along with the actual model object (or pickle file path) and storing that class also with pickle, but it sounds a bit cumbersome, so maybe you can spread some light with more efficient ideas :)

Cheers.",prediction flow with gaussian distributed features hi all just recently started as a data scientist so i thought i could use the wisdom of this subreddit before i get up to speed and compare methodologies to see what can help my team better so say i have a dataset for a classification problem with several features not all that are normally distributed and for the sake of numerical stability im normalizing those values to their respective zvalues using the training sets means and std to prevent leakage now after i train the model and get some results im happy with using the test set that was normalized also with the trainings mean and std we trigger some of our tests and deploy pipelines whatever they are and later on well use that model in production with new unseen data my question is what is your most popular go to choice to store those mean and std values for when youll need to normalize the unseen datas features prior to the prediction the same question applies for filling null values simplest thing i thought of with an emphasis on the is a wrapper class that stores all those values as member fields along with the actual model object or pickle file path and storing that class also with pickle but it sounds a bit cumbersome so maybe you can spread some light with more efficient ideas cheers,prediction flow gaussian distribute feature hi recently start data scientist think use wisdom subreddit speed compare methodology help team well dataset classification problem feature normally distribute sake numerical stability m normalize value respective zvalue training set mean std prevent leakage train model result m happy test set normalize training mean std trigger test deploy pipeline later use model production new unseen datum question popular choice store mean std value ll need normalize unseen data feature prior prediction question apply fill null value simple thing think emphasis wrapper class store value member field actual model object pickle file path store class pickle sound bit cumbersome maybe spread light efficient idea cheer
1kobhx7,Demand forecasting using multiple variables,I am working on a demand forecasting model to accurately predict test slots across different areas. I have been following the Rob Hyndman book. But the book essentially deals with just one feature and predicting its future values. But my model takes into account a lot of variables. How can I deal with that ? What kind of EDA should I perform ?? Is it better to make every feature stationary ? ,15,41,2025-05-16T20:50:43+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kobhx7/demand_forecasting_using_multiple_variables/,Demand forecasting using multiple variables I am working on a demand forecasting model to accurately predict test slots across different areas. I have been following the Rob Hyndman book. But the book essentially deals with just one feature and predicting its future values. But my model takes into account a lot of variables. How can I deal with that ? What kind of EDA should I perform ?? Is it better to make every feature stationary ? ,demand forecasting using multiple variables i am working on a demand forecasting model to accurately predict test slots across different areas i have been following the rob hyndman book but the book essentially deals with just one feature and predicting its future values but my model takes into account a lot of variables how can i deal with that what kind of eda should i perform is it better to make every feature stationary,demand forecasting multiple variable work demand forecasting model accurately predict test slot different area follow rob hyndman book book essentially deal feature predict future value model take account lot variable deal kind eda perform well feature stationary
1ko8ngz,When is the right time to move from Jupyter into a full modular pipeline?,"I feel stuck in the middle where my notebook works well, but it’s growing, and I know clients will add new requirements. I don’t want to introduce infrastructure I don’t need yet, but I also don’t want to be caught off guard when it’s important. 

How do you know when it’s time to level up, and what lightweight steps help you prepare?

Any books that can help me scale my jupyter notebooks into bigger solutions? ",76,45,2025-05-16T18:49:48+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ko8ngz/when_is_the_right_time_to_move_from_jupyter_into/,"When is the right time to move from Jupyter into a full modular pipeline? I feel stuck in the middle where my notebook works well, but it’s growing, and I know clients will add new requirements. I don’t want to introduce infrastructure I don’t need yet, but I also don’t want to be caught off guard when it’s important. 

How do you know when it’s time to level up, and what lightweight steps help you prepare?

Any books that can help me scale my jupyter notebooks into bigger solutions? ",when is the right time to move from jupyter into a full modular pipeline i feel stuck in the middle where my notebook works well but its growing and i know clients will add new requirements i dont want to introduce infrastructure i dont need yet but i also dont want to be caught off guard when its important how do you know when its time to level up and what lightweight steps help you prepare any books that can help me scale my jupyter notebooks into bigger solutions,right time jupyter modular pipeline feel stuck middle notebook work grow know client add new requirement not want introduce infrastructure not need not want catch guard important know time level lightweight step help prepare book help scale jupyter notebook big solution
1ko8lwv,How would you structure a data pipeline project that needs to handle near-identical logic across different input files?,I’m trying to turn a Jupyter notebook that processes 100k rows in a spreadsheet into something that can be reused across multiple datasets. I’ve considered parameterized config files but I want to hear from folks who’ve built reusable pipelines in client facing or consulting setups.,3,3,2025-05-16T18:47:59+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ko8lwv/how_would_you_structure_a_data_pipeline_project/,How would you structure a data pipeline project that needs to handle near-identical logic across different input files? I’m trying to turn a Jupyter notebook that processes 100k rows in a spreadsheet into something that can be reused across multiple datasets. I’ve considered parameterized config files but I want to hear from folks who’ve built reusable pipelines in client facing or consulting setups.,how would you structure a data pipeline project that needs to handle nearidentical logic across different input files im trying to turn a jupyter notebook that processes k rows in a spreadsheet into something that can be reused across multiple datasets ive considered parameterized config files but i want to hear from folks whove built reusable pipelines in client facing or consulting setups,structure data pipeline project need handle nearidentical logic different input file m try turn jupyter notebook process k row spreadsheet reuse multiple dataset ve consider parameterized config file want hear folk ve build reusable pipeline client face consult setup
1ko8j3v,"Jupyter notebook has grown into a 200+ line pipeline for a pandas heavy, linear logic, processor. What’s the smartest way to refactor without overengineering it or breaking the ‘run all’ simplicity?","I’m building an analysis that processes spreadsheets, transforms the data, and outputs HTML files. 

It works, but it’s hard to maintain. 

I’m not sure if I should start modularizing into scripts, introduce config files, or just reorganize inside the notebook. Looking for advice from others who’ve scaled up from this stage. It’s easy to make it work with new files, but I can’t help but wonder what the next stage looks like? 

EDIT: Really appreciate all the thoughtful replies so far. I’ve made notes with some great perspectives on refactoring, modularizing, and managing complexity without overengineering.

Follow-up question for those further down the path:

Let’s say I do what many of you have recommended and I refactor my project into clean .py files, introduce config files, and modularize the logic into a more maintainable structure. What comes after that?

I’m self taught and using this passion project as a way to build my skills. Once I’ve got something that “works well” and is well organized… what’s the next stage? 

Do I aim for packaging it? Turning it into a product? Adding tests? Making a CLI? 

I’d love to hear from others who’ve taken their passion project to the next level! 

How did you keep leveling up?",136,82,2025-05-16T18:44:44+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ko8j3v/jupyter_notebook_has_grown_into_a_200_line/,"Jupyter notebook has grown into a 200+ line pipeline for a pandas heavy, linear logic, processor. What’s the smartest way to refactor without overengineering it or breaking the ‘run all’ simplicity? I’m building an analysis that processes spreadsheets, transforms the data, and outputs HTML files. 

It works, but it’s hard to maintain. 

I’m not sure if I should start modularizing into scripts, introduce config files, or just reorganize inside the notebook. Looking for advice from others who’ve scaled up from this stage. It’s easy to make it work with new files, but I can’t help but wonder what the next stage looks like? 

EDIT: Really appreciate all the thoughtful replies so far. I’ve made notes with some great perspectives on refactoring, modularizing, and managing complexity without overengineering.

Follow-up question for those further down the path:

Let’s say I do what many of you have recommended and I refactor my project into clean .py files, introduce config files, and modularize the logic into a more maintainable structure. What comes after that?

I’m self taught and using this passion project as a way to build my skills. Once I’ve got something that “works well” and is well organized… what’s the next stage? 

Do I aim for packaging it? Turning it into a product? Adding tests? Making a CLI? 

I’d love to hear from others who’ve taken their passion project to the next level! 

How did you keep leveling up?",jupyter notebook has grown into a line pipeline for a pandas heavy linear logic processor whats the smartest way to refactor without overengineering it or breaking the run all simplicity im building an analysis that processes spreadsheets transforms the data and outputs html files it works but its hard to maintain im not sure if i should start modularizing into scripts introduce config files or just reorganize inside the notebook looking for advice from others whove scaled up from this stage its easy to make it work with new files but i cant help but wonder what the next stage looks like edit really appreciate all the thoughtful replies so far ive made notes with some great perspectives on refactoring modularizing and managing complexity without overengineering followup question for those further down the path lets say i do what many of you have recommended and i refactor my project into clean py files introduce config files and modularize the logic into a more maintainable structure what comes after that im self taught and using this passion project as a way to build my skills once ive got something that works well and is well organized whats the next stage do i aim for packaging it turning it into a product adding tests making a cli id love to hear from others whove taken their passion project to the next level how did you keep leveling up,jupyter notebook grow line pipeline panda heavy linear logic processor s smart way refactor overengineere break run simplicity m build analysis process spreadsheet transform datum output html file work hard maintain m sure start modularize script introduce config file reorganize inside notebook look advice ve scale stage easy work new file not help wonder stage look like edit appreciate thoughtful reply far ve note great perspective refactore modularizing manage complexity overengineere followup question path let recommend refactor project clean py file introduce config file modularize logic maintainable structure come m self teach passion project way build skill ve get work organize s stage aim package turn product add test make cli d love hear ve take passion project level level
1ko0frr,Company Data Retention Policies and GDPR,"How long are your data retention policies?

How do you handle GDPR rules?

My company is instituting a very, very conservative retention policy of <9months of raw event-level data (but storing 15-months worth of aggregated data). Additionally, the only way this company thinks about GDPR compliance is to delete user records instead of anonymizing. 

I'm curious how your companies deal with both, and what the risks would be with instituting such policies.",0,2,2025-05-16T13:09:09+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ko0frr/company_data_retention_policies_and_gdpr/,"Company Data Retention Policies and GDPR How long are your data retention policies?

How do you handle GDPR rules?

My company is instituting a very, very conservative retention policy of <9months of raw event-level data (but storing 15-months worth of aggregated data). Additionally, the only way this company thinks about GDPR compliance is to delete user records instead of anonymizing. 

I'm curious how your companies deal with both, and what the risks would be with instituting such policies.",company data retention policies and gdpr how long are your data retention policies how do you handle gdpr rules my company is instituting a very very conservative retention policy of months of raw eventlevel data but storing months worth of aggregated data additionally the only way this company thinks about gdpr compliance is to delete user records instead of anonymizing im curious how your companies deal with both and what the risks would be with instituting such policies,company datum retention policy gdpr long data retention policy handle gdpr rule company institute conservative retention policy month raw eventlevel datum store month worth aggregate datum additionally way company think gdpr compliance delete user record instead anonymize m curious company deal risk institute policy
1kncg7f,Is our job just to P hack for the stakeholders?,"Specifically in experimentation and causal inference.
",347,109,2025-05-15T16:24:08+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kncg7f/is_our_job_just_to_p_hack_for_the_stakeholders/,"Is our job just to P hack for the stakeholders? Specifically in experimentation and causal inference.
",is our job just to p hack for the stakeholders specifically in experimentation and causal inference,job p hack stakeholder specifically experimentation causal inference
1kn66el,Federated Platform for Secure Research Data Sharing,,6,0,2025-05-15T11:49:08+00:00,datascience,/r/clinicalresearch/comments/1kn5hf3/federated_platform_for_secure_research_data/,Federated Platform for Secure Research Data Sharing ,federated platform for secure research data sharing,federate platform secure research datum sharing
1kmv770,Anyone here experimenting with implementing Transformers on tabular data like Strip? Looking for some coding repo to play around and learn.,Here’s the Stripe case: https://techcrunch.com/2025/05/07/stripe-unveils-ai-foundation-model-for-payments-reveals-deeper-partnership-with-nvidia/,7,4,2025-05-15T00:38:54+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kmv770/anyone_here_experimenting_with_implementing/,Anyone here experimenting with implementing Transformers on tabular data like Strip? Looking for some coding repo to play around and learn. Here’s the Stripe case: https://techcrunch.com/2025/05/07/stripe-unveils-ai-foundation-model-for-payments-reveals-deeper-partnership-with-nvidia/,anyone here experimenting with implementing transformers on tabular data like strip looking for some coding repo to play around and learn heres the stripe case,experiment implement transformer tabular datum like strip look code repo play learn here stripe case
1km3wa1,Is LinkedIn data trust worthy?,Hey all. So I got my month of Linkdin premium and I am pretty shocked to see that for many data science positions it’s saying that more applicants have a masters? Is this actually true? I thought it would be the other way around. This is a job post that was up for 2 hours with over 100 clicks on apply. I know that doesn’t mean they are all real applications but I’m just curious to know what the communities thoughts on this are? ,147,73,2025-05-14T02:06:00+00:00,datascience,https://i.redd.it/3zlnro11on0f1.jpeg,Is LinkedIn data trust worthy? Hey all. So I got my month of Linkdin premium and I am pretty shocked to see that for many data science positions it’s saying that more applicants have a masters? Is this actually true? I thought it would be the other way around. This is a job post that was up for 2 hours with over 100 clicks on apply. I know that doesn’t mean they are all real applications but I’m just curious to know what the communities thoughts on this are? ,is linkedin data trust worthy hey all so i got my month of linkdin premium and i am pretty shocked to see that for many data science positions its saying that more applicants have a masters is this actually true i thought it would be the other way around this is a job post that was up for hours with over clicks on apply i know that doesnt mean they are all real applications but im just curious to know what the communities thoughts on this are,linkedin datum trust worthy hey get month linkdin premium pretty shocked datum science position saying applicant masters actually true think way job post hour click apply know not mean real application m curious know community thought
1klv393,"Those in manufacturing and science/engineering, aside from classic DoE (full-fact, CCD, etc.), what other experimental design tools do you use?",Title. My role mostly uses central composite designs and the standard lean six sigma quality tools because those are what management and the engineering teams are used to. Our team is slowly integrating other techniques like Bayesian optimization or interesting ways to analyze data (my new fave is functional data analysis) and I'd love to hear what other tools you guys use and your success/failures with them.,26,14,2025-05-13T19:32:51+00:00,datascience,https://www.reddit.com/r/datascience/comments/1klv393/those_in_manufacturing_and_scienceengineering/,"Those in manufacturing and science/engineering, aside from classic DoE (full-fact, CCD, etc.), what other experimental design tools do you use? Title. My role mostly uses central composite designs and the standard lean six sigma quality tools because those are what management and the engineering teams are used to. Our team is slowly integrating other techniques like Bayesian optimization or interesting ways to analyze data (my new fave is functional data analysis) and I'd love to hear what other tools you guys use and your success/failures with them.",those in manufacturing and scienceengineering aside from classic doe fullfact ccd etc what other experimental design tools do you use title my role mostly uses central composite designs and the standard lean six sigma quality tools because those are what management and the engineering teams are used to our team is slowly integrating other techniques like bayesian optimization or interesting ways to analyze data my new fave is functional data analysis and id love to hear what other tools you guys use and your successfailures with them,manufacturing scienceengineere aside classic doe fullfact ccd etc experimental design tool use title role use central composite design standard lean sigma quality tool management engineering team team slowly integrate technique like bayesian optimization interesting way analyze datum new fave functional datum analysis d love hear tool guy use successfailure
1kl55q1,What do you use to build dashboards?,"Hi guys, I've been a data scientist for 5 years. I've done lots of different types of work and unfortunately that has included a lot of dashboarding (no offense if you enjoy making dashboards). I'm wondering what tools people here are using and if you like them. In my career I've used mode, looker, streamlit and retool off the top of my head. I think mode was my favorite because you could type sql right into it and get the charts you wanted but still was overall unsatisfied with it.

  
I'm wondering what tools the people here are using and if you find it meets all your needs? One of my frustrations with these tools is that even platforms like Looker—designed to be self-serve for general staff—end up being confusing for people without a data science background.

Are there any tools (maybe powered my LLMs now) that allow non data science people to write prompts that update production dashboards? A simple example is if you have a revenue dashboard showing net revenue and a PM, director etc wanted you to add an additional gross revenue metric. With the tools I'm aware of I would have to go into the BI tool and update the chart myself to show that metric. Are there any tools that allow you to just type in a prompt and make those kinds of edits?",75,78,2025-05-12T21:52:24+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kl55q1/what_do_you_use_to_build_dashboards/,"What do you use to build dashboards? Hi guys, I've been a data scientist for 5 years. I've done lots of different types of work and unfortunately that has included a lot of dashboarding (no offense if you enjoy making dashboards). I'm wondering what tools people here are using and if you like them. In my career I've used mode, looker, streamlit and retool off the top of my head. I think mode was my favorite because you could type sql right into it and get the charts you wanted but still was overall unsatisfied with it.

  
I'm wondering what tools the people here are using and if you find it meets all your needs? One of my frustrations with these tools is that even platforms like Looker—designed to be self-serve for general staff—end up being confusing for people without a data science background.

Are there any tools (maybe powered my LLMs now) that allow non data science people to write prompts that update production dashboards? A simple example is if you have a revenue dashboard showing net revenue and a PM, director etc wanted you to add an additional gross revenue metric. With the tools I'm aware of I would have to go into the BI tool and update the chart myself to show that metric. Are there any tools that allow you to just type in a prompt and make those kinds of edits?",what do you use to build dashboards hi guys ive been a data scientist for years ive done lots of different types of work and unfortunately that has included a lot of dashboarding no offense if you enjoy making dashboards im wondering what tools people here are using and if you like them in my career ive used mode looker streamlit and retool off the top of my head i think mode was my favorite because you could type sql right into it and get the charts you wanted but still was overall unsatisfied with it im wondering what tools the people here are using and if you find it meets all your needs one of my frustrations with these tools is that even platforms like lookerdesigned to be selfserve for general staffend up being confusing for people without a data science background are there any tools maybe powered my llms now that allow non data science people to write prompts that update production dashboards a simple example is if you have a revenue dashboard showing net revenue and a pm director etc wanted you to add an additional gross revenue metric with the tools im aware of i would have to go into the bi tool and update the chart myself to show that metric are there any tools that allow you to just type in a prompt and make those kinds of edits,use build dashboard hi guy ve data scientist year ve lot different type work unfortunately include lot dashboarde offense enjoy make dashboard m wonder tool people like career ve mode looker streamlit retool head think mode favorite type sql right chart want overall unsatisfie m wonder tool people find meet need frustration tool platform like lookerdesigne selfserve general staffend confuse people data science background tool maybe power llm allow non data science people write prompt update production dashboard simple example revenue dashboard show net revenue pm director etc want add additional gross revenue metric tool m aware bi tool update chart metric tool allow type prompt kind edit
1kl2fq2,[8 YoE] 7 Years Software Engineer Trying to Pivot to Data Analytics/Science/Machine Learning,,0,12,2025-05-12T20:03:26+00:00,datascience,/r/EngineeringResumes/comments/1kkxd78/8_yoe_7_years_software_engineer_trying_to_pivot/,[8 YoE] 7 Years Software Engineer Trying to Pivot to Data Analytics/Science/Machine Learning ,yoe years software engineer trying to pivot to data analyticssciencemachine learning,yoe year software engineer try pivot datum analyticssciencemachine learning
1kl2ck3,Do open source contributors still need to do coding challenges?,"I’ve become an avid open source contributor over the past few years in a few popular ML, Econ, and Jax ecosystem packages.

In my opinion being able to take someone else’s code and fix bugs or add features is a much better signal than leetcode and hacker rank. I’m really hoping I don’t have to study leetcode/hackerrank for my next job search (DS/MLE roles) and I’d rather just keep doing open source work that’s more relevant.

For the other open source contributors out there - are you ever able to get out of coding challenges by citing your own pull requests?


",26,11,2025-05-12T20:00:03+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kl2ck3/do_open_source_contributors_still_need_to_do/,"Do open source contributors still need to do coding challenges? I’ve become an avid open source contributor over the past few years in a few popular ML, Econ, and Jax ecosystem packages.

In my opinion being able to take someone else’s code and fix bugs or add features is a much better signal than leetcode and hacker rank. I’m really hoping I don’t have to study leetcode/hackerrank for my next job search (DS/MLE roles) and I’d rather just keep doing open source work that’s more relevant.

For the other open source contributors out there - are you ever able to get out of coding challenges by citing your own pull requests?


",do open source contributors still need to do coding challenges ive become an avid open source contributor over the past few years in a few popular ml econ and jax ecosystem packages in my opinion being able to take someone elses code and fix bugs or add features is a much better signal than leetcode and hacker rank im really hoping i dont have to study leetcodehackerrank for my next job search dsmle roles and id rather just keep doing open source work thats more relevant for the other open source contributors out there are you ever able to get out of coding challenges by citing your own pull requests,open source contributor need code challenge ve avid open source contributor past year popular ml econ jax ecosystem package opinion able else code fix bug add feature well signal leetcode hacker rank m hope not study leetcodehackerrank job search dsmle role d open source work s relevant open source contributor able code challenge cite pull request
1kky19i,Now you're paying an analyst $50/hr to standardize date formats instead of doing actual analysis work.,,374,23,2025-05-12T17:12:00+00:00,datascience,https://i.redd.it/ccnonqd9vd0f1.png,Now you're paying an analyst $50/hr to standardize date formats instead of doing actual analysis work. ,now youre paying an analyst hr to standardize date formats instead of doing actual analysis work,pay analyst hr standardize date format instead actual analysis work
1kkwjla,"""Day Since Last X"" feature preprocessing","Hi Everyone! Bit of a technical modeling question here. Apologies if this is very basic preprocessing stuff but I'm a younger data scientist working in industry and I'm still learning.

  
Say you have a pretty standard binary classification model predicting 1 = we should market to this customer and 0 = we should not market to this customer (the exact labeling scheme is a bit proprietary). 

I have a few features that are in the style ""days since last touchpoint"". For example ""days since we last emailed this person"" or ""days since we last sold to this person"". However, a solid percentage of the rows are NULL, meaning we have never emailed or sold to this person. Any thoughts on how should I handle NULLs for this type of column? I've been imputing with MAX(days since we last sold to this person) + 1 but I'm starting to think that could be confusing my model. I think the reality of the situation is that someone with 1 purchase a long time ago is **a lot** more likely to purchase today than someone who has never purchased anything at all. The person with 0 purchases may not even be interested in our product, while we have evidence that the person with 1 purchase a long time ago is at least a fit for our product. Imputing with MAX(days since we last sold to this person) + 1 poses these two cases as very similar to the model.

For reference I'm testing with several tree-based models (light GBM and random forest) and comparing metrics to pick between the architecture options. So far I've been getting the best results with light GBM.

One thing I'm thinking about is whether I should just leave the people who have never sold as NULLs and have my model pick the direction to split for missing values. (I believe this would work with LightGBM but not RandomForest).

Another option is to break down the ""days since last sale"" feature into categories, maybe quantiles with a special category for NULLS, and then dummy encode.

Has anyone else used these types of ""days since last touchpoint"" features in propensity modeling/marketing modeling?",29,16,2025-05-12T16:13:47+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kkwjla/day_since_last_x_feature_preprocessing/,"""Day Since Last X"" feature preprocessing Hi Everyone! Bit of a technical modeling question here. Apologies if this is very basic preprocessing stuff but I'm a younger data scientist working in industry and I'm still learning.

  
Say you have a pretty standard binary classification model predicting 1 = we should market to this customer and 0 = we should not market to this customer (the exact labeling scheme is a bit proprietary). 

I have a few features that are in the style ""days since last touchpoint"". For example ""days since we last emailed this person"" or ""days since we last sold to this person"". However, a solid percentage of the rows are NULL, meaning we have never emailed or sold to this person. Any thoughts on how should I handle NULLs for this type of column? I've been imputing with MAX(days since we last sold to this person) + 1 but I'm starting to think that could be confusing my model. I think the reality of the situation is that someone with 1 purchase a long time ago is **a lot** more likely to purchase today than someone who has never purchased anything at all. The person with 0 purchases may not even be interested in our product, while we have evidence that the person with 1 purchase a long time ago is at least a fit for our product. Imputing with MAX(days since we last sold to this person) + 1 poses these two cases as very similar to the model.

For reference I'm testing with several tree-based models (light GBM and random forest) and comparing metrics to pick between the architecture options. So far I've been getting the best results with light GBM.

One thing I'm thinking about is whether I should just leave the people who have never sold as NULLs and have my model pick the direction to split for missing values. (I believe this would work with LightGBM but not RandomForest).

Another option is to break down the ""days since last sale"" feature into categories, maybe quantiles with a special category for NULLS, and then dummy encode.

Has anyone else used these types of ""days since last touchpoint"" features in propensity modeling/marketing modeling?",day since last x feature preprocessing hi everyone bit of a technical modeling question here apologies if this is very basic preprocessing stuff but im a younger data scientist working in industry and im still learning say you have a pretty standard binary classification model predicting we should market to this customer and we should not market to this customer the exact labeling scheme is a bit proprietary i have a few features that are in the style days since last touchpoint for example days since we last emailed this person or days since we last sold to this person however a solid percentage of the rows are null meaning we have never emailed or sold to this person any thoughts on how should i handle nulls for this type of column ive been imputing with maxdays since we last sold to this person but im starting to think that could be confusing my model i think the reality of the situation is that someone with purchase a long time ago is a lot more likely to purchase today than someone who has never purchased anything at all the person with purchases may not even be interested in our product while we have evidence that the person with purchase a long time ago is at least a fit for our product imputing with maxdays since we last sold to this person poses these two cases as very similar to the model for reference im testing with several treebased models light gbm and random forest and comparing metrics to pick between the architecture options so far ive been getting the best results with light gbm one thing im thinking about is whether i should just leave the people who have never sold as nulls and have my model pick the direction to split for missing values i believe this would work with lightgbm but not randomforest another option is to break down the days since last sale feature into categories maybe quantiles with a special category for nulls and then dummy encode has anyone else used these types of days since last touchpoint features in propensity modelingmarketing modeling,day x feature preprocesse hi bit technical modeling question apology basic preprocessing stuff m young datum scientist work industry m learn pretty standard binary classification model predict market customer market customer exact labeling scheme bit proprietary feature style day touchpoint example day email person day sell person solid percentage row null meaning email sell person thought handle null type column ve impute maxday sell person m start think confuse model think reality situation purchase long time ago lot likely purchase today purchase person purchase interested product evidence person purchase long time ago fit product impute maxday sell person pose case similar model reference m test treebase model light gbm random forest compare metric pick architecture option far ve get good result light gbm thing m think leave people sell null model pick direction split miss value believe work lightgbm randomforest option break day sale feature category maybe quantile special category null dummy encode type day touchpoint feature propensity modelingmarketing modeling
1kktdbl,is it necessary to learn some language other than python?,"that's pretty much it. i'm proficient in python already, but was wondering if, to be a better DS, i'd need to learn something else, or is it better to focus on studying something else rather than a new language.

  
edit: yes, SQL is obviously a must. i already know it. sorry for the overlook.",96,75,2025-05-12T14:05:50+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kktdbl/is_it_necessary_to_learn_some_language_other_than/,"is it necessary to learn some language other than python? that's pretty much it. i'm proficient in python already, but was wondering if, to be a better DS, i'd need to learn something else, or is it better to focus on studying something else rather than a new language.

  
edit: yes, SQL is obviously a must. i already know it. sorry for the overlook.",is it necessary to learn some language other than python thats pretty much it im proficient in python already but was wondering if to be a better ds id need to learn something else or is it better to focus on studying something else rather than a new language edit yes sql is obviously a must i already know it sorry for the overlook,necessary learn language python s pretty m proficient python wonder well ds d need learn well focus study new language edit yes sql obviously know sorry overlook
1kkjf6g,"Weekly Entering & Transitioning - Thread 12 May, 2025 - 19 May, 2025"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",7,20,2025-05-12T04:01:41+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kkjf6g/weekly_entering_transitioning_thread_12_may_2025/,"Weekly Entering & Transitioning - Thread 12 May, 2025 - 19 May, 2025  

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",weekly entering transitioning thread may may welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the and resources pages on our wiki you can also search for answers in,weekly enter transition thread welcome week enter transition thread thread question getting start study transition data science field topic include learn resource eg book tutorial video traditional education eg schools degree elective alternative education eg online course bootcamp job search question eg resume apply career prospect elementary question eg start wait answer community check resource page wiki search answer
1kjvita,rixpress: an R package to set up multi-language reproducible analytics pipelines (2 Minute intro video),,8,3,2025-05-11T07:39:05+00:00,datascience,https://youtu.be/a1eNG9TFZ_o?si=yWRIpPGWEP9NY-4Y,rixpress: an R package to set up multi-language reproducible analytics pipelines (2 Minute intro video) ,rixpress an r package to set up multilanguage reproducible analytics pipelines minute intro video,rixpress r package set multilanguage reproducible analytic pipeline minute intro video
1kjuwou,Where Can I Find Legit Remote Data Science Jobs That Hire Globally?,"Hey folks! I’m on the hunt for trustworthy remote job boards or sites that regularly post real data science and data analyst roles—and more importantly, are open to hiring from anywhere in the world. I’ve noticed sites like Indeed don’t support my country, and while LinkedIn has plenty of remote listings, many seem sketchy or not legit. 

So, what platforms or communities do you recommend for finding genuine remote gigs in this field that are truly global? Any tips on spotting legit postings would also be super helpful! 

Thanks in advance for sharing your experiences!",38,21,2025-05-11T06:57:15+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kjuwou/where_can_i_find_legit_remote_data_science_jobs/,"Where Can I Find Legit Remote Data Science Jobs That Hire Globally? Hey folks! I’m on the hunt for trustworthy remote job boards or sites that regularly post real data science and data analyst roles—and more importantly, are open to hiring from anywhere in the world. I’ve noticed sites like Indeed don’t support my country, and while LinkedIn has plenty of remote listings, many seem sketchy or not legit. 

So, what platforms or communities do you recommend for finding genuine remote gigs in this field that are truly global? Any tips on spotting legit postings would also be super helpful! 

Thanks in advance for sharing your experiences!",where can i find legit remote data science jobs that hire globally hey folks im on the hunt for trustworthy remote job boards or sites that regularly post real data science and data analyst rolesand more importantly are open to hiring from anywhere in the world ive noticed sites like indeed dont support my country and while linkedin has plenty of remote listings many seem sketchy or not legit so what platforms or communities do you recommend for finding genuine remote gigs in this field that are truly global any tips on spotting legit postings would also be super helpful thanks in advance for sharing your experiences,find legit remote data science job hire globally hey folk m hunt trustworthy remote job board site regularly post real data science datum analyst rolesand importantly open hire world ve notice site like not support country linkedin plenty remote listing sketchy legit platform community recommend find genuine remote gig field truly global tip spot legit posting super helpful thank advance share experience
1kjqlcv,New Python Package Feedback - Try in Google Collab,"I’ve been occasionally working on this in my spare time and would appreciate feedback.

[Try the package in Colab](https://colab.research.google.com/github/OlivierNDO/framecheck/blob/main/framecheck_quickstart.ipynb)

The idea for ‘framecheck’ is to catch bad data in a data frame before it flows downstream in *very few* lines of code. 

You’d also easily isolate the records with problematic data. This isn’t revolutionary or new - what I wanted was a way to do this in fewer lines of code than other packages like great expectations and pydantic.

Really I just want honest feedback. If people don’t find it useful, I won’t put more time into it.

pip install framecheck

Repo with reproducible examples:

https://github.com/OlivierNDO/framecheck",54,33,2025-05-11T02:27:05+00:00,datascience,https://i.redd.it/z5qrbw22d20f1.jpeg,"New Python Package Feedback - Try in Google Collab I’ve been occasionally working on this in my spare time and would appreciate feedback.

[Try the package in Colab](https://colab.research.google.com/github/OlivierNDO/framecheck/blob/main/framecheck_quickstart.ipynb)

The idea for ‘framecheck’ is to catch bad data in a data frame before it flows downstream in *very few* lines of code. 

You’d also easily isolate the records with problematic data. This isn’t revolutionary or new - what I wanted was a way to do this in fewer lines of code than other packages like great expectations and pydantic.

Really I just want honest feedback. If people don’t find it useful, I won’t put more time into it.

pip install framecheck

Repo with reproducible examples:

https://github.com/OlivierNDO/framecheck",new python package feedback try in google collab ive been occasionally working on this in my spare time and would appreciate feedback the idea for framecheck is to catch bad data in a data frame before it flows downstream in very few lines of code youd also easily isolate the records with problematic data this isnt revolutionary or new what i wanted was a way to do this in fewer lines of code than other packages like great expectations and pydantic really i just want honest feedback if people dont find it useful i wont put more time into it pip install framecheck repo with reproducible examples,new python package feedback try google collab ve occasionally work spare time appreciate feedback idea framecheck catch bad datum data frame flow downstream line code d easily isolate record problematic datum not revolutionary new want way few line code package like great expectation pydantic want honest feedback people not find useful will not time pip install framecheck repo reproducible example
1kjjb32,I am a staff data scientist at a big tech company -- AMA,"**Why I’m doing this**

I am low on karma. Plus, it just feels good to help.

**About me**

I’m currently a staff data scientist at a big tech company in Silicon Valley. I’ve been in the field for about 10 years since earning my PhD in Statistics. I’ve worked at companies of various sizes — from seed-stage startups to pre-IPO unicorns to some of the largest tech companies.

**A few caveats**

* Anything I share reflects my personal experience and may carry some bias.
* My experience is based in the US, particularly in Silicon Valley.
* I have some people management experience but have mostly worked as an IC
* Data science is a broad term. I’m most familiar with machine learning scientist, experimentation/causal inference, and data analyst roles.
* I may not be able to respond immediately, but I’ll aim to reply within 24 hours.

**Update:**

Wow, I didn’t expect this to get so much attention. I’m a bit overwhelmed by the number of comments and DMs, so I may not be able to reply to everyone. That said, I’ll do my best to respond to as many as I can over the next week. Really appreciate all the thoughtful questions and discussions!",1210,436,2025-05-10T20:17:33+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kjjb32/i_am_a_staff_data_scientist_at_a_big_tech_company/,"I am a staff data scientist at a big tech company -- AMA **Why I’m doing this**

I am low on karma. Plus, it just feels good to help.

**About me**

I’m currently a staff data scientist at a big tech company in Silicon Valley. I’ve been in the field for about 10 years since earning my PhD in Statistics. I’ve worked at companies of various sizes — from seed-stage startups to pre-IPO unicorns to some of the largest tech companies.

**A few caveats**

* Anything I share reflects my personal experience and may carry some bias.
* My experience is based in the US, particularly in Silicon Valley.
* I have some people management experience but have mostly worked as an IC
* Data science is a broad term. I’m most familiar with machine learning scientist, experimentation/causal inference, and data analyst roles.
* I may not be able to respond immediately, but I’ll aim to reply within 24 hours.

**Update:**

Wow, I didn’t expect this to get so much attention. I’m a bit overwhelmed by the number of comments and DMs, so I may not be able to reply to everyone. That said, I’ll do my best to respond to as many as I can over the next week. Really appreciate all the thoughtful questions and discussions!",i am a staff data scientist at a big tech company ama why im doing this i am low on karma plus it just feels good to help about me im currently a staff data scientist at a big tech company in silicon valley ive been in the field for about years since earning my phd in statistics ive worked at companies of various sizes from seedstage startups to preipo unicorns to some of the largest tech companies a few caveats anything i share reflects my personal experience and may carry some bias my experience is based in the us particularly in silicon valley i have some people management experience but have mostly worked as an ic data science is a broad term im most familiar with machine learning scientist experimentationcausal inference and data analyst roles i may not be able to respond immediately but ill aim to reply within hours update wow i didnt expect this to get so much attention im a bit overwhelmed by the number of comments and dms so i may not be able to reply to everyone that said ill do my best to respond to as many as i can over the next week really appreciate all the thoughtful questions and discussions,staff data scientist big tech company ama m low karma plus feel good help m currently staff data scientist big tech company silicon valley ve field year earn phd statistic ve work company size seedstage startup preipo unicorn large tech company caveat share reflect personal experience carry bias experience base particularly silicon valley people management experience work ic data science broad term m familiar machine learning scientist experimentationcausal inference datum analyst role able respond immediately ill aim reply hour update wow not expect attention m bit overwhelmed number comment dms able reply say ill good respond week appreciate thoughtful question discussion
1kjca29,"Does your company have a dedicated team/person for MLOps? If not, how do you manage MLOps?","As someone in MLOps, I am curious to hear how other companies and teams manage the MLOps process and workflow. My company (because it's a huge enterprise) has multiple teams doing some type of MLOps or MLOps-adjacent projects. But I know that other companies do this very differently.

So does your team have a separate dedicated person or a group for MLOps and managing model lifecycle in production? If not, how do you manage it? Is the data scientist / MLE expected to do all?",27,26,2025-05-10T15:00:28+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kjca29/does_your_company_have_a_dedicated_teamperson_for/,"Does your company have a dedicated team/person for MLOps? If not, how do you manage MLOps? As someone in MLOps, I am curious to hear how other companies and teams manage the MLOps process and workflow. My company (because it's a huge enterprise) has multiple teams doing some type of MLOps or MLOps-adjacent projects. But I know that other companies do this very differently.

So does your team have a separate dedicated person or a group for MLOps and managing model lifecycle in production? If not, how do you manage it? Is the data scientist / MLE expected to do all?",does your company have a dedicated teamperson for mlops if not how do you manage mlops as someone in mlops i am curious to hear how other companies and teams manage the mlops process and workflow my company because its a huge enterprise has multiple teams doing some type of mlops or mlopsadjacent projects but i know that other companies do this very differently so does your team have a separate dedicated person or a group for mlops and managing model lifecycle in production if not how do you manage it is the data scientist mle expected to do all,company dedicated teamperson mlop manage mlop mlop curious hear company team manage mlop process workflow company huge enterprise multiple team type mlop mlopsadjacent project know company differently team separate dedicated person group mlop managing model lifecycle production manage data scientist mle expect
1kj40s6,How Can Early-Level Data Scientists Get Noticed by Recruiters and Industry Pros?,"Hey everyone! 

I started my journey in the data science world almost a year ago, and I'm wondering: What’s the best way to market myself so that I actually get noticed by recruiters and industry professionals? How do you build that presence and get on the radar of the right people?  
  
**Any tips on networking, personal branding, or strategies that worked for you would be amazing to hear!**",202,120,2025-05-10T06:45:43+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kj40s6/how_can_earlylevel_data_scientists_get_noticed_by/,"How Can Early-Level Data Scientists Get Noticed by Recruiters and Industry Pros? Hey everyone! 

I started my journey in the data science world almost a year ago, and I'm wondering: What’s the best way to market myself so that I actually get noticed by recruiters and industry professionals? How do you build that presence and get on the radar of the right people?  
  
**Any tips on networking, personal branding, or strategies that worked for you would be amazing to hear!**",how can earlylevel data scientists get noticed by recruiters and industry pros hey everyone i started my journey in the data science world almost a year ago and im wondering whats the best way to market myself so that i actually get noticed by recruiters and industry professionals how do you build that presence and get on the radar of the right people any tips on networking personal branding or strategies that worked for you would be amazing to hear,earlylevel data scientist notice recruiter industry pro hey start journey data science world year ago m wonder s good way market actually notice recruiter industry professional build presence radar right people tip network personal branding strategy work amazing hear
1kiubls,What are some useful DS/DE projects I can do during slow periods at work?,Things are super slow at work due to economic uncertainty. I'm used to being super busy so I never had to think up my own problems/projects. Any ideas for useful projects I can do or sell to management? Thanks.,21,15,2025-05-09T21:49:35+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kiubls/what_are_some_useful_dsde_projects_i_can_do/,What are some useful DS/DE projects I can do during slow periods at work? Things are super slow at work due to economic uncertainty. I'm used to being super busy so I never had to think up my own problems/projects. Any ideas for useful projects I can do or sell to management? Thanks.,what are some useful dsde projects i can do during slow periods at work things are super slow at work due to economic uncertainty im used to being super busy so i never had to think up my own problemsprojects any ideas for useful projects i can do or sell to management thanks,useful dsde project slow period work thing super slow work economic uncertainty m super busy think problemsproject idea useful project sell management thank
1kionyr,I have an in-person interview with the CTO of a company in 2 weeks. I have no industry work experience for data science. Only project based experience. How f*cked am I?,Help,87,37,2025-05-09T17:47:12+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kionyr/i_have_an_inperson_interview_with_the_cto_of_a/,I have an in-person interview with the CTO of a company in 2 weeks. I have no industry work experience for data science. Only project based experience. How f*cked am I? Help,i have an inperson interview with the cto of a company in weeks i have no industry work experience for data science only project based experience how fcked am i help,inperson interview cto company week industry work experience datum science project base experience fcke help
1ki9zo3,Client told me MS Copilot replicated what I built. It didn’t.,"I built three MVP models for a client over 12 weeks. Nothing fancy: an LSTM, a prophet model, and XGBoost. The difficulty, as usual, was getting and understanding the data and cleaning it. The company is largely data illiterate. Turned in all 3 models, they loved it then all of a sudden canceled the pending contract to move them to production. Why? They had a devops person do in MS Copilot Analyst (a new specialized version of MS Copilot studio) and it took them 1 week! Would I like to sign a lesser contract to advise this person though? I finally looked at their code and it’s 40 lines of code using a subset of the California housing dataset run using a Random Forest regressor. They had literally nothing. My advice to them: go f*%k yourself. ",1096,133,2025-05-09T04:28:25+00:00,datascience,https://www.reddit.com/r/datascience/comments/1ki9zo3/client_told_me_ms_copilot_replicated_what_i_built/,"Client told me MS Copilot replicated what I built. It didn’t. I built three MVP models for a client over 12 weeks. Nothing fancy: an LSTM, a prophet model, and XGBoost. The difficulty, as usual, was getting and understanding the data and cleaning it. The company is largely data illiterate. Turned in all 3 models, they loved it then all of a sudden canceled the pending contract to move them to production. Why? They had a devops person do in MS Copilot Analyst (a new specialized version of MS Copilot studio) and it took them 1 week! Would I like to sign a lesser contract to advise this person though? I finally looked at their code and it’s 40 lines of code using a subset of the California housing dataset run using a Random Forest regressor. They had literally nothing. My advice to them: go f*%k yourself. ",client told me ms copilot replicated what i built it didnt i built three mvp models for a client over weeks nothing fancy an lstm a prophet model and xgboost the difficulty as usual was getting and understanding the data and cleaning it the company is largely data illiterate turned in all models they loved it then all of a sudden canceled the pending contract to move them to production why they had a devops person do in ms copilot analyst a new specialized version of ms copilot studio and it took them week would i like to sign a lesser contract to advise this person though i finally looked at their code and its lines of code using a subset of the california housing dataset run using a random forest regressor they had literally nothing my advice to them go fk yourself,client tell ms copilot replicate build not build mvp model client week fancy lstm prophet model xgboost difficulty usual get understand datum clean company largely datum illiterate turn model love sudden cancel pende contract production devops person ms copilot analyst new specialized version ms copilot studio take week like sign less contract advise person finally look code line code subset california housing dataset run random forest regressor literally advice fk
1ki5bob,May be of interest to anyone looking to learn Python with a stats bias,,0,0,2025-05-09T00:13:09+00:00,datascience,/r/pythontips/comments/1ki54aw/python_for_engineers_and_scientists/,May be of interest to anyone looking to learn Python with a stats bias ,may be of interest to anyone looking to learn python with a stats bias,interest look learn python stat bias
1khu4f8,This is how I got a (potential) offer revoked: A learning lesson,"I’m based in the Bay Area with 5 YOE. A couple of months ago, I interviewed for a role I wasn’t too excited about, but the pay was super compelling. In the first recruiter call, they asked for my salary expectations. I asked for their range, as an example here, let’s say they said $150K–$180K. I said, “That works, I’m looking for something above $150K.” I think this was my first mistake, more on that later.

I am a person with low self esteem(or serious imposter syndrome) and when I say I nailed all 8 rounds, I really must believe that. The recruiter followed up the day after 8th round saying team is interested in extending an offer. Then on compensation expectations the recruiter said, “You mentioned $150K earlier.” I clarified that I was targeting the upper end based on my fit and experience. They responded with, “So $180K?” and I just said yes. It felt a bit like putting words in my mouth.

Next day, I got an email saying that I have to wait for the offer decision as they are interviewing  other candidates. Haven’t heard back since. I don’t think I did anything fundamentally wrong or if I should have regrets but curious what others think.

Edit: Just to clarify, in my mind I thought that’s how negotiations work. They will come back and say can’t do 150 but can do 140. But I guess not.",243,124,2025-05-08T16:16:55+00:00,datascience,https://www.reddit.com/r/datascience/comments/1khu4f8/this_is_how_i_got_a_potential_offer_revoked_a/,"This is how I got a (potential) offer revoked: A learning lesson I’m based in the Bay Area with 5 YOE. A couple of months ago, I interviewed for a role I wasn’t too excited about, but the pay was super compelling. In the first recruiter call, they asked for my salary expectations. I asked for their range, as an example here, let’s say they said $150K–$180K. I said, “That works, I’m looking for something above $150K.” I think this was my first mistake, more on that later.

I am a person with low self esteem(or serious imposter syndrome) and when I say I nailed all 8 rounds, I really must believe that. The recruiter followed up the day after 8th round saying team is interested in extending an offer. Then on compensation expectations the recruiter said, “You mentioned $150K earlier.” I clarified that I was targeting the upper end based on my fit and experience. They responded with, “So $180K?” and I just said yes. It felt a bit like putting words in my mouth.

Next day, I got an email saying that I have to wait for the offer decision as they are interviewing  other candidates. Haven’t heard back since. I don’t think I did anything fundamentally wrong or if I should have regrets but curious what others think.

Edit: Just to clarify, in my mind I thought that’s how negotiations work. They will come back and say can’t do 150 but can do 140. But I guess not.",this is how i got a potential offer revoked a learning lesson im based in the bay area with yoe a couple of months ago i interviewed for a role i wasnt too excited about but the pay was super compelling in the first recruiter call they asked for my salary expectations i asked for their range as an example here lets say they said kk i said that works im looking for something above k i think this was my first mistake more on that later i am a person with low self esteemor serious imposter syndrome and when i say i nailed all rounds i really must believe that the recruiter followed up the day after th round saying team is interested in extending an offer then on compensation expectations the recruiter said you mentioned k earlier i clarified that i was targeting the upper end based on my fit and experience they responded with so k and i just said yes it felt a bit like putting words in my mouth next day i got an email saying that i have to wait for the offer decision as they are interviewing other candidates havent heard back since i dont think i did anything fundamentally wrong or if i should have regrets but curious what others think edit just to clarify in my mind i thought thats how negotiations work they will come back and say cant do but can do but i guess not,get potential offer revoke learning lesson m base bay area yoe couple month ago interview role not excited pay super compelling recruiter ask salary expectation ask range example let say kk say work m look k think mistake later person low self esteemor impost syndrome nail round believe recruiter follow day th round say team interested extend offer compensation expectation recruiter say mention k early clarify target upper end base fit experience respond k say yes feel bit like put word mouth day get email say wait offer decision interview candidate not hear not think fundamentally wrong regret curious think edit clarify mind think s negotiation work come not guess
1khkkv8,"Code is shit, business wants to scale, what could go wrong?","A bit of context. I have taken charge of a project recently. It's a product in a client facing app. The implementation of the ML system is messy. The data pipelines consists of many sql codes. These codes contain rather complicated business knowledge. There is airflow that schedules them, so there is observability. 

This code has been used to run experiments for the past 2 months. I don't know how much firefighting has been going on. But in the past week that I picked up the project, I spent 3 days on firefighting. 

I understand that, at least theoretically, when scaling, everything that could go wrong goes wrong. But I want to hear real life experiences. When facing such issues, what have you done that worked? Could you find a way to fix code while helping with scaling? Did firefightings get in the way? Any past experience would help. Thanks! ",31,15,2025-05-08T07:53:48+00:00,datascience,https://www.reddit.com/r/datascience/comments/1khkkv8/code_is_shit_business_wants_to_scale_what_could/,"Code is shit, business wants to scale, what could go wrong? A bit of context. I have taken charge of a project recently. It's a product in a client facing app. The implementation of the ML system is messy. The data pipelines consists of many sql codes. These codes contain rather complicated business knowledge. There is airflow that schedules them, so there is observability. 

This code has been used to run experiments for the past 2 months. I don't know how much firefighting has been going on. But in the past week that I picked up the project, I spent 3 days on firefighting. 

I understand that, at least theoretically, when scaling, everything that could go wrong goes wrong. But I want to hear real life experiences. When facing such issues, what have you done that worked? Could you find a way to fix code while helping with scaling? Did firefightings get in the way? Any past experience would help. Thanks! ",code is shit business wants to scale what could go wrong a bit of context i have taken charge of a project recently its a product in a client facing app the implementation of the ml system is messy the data pipelines consists of many sql codes these codes contain rather complicated business knowledge there is airflow that schedules them so there is observability this code has been used to run experiments for the past months i dont know how much firefighting has been going on but in the past week that i picked up the project i spent days on firefighting i understand that at least theoretically when scaling everything that could go wrong goes wrong but i want to hear real life experiences when facing such issues what have you done that worked could you find a way to fix code while helping with scaling did firefightings get in the way any past experience would help thanks,code shit business want scale wrong bit context take charge project recently product client face app implementation ml system messy data pipeline consist sql code code contain complicated business knowledge airflow schedule observability code run experiment past month not know firefighting go past week pick project spend day firefighting understand theoretically scale wrong go wrong want hear real life experience face issue work find way fix code help scaling firefighting way past experience help thank
1khj1wm,Final verdict on LLM generated confidence scores?,,5,9,2025-05-08T06:05:16+00:00,datascience,/r/LocalLLaMA/comments/1khfhoh/final_verdict_on_llm_generated_confidence_scores/,Final verdict on LLM generated confidence scores? ,final verdict on llm generated confidence scores,final verdict llm generate confidence score
1khic8u,The worst thing about being a Data Scientist is that the best you can do you sometimes is not even nearly enough,"This specially sucks as a consultant. You get hired because some guy from Sales department of the consulting company convinced the client that they would give them a Data Scientist consultant that would solve all their problems and build perfect Machine Learning models. 


Then you join the client and quickly realize that is literary impossible to do any meaningful work with the poor data and the unjustified expectations they have. 

As an ethical worker, you work hard and to everything that is possible with the data at hand (and maybe some external data you magically gathered). You use everything that you know and don't know, take some time to study the state of the art, chat with some LLMs on their ideas for the project, run hundreds of different experiments (should I use different sets of features? Should I log transform some numerical features? Should I apply PCA? How many ML algorithms should I try?) 

And at the end of day... The model still sucks. You overfit the hell of the model, makes a gigantic boosting model with max_depth  set as 1000, and you still don't match the dumb manager expectations. 

I don't know how common that it is in other professions, but an intrinsic thing of working in Data Science is that you are never sure that your work will eventually turn out to be something good, no matter how hard you try. ",554,88,2025-05-08T05:17:59+00:00,datascience,https://www.reddit.com/r/datascience/comments/1khic8u/the_worst_thing_about_being_a_data_scientist_is/,"The worst thing about being a Data Scientist is that the best you can do you sometimes is not even nearly enough This specially sucks as a consultant. You get hired because some guy from Sales department of the consulting company convinced the client that they would give them a Data Scientist consultant that would solve all their problems and build perfect Machine Learning models. 


Then you join the client and quickly realize that is literary impossible to do any meaningful work with the poor data and the unjustified expectations they have. 

As an ethical worker, you work hard and to everything that is possible with the data at hand (and maybe some external data you magically gathered). You use everything that you know and don't know, take some time to study the state of the art, chat with some LLMs on their ideas for the project, run hundreds of different experiments (should I use different sets of features? Should I log transform some numerical features? Should I apply PCA? How many ML algorithms should I try?) 

And at the end of day... The model still sucks. You overfit the hell of the model, makes a gigantic boosting model with max_depth  set as 1000, and you still don't match the dumb manager expectations. 

I don't know how common that it is in other professions, but an intrinsic thing of working in Data Science is that you are never sure that your work will eventually turn out to be something good, no matter how hard you try. ",the worst thing about being a data scientist is that the best you can do you sometimes is not even nearly enough this specially sucks as a consultant you get hired because some guy from sales department of the consulting company convinced the client that they would give them a data scientist consultant that would solve all their problems and build perfect machine learning models then you join the client and quickly realize that is literary impossible to do any meaningful work with the poor data and the unjustified expectations they have as an ethical worker you work hard and to everything that is possible with the data at hand and maybe some external data you magically gathered you use everything that you know and dont know take some time to study the state of the art chat with some llms on their ideas for the project run hundreds of different experiments should i use different sets of features should i log transform some numerical features should i apply pca how many ml algorithms should i try and at the end of day the model still sucks you overfit the hell of the model makes a gigantic boosting model with maxdepth set as and you still dont match the dumb manager expectations i dont know how common that it is in other professions but an intrinsic thing of working in data science is that you are never sure that your work will eventually turn out to be something good no matter how hard you try,bad thing data scientist good nearly specially suck consultant hire guy sale department consult company convince client data scientist consultant solve problem build perfect machine learning model join client quickly realize literary impossible meaningful work poor datum unjustified expectation ethical worker work hard possible datum hand maybe external datum magically gather use know not know time study state art chat llm idea project run hundred different experiment use different set feature log transform numerical feature apply pca ml algorithm try end day model suck overfit hell model make gigantic boost model maxdepth set not match dumb manager expectation not know common profession intrinsic thing work data science sure work eventually turn good matter hard try
1kh87dv,"If part of your job involves explaining to non-technical coworkers and/or management why GenAI is not always the right approach, how do you do that?","Discussion idea inspired by that thread on tools. 

Bonus points if you've found anything that works on people who really think they understand GenAI but don't understand it's failure points or ways it could steer a company wrong, or those who think it's the solution to every problem. 

I'm currently a frustrato potato from this so any thoughts are very much appreciated ",76,41,2025-05-07T20:49:40+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kh87dv/if_part_of_your_job_involves_explaining_to/,"If part of your job involves explaining to non-technical coworkers and/or management why GenAI is not always the right approach, how do you do that? Discussion idea inspired by that thread on tools. 

Bonus points if you've found anything that works on people who really think they understand GenAI but don't understand it's failure points or ways it could steer a company wrong, or those who think it's the solution to every problem. 

I'm currently a frustrato potato from this so any thoughts are very much appreciated ",if part of your job involves explaining to nontechnical coworkers andor management why genai is not always the right approach how do you do that discussion idea inspired by that thread on tools bonus points if youve found anything that works on people who really think they understand genai but dont understand its failure points or ways it could steer a company wrong or those who think its the solution to every problem im currently a frustrato potato from this so any thoughts are very much appreciated,job involve explain nontechnical coworker andor management genai right approach discussion idea inspire thread tool bonus point ve find work people think understand genai not understand failure point way steer company wrong think solution problem m currently frustrato potato thought appreciated
1kgzki4,Is HackerRank/LeetCode a valid way to screen candidates?,"Reverse questions: is it a red flag if a company is using HackerRank / LeetCode challenges in order to filter candidates?

I am a strong believer in technical expertise, meaning that a DS needs to know what is doing. You cannot improvise ML expertise when it comes to bring stuff into production.

Nevertheless, I think those kind of challenges works only if you're a monkey-coder that recently worked on that exact stuff, and specifically practiced for those challenges. No way that I know by heart all the subtle nuances of SQL or edge cases in ML, but on the other hand I'm most certainly able to solve those issues in real life projects.

Bottom line: do you think those are legit way of filter candidates (and we should prepare for that when applying to roles) or not?",62,53,2025-05-07T15:03:14+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kgzki4/is_hackerrankleetcode_a_valid_way_to_screen/,"Is HackerRank/LeetCode a valid way to screen candidates? Reverse questions: is it a red flag if a company is using HackerRank / LeetCode challenges in order to filter candidates?

I am a strong believer in technical expertise, meaning that a DS needs to know what is doing. You cannot improvise ML expertise when it comes to bring stuff into production.

Nevertheless, I think those kind of challenges works only if you're a monkey-coder that recently worked on that exact stuff, and specifically practiced for those challenges. No way that I know by heart all the subtle nuances of SQL or edge cases in ML, but on the other hand I'm most certainly able to solve those issues in real life projects.

Bottom line: do you think those are legit way of filter candidates (and we should prepare for that when applying to roles) or not?",is hackerrankleetcode a valid way to screen candidates reverse questions is it a red flag if a company is using hackerrank leetcode challenges in order to filter candidates i am a strong believer in technical expertise meaning that a ds needs to know what is doing you cannot improvise ml expertise when it comes to bring stuff into production nevertheless i think those kind of challenges works only if youre a monkeycoder that recently worked on that exact stuff and specifically practiced for those challenges no way that i know by heart all the subtle nuances of sql or edge cases in ml but on the other hand im most certainly able to solve those issues in real life projects bottom line do you think those are legit way of filter candidates and we should prepare for that when applying to roles or not,hackerrankleetcode valid way screen candidate reverse question red flag company hackerrank leetcode challenge order filter candidate strong believer technical expertise mean ds need know improvise ml expertise come bring stuff production think kind challenge work monkeycoder recently work exact stuff specifically practice challenge way know heart subtle nuance sql edge case ml hand m certainly able solve issue real life project line think legit way filter candidate prepare apply role
1kgz66a,Grinding through regression discontinuity resulted in this post - feel free to check it out,"Title should check out. Been reading on RDD in the spare time I had in the past few months. I put everything together after applying it in my company (#1 online marketplace in the Netherlands) — the result: a few late nights and this [blog post.](https://towardsdatascience.com/regression-discontinuity-design-how-it-works-and-when-to-use-it/)

Thanks to the few redditors that shared [their input](https://www.reddit.com/r/CausalInference/comments/1i801e0/call_for_input_regression_discontinuity_design/) on the technique and application. It made me wiser!",10,3,2025-05-07T14:46:52+00:00,datascience,https://towardsdatascience.com/regression-discontinuity-design-how-it-works-and-when-to-use-it/,"Grinding through regression discontinuity resulted in this post - feel free to check it out Title should check out. Been reading on RDD in the spare time I had in the past few months. I put everything together after applying it in my company (#1 online marketplace in the Netherlands) — the result: a few late nights and this [blog post.](https://towardsdatascience.com/regression-discontinuity-design-how-it-works-and-when-to-use-it/)

Thanks to the few redditors that shared [their input](https://www.reddit.com/r/CausalInference/comments/1i801e0/call_for_input_regression_discontinuity_design/) on the technique and application. It made me wiser!",grinding through regression discontinuity resulted in this post feel free to check it out title should check out been reading on rdd in the spare time i had in the past few months i put everything together after applying it in my company online marketplace in the netherlands the result a few late nights and this thanks to the few redditors that shared on the technique and application it made me wiser,grind regression discontinuity result post feel free check title check read rdd spare time past month apply company online marketplace netherlands result late night thank redditor share technique application wiser
1kgz36l,Anyone else tried of always discussing tech/tools?,"Maybe it’s just my company but we spend the majority of our time discussing the pros/cons of new tech. Databricks, Snowflake, various dashboards software. I agree that tech is important but a new tool isn’t going to magically fix everything. We also need communication, documentation, and process. Also, what are we actually trying to accomplish? We can buy a new fancy tool but what’s the end goal? It’s getting worse with AI. Use AI isn’t a goal. How do we solve problem X is a goal. Maybe it’s AI but maybe it’s something else.",120,26,2025-05-07T14:43:14+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kgz36l/anyone_else_tried_of_always_discussing_techtools/,"Anyone else tried of always discussing tech/tools? Maybe it’s just my company but we spend the majority of our time discussing the pros/cons of new tech. Databricks, Snowflake, various dashboards software. I agree that tech is important but a new tool isn’t going to magically fix everything. We also need communication, documentation, and process. Also, what are we actually trying to accomplish? We can buy a new fancy tool but what’s the end goal? It’s getting worse with AI. Use AI isn’t a goal. How do we solve problem X is a goal. Maybe it’s AI but maybe it’s something else.",anyone else tried of always discussing techtools maybe its just my company but we spend the majority of our time discussing the proscons of new tech databricks snowflake various dashboards software i agree that tech is important but a new tool isnt going to magically fix everything we also need communication documentation and process also what are we actually trying to accomplish we can buy a new fancy tool but whats the end goal its getting worse with ai use ai isnt a goal how do we solve problem x is a goal maybe its ai but maybe its something else,try discuss techtool maybe company spend majority time discuss proscon new tech databrick snowflake dashboard software agree tech important new tool not go magically fix need communication documentation process actually try accomplish buy new fancy tool s end goal get bad ai use ai not goal solve problem x goal maybe ai maybe
1kgsn61,Am I or my PMs crazy? - Unknown unknowns.,"My company wants to develop a product that detects ""unknown unknowns"" it a complex system, in an unsupervised manner, in order to identify new issues before they even begin. I think this is an ill-defined task, and I think what they actually want is a supervised, not unsupervised ML pipeline. But they refuse to commit to the idea of a ""loss function"" in the system, because ""anything could be an interesting novelty in our system"". 

The system produces thousands of time series monitoring metrics. They want to stream all these metrics through anomaly detection model. Right now, the model throws thousands of anomalies, almost all of them meaningless. I think this is expected, because statistical anomalies don't have much to do with *actionable events.* Even more broadly **I think unsupervised learning cannot ever produce business value.** You always need some sort of supervised wrapper around it.

What PMs want to do: flag all outliers in the system, because they are potential problems

What I think we should be doing: (1) define the ""health (loss) function"" in the system (2) whenever the health function degrades look for root causes / predictors / correlates of the issues (3) find patterns in the system degradation - find *unknown* causes of *known* adverse system states 

Am I missing something? Are you guys doing something similar or have some interesting reads? Thanks",101,63,2025-05-07T08:54:28+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kgsn61/am_i_or_my_pms_crazy_unknown_unknowns/,"Am I or my PMs crazy? - Unknown unknowns. My company wants to develop a product that detects ""unknown unknowns"" it a complex system, in an unsupervised manner, in order to identify new issues before they even begin. I think this is an ill-defined task, and I think what they actually want is a supervised, not unsupervised ML pipeline. But they refuse to commit to the idea of a ""loss function"" in the system, because ""anything could be an interesting novelty in our system"". 

The system produces thousands of time series monitoring metrics. They want to stream all these metrics through anomaly detection model. Right now, the model throws thousands of anomalies, almost all of them meaningless. I think this is expected, because statistical anomalies don't have much to do with *actionable events.* Even more broadly **I think unsupervised learning cannot ever produce business value.** You always need some sort of supervised wrapper around it.

What PMs want to do: flag all outliers in the system, because they are potential problems

What I think we should be doing: (1) define the ""health (loss) function"" in the system (2) whenever the health function degrades look for root causes / predictors / correlates of the issues (3) find patterns in the system degradation - find *unknown* causes of *known* adverse system states 

Am I missing something? Are you guys doing something similar or have some interesting reads? Thanks",am i or my pms crazy unknown unknowns my company wants to develop a product that detects unknown unknowns it a complex system in an unsupervised manner in order to identify new issues before they even begin i think this is an illdefined task and i think what they actually want is a supervised not unsupervised ml pipeline but they refuse to commit to the idea of a loss function in the system because anything could be an interesting novelty in our system the system produces thousands of time series monitoring metrics they want to stream all these metrics through anomaly detection model right now the model throws thousands of anomalies almost all of them meaningless i think this is expected because statistical anomalies dont have much to do with actionable events even more broadly i think unsupervised learning cannot ever produce business value you always need some sort of supervised wrapper around it what pms want to do flag all outliers in the system because they are potential problems what i think we should be doing define the health loss function in the system whenever the health function degrades look for root causes predictors correlates of the issues find patterns in the system degradation find unknown causes of known adverse system states am i missing something are you guys doing something similar or have some interesting reads thanks,pm crazy unknown unknown company want develop product detect unknown unknown complex system unsupervised manner order identify new issue begin think illdefine task think actually want supervised unsupervised ml pipeline refuse commit idea loss function system interesting novelty system system produce thousand time series monitor metric want stream metric anomaly detection model right model throw thousand anomaly meaningless think expect statistical anomaly not actionable event broadly think unsupervised learning produce business value need sort supervised wrapper pm want flag outlier system potential problem think define health loss function system health function degrade look root cause predictor correlate issue find pattern system degradation find unknown cause known adverse system state miss guy similar interesting read thank
1kglzv7,I wrote a walkthrough post that covers Shape Constrained P-Splines for fitting monotonic relationships in python. I also showed how you can use general purpose optimizers like JAX and Scipy to fit these terms. Hope some of y'all find it helpful!,,19,6,2025-05-07T01:57:15+00:00,datascience,http://statmills.com/2025-05-03-monotonic_spline_jax/,I wrote a walkthrough post that covers Shape Constrained P-Splines for fitting monotonic relationships in python. I also showed how you can use general purpose optimizers like JAX and Scipy to fit these terms. Hope some of y'all find it helpful! ,i wrote a walkthrough post that covers shape constrained psplines for fitting monotonic relationships in python i also showed how you can use general purpose optimizers like jax and scipy to fit these terms hope some of yall find it helpful,write walkthrough post cover shape constrain pspline fitting monotonic relationship python show use general purpose optimizer like jax scipy fit term hope you find helpful
1kgkpr5,how does the http:livecode/amazon..... link work for data science technical interview ?,"I had a call with the recruiter yesterday and this was for an interview for a DS position at AMZ. 

Recruiter told me you can't execute any code on the whiteboard. Then I got another email saying here is the link to ""livecode"" for coding exercise and I can choose the programming language of my choice. 

Can someone explain to me what is this whiteboard ? or the livecode ? and how does it work ?",5,2,2025-05-07T00:51:29+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kgkpr5/how_does_the_httplivecodeamazon_link_work_for/,"how does the http:livecode/amazon..... link work for data science technical interview ? I had a call with the recruiter yesterday and this was for an interview for a DS position at AMZ. 

Recruiter told me you can't execute any code on the whiteboard. Then I got another email saying here is the link to ""livecode"" for coding exercise and I can choose the programming language of my choice. 

Can someone explain to me what is this whiteboard ? or the livecode ? and how does it work ?",how does the link work for data science technical interview i had a call with the recruiter yesterday and this was for an interview for a ds position at amz recruiter told me you cant execute any code on the whiteboard then i got another email saying here is the link to livecode for coding exercise and i can choose the programming language of my choice can someone explain to me what is this whiteboard or the livecode and how does it work,link work datum science technical interview recruiter yesterday interview ds position amz recruiter tell not execute code whiteboard get email say link livecode code exercise choose programming language choice explain whiteboard livecode work
1kgk3hw,"A complete guide covering foundational Linux concepts, core tasks, and best practices.",,46,5,2025-05-07T00:20:50+00:00,datascience,https://github.com/AhmedOsamaMath/linux-basics,"A complete guide covering foundational Linux concepts, core tasks, and best practices. ",a complete guide covering foundational linux concepts core tasks and best practices,complete guide cover foundational linux concept core task good practice
1kgdevk,"AWS Batch alternative — deploy to 10,000 VMs with one line of code","I just launched an open-source batch-processing platform that can scale Python to **10,000 VMs in under 2 seconds**, with just **one line of code**.

I've been frustrated by how slow and painful it is to iterate on large batch processing pipelines. Even small changes require rebuilding Docker containers, waiting for AWS Batch or GCP Batch to redeploy, and dealing with cold-start VM delays — a **5+ minute dev cycle per iteration**, just to see what error your code throws *this time*, and then doing it all over again.

Most other tools in this space are too complex, closed-source or fully managed, hard to self-host, or simply too expensive. If you've encountered similar barriers give Burla a try.

docs: [https://docs.burla.dev/](https://docs.burla.dev/)

github: [https://github.com/Burla-Cloud](https://github.com/Burla-Cloud)",24,23,2025-05-06T19:31:15+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kgdevk/aws_batch_alternative_deploy_to_10000_vms_with/,"AWS Batch alternative — deploy to 10,000 VMs with one line of code I just launched an open-source batch-processing platform that can scale Python to **10,000 VMs in under 2 seconds**, with just **one line of code**.

I've been frustrated by how slow and painful it is to iterate on large batch processing pipelines. Even small changes require rebuilding Docker containers, waiting for AWS Batch or GCP Batch to redeploy, and dealing with cold-start VM delays — a **5+ minute dev cycle per iteration**, just to see what error your code throws *this time*, and then doing it all over again.

Most other tools in this space are too complex, closed-source or fully managed, hard to self-host, or simply too expensive. If you've encountered similar barriers give Burla a try.

docs: [https://docs.burla.dev/](https://docs.burla.dev/)

github: [https://github.com/Burla-Cloud](https://github.com/Burla-Cloud)",aws batch alternative deploy to vms with one line of code i just launched an opensource batchprocessing platform that can scale python to vms in under seconds with just one line of code ive been frustrated by how slow and painful it is to iterate on large batch processing pipelines even small changes require rebuilding docker containers waiting for aws batch or gcp batch to redeploy and dealing with coldstart vm delays a minute dev cycle per iteration just to see what error your code throws this time and then doing it all over again most other tools in this space are too complex closedsource or fully managed hard to selfhost or simply too expensive if youve encountered similar barriers give burla a try docs github,aw batch alternative deploy vms line code launch opensource batchprocessing platform scale python vms second line code ve frustrate slow painful iterate large batch process pipeline small change require rebuild docker container wait aw batch gcp batch redeploy deal coldstart vm delay minute dev cycle iteration error code throw time tool space complex closedsource fully manage hard selfhost simply expensive ve encounter similar barrier burla try doc github
1kfwny7,[Request for feedback] dataframe library,"I'm working on a dataframe library and wanted to make sure the API makes sense and is easy to get started with. No official documentation yet but wanted to get a feel of what people think of it so far.

I have some tutorials on the [github repo](https://github.com/mchav/dataframe) and a [jupyter lab environment](https://ihaskell-dataframe-crf7g5fvcpahdegz.westus2-01.azurewebsites.net/) running. Would appreciate some feedback on the API and usability. Functionality is still limited and this site is so far just a sandbox. Thanks so much.",14,12,2025-05-06T05:11:25+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kfwny7/request_for_feedback_dataframe_library/,"[Request for feedback] dataframe library I'm working on a dataframe library and wanted to make sure the API makes sense and is easy to get started with. No official documentation yet but wanted to get a feel of what people think of it so far.

I have some tutorials on the [github repo](https://github.com/mchav/dataframe) and a [jupyter lab environment](https://ihaskell-dataframe-crf7g5fvcpahdegz.westus2-01.azurewebsites.net/) running. Would appreciate some feedback on the API and usability. Functionality is still limited and this site is so far just a sandbox. Thanks so much.",request for feedback dataframe library im working on a dataframe library and wanted to make sure the api makes sense and is easy to get started with no official documentation yet but wanted to get a feel of what people think of it so far i have some tutorials on the and a running would appreciate some feedback on the api and usability functionality is still limited and this site is so far just a sandbox thanks so much,request feedback dataframe library m work dataframe library want sure api make sense easy start official documentation want feel people think far tutorial running appreciate feedback api usability functionality limited site far sandbox thank
1kfbtob,"Please, for the love of god ... just give me something!!",,754,30,2025-05-05T13:37:31+00:00,datascience,https://i.redd.it/j1tp2b00vyye1.png,"Please, for the love of god ... just give me something!! ",please for the love of god just give me something,love god
1kfb10a,Self-Service Open Data Portal: Zero-Ops & Fully Managed for Data Scientists,"__Disclaimer: I’m one of the creators of PortalJS.__

Hi everyone, I wanted to share this open-source product for data portals with the Data Science community. Appreciate your attention!

**Our mission:**

Open data publishing shouldn’t be hard. We want local governments, academics, and NGOs to treat publishing their data like any other SaaS subscription: sign up, upload, update, and go.

**Why PortalJS?**

- Small teams need a simple, affordable way to get their data out there.
- Existing platforms are either extremely expensive or require a technical team to set up and maintain.
- Scaling an open data portal usually means dedicating an entire engineering department—and we believe that shouldn’t be the case.

Happy to answer any questions!",2,0,2025-05-05T13:00:46+00:00,datascience,https://www.portaljs.com/?utm_source=reddit&utm_medium=post&utm_campaign=datascience,"Self-Service Open Data Portal: Zero-Ops & Fully Managed for Data Scientists __Disclaimer: I’m one of the creators of PortalJS.__

Hi everyone, I wanted to share this open-source product for data portals with the Data Science community. Appreciate your attention!

**Our mission:**

Open data publishing shouldn’t be hard. We want local governments, academics, and NGOs to treat publishing their data like any other SaaS subscription: sign up, upload, update, and go.

**Why PortalJS?**

- Small teams need a simple, affordable way to get their data out there.
- Existing platforms are either extremely expensive or require a technical team to set up and maintain.
- Scaling an open data portal usually means dedicating an entire engineering department—and we believe that shouldn’t be the case.

Happy to answer any questions!",selfservice open data portal zeroops fully managed for data scientists disclaimer im one of the creators of portaljs hi everyone i wanted to share this opensource product for data portals with the data science community appreciate your attention our mission open data publishing shouldnt be hard we want local governments academics and ngos to treat publishing their data like any other saas subscription sign up upload update and go why portaljs small teams need a simple affordable way to get their data out there existing platforms are either extremely expensive or require a technical team to set up and maintain scaling an open data portal usually means dedicating an entire engineering departmentand we believe that shouldnt be the case happy to answer any questions,selfservice open datum portal zeroop fully manage datum scientist disclaimer m creator portaljs hi want share opensource product datum portal data science community appreciate attention mission open datum publishing not hard want local government academic ngo treat publish datum like saas subscription sign upload update portaljs small team need simple affordable way datum exist platform extremely expensive require technical team set maintain scale open datum portal usually mean dedicate entire engineering departmentand believe not case happy answer question
1kf4g8b,Need referral for AmEx for Data Science position,"Anyone working in AmEx specifically in India in any IT/Tech related field, I need a referral for a Data Science position at AmEx Gurugram, India",0,1,2025-05-05T05:57:00+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kf4g8b/need_referral_for_amex_for_data_science_position/,"Need referral for AmEx for Data Science position Anyone working in AmEx specifically in India in any IT/Tech related field, I need a referral for a Data Science position at AmEx Gurugram, India",need referral for amex for data science position anyone working in amex specifically in india in any ittech related field i need a referral for a data science position at amex gurugram india,need referral amex datum science position work amex specifically india ittech relate field need referral data science position amex gurugram india
1kf2nlk,"Weekly Entering & Transitioning - Thread 05 May, 2025 - 12 May, 2025"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",12,51,2025-05-05T04:01:31+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kf2nlk/weekly_entering_transitioning_thread_05_may_2025/,"Weekly Entering & Transitioning - Thread 05 May, 2025 - 12 May, 2025  

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",weekly entering transitioning thread may may welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the and resources pages on our wiki you can also search for answers in,weekly enter transition thread welcome week enter transition thread thread question getting start study transition data science field topic include learn resource eg book tutorial video traditional education eg schools degree elective alternative education eg online course bootcamp job search question eg resume apply career prospect elementary question eg start wait answer community check resource page wiki search answer
1kerpax,How would you architect this?,"I work for a startup where the main product is a sales meeting analyser. Naturally there are a ton of features that require audio and video processing, like diarization, ASR, video classification, etc…

The CEO is in cost savings mode and he wants to reduce our compute costs. Currently our ML pipeline is built on top of kubernetes and we always have at least on gpu machine up per task (T4s and L4s) per day and we dont have a lot of clients, meaning most of the time the gpus are idle and we are paying for them. I suggested moving those tasks to cloud functions that use GPUs, since we are using GCP and they have recently came out with that feature, but the CEO wants to use gemini to replace these tasks since we will most likely be on the free tier.

The problems I see is that once we leave the free tier the costs will be more than 10x our current costs and that there are downstream ML tasks that depend on these, so changing the input distribution is not really a good idea… for example, we have a text classifier that was trained with text from whisper - changing it to gemini does not seem to be a good idea to me…

he claimed he wants it to be maintainable so an api request makes more sense to him, but the reason why he wants it to be maintainable is because a lot of ML people are leaving (mainly because of his wrong decisions and micro management - is this another of his wrong decisions?)

using gemini to do asr and diarization, for example, just feels way way wrong",9,8,2025-05-04T19:09:35+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kerpax/how_would_you_architect_this/,"How would you architect this? I work for a startup where the main product is a sales meeting analyser. Naturally there are a ton of features that require audio and video processing, like diarization, ASR, video classification, etc…

The CEO is in cost savings mode and he wants to reduce our compute costs. Currently our ML pipeline is built on top of kubernetes and we always have at least on gpu machine up per task (T4s and L4s) per day and we dont have a lot of clients, meaning most of the time the gpus are idle and we are paying for them. I suggested moving those tasks to cloud functions that use GPUs, since we are using GCP and they have recently came out with that feature, but the CEO wants to use gemini to replace these tasks since we will most likely be on the free tier.

The problems I see is that once we leave the free tier the costs will be more than 10x our current costs and that there are downstream ML tasks that depend on these, so changing the input distribution is not really a good idea… for example, we have a text classifier that was trained with text from whisper - changing it to gemini does not seem to be a good idea to me…

he claimed he wants it to be maintainable so an api request makes more sense to him, but the reason why he wants it to be maintainable is because a lot of ML people are leaving (mainly because of his wrong decisions and micro management - is this another of his wrong decisions?)

using gemini to do asr and diarization, for example, just feels way way wrong",how would you architect this i work for a startup where the main product is a sales meeting analyser naturally there are a ton of features that require audio and video processing like diarization asr video classification etc the ceo is in cost savings mode and he wants to reduce our compute costs currently our ml pipeline is built on top of kubernetes and we always have at least on gpu machine up per task ts and ls per day and we dont have a lot of clients meaning most of the time the gpus are idle and we are paying for them i suggested moving those tasks to cloud functions that use gpus since we are using gcp and they have recently came out with that feature but the ceo wants to use gemini to replace these tasks since we will most likely be on the free tier the problems i see is that once we leave the free tier the costs will be more than x our current costs and that there are downstream ml tasks that depend on these so changing the input distribution is not really a good idea for example we have a text classifier that was trained with text from whisper changing it to gemini does not seem to be a good idea to me he claimed he wants it to be maintainable so an api request makes more sense to him but the reason why he wants it to be maintainable is because a lot of ml people are leaving mainly because of his wrong decisions and micro management is this another of his wrong decisions using gemini to do asr and diarization for example just feels way way wrong,architect work startup main product sale meeting analyser naturally ton feature require audio video processing like diarization asr video classification etc ceo cost saving mode want reduce compute cost currently ml pipeline build kubernete gpu machine task ts ls day not lot client mean time gpu idle pay suggest move task cloud function use gpu gcp recently come feature ceo want use gemini replace task likely free tier problem leave free tier cost x current cost downstream ml task depend change input distribution good idea example text classifier train text whisper change gemini good idea claim want maintainable api request make sense reason want maintainable lot ml people leave mainly wrong decision micro management wrong decision gemini asr diarization example feel way way wrong
1kdzcmj,Gotta love recommender systems 😂,Whippets #1,76,10,2025-05-03T18:14:14+00:00,datascience,https://i.redd.it/0dld8quqylye1.jpeg,Gotta love recommender systems 😂 Whippets #1,gotta love recommender systems facewithtearsofjoy whippets,get to love recommender system facewithtearsofjoy whippet
1kdlxel,Wich computer are you using?,"Hi guys I'm thinking of buy a new computer, do you have some ideas (no Apple)? Wich computer are you using today? In looking mobility so a laptop is the option.

Thanks guys ",0,72,2025-05-03T05:54:15+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kdlxel/wich_computer_are_you_using/,"Wich computer are you using? Hi guys I'm thinking of buy a new computer, do you have some ideas (no Apple)? Wich computer are you using today? In looking mobility so a laptop is the option.

Thanks guys ",wich computer are you using hi guys im thinking of buy a new computer do you have some ideas no apple wich computer are you using today in looking mobility so a laptop is the option thanks guys,wich computer hi guy m think buy new computer idea apple wich computer today look mobility laptop option thank guy
1kd4lul,[D] Is Applied machine learning on time series doomed to be flawed bullshit almost all the time?,"At this point, I genuinely can't trust any of the time series machine learning papers I have been reading especially in scientific domains like environmental science and medecine but it's the same story in other fields. Even when the dataset itself is reliable, which is rare, there’s almost always something fundamentally broken in the methodology. God help me, if I see one more SHAP summary plot treated like it's the Rosetta Stone of model behavior, I might lose it. Even causal ML approaches where I had hoped we might find some solid approaches are messy, for example transfer entropy alone can be computed in 50 different ways and bottom line the closer we get to the actual truth the closer we get to Landau´s limit, finding the “truth” requires so much effort that it's practically inaccessible...The worst part is almost no one has time to write critical reviews, so applied ML papers keep getting published, cited, and used to justify decisions in policy and science...Please, if you're working in ML interpretability, keep writing thoughtful critical reviews, we're in real need of more careful work to help sort out this growing mess.

",214,57,2025-05-02T16:01:11+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kd4lul/d_is_applied_machine_learning_on_time_series/,"[D] Is Applied machine learning on time series doomed to be flawed bullshit almost all the time? At this point, I genuinely can't trust any of the time series machine learning papers I have been reading especially in scientific domains like environmental science and medecine but it's the same story in other fields. Even when the dataset itself is reliable, which is rare, there’s almost always something fundamentally broken in the methodology. God help me, if I see one more SHAP summary plot treated like it's the Rosetta Stone of model behavior, I might lose it. Even causal ML approaches where I had hoped we might find some solid approaches are messy, for example transfer entropy alone can be computed in 50 different ways and bottom line the closer we get to the actual truth the closer we get to Landau´s limit, finding the “truth” requires so much effort that it's practically inaccessible...The worst part is almost no one has time to write critical reviews, so applied ML papers keep getting published, cited, and used to justify decisions in policy and science...Please, if you're working in ML interpretability, keep writing thoughtful critical reviews, we're in real need of more careful work to help sort out this growing mess.

",d is applied machine learning on time series doomed to be flawed bullshit almost all the time at this point i genuinely cant trust any of the time series machine learning papers i have been reading especially in scientific domains like environmental science and medecine but its the same story in other fields even when the dataset itself is reliable which is rare theres almost always something fundamentally broken in the methodology god help me if i see one more shap summary plot treated like its the rosetta stone of model behavior i might lose it even causal ml approaches where i had hoped we might find some solid approaches are messy for example transfer entropy alone can be computed in different ways and bottom line the closer we get to the actual truth the closer we get to landaus limit finding the truth requires so much effort that its practically inaccessiblethe worst part is almost no one has time to write critical reviews so applied ml papers keep getting published cited and used to justify decisions in policy and scienceplease if youre working in ml interpretability keep writing thoughtful critical reviews were in real need of more careful work to help sort out this growing mess,d apply machine learning time series doom flawed bullshit time point genuinely not trust time series machine learn paper read especially scientific domain like environmental science medecine story field dataset reliable rare s fundamentally break methodology god help shap summary plot treat like rosetta stone model behavior lose causal ml approach hope find solid approach messy example transfer entropy compute different way line close actual truth close landaus limit find truth require effort practically inaccessiblethe bad time write critical review apply ml paper getting publish cite justify decision policy scienceplease work ml interpretability write thoughtful critical review real need careful work help sort grow mess
1kcrsyn,Tired of everyone becoming an AI Expert all of a sudden,"Literally every person who can type prompts into an LLM is now an AI consultant/expert. I’m sick of it, today a sales manager literally said ‘oh I can get Gemini to make my charts from excel directly with one prompt so ig we no longer require Data Scientists and their support hehe’

These dumbos think making basic level charts equals DS work. Not even data analytics, literally data science? 

I’m sick of it. I hope each one of yall cause a data leak, breach the confidentiality by voluntarily giving private info to Gemini/OpenAi and finally create immense tech debt by developing your vibe coded projects.

Rant over ",1551,136,2025-05-02T03:49:50+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kcrsyn/tired_of_everyone_becoming_an_ai_expert_all_of_a/,"Tired of everyone becoming an AI Expert all of a sudden Literally every person who can type prompts into an LLM is now an AI consultant/expert. I’m sick of it, today a sales manager literally said ‘oh I can get Gemini to make my charts from excel directly with one prompt so ig we no longer require Data Scientists and their support hehe’

These dumbos think making basic level charts equals DS work. Not even data analytics, literally data science? 

I’m sick of it. I hope each one of yall cause a data leak, breach the confidentiality by voluntarily giving private info to Gemini/OpenAi and finally create immense tech debt by developing your vibe coded projects.

Rant over ",tired of everyone becoming an ai expert all of a sudden literally every person who can type prompts into an llm is now an ai consultantexpert im sick of it today a sales manager literally said oh i can get gemini to make my charts from excel directly with one prompt so ig we no longer require data scientists and their support hehe these dumbos think making basic level charts equals ds work not even data analytics literally data science im sick of it i hope each one of yall cause a data leak breach the confidentiality by voluntarily giving private info to geminiopenai and finally create immense tech debt by developing your vibe coded projects rant over,tired ai expert sudden literally person type prompt llm ai consultantexpert m sick today sale manager literally say oh gemini chart excel directly prompt ig long require data scientist support hehe dumbo think make basic level chart equal ds work datum analytic literally data science m sick hope you cause data leak breach confidentiality voluntarily give private info geminiopenai finally create immense tech debt develop vibe code project rant
1kcrrzu,Do you have to keep up with the latest research papers if you are working with LLMs as an AI developer?,"I've been diving deeper into LLMs these days (especially agentic AI) and I'm slightly surprised that there's a lot of references to various papers when going through what are pretty basic tutorials.

For example, just on prompt engineering alone, quite a few tutorials referenced the Chain of Thought paper (Wei et al, 2022). When I was looking at intro tutorials on agents, many of them referred to the ICLR ReAct paper (Yao et al, 2023). In regards to finetuning LLMs, many of them referenced the QLoRa paper (Dettmers et al, 2023).

I had assumed that as a developer (not as a researcher), I could just use a lot of these LLM tools out of the box with just documentation but do I have to read the latest ICLR (or other ML journal/conference) papers to interact with them now? Is this common?

AI developers: how often are you browsing through and reading through papers? I just wanted to build stuff and want to minimize academic work...",19,17,2025-05-02T03:48:16+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kcrrzu/do_you_have_to_keep_up_with_the_latest_research/,"Do you have to keep up with the latest research papers if you are working with LLMs as an AI developer? I've been diving deeper into LLMs these days (especially agentic AI) and I'm slightly surprised that there's a lot of references to various papers when going through what are pretty basic tutorials.

For example, just on prompt engineering alone, quite a few tutorials referenced the Chain of Thought paper (Wei et al, 2022). When I was looking at intro tutorials on agents, many of them referred to the ICLR ReAct paper (Yao et al, 2023). In regards to finetuning LLMs, many of them referenced the QLoRa paper (Dettmers et al, 2023).

I had assumed that as a developer (not as a researcher), I could just use a lot of these LLM tools out of the box with just documentation but do I have to read the latest ICLR (or other ML journal/conference) papers to interact with them now? Is this common?

AI developers: how often are you browsing through and reading through papers? I just wanted to build stuff and want to minimize academic work...",do you have to keep up with the latest research papers if you are working with llms as an ai developer ive been diving deeper into llms these days especially agentic ai and im slightly surprised that theres a lot of references to various papers when going through what are pretty basic tutorials for example just on prompt engineering alone quite a few tutorials referenced the chain of thought paper wei et al when i was looking at intro tutorials on agents many of them referred to the iclr react paper yao et al in regards to finetuning llms many of them referenced the qlora paper dettmers et al i had assumed that as a developer not as a researcher i could just use a lot of these llm tools out of the box with just documentation but do i have to read the latest iclr or other ml journalconference papers to interact with them now is this common ai developers how often are you browsing through and reading through papers i just wanted to build stuff and want to minimize academic work,late research paper work llm ai developer ve dive deeply llm day especially agentic ai m slightly surprised s lot reference paper go pretty basic tutorial example prompt engineering tutorial reference chain thought paper wei et al look intro tutorial agent refer iclr react paper yao et al regard finetune llm reference qlora paper dettmer et al assume developer researcher use lot llm tool box documentation read late iclr ml journalconference paper interact common ai developer browse read paper want build stuff want minimize academic work
1kbps44,Made this meme for a presentation I have to give tomorrow at work,,189,30,2025-04-30T19:57:24+00:00,datascience,https://i.redd.it/xp4zs98d21ye1.png,Made this meme for a presentation I have to give tomorrow at work ,made this meme for a presentation i have to give tomorrow at work,meme presentation tomorrow work
1kbfya2,Breaking into DS from academia,"Hi everyone,

I need advice from industry DS folks. I'm currently a bioinformatics postdoc in the US, and it seems like our world is collapsing with all the cuts from the current administration. I'm considering moving to industry DS (any field), as I'm essentially doing DS in the biomedical field right now.

I tried making a DS/industry style 1-page resume; could you please advise whether it is good and how to improve? Be harsh, no problemo with that. And a couple of specific questions:

1. A friend told me I should write ""Data Scientist"" as my previous roles, as recruiters will dump my CV after seeing ""Computational Biologist"" or ""Bioinformatics Scientist."" Is this OK practice? The work I've done, in principle, is data science.
2. Am I missing any critical skills that every senior-level industry DS should have?

Thanks everyone in advance!! 

https://preview.redd.it/0o0mg29szyxe1.png?width=2550&format=png&auto=webp&s=85d0ec3cdab2e439c42445f90a76f898fa2a3b13

  
",114,82,2025-04-30T13:03:28+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kbfya2/breaking_into_ds_from_academia/,"Breaking into DS from academia Hi everyone,

I need advice from industry DS folks. I'm currently a bioinformatics postdoc in the US, and it seems like our world is collapsing with all the cuts from the current administration. I'm considering moving to industry DS (any field), as I'm essentially doing DS in the biomedical field right now.

I tried making a DS/industry style 1-page resume; could you please advise whether it is good and how to improve? Be harsh, no problemo with that. And a couple of specific questions:

1. A friend told me I should write ""Data Scientist"" as my previous roles, as recruiters will dump my CV after seeing ""Computational Biologist"" or ""Bioinformatics Scientist."" Is this OK practice? The work I've done, in principle, is data science.
2. Am I missing any critical skills that every senior-level industry DS should have?

Thanks everyone in advance!! 

https://preview.redd.it/0o0mg29szyxe1.png?width=2550&format=png&auto=webp&s=85d0ec3cdab2e439c42445f90a76f898fa2a3b13

  
",breaking into ds from academia hi everyone i need advice from industry ds folks im currently a bioinformatics postdoc in the us and it seems like our world is collapsing with all the cuts from the current administration im considering moving to industry ds any field as im essentially doing ds in the biomedical field right now i tried making a dsindustry style page resume could you please advise whether it is good and how to improve be harsh no problemo with that and a couple of specific questions a friend told me i should write data scientist as my previous roles as recruiters will dump my cv after seeing computational biologist or bioinformatics scientist is this ok practice the work ive done in principle is data science am i missing any critical skills that every seniorlevel industry ds should have thanks everyone in advance,break ds academia hi need advice industry ds folk m currently bioinformatics postdoc like world collapse cut current administration m consider move industry ds field m essentially ds biomedical field right try make dsindustry style page resume advise good improve harsh problemo couple specific question friend tell write data scientist previous role recruiter dump cv see computational biologist bioinformatics scientist ok practice work ve principle datum science miss critical skill seniorlevel industry ds thank advance
1kb5xj6,DS in healthcare,"So I have a situation.   
I have a dataset that contains real-world clinical vignettes drawn from frontline healthcare settings. Each sample presents a prompt representing a clinical case scenario, along with the response from a human clinician. The goal is to predict the the phisician's response based on the prompt.

These vignettes simulate the types of decisions nurses  must make every day, particularly in low-resource environments where access to specialists or diagnostic equipment may be limited.

* These are real clinical scenarios, and the dataset is small because expert-labelled data is difficult and time-consuming to collect.
* Prompts are diverse across medical specialties, geographic regions, and healthcare facility levels, requiring broad clinical reasoning and adaptability.
* Responses may include abbreviations, structured reasoning (e.g. ""Summary:"", ""Diagnosis:"", ""Plan:""), or free text.

my first go to is to fine tune a small LLM to do this but I have feeling it won't be enough given how diverse the specialties are and the size of the dataset.  
Anyone has done something like this before? any help or resources would be welcomed.",11,20,2025-04-30T02:34:27+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kb5xj6/ds_in_healthcare/,"DS in healthcare So I have a situation.   
I have a dataset that contains real-world clinical vignettes drawn from frontline healthcare settings. Each sample presents a prompt representing a clinical case scenario, along with the response from a human clinician. The goal is to predict the the phisician's response based on the prompt.

These vignettes simulate the types of decisions nurses  must make every day, particularly in low-resource environments where access to specialists or diagnostic equipment may be limited.

* These are real clinical scenarios, and the dataset is small because expert-labelled data is difficult and time-consuming to collect.
* Prompts are diverse across medical specialties, geographic regions, and healthcare facility levels, requiring broad clinical reasoning and adaptability.
* Responses may include abbreviations, structured reasoning (e.g. ""Summary:"", ""Diagnosis:"", ""Plan:""), or free text.

my first go to is to fine tune a small LLM to do this but I have feeling it won't be enough given how diverse the specialties are and the size of the dataset.  
Anyone has done something like this before? any help or resources would be welcomed.",ds in healthcare so i have a situation i have a dataset that contains realworld clinical vignettes drawn from frontline healthcare settings each sample presents a prompt representing a clinical case scenario along with the response from a human clinician the goal is to predict the the phisicians response based on the prompt these vignettes simulate the types of decisions nurses must make every day particularly in lowresource environments where access to specialists or diagnostic equipment may be limited these are real clinical scenarios and the dataset is small because expertlabelled data is difficult and timeconsuming to collect prompts are diverse across medical specialties geographic regions and healthcare facility levels requiring broad clinical reasoning and adaptability responses may include abbreviations structured reasoning eg summary diagnosis plan or free text my first go to is to fine tune a small llm to do this but i have feeling it wont be enough given how diverse the specialties are and the size of the dataset anyone has done something like this before any help or resources would be welcomed,ds healthcare situation dataset contain realworld clinical vignette draw frontline healthcare setting sample present prompt represent clinical case scenario response human clinician goal predict phisician response base prompt vignette simulate type decision nurse day particularly lowresource environment access specialist diagnostic equipment limit real clinical scenario dataset small expertlabelle datum difficult timeconsuming collect prompt diverse medical specialty geographic region healthcare facility level require broad clinical reasoning adaptability response include abbreviation structure reasoning eg summary diagnosis plan free text fine tune small llm feel will not give diverse specialty size dataset like help resource welcome
1kayvx4,Putting Forecast model into Production help,"I am looking for feedback on deploying a Sarima model. 


I am using the model to predict sales revenue on a monthly basis. The goal is identifying the trend of our revenue and then making purchasing decisions based on the trend moving up or down. I am currently forecasting 3 months into the future, storing those predictions in a table, and exporting the table onto our SQL server. 


It is now time to refresh the forecast. I think that I retrain the model on all of the data, including the last 3 months, and then forecast another 3 months. 


My concern is that I will not be able to rollback the model to the original version if I need to do so for whatever reason. Is this a reasonable concern? Also, should I just forecast 1 month in advance instead of 3 if I am retraining the model anyway? 


This is my first time deploying a time series model. I am a one person shop, so I don't have anyone with experience to guide me. Please and thank you. ",11,15,2025-04-29T21:02:44+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kayvx4/putting_forecast_model_into_production_help/,"Putting Forecast model into Production help I am looking for feedback on deploying a Sarima model. 


I am using the model to predict sales revenue on a monthly basis. The goal is identifying the trend of our revenue and then making purchasing decisions based on the trend moving up or down. I am currently forecasting 3 months into the future, storing those predictions in a table, and exporting the table onto our SQL server. 


It is now time to refresh the forecast. I think that I retrain the model on all of the data, including the last 3 months, and then forecast another 3 months. 


My concern is that I will not be able to rollback the model to the original version if I need to do so for whatever reason. Is this a reasonable concern? Also, should I just forecast 1 month in advance instead of 3 if I am retraining the model anyway? 


This is my first time deploying a time series model. I am a one person shop, so I don't have anyone with experience to guide me. Please and thank you. ",putting forecast model into production help i am looking for feedback on deploying a sarima model i am using the model to predict sales revenue on a monthly basis the goal is identifying the trend of our revenue and then making purchasing decisions based on the trend moving up or down i am currently forecasting months into the future storing those predictions in a table and exporting the table onto our sql server it is now time to refresh the forecast i think that i retrain the model on all of the data including the last months and then forecast another months my concern is that i will not be able to rollback the model to the original version if i need to do so for whatever reason is this a reasonable concern also should i just forecast month in advance instead of if i am retraining the model anyway this is my first time deploying a time series model i am a one person shop so i dont have anyone with experience to guide me please and thank you,put forecast model production help look feedback deploy sarima model model predict sale revenue monthly basis goal identify trend revenue make purchasing decision base trend move currently forecast month future store prediction table export table sql server time refresh forecast think retrain model datum include month forecast month concern able rollback model original version need reason reasonable concern forecast month advance instead retrain model time deploy time series model person shop not experience guide thank
1kapuvz,Transition to SDE,"Is there anyone here who has transitioned to SDE from DS? I have been working as a data scientist for over 2 years now, so my CV comprises of DS related experience only. I want to explore opportunities in SDE (as well as DS/MLE) since I am not enjoying the kind of work I am doing now. My background is CS. 

If someone has done it, can you suggest how to prepare for it given that I have worked as DS? Should I include SDE related self projects? Btw there's no opportunity in my current organization to internally transition to SDE. And I am more inclined towards product related companies.",29,11,2025-04-29T14:52:35+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kapuvz/transition_to_sde/,"Transition to SDE Is there anyone here who has transitioned to SDE from DS? I have been working as a data scientist for over 2 years now, so my CV comprises of DS related experience only. I want to explore opportunities in SDE (as well as DS/MLE) since I am not enjoying the kind of work I am doing now. My background is CS. 

If someone has done it, can you suggest how to prepare for it given that I have worked as DS? Should I include SDE related self projects? Btw there's no opportunity in my current organization to internally transition to SDE. And I am more inclined towards product related companies.",transition to sde is there anyone here who has transitioned to sde from ds i have been working as a data scientist for over years now so my cv comprises of ds related experience only i want to explore opportunities in sde as well as dsmle since i am not enjoying the kind of work i am doing now my background is cs if someone has done it can you suggest how to prepare for it given that i have worked as ds should i include sde related self projects btw theres no opportunity in my current organization to internally transition to sde and i am more inclined towards product related companies,transition sde transition sde ds work data scientist year cv comprise ds relate experience want explore opportunity sde dsmle enjoy kind work background cs suggest prepare give work ds include sde relate self project btw s opportunity current organization internally transition sde inclined product relate company
1kapczj,"What is the best way to parse and order a PDF from forum screenshots that includes a lot of cached text, quotes, random order and overall a mess.","Hello dear people! Been dealing with this very interesting problem that I'm not 100% sure how to tackle. A local forum went down some time ago and they lost a few hours worth of data since backups aren't hourly. Quite a few topics were lost, as well as some of them apparently became corrupted and also got lost. One of them included a very nice discussion about local mountaineering and beautiful locations which a lot of people are saddened to lost since we discussed many trails. Somehow, people managed to collect data from various cached sources, computers, some screenshots, but mostly old google, bing caches while they worked and webarchive. 

Now it's all properly ordered in pdf document but the thing is the layouts often change and so does resolution but the general idea of how data is represented is the same. There's also some artifacts in data from webarchive for example - they have an element hovering over text and you can't see it, but if you ctrl-f to search for it it's there somehow, hidden under the image haha. No javascript in PDF, something else, probably  colored, no idea.

The ideas I had were (btw PDF is OCR'd already):

&nbsp;

- PDF to text and try to regex + LLM process it all somehow?

- Somehow ""train"" (if train is a proper word here?) machine vision / machine learning for each separate layout so that it knows how to extract data

&nbsp;

But I also face issue that some posts are for example screenshoted in ""half"", e.g. page 360 has the text cut out and continue on page 361 with random stuff on top from the archival's page (e.g. webarchive or bing cache info). I would need to also truncate this, but that should be easy.

&nbsp;

- Or option 3 with those new LLMs that can somehow recognize images or work with PDF (idk how they do it) I could maybe have the LLM do the whole heavy load of processing? I could pick up one of better new models with big context length and remembrance, I just checked total character count, it's 8.588.362 characters or 2.147.090 tokens approximately, but I believe the data could be split and later manually combined or something? I'm not sure I'm really new to this. The main goal is to have a nice json output with all data properly curated.

&nbsp;

Many thanks! Much appreciated.",7,8,2025-04-29T14:30:58+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kapczj/what_is_the_best_way_to_parse_and_order_a_pdf/,"What is the best way to parse and order a PDF from forum screenshots that includes a lot of cached text, quotes, random order and overall a mess. Hello dear people! Been dealing with this very interesting problem that I'm not 100% sure how to tackle. A local forum went down some time ago and they lost a few hours worth of data since backups aren't hourly. Quite a few topics were lost, as well as some of them apparently became corrupted and also got lost. One of them included a very nice discussion about local mountaineering and beautiful locations which a lot of people are saddened to lost since we discussed many trails. Somehow, people managed to collect data from various cached sources, computers, some screenshots, but mostly old google, bing caches while they worked and webarchive. 

Now it's all properly ordered in pdf document but the thing is the layouts often change and so does resolution but the general idea of how data is represented is the same. There's also some artifacts in data from webarchive for example - they have an element hovering over text and you can't see it, but if you ctrl-f to search for it it's there somehow, hidden under the image haha. No javascript in PDF, something else, probably  colored, no idea.

The ideas I had were (btw PDF is OCR'd already):

&nbsp;

- PDF to text and try to regex + LLM process it all somehow?

- Somehow ""train"" (if train is a proper word here?) machine vision / machine learning for each separate layout so that it knows how to extract data

&nbsp;

But I also face issue that some posts are for example screenshoted in ""half"", e.g. page 360 has the text cut out and continue on page 361 with random stuff on top from the archival's page (e.g. webarchive or bing cache info). I would need to also truncate this, but that should be easy.

&nbsp;

- Or option 3 with those new LLMs that can somehow recognize images or work with PDF (idk how they do it) I could maybe have the LLM do the whole heavy load of processing? I could pick up one of better new models with big context length and remembrance, I just checked total character count, it's 8.588.362 characters or 2.147.090 tokens approximately, but I believe the data could be split and later manually combined or something? I'm not sure I'm really new to this. The main goal is to have a nice json output with all data properly curated.

&nbsp;

Many thanks! Much appreciated.",what is the best way to parse and order a pdf from forum screenshots that includes a lot of cached text quotes random order and overall a mess hello dear people been dealing with this very interesting problem that im not sure how to tackle a local forum went down some time ago and they lost a few hours worth of data since backups arent hourly quite a few topics were lost as well as some of them apparently became corrupted and also got lost one of them included a very nice discussion about local mountaineering and beautiful locations which a lot of people are saddened to lost since we discussed many trails somehow people managed to collect data from various cached sources computers some screenshots but mostly old google bing caches while they worked and webarchive now its all properly ordered in pdf document but the thing is the layouts often change and so does resolution but the general idea of how data is represented is the same theres also some artifacts in data from webarchive for example they have an element hovering over text and you cant see it but if you ctrlf to search for it its there somehow hidden under the image haha no javascript in pdf something else probably colored no idea the ideas i had were btw pdf is ocrd already nbsp pdf to text and try to regex llm process it all somehow somehow train if train is a proper word here machine vision machine learning for each separate layout so that it knows how to extract data nbsp but i also face issue that some posts are for example screenshoted in half eg page has the text cut out and continue on page with random stuff on top from the archivals page eg webarchive or bing cache info i would need to also truncate this but that should be easy nbsp or option with those new llms that can somehow recognize images or work with pdf idk how they do it i could maybe have the llm do the whole heavy load of processing i could pick up one of better new models with big context length and remembrance i just checked total character count its characters or tokens approximately but i believe the data could be split and later manually combined or something im not sure im really new to this the main goal is to have a nice json output with all data properly curated nbsp many thanks much appreciated,good way parse order pdf forum screenshot include lot cache text quote random order overall mess hello dear people deal interesting problem m sure tackle local forum go time ago lose hour worth datum backup not hourly topic lose apparently corrupted get lose include nice discussion local mountaineering beautiful location lot people sadden lose discuss trail people manage collect datum cache source computer screenshot old google bing cache work webarchive properly order pdf document thing layout change resolution general idea datum represent s artifact datum webarchive example element hover text not ctrlf search hide image haha javascript pdf probably color idea idea btw pdf ocrd nbsp pdf text try regex llm process train train proper word machine vision machine learn separate layout know extract datum nbsp face issue post example screenshote half eg page text cut continue page random stuff archival page eg webarchive bing cache info need truncate easy nbsp option new llm recognize image work pdf idk maybe llm heavy load processing pick well new model big context length remembrance check total character count character token approximately believe datum split later manually combined m sure m new main goal nice json output datum properly curate nbsp thank appreciate
1kanby4,The role of data science in the age of GenAI,"I've been working in the space of ML for around 10 years now. I have a stats background, and when I started I was mostly training regression models on tabular data, or the occasional tf-idf + SVM pipeline for text classification. Nowadays, I work mainly with unstructured data and for the majority of problems my company is facing, calling a pre-trained LLM through an API is both sufficient and the most cost-effective solution - even deploying a small BERT-based classifier costs more and requires data labeling. I know this is not the case for all companies, but it's becoming very common.

Over the years, I've developed software engineering skills, and these days my work revolves around infra-as-code, CI/CD pipelines and API integration with ML applications. Although these skills are valuable, it's far away from data science.

For those who are in the same boat as me (and I know there are many), I'm curious to know how you apply and maintain your data science skills in this age of GenAI? ",383,92,2025-04-29T12:59:54+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kanby4/the_role_of_data_science_in_the_age_of_genai/,"The role of data science in the age of GenAI I've been working in the space of ML for around 10 years now. I have a stats background, and when I started I was mostly training regression models on tabular data, or the occasional tf-idf + SVM pipeline for text classification. Nowadays, I work mainly with unstructured data and for the majority of problems my company is facing, calling a pre-trained LLM through an API is both sufficient and the most cost-effective solution - even deploying a small BERT-based classifier costs more and requires data labeling. I know this is not the case for all companies, but it's becoming very common.

Over the years, I've developed software engineering skills, and these days my work revolves around infra-as-code, CI/CD pipelines and API integration with ML applications. Although these skills are valuable, it's far away from data science.

For those who are in the same boat as me (and I know there are many), I'm curious to know how you apply and maintain your data science skills in this age of GenAI? ",the role of data science in the age of genai ive been working in the space of ml for around years now i have a stats background and when i started i was mostly training regression models on tabular data or the occasional tfidf svm pipeline for text classification nowadays i work mainly with unstructured data and for the majority of problems my company is facing calling a pretrained llm through an api is both sufficient and the most costeffective solution even deploying a small bertbased classifier costs more and requires data labeling i know this is not the case for all companies but its becoming very common over the years ive developed software engineering skills and these days my work revolves around infraascode cicd pipelines and api integration with ml applications although these skills are valuable its far away from data science for those who are in the same boat as me and i know there are many im curious to know how you apply and maintain your data science skills in this age of genai,role data science age genai ve work space ml year stat background start train regression model tabular datum occasional tfidf svm pipeline text classification nowadays work mainly unstructured datum majority problem company face call pretraine llm api sufficient costeffective solution deploy small bertbase classifier cost require datum labeling know case company common year ve develop software engineering skill day work revolve infraascode cicd pipeline api integration ml application skill valuable far away data science boat know m curious know apply maintain data science skill age genai
1kaki1s,is it data leakage?,"We are predicting conversion. Conversion means customer converted from paying one-off to paying regular (subscribe)

If one feature is categorical feature ""Activity"" , consisting 15+ categories and one of the category is ""conversion"" (labelling whether the customer converted or not). The other 14 categories are various. Examples are emails, newsletter, acquisition, etc. they're companies recorded of how it got this customers (no matter it's one-off or regular customer) It may or may not be converted customers

so we definitely cannot use the one category as a feature in our model otherwise it would create data leakage. What about the other 14 categories?

What if i create dummy variables from these 15 categories + and select just 2-3 to help modelling? Would it still create leakage ?

I asked this to 1. my professor 2. A professional data analyst They gave different answers. Can anyone help adding some more ideas?

I tried using the whole features (convert it to dummy and drop 1), it helps the model. For random forests, the top one with high feature importance is this Activity\_conversion (dummy of activity - conversion) feature

  
Note: found this question on a forum.",6,14,2025-04-29T10:19:41+00:00,datascience,https://www.reddit.com/r/datascience/comments/1kaki1s/is_it_data_leakage/,"is it data leakage? We are predicting conversion. Conversion means customer converted from paying one-off to paying regular (subscribe)

If one feature is categorical feature ""Activity"" , consisting 15+ categories and one of the category is ""conversion"" (labelling whether the customer converted or not). The other 14 categories are various. Examples are emails, newsletter, acquisition, etc. they're companies recorded of how it got this customers (no matter it's one-off or regular customer) It may or may not be converted customers

so we definitely cannot use the one category as a feature in our model otherwise it would create data leakage. What about the other 14 categories?

What if i create dummy variables from these 15 categories + and select just 2-3 to help modelling? Would it still create leakage ?

I asked this to 1. my professor 2. A professional data analyst They gave different answers. Can anyone help adding some more ideas?

I tried using the whole features (convert it to dummy and drop 1), it helps the model. For random forests, the top one with high feature importance is this Activity\_conversion (dummy of activity - conversion) feature

  
Note: found this question on a forum.",is it data leakage we are predicting conversion conversion means customer converted from paying oneoff to paying regular subscribe if one feature is categorical feature activity consisting categories and one of the category is conversion labelling whether the customer converted or not the other categories are various examples are emails newsletter acquisition etc theyre companies recorded of how it got this customers no matter its oneoff or regular customer it may or may not be converted customers so we definitely cannot use the one category as a feature in our model otherwise it would create data leakage what about the other categories what if i create dummy variables from these categories and select just to help modelling would it still create leakage i asked this to my professor a professional data analyst they gave different answers can anyone help adding some more ideas i tried using the whole features convert it to dummy and drop it helps the model for random forests the top one with high feature importance is this activityconversion dummy of activity conversion feature note found this question on a forum,datum leakage predict conversion conversion mean customer convert pay oneoff pay regular subscribe feature categorical feature activity consist category category conversion label customer convert category example email newsletter acquisition etc company record get customer matter oneoff regular customer convert customer definitely use category feature model create datum leakage category create dummy variable category select help modelling create leakage ask professor professional datum analyst give different answer help add idea try feature convert dummy drop help model random forest high feature importance activityconversion dummy activity conversion feature note find question forum
1ka2l4q,I'll just do it later,,332,15,2025-04-28T18:20:02+00:00,datascience,https://i.redd.it/cfhnln9yamxe1.jpeg,I'll just do it later ,ill just do it later,ill later
1k9uwf6,A paper from the latest SIGBOVIK proceedings,,335,12,2025-04-28T12:57:38+00:00,datascience,https://i.redd.it/ophkf4pkpkxe1.jpeg,A paper from the latest SIGBOVIK proceedings ,a paper from the latest sigbovik proceedings,paper late sigbovik proceeding
1k9momp,"Weekly Entering & Transitioning - Thread 28 Apr, 2025 - 05 May, 2025"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",10,28,2025-04-28T04:01:31+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k9momp/weekly_entering_transitioning_thread_28_apr_2025/,"Weekly Entering & Transitioning - Thread 28 Apr, 2025 - 05 May, 2025  

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",weekly entering transitioning thread apr may welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the and resources pages on our wiki you can also search for answers in,weekly enter transition thread apr welcome week enter transition thread thread question getting start study transition data science field topic include learn resource eg book tutorial video traditional education eg schools degree elective alternative education eg online course bootcamp job search question eg resume apply career prospect elementary question eg start wait answer community check resource page wiki search answer
1k8hjp4,This environment would be a real nightmare for me.,"YouTube released some interesting metrics for their 20 year celebration and their data environment is just insane.

- Processing infrastructure handling 20+ million daily video uploads 
- Storage and retrieval systems managing 20+ billion total videos
- Analytics pipelines tracking 3.5+ billion daily likes and 100+ million daily comments
- Real-time processing of engagement metrics (creator-hearted comments reaching 10 million daily)
- Infrastructure supporting multimodal data types (video, audio, comments, metadata)

From an analytics point of view, it would be extremely difficult to validate anything you build in this environment, especially if it's something that is very obscure. 
Supposed they calculate a ""Content Stickiness Factor"" (a metric which quantifies how much a video prevents users from leaving the platform), 
how would anyone validate that a factor of 0.3 is correct for creator X? That is just for 1 creator in one segment, there are different segments which all have different behaviors eg podcasts which might be longer vs shorts

I would assume training ml models, or basic queries would be either slow or very expensive which punishes mistakes a lot. You either run 10 computer for 10 days or or 2000 computers for 1.5 hours, and if you forget that 2000 computer cluster running, for just a few minutes for lunch maybe, or worse over the weekend, you will come back to regret it.

Any mistakes you do are amplified by the amount of data, you omitting a single ""LIMIT 10"" or use a ""SELECT * "" in the wrong place and you could easy cost the company millions of dollars.
""Forgot a single cluster running, well you just lost us $10 million dollars buddy""

And because of these challenges, l believe such an environment demands excellence, not to ensure that no one makes mistakes, but to prevent obvious ones and reduce the probability of catastrophic ones.

l am very curious how such an environment is managed and would love to see it someday.






[YouTube article](https://blog.youtube/news-and-events/happy-birthday-youtube-20/)",122,25,2025-04-26T16:55:12+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k8hjp4/this_environment_would_be_a_real_nightmare_for_me/,"This environment would be a real nightmare for me. YouTube released some interesting metrics for their 20 year celebration and their data environment is just insane.

- Processing infrastructure handling 20+ million daily video uploads 
- Storage and retrieval systems managing 20+ billion total videos
- Analytics pipelines tracking 3.5+ billion daily likes and 100+ million daily comments
- Real-time processing of engagement metrics (creator-hearted comments reaching 10 million daily)
- Infrastructure supporting multimodal data types (video, audio, comments, metadata)

From an analytics point of view, it would be extremely difficult to validate anything you build in this environment, especially if it's something that is very obscure. 
Supposed they calculate a ""Content Stickiness Factor"" (a metric which quantifies how much a video prevents users from leaving the platform), 
how would anyone validate that a factor of 0.3 is correct for creator X? That is just for 1 creator in one segment, there are different segments which all have different behaviors eg podcasts which might be longer vs shorts

I would assume training ml models, or basic queries would be either slow or very expensive which punishes mistakes a lot. You either run 10 computer for 10 days or or 2000 computers for 1.5 hours, and if you forget that 2000 computer cluster running, for just a few minutes for lunch maybe, or worse over the weekend, you will come back to regret it.

Any mistakes you do are amplified by the amount of data, you omitting a single ""LIMIT 10"" or use a ""SELECT * "" in the wrong place and you could easy cost the company millions of dollars.
""Forgot a single cluster running, well you just lost us $10 million dollars buddy""

And because of these challenges, l believe such an environment demands excellence, not to ensure that no one makes mistakes, but to prevent obvious ones and reduce the probability of catastrophic ones.

l am very curious how such an environment is managed and would love to see it someday.






[YouTube article](https://blog.youtube/news-and-events/happy-birthday-youtube-20/)",this environment would be a real nightmare for me youtube released some interesting metrics for their year celebration and their data environment is just insane processing infrastructure handling million daily video uploads storage and retrieval systems managing billion total videos analytics pipelines tracking billion daily likes and million daily comments realtime processing of engagement metrics creatorhearted comments reaching million daily infrastructure supporting multimodal data types video audio comments metadata from an analytics point of view it would be extremely difficult to validate anything you build in this environment especially if its something that is very obscure supposed they calculate a content stickiness factor a metric which quantifies how much a video prevents users from leaving the platform how would anyone validate that a factor of is correct for creator x that is just for creator in one segment there are different segments which all have different behaviors eg podcasts which might be longer vs shorts i would assume training ml models or basic queries would be either slow or very expensive which punishes mistakes a lot you either run computer for days or or computers for hours and if you forget that computer cluster running for just a few minutes for lunch maybe or worse over the weekend you will come back to regret it any mistakes you do are amplified by the amount of data you omitting a single limit or use a select in the wrong place and you could easy cost the company millions of dollars forgot a single cluster running well you just lost us million dollars buddy and because of these challenges l believe such an environment demands excellence not to ensure that no one makes mistakes but to prevent obvious ones and reduce the probability of catastrophic ones l am very curious how such an environment is managed and would love to see it someday,environment real nightmare youtube release interesting metric year celebration data environment insane processing infrastructure handle million daily video upload storage retrieval system manage billion total video analytic pipeline track billion daily like million daily comment realtime processing engagement metric creatorhearte comment reach million daily infrastructure support multimodal datum type video audio comment metadata analytic point view extremely difficult validate build environment especially obscure suppose calculate content stickiness factor metric quantify video prevent user leave platform validate factor correct creator x creator segment different segment different behavior eg podcast long vs short assume training ml model basic query slow expensive punish mistake lot run computer day computer hour forget computer cluster run minute lunch maybe bad weekend come regret mistake amplify datum omit single limit use select wrong place easy cost company million dollar forget single cluster run lose million dollar buddy challenge l believe environment demand excellence ensure make mistake prevent obvious one reduce probability catastrophic one l curious environment manage love someday
1k89ohp,People here working in Healthcare how do you communicate with Healthcare professionals?,"I'm pursuing my doctoral deg in data science. My domain is ai in Healthcare. We collab with a hospital from where I get my data. In return im practically at their beck and call. They expect me analyze some of their data and automate a few tasks. Not a big deal when I have to build a model it's usually a simple classification model where I use ml models or do some transfer learning. The problem is communicating the feature selection/extraction process. I don't need that many features for the given number of data points. 

How do I explain to them that even if clinically those two features are the most important for the diagnosis I still have to scrape one of them. It's too correlated(>0.9) and is only adding noise. And I do ask them to give me more variable data and they can't. They insist I do dimensionality reduction but then I end up with lower accuracy. I don't understand why people think ai is intuitive or will know things that we humans don't. It can only perform based on the data given. 

",30,10,2025-04-26T10:14:41+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k89ohp/people_here_working_in_healthcare_how_do_you/,"People here working in Healthcare how do you communicate with Healthcare professionals? I'm pursuing my doctoral deg in data science. My domain is ai in Healthcare. We collab with a hospital from where I get my data. In return im practically at their beck and call. They expect me analyze some of their data and automate a few tasks. Not a big deal when I have to build a model it's usually a simple classification model where I use ml models or do some transfer learning. The problem is communicating the feature selection/extraction process. I don't need that many features for the given number of data points. 

How do I explain to them that even if clinically those two features are the most important for the diagnosis I still have to scrape one of them. It's too correlated(>0.9) and is only adding noise. And I do ask them to give me more variable data and they can't. They insist I do dimensionality reduction but then I end up with lower accuracy. I don't understand why people think ai is intuitive or will know things that we humans don't. It can only perform based on the data given. 

",people here working in healthcare how do you communicate with healthcare professionals im pursuing my doctoral deg in data science my domain is ai in healthcare we collab with a hospital from where i get my data in return im practically at their beck and call they expect me analyze some of their data and automate a few tasks not a big deal when i have to build a model its usually a simple classification model where i use ml models or do some transfer learning the problem is communicating the feature selectionextraction process i dont need that many features for the given number of data points how do i explain to them that even if clinically those two features are the most important for the diagnosis i still have to scrape one of them its too correlated and is only adding noise and i do ask them to give me more variable data and they cant they insist i do dimensionality reduction but then i end up with lower accuracy i dont understand why people think ai is intuitive or will know things that we humans dont it can only perform based on the data given,people work healthcare communicate healthcare professional m pursue doctoral deg data science domain ai healthcare collab hospital datum return m practically beck expect analyze datum automate task big deal build model usually simple classification model use ml model transfer learn problem communicate feature selectionextraction process not need feature give number datum point explain clinically feature important diagnosis scrape correlate add noise ask variable datum not insist dimensionality reduction end low accuracy not understand people think ai intuitive know thing human not perform base datum give
1k87wnq,Thoughts on getting a Masters while working as a DS?,"I entered DS straight after an undergrad in Computer Science. During my degree I did multiple DS internships and an ML research internship. I figured out I didn't like research so a PhD was out. I couldn't afford to stay on for a Masters so I went straight into work and found a DS role, where I'm performing very well and getting promoted quickly.

I like my current org but it's a very narrow field of work so I might want to move on in 2-3 years. I see a lot of postings (both internally and externally) require a Masters, so I'm wondering if I'm putting myself at a disadvantage by not having one.

My current employer has tuition reimbursement up to ~$6k a year so I was thinking of doing a part-time Masters (something like OMSCS, OMSA, or a statistics MS program offered by a local uni) - partially for the signalling of having a Masters, and partially because I just really love learning and I feel like the learning has stagnated in my current role... 

On the other hand I'm worried that doing a Masters alongside work will impact my ability to focus on my job & progression plans. I've already done two Masters courses part-time (free, credit-bearing but can't transfer them to a degree) and found it ok but any of the degrees I've been considering would be much more workload. 

Another option would be to take a year out between jobs and do a Masters, but with the job market the way it is that feels like a big risk.

Thanks in advance for your opinions/discussion :)",71,47,2025-04-26T08:05:54+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k87wnq/thoughts_on_getting_a_masters_while_working_as_a/,"Thoughts on getting a Masters while working as a DS? I entered DS straight after an undergrad in Computer Science. During my degree I did multiple DS internships and an ML research internship. I figured out I didn't like research so a PhD was out. I couldn't afford to stay on for a Masters so I went straight into work and found a DS role, where I'm performing very well and getting promoted quickly.

I like my current org but it's a very narrow field of work so I might want to move on in 2-3 years. I see a lot of postings (both internally and externally) require a Masters, so I'm wondering if I'm putting myself at a disadvantage by not having one.

My current employer has tuition reimbursement up to ~$6k a year so I was thinking of doing a part-time Masters (something like OMSCS, OMSA, or a statistics MS program offered by a local uni) - partially for the signalling of having a Masters, and partially because I just really love learning and I feel like the learning has stagnated in my current role... 

On the other hand I'm worried that doing a Masters alongside work will impact my ability to focus on my job & progression plans. I've already done two Masters courses part-time (free, credit-bearing but can't transfer them to a degree) and found it ok but any of the degrees I've been considering would be much more workload. 

Another option would be to take a year out between jobs and do a Masters, but with the job market the way it is that feels like a big risk.

Thanks in advance for your opinions/discussion :)",thoughts on getting a masters while working as a ds i entered ds straight after an undergrad in computer science during my degree i did multiple ds internships and an ml research internship i figured out i didnt like research so a phd was out i couldnt afford to stay on for a masters so i went straight into work and found a ds role where im performing very well and getting promoted quickly i like my current org but its a very narrow field of work so i might want to move on in years i see a lot of postings both internally and externally require a masters so im wondering if im putting myself at a disadvantage by not having one my current employer has tuition reimbursement up to k a year so i was thinking of doing a parttime masters something like omscs omsa or a statistics ms program offered by a local uni partially for the signalling of having a masters and partially because i just really love learning and i feel like the learning has stagnated in my current role on the other hand im worried that doing a masters alongside work will impact my ability to focus on my job progression plans ive already done two masters courses parttime free creditbearing but cant transfer them to a degree and found it ok but any of the degrees ive been considering would be much more workload another option would be to take a year out between jobs and do a masters but with the job market the way it is that feels like a big risk thanks in advance for your opinionsdiscussion,thought get master work ds enter ds straight undergrad computer science degree multiple ds internship ml research internship figure not like research phd not afford stay master go straight work find ds role m perform getting promote quickly like current org narrow field work want year lot posting internally externally require master m wonder m put disadvantage have current employer tuition reimbursement k year think parttime master like omsc omsa statistic ms program offer local uni partially signalling have master partially love learning feel like learning stagnate current role hand m worried master alongside work impact ability focus job progression plan ve master course parttime free creditbearing not transfer degree find ok degree ve consider workload option year job master job market way feel like big risk thank advance opinionsdiscussion
1k81pru,An example of how statistics can be used to unintentionally deceive (and why data analysis is important).,,47,14,2025-04-26T01:46:55+00:00,datascience,https://www.reddit.com/r/2westerneurope4u/comments/1k78yjt/comment/mp2mlra/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button,An example of how statistics can be used to unintentionally deceive (and why data analysis is important). ,an example of how statistics can be used to unintentionally deceive and why data analysis is important,example statistic unintentionally deceive datum analysis important
1k80mxy,Question about How to Use Churn Prediction,"When churn prediction is done, we have predictions of who will churn and who will retain.

  
I am wondering what the typical strategy is after this. 

Like target the people who are predicting as being retained (perhaps to upsell on them) or try to get people back who are predicted as churning? My guess is it is something that depends on the priority of the business.

I'm also thinking, if we output a probability that is borderline, that could be an interesting target to attempt to persuade. 

",41,30,2025-04-26T00:49:51+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k80mxy/question_about_how_to_use_churn_prediction/,"Question about How to Use Churn Prediction When churn prediction is done, we have predictions of who will churn and who will retain.

  
I am wondering what the typical strategy is after this. 

Like target the people who are predicting as being retained (perhaps to upsell on them) or try to get people back who are predicted as churning? My guess is it is something that depends on the priority of the business.

I'm also thinking, if we output a probability that is borderline, that could be an interesting target to attempt to persuade. 

",question about how to use churn prediction when churn prediction is done we have predictions of who will churn and who will retain i am wondering what the typical strategy is after this like target the people who are predicting as being retained perhaps to upsell on them or try to get people back who are predicted as churning my guess is it is something that depends on the priority of the business im also thinking if we output a probability that is borderline that could be an interesting target to attempt to persuade,question use churn prediction churn prediction prediction churn retain wonder typical strategy like target people predict retain upsell try people predict churn guess depend priority business m think output probability borderline interesting target attempt persuade
1k804yc,"Thought I was prepping for ML/DS internships... turns out I need full-stack, backend, cloud, AND dark magic to qualify","I'm currently doing my undergrad and have built up a decent foundation in machine learning and data science. I figured I was on track, until I actually started looking for internships.

Now every ML/DS internship description looks like:  
""Must know full-stack development, backend, frontend, cloud engineering, DevOps, machine learning, deep learning, computer vision, and also invent a new programming language while you're at it.""

Bro I just wanted to do some modeling, not rebuild Twitter from scratch..

I know basic stuff like SDLC, Git, and cloud fundamentals, but I honestly have no clue about real frontend/backend development. Now I’m thinking I need to buckle down and properly learn SWE if I ever want to land an ML/DS internship.

First, am I wrong for thinking this way? Is full-stack knowledge pretty much required now for ML/DS intern roles, or am I just applying to cracked job posts?  
Second, if I do need to learn SWE properly, where should I start?

I don't want to sit through super basic ""hello world"" courses (no offense to IBM/Meta Coursera certs, but I need something a little more serious). I heard the Amazon Junior Developer program on Coursera might be good? Anyone tried it?

Not trying to waste time spinning in circles. Just wanna know how people here approached it if you were in a similar spot. Appreciate any advice.",305,61,2025-04-26T00:23:51+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k804yc/thought_i_was_prepping_for_mlds_internships_turns/,"Thought I was prepping for ML/DS internships... turns out I need full-stack, backend, cloud, AND dark magic to qualify I'm currently doing my undergrad and have built up a decent foundation in machine learning and data science. I figured I was on track, until I actually started looking for internships.

Now every ML/DS internship description looks like:  
""Must know full-stack development, backend, frontend, cloud engineering, DevOps, machine learning, deep learning, computer vision, and also invent a new programming language while you're at it.""

Bro I just wanted to do some modeling, not rebuild Twitter from scratch..

I know basic stuff like SDLC, Git, and cloud fundamentals, but I honestly have no clue about real frontend/backend development. Now I’m thinking I need to buckle down and properly learn SWE if I ever want to land an ML/DS internship.

First, am I wrong for thinking this way? Is full-stack knowledge pretty much required now for ML/DS intern roles, or am I just applying to cracked job posts?  
Second, if I do need to learn SWE properly, where should I start?

I don't want to sit through super basic ""hello world"" courses (no offense to IBM/Meta Coursera certs, but I need something a little more serious). I heard the Amazon Junior Developer program on Coursera might be good? Anyone tried it?

Not trying to waste time spinning in circles. Just wanna know how people here approached it if you were in a similar spot. Appreciate any advice.",thought i was prepping for mlds internships turns out i need fullstack backend cloud and dark magic to qualify im currently doing my undergrad and have built up a decent foundation in machine learning and data science i figured i was on track until i actually started looking for internships now every mlds internship description looks like must know fullstack development backend frontend cloud engineering devops machine learning deep learning computer vision and also invent a new programming language while youre at it bro i just wanted to do some modeling not rebuild twitter from scratch i know basic stuff like sdlc git and cloud fundamentals but i honestly have no clue about real frontendbackend development now im thinking i need to buckle down and properly learn swe if i ever want to land an mlds internship first am i wrong for thinking this way is fullstack knowledge pretty much required now for mlds intern roles or am i just applying to cracked job posts second if i do need to learn swe properly where should i start i dont want to sit through super basic hello world courses no offense to ibmmeta coursera certs but i need something a little more serious i heard the amazon junior developer program on coursera might be good anyone tried it not trying to waste time spinning in circles just wanna know how people here approached it if you were in a similar spot appreciate any advice,think preppe mld internship turn need fullstack backend cloud dark magic qualify m currently undergrad build decent foundation machine learning data science figure track actually start look internship mld internship description look like know fullstack development backend frontend cloud engineering devop machine learn deep learn computer vision invent new programming language bro want modeling rebuild twitter scratch know basic stuff like sdlc git cloud fundamental honestly clue real frontendbackend development m think need buckle properly learn swe want land mld internship wrong think way fullstack knowledge pretty require mld intern role apply crack job post second need learn swe properly start not want sit super basic hello world course offense ibmmeta coursera cert need little hear amazon junior developer program coursera good try try waste time spin circle wanna know people approach similar spot appreciate advice
1k7xi9g,Responsible Tech Certificates: A Worthwhile Expense?,"Curious what people here think about this article: [
Responsible Tech Certificates: A Worthwhile Expense?
](https://alltechishuman.org/all-tech-is-human-blog/responsible-tech-certificates-a-worthwhile-expense) 

Personally I find these to be mostly a waste of money, but as someone who's interested in getting into ethical AI, was wondering if anyone has had a similar experience and if it helped them get their foot in the door.",4,5,2025-04-25T22:17:08+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k7xi9g/responsible_tech_certificates_a_worthwhile_expense/,"Responsible Tech Certificates: A Worthwhile Expense? Curious what people here think about this article: [
Responsible Tech Certificates: A Worthwhile Expense?
](https://alltechishuman.org/all-tech-is-human-blog/responsible-tech-certificates-a-worthwhile-expense) 

Personally I find these to be mostly a waste of money, but as someone who's interested in getting into ethical AI, was wondering if anyone has had a similar experience and if it helped them get their foot in the door.",responsible tech certificates a worthwhile expense curious what people here think about this article responsible tech certificates a worthwhile expense personally i find these to be mostly a waste of money but as someone whos interested in getting into ethical ai was wondering if anyone has had a similar experience and if it helped them get their foot in the door,responsible tech certificate worthwhile expense curious people think article responsible tech certificate worthwhile expense personally find waste money s interested get ethical ai wonder similar experience help foot door
1k76c0v,Step in the right or wrong direction long term?,"I’m a sophomore double majoring in Data Analytics and Data Engineering with a minor in Computer Science. (It sounds like a lot, but I came in with an associate’s degree from high school, so it’s honestly not a ton)

My end goal is to become a Data Scientist, ideally specializing in time-series forecasting or recommendation systems. I plan to go straight into a Master’s in Data Science after undergrad.

Today, I just got an offer for a Business Analyst Internship. The role focuses heavily on SQL and Power BI, but doesn’t involve any Python, machine learning, or advanced statistics. It’s a great opportunity and I’d be working with a Business Analytics team at a credit union, but I’m a bit torn.

Will having “Business Analyst Intern” on my resume make me look less competitive for future data science internships or full-time roles—especially compared to students who land internships with “Data Scientist” or “Data Science Intern” in the title?

I know I’m only a sophomore, and I don’t want to overthink it, but I also don’t want to unintentionally steer myself toward an analyst-only path.

Any advice or insight would be appreciated!",7,46,2025-04-24T23:16:01+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k76c0v/step_in_the_right_or_wrong_direction_long_term/,"Step in the right or wrong direction long term? I’m a sophomore double majoring in Data Analytics and Data Engineering with a minor in Computer Science. (It sounds like a lot, but I came in with an associate’s degree from high school, so it’s honestly not a ton)

My end goal is to become a Data Scientist, ideally specializing in time-series forecasting or recommendation systems. I plan to go straight into a Master’s in Data Science after undergrad.

Today, I just got an offer for a Business Analyst Internship. The role focuses heavily on SQL and Power BI, but doesn’t involve any Python, machine learning, or advanced statistics. It’s a great opportunity and I’d be working with a Business Analytics team at a credit union, but I’m a bit torn.

Will having “Business Analyst Intern” on my resume make me look less competitive for future data science internships or full-time roles—especially compared to students who land internships with “Data Scientist” or “Data Science Intern” in the title?

I know I’m only a sophomore, and I don’t want to overthink it, but I also don’t want to unintentionally steer myself toward an analyst-only path.

Any advice or insight would be appreciated!",step in the right or wrong direction long term im a sophomore double majoring in data analytics and data engineering with a minor in computer science it sounds like a lot but i came in with an associates degree from high school so its honestly not a ton my end goal is to become a data scientist ideally specializing in timeseries forecasting or recommendation systems i plan to go straight into a masters in data science after undergrad today i just got an offer for a business analyst internship the role focuses heavily on sql and power bi but doesnt involve any python machine learning or advanced statistics its a great opportunity and id be working with a business analytics team at a credit union but im a bit torn will having business analyst intern on my resume make me look less competitive for future data science internships or fulltime rolesespecially compared to students who land internships with data scientist or data science intern in the title i know im only a sophomore and i dont want to overthink it but i also dont want to unintentionally steer myself toward an analystonly path any advice or insight would be appreciated,step right wrong direction long term m sophomore double majoring data analytic datum engineering minor computer science sound like lot come associate degree high school honestly ton end goal data scientist ideally specialize timeserie forecasting recommendation system plan straight master datum science undergrad today get offer business analyst internship role focus heavily sql power bi not involve python machine learning advanced statistic great opportunity d work business analytic team credit union m bit torn have business analyst intern resume look competitive future datum science internship fulltime rolesespecially compare student land internship datum scientist datum science intern title know m sophomore not want overthink not want unintentionally steer analystonly path advice insight appreciate
1k6za0y,Signs of burnout?,"Hey all,

I posted a little bit about my current job situation in a previous post: [https://www.reddit.com/r/datascience/comments/1javfus/do\_you\_deal\_with\_unrealistic\_expectations\_from/](https://www.reddit.com/r/datascience/comments/1javfus/do_you_deal_with_unrealistic_expectations_from/)

Ever since the year started, I've just been looped into tasks where I have no context what it's supposed to do, don't have the requirements clear, frequently have my boss try to get something out without clear requirements and then us fixing it after the fact with another co-worker constantly expressing dissapointment and frustration for things not churning out sooner.

For the past month, I've been working several 12-14 hour shifts. On days when I don't have quick turnaround times, I've noticed myself losing focus, losing interest in the work overall. I signed up for a bunch of Udemy classes in the beginning of the year and feel like my headspace isn't there to upskill even though I had a lot of enthusiasm before. 

Has anybody gone through this situation and have advice? I want to change my job eventually in a few months, but I want to spend time preparing rather than just jump ship at the moment, esp in this market. ",36,21,2025-04-24T18:16:54+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k6za0y/signs_of_burnout/,"Signs of burnout? Hey all,

I posted a little bit about my current job situation in a previous post: [https://www.reddit.com/r/datascience/comments/1javfus/do\_you\_deal\_with\_unrealistic\_expectations\_from/](https://www.reddit.com/r/datascience/comments/1javfus/do_you_deal_with_unrealistic_expectations_from/)

Ever since the year started, I've just been looped into tasks where I have no context what it's supposed to do, don't have the requirements clear, frequently have my boss try to get something out without clear requirements and then us fixing it after the fact with another co-worker constantly expressing dissapointment and frustration for things not churning out sooner.

For the past month, I've been working several 12-14 hour shifts. On days when I don't have quick turnaround times, I've noticed myself losing focus, losing interest in the work overall. I signed up for a bunch of Udemy classes in the beginning of the year and feel like my headspace isn't there to upskill even though I had a lot of enthusiasm before. 

Has anybody gone through this situation and have advice? I want to change my job eventually in a few months, but I want to spend time preparing rather than just jump ship at the moment, esp in this market. ",signs of burnout hey all i posted a little bit about my current job situation in a previous post ever since the year started ive just been looped into tasks where i have no context what its supposed to do dont have the requirements clear frequently have my boss try to get something out without clear requirements and then us fixing it after the fact with another coworker constantly expressing dissapointment and frustration for things not churning out sooner for the past month ive been working several hour shifts on days when i dont have quick turnaround times ive noticed myself losing focus losing interest in the work overall i signed up for a bunch of udemy classes in the beginning of the year and feel like my headspace isnt there to upskill even though i had a lot of enthusiasm before has anybody gone through this situation and have advice i want to change my job eventually in a few months but i want to spend time preparing rather than just jump ship at the moment esp in this market,sign burnout hey post little bit current job situation previous post year start ve loop task context suppose not requirement clear frequently boss try clear requirement fix fact coworker constantly express dissapointment frustration thing churn soon past month ve work hour shift day not quick turnaround time ve notice lose focus lose interest work overall sign bunch udemy class beginning year feel like headspace not upskill lot enthusiasm anybody go situation advice want change job eventually month want spend time prepare jump ship moment esp market
1k6wi45,"What are some universities that you believe are ""Cash-Cows""",,86,127,2025-04-24T16:25:16+00:00,datascience,/r/gradadmissions/comments/1k6b189/what_are_some_universities_that_you_believe_are/,"What are some universities that you believe are ""Cash-Cows"" ",what are some universities that you believe are cashcows,university believe cashcow
1k6tz9y,Leadership said they doesn’t understand what we do,"Our DS group was moved under a traditional IT org that is totally focused on delivery. We saw signs that they didn’t understand prework required to do the science side of the job, get the data clean, figure out the right features and models, etc. 

We have been briefing leadership on projects, goals, timelines. Seemed like they got it. Now they admit to my boss they really don’t understand what our group does at all. 

Very frustrating. Anyone else have this situation",194,77,2025-04-24T14:43:37+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k6tz9y/leadership_said_they_doesnt_understand_what_we_do/,"Leadership said they doesn’t understand what we do Our DS group was moved under a traditional IT org that is totally focused on delivery. We saw signs that they didn’t understand prework required to do the science side of the job, get the data clean, figure out the right features and models, etc. 

We have been briefing leadership on projects, goals, timelines. Seemed like they got it. Now they admit to my boss they really don’t understand what our group does at all. 

Very frustrating. Anyone else have this situation",leadership said they doesnt understand what we do our ds group was moved under a traditional it org that is totally focused on delivery we saw signs that they didnt understand prework required to do the science side of the job get the data clean figure out the right features and models etc we have been briefing leadership on projects goals timelines seemed like they got it now they admit to my boss they really dont understand what our group does at all very frustrating anyone else have this situation,leadership say not understand ds group move traditional org totally focused delivery see sign not understand prework require science job datum clean figure right feature model etc brief leadership project goal timeline like get admit boss not understand group frustrating situation
1k6rj0y,Deep Analysis — the analytics analogue to deep research,,12,0,2025-04-24T12:56:42+00:00,datascience,https://medium.com/firebird-technologies/deep-analysis-the-analytics-analogue-to-deep-research-45ecd8c60096,Deep Analysis — the analytics analogue to deep research ,deep analysis the analytics analogue to deep research,deep analysis analytic analogue deep research
1k6pqem,Polars: what is the status of compatibility with other Python packages?,,8,5,2025-04-24T11:22:17+00:00,datascience,/r/Python/comments/1k6ppc7/polars_what_is_the_status_of_compatibility_with/,Polars: what is the status of compatibility with other Python packages? ,polars what is the status of compatibility with other python packages,polar status compatibility python package
1k63zii,"To Interviewers who ask product metrics  cases study, what makes you say yes or no to a candidate, do you want complex metrics? Or basic works too?","Hi, 
I was curious to know if you are an interviewer, lest say at faang or similar big tech, what makes you feel yes this is good candidate and we can hire, what are the deal breakers or something that impress you or think that a red flag? 

Like you want them to think about out of box metrics, or complex metrics or even basic engagement metrics like DAUs, conversions rates, view rates, etc are good enough? Also, i often see people mention a/b test whenever the questions asked so do you want them to go on deep in it?  Or anything you look them to answer? Also, how long do you want the conversation to happen?

Edit- also anything you think that makes them stands out or topics they mention make them stands out? ",49,17,2025-04-23T16:47:23+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k63zii/to_interviewers_who_ask_product_metrics_cases/,"To Interviewers who ask product metrics  cases study, what makes you say yes or no to a candidate, do you want complex metrics? Or basic works too? Hi, 
I was curious to know if you are an interviewer, lest say at faang or similar big tech, what makes you feel yes this is good candidate and we can hire, what are the deal breakers or something that impress you or think that a red flag? 

Like you want them to think about out of box metrics, or complex metrics or even basic engagement metrics like DAUs, conversions rates, view rates, etc are good enough? Also, i often see people mention a/b test whenever the questions asked so do you want them to go on deep in it?  Or anything you look them to answer? Also, how long do you want the conversation to happen?

Edit- also anything you think that makes them stands out or topics they mention make them stands out? ",to interviewers who ask product metrics cases study what makes you say yes or no to a candidate do you want complex metrics or basic works too hi i was curious to know if you are an interviewer lest say at faang or similar big tech what makes you feel yes this is good candidate and we can hire what are the deal breakers or something that impress you or think that a red flag like you want them to think about out of box metrics or complex metrics or even basic engagement metrics like daus conversions rates view rates etc are good enough also i often see people mention ab test whenever the questions asked so do you want them to go on deep in it or anything you look them to answer also how long do you want the conversation to happen edit also anything you think that makes them stands out or topics they mention make them stands out,interviewer ask product metric case study make yes candidate want complex metric basic work hi curious know interviewer lest faang similar big tech make feel yes good candidate hire deal breaker impress think red flag like want think box metric complex metric basic engagement metric like daus conversion rate view rate etc good people mention ab test question ask want deep look answer long want conversation happen edit think make stand topic mention stand
1k60gey,How can I come up with better feature ideas?,"I'm currently working on a credit scoring model. I have tried various feature engineering approaches using my domain knowledge, and my manager has also shared some suggestions. Additionally, I’ve explored several feature selection techniques. However, the model's performance still isn't meeting my manager’s expectations.

At this point, I’ve even tried manually adding and removing features step by step to observe any changes in performance. I understand that modeling is all about domain knowledge, but I can't help wishing there were a magical tool that could suggest the best feature ideas.",20,19,2025-04-23T14:24:10+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k60gey/how_can_i_come_up_with_better_feature_ideas/,"How can I come up with better feature ideas? I'm currently working on a credit scoring model. I have tried various feature engineering approaches using my domain knowledge, and my manager has also shared some suggestions. Additionally, I’ve explored several feature selection techniques. However, the model's performance still isn't meeting my manager’s expectations.

At this point, I’ve even tried manually adding and removing features step by step to observe any changes in performance. I understand that modeling is all about domain knowledge, but I can't help wishing there were a magical tool that could suggest the best feature ideas.",how can i come up with better feature ideas im currently working on a credit scoring model i have tried various feature engineering approaches using my domain knowledge and my manager has also shared some suggestions additionally ive explored several feature selection techniques however the models performance still isnt meeting my managers expectations at this point ive even tried manually adding and removing features step by step to observe any changes in performance i understand that modeling is all about domain knowledge but i cant help wishing there were a magical tool that could suggest the best feature ideas,come well feature idea m currently work credit scoring model try feature engineering approach domain knowledge manager share suggestion additionally ve explore feature selection technique model performance not meet manager expectation point ve try manually add remove feature step step observe change performance understand modeling domain knowledge not help wish magical tool suggest good feature idea
1k5ikzd,How is your teaming using AI for DS?,"I see a lot of job posting saying “leverage AI to add value”. What does this actually mean? Using AI to complete DS work or is AI is an extension of DS work?

I’ve seen a lot of cool is cases outside of DS like content generation or agents but not as much in DS itself. Mostly just code assist of document creation/summary which is a tool to help DS but not DS itself.",74,56,2025-04-22T21:48:15+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k5ikzd/how_is_your_teaming_using_ai_for_ds/,"How is your teaming using AI for DS? I see a lot of job posting saying “leverage AI to add value”. What does this actually mean? Using AI to complete DS work or is AI is an extension of DS work?

I’ve seen a lot of cool is cases outside of DS like content generation or agents but not as much in DS itself. Mostly just code assist of document creation/summary which is a tool to help DS but not DS itself.",how is your teaming using ai for ds i see a lot of job posting saying leverage ai to add value what does this actually mean using ai to complete ds work or is ai is an extension of ds work ive seen a lot of cool is cases outside of ds like content generation or agents but not as much in ds itself mostly just code assist of document creationsummary which is a tool to help ds but not ds itself,team ai ds lot job posting say leverage ai add value actually mean ai complete ds work ai extension ds work ve see lot cool case outside ds like content generation agent ds code assist document creationsummary tool help ds ds
1k52w1u,Request for Review,,0,7,2025-04-22T10:23:19+00:00,datascience,/r/learndatascience/comments/1k4xcj2/request_for_review/,Request for Review ,request for review,request review
1k4u3dp,Any experience with Incrmntal for marketing studies?,"My firm was contacted by a marketing measurement company called Incrmntal. Their product is an MMM that uses interrupted time series (i.e. synthetic control) with a reinforcement learning step. Their documentation is very light. There are no simulation studies and just a handful of comparisons with A/B tests. It's not clear what the reinforcement learning process is, if it's there at all, and the time series model is similarly opaque. The whole thing seems pretty scammy. The marketing materials are fairly aggressive and make repeatedly inaccurate claims.

Has anyone used them? Any insights into what they're doing? How well did it work for you?",7,5,2025-04-22T01:13:22+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k4u3dp/any_experience_with_incrmntal_for_marketing/,"Any experience with Incrmntal for marketing studies? My firm was contacted by a marketing measurement company called Incrmntal. Their product is an MMM that uses interrupted time series (i.e. synthetic control) with a reinforcement learning step. Their documentation is very light. There are no simulation studies and just a handful of comparisons with A/B tests. It's not clear what the reinforcement learning process is, if it's there at all, and the time series model is similarly opaque. The whole thing seems pretty scammy. The marketing materials are fairly aggressive and make repeatedly inaccurate claims.

Has anyone used them? Any insights into what they're doing? How well did it work for you?",any experience with incrmntal for marketing studies my firm was contacted by a marketing measurement company called incrmntal their product is an mmm that uses interrupted time series ie synthetic control with a reinforcement learning step their documentation is very light there are no simulation studies and just a handful of comparisons with ab tests its not clear what the reinforcement learning process is if its there at all and the time series model is similarly opaque the whole thing seems pretty scammy the marketing materials are fairly aggressive and make repeatedly inaccurate claims has anyone used them any insights into what theyre doing how well did it work for you,experience incrmntal marketing study firm contact marketing measurement company call incrmntal product mmm use interrupted time series ie synthetic control reinforcement learning step documentation light simulation study handful comparison ab test clear reinforcement learning process time series model similarly opaque thing pretty scammy marketing material fairly aggressive repeatedly inaccurate claim insight work
1k4q8b8,In an effort to keep learning,"I have a new DS starting soon...modalities change and all of that, more importantly, for those of you hired in the last year, what are some things you wish were presented earlier than they were ( or things done in general)? Looking to make this a very positive experience for the new employee.",25,24,2025-04-21T22:12:22+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k4q8b8/in_an_effort_to_keep_learning/,"In an effort to keep learning I have a new DS starting soon...modalities change and all of that, more importantly, for those of you hired in the last year, what are some things you wish were presented earlier than they were ( or things done in general)? Looking to make this a very positive experience for the new employee.",in an effort to keep learning i have a new ds starting soonmodalities change and all of that more importantly for those of you hired in the last year what are some things you wish were presented earlier than they were or things done in general looking to make this a very positive experience for the new employee,effort learn new ds start soonmodalitie change importantly hire year thing wish present early thing general look positive experience new employee
1k4geso,Ever met a person you think lied about working in Data Science?,"You ever get the feeling someone online or in-person just straight up lied to you about having a Data Science job (Data Scientist, Data Analyst, Data Engineer, Machine Learning Engineer, Data Architect, etc.)?

I was recently talking to someone at a technical meet-up for working professionals and one person was saying some really weird stuff. It was like they had heard of the technical terms before, but didn't actually have the experience working with the technologies/skills. For example, they mentioned that they had ""All sorts of experience with Kafka"" but didn't know that it is a tool that Data Engineers and related professionals could use for their workflows. They also mixed up the definitions of common machine learning models, what said models could do for a business, NoSQL & SQL, etc. It was jarring.

Also, sometimes I get the impression that a minority of people on this subreddit come on and lie about ever having a Data Science job. The more obvious examples are those who post the Chat-GPT answers to post questions. No shade thrown to anyone here. I encounter many qualified people here and have learned new stuff just reading through posts.

Any of you ever had an experience like that?

**Edit:** Hello all. Thank you for all of the responses on this post. I have gotten some good perspective, some hilarious comments, and some cool advice. I appreciate all of you on this sub-reddit.

I do want to say that I do not believe that all Data Scientists need to know Kafka (or any other specific tech. I don't know a bunch of stuff). I brought up the Kafka example because it was the most egregious (the person claimed to have all these years of experience, but didn't know a bunch of stuff including the basics). The conversation was 35 minutes, so I only wanted to bring up the outliers/notable examples.

And I want to emphasize that I was talking about **all** Data Science jobs (Data Scientist, Data Analyst, Data Engineer, Machine Learning Engineer, Data Architect, etc.). Because I think that these are all valid roles and that we all have unique experiences, skills, and knowledge to bring to this field.

Anyways, I appreciate all the comments and I will read through them after work.",277,153,2025-04-21T15:30:34+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k4geso/ever_met_a_person_you_think_lied_about_working_in/,"Ever met a person you think lied about working in Data Science? You ever get the feeling someone online or in-person just straight up lied to you about having a Data Science job (Data Scientist, Data Analyst, Data Engineer, Machine Learning Engineer, Data Architect, etc.)?

I was recently talking to someone at a technical meet-up for working professionals and one person was saying some really weird stuff. It was like they had heard of the technical terms before, but didn't actually have the experience working with the technologies/skills. For example, they mentioned that they had ""All sorts of experience with Kafka"" but didn't know that it is a tool that Data Engineers and related professionals could use for their workflows. They also mixed up the definitions of common machine learning models, what said models could do for a business, NoSQL & SQL, etc. It was jarring.

Also, sometimes I get the impression that a minority of people on this subreddit come on and lie about ever having a Data Science job. The more obvious examples are those who post the Chat-GPT answers to post questions. No shade thrown to anyone here. I encounter many qualified people here and have learned new stuff just reading through posts.

Any of you ever had an experience like that?

**Edit:** Hello all. Thank you for all of the responses on this post. I have gotten some good perspective, some hilarious comments, and some cool advice. I appreciate all of you on this sub-reddit.

I do want to say that I do not believe that all Data Scientists need to know Kafka (or any other specific tech. I don't know a bunch of stuff). I brought up the Kafka example because it was the most egregious (the person claimed to have all these years of experience, but didn't know a bunch of stuff including the basics). The conversation was 35 minutes, so I only wanted to bring up the outliers/notable examples.

And I want to emphasize that I was talking about **all** Data Science jobs (Data Scientist, Data Analyst, Data Engineer, Machine Learning Engineer, Data Architect, etc.). Because I think that these are all valid roles and that we all have unique experiences, skills, and knowledge to bring to this field.

Anyways, I appreciate all the comments and I will read through them after work.",ever met a person you think lied about working in data science you ever get the feeling someone online or inperson just straight up lied to you about having a data science job data scientist data analyst data engineer machine learning engineer data architect etc i was recently talking to someone at a technical meetup for working professionals and one person was saying some really weird stuff it was like they had heard of the technical terms before but didnt actually have the experience working with the technologiesskills for example they mentioned that they had all sorts of experience with kafka but didnt know that it is a tool that data engineers and related professionals could use for their workflows they also mixed up the definitions of common machine learning models what said models could do for a business nosql sql etc it was jarring also sometimes i get the impression that a minority of people on this subreddit come on and lie about ever having a data science job the more obvious examples are those who post the chatgpt answers to post questions no shade thrown to anyone here i encounter many qualified people here and have learned new stuff just reading through posts any of you ever had an experience like that edit hello all thank you for all of the responses on this post i have gotten some good perspective some hilarious comments and some cool advice i appreciate all of you on this subreddit i do want to say that i do not believe that all data scientists need to know kafka or any other specific tech i dont know a bunch of stuff i brought up the kafka example because it was the most egregious the person claimed to have all these years of experience but didnt know a bunch of stuff including the basics the conversation was minutes so i only wanted to bring up the outliersnotable examples and i want to emphasize that i was talking about all data science jobs data scientist data analyst data engineer machine learning engineer data architect etc because i think that these are all valid roles and that we all have unique experiences skills and knowledge to bring to this field anyways i appreciate all the comments and i will read through them after work,meet person think lie work data science feeling online inperson straight lie have data science job data scientist data analyst data engineer machine learn engineer datum architect etc recently talk technical meetup work professional person say weird stuff like hear technical term not actually experience work technologiesskill example mention sort experience kafka not know tool data engineer related professional use workflow mix definition common machine learning model say model business nosql sql etc jarring impression minority people subreddit come lie have data science job obvious example post chatgpt answer post question shade throw encounter qualified people learn new stuff read post experience like edit hello thank response post get good perspective hilarious comment cool advice appreciate subreddit want believe data scientist need know kafka specific tech not know bunch stuff bring kafka example egregious person claim year experience not know bunch stuff include basic conversation minute want bring outliersnotable example want emphasize talk datum science job data scientist data analyst data engineer machine learn engineer datum architect etc think valid role unique experience skill knowledge bring field anyways appreciate comment read work
1k44mgg,"Weekly Entering & Transitioning - Thread 21 Apr, 2025 - 28 Apr, 2025"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",9,37,2025-04-21T04:01:43+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k44mgg/weekly_entering_transitioning_thread_21_apr_2025/,"Weekly Entering & Transitioning - Thread 21 Apr, 2025 - 28 Apr, 2025  

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",weekly entering transitioning thread apr apr welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the and resources pages on our wiki you can also search for answers in,weekly enter transition thread apr apr welcome week enter transition thread thread question getting start study transition data science field topic include learn resource eg book tutorial video traditional education eg schools degree elective alternative education eg online course bootcamp job search question eg resume apply career prospect elementary question eg start wait answer community check resource page wiki search answer
1k3nxj7,"Pandas, why the hype?","I'm an R user and I'm at the point where I'm not really improving my programming skills all that much, so I finally decided to learn Python in earnest. I've put together a few projects that combine general programming, ML implementation, and basic data analysis. And overall, I quite like python and it really hasn't been too difficult to pick up. And the few times I've run into an issue, I've generally blamed it on R (e.g . the day I learned about mutable objects was a frustrating one). However, basic analysis - like summary stats - feels impossible.

All this time I've heard Python users hype up pandas. But now that I am actually learning it, I can't help think why? Simple aggregations and other tasks require so much code. But more confusng is the syntax, which seems to be odds with itself at times.  Sometimes we put the column name in the parentheses of a function, other times be but the column name in brackets before the function. Sometimes we call the function normally (e.g.mean()), other times it is contain by quotations. The whole thing reminds me of the Angostura bitters bottle story, where one of the brothers designed the bottles and the other designed the label without talking to one another.

Anyway, this wasn't really meant to be a rant. I'm sticking with it, but does it get better? Should I look at polars instead?

To R users, everyone needs to figure out what Hadley Wickham drinks and send him a case of it.",403,211,2025-04-20T14:36:36+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k3nxj7/pandas_why_the_hype/,"Pandas, why the hype? I'm an R user and I'm at the point where I'm not really improving my programming skills all that much, so I finally decided to learn Python in earnest. I've put together a few projects that combine general programming, ML implementation, and basic data analysis. And overall, I quite like python and it really hasn't been too difficult to pick up. And the few times I've run into an issue, I've generally blamed it on R (e.g . the day I learned about mutable objects was a frustrating one). However, basic analysis - like summary stats - feels impossible.

All this time I've heard Python users hype up pandas. But now that I am actually learning it, I can't help think why? Simple aggregations and other tasks require so much code. But more confusng is the syntax, which seems to be odds with itself at times.  Sometimes we put the column name in the parentheses of a function, other times be but the column name in brackets before the function. Sometimes we call the function normally (e.g.mean()), other times it is contain by quotations. The whole thing reminds me of the Angostura bitters bottle story, where one of the brothers designed the bottles and the other designed the label without talking to one another.

Anyway, this wasn't really meant to be a rant. I'm sticking with it, but does it get better? Should I look at polars instead?

To R users, everyone needs to figure out what Hadley Wickham drinks and send him a case of it.",pandas why the hype im an r user and im at the point where im not really improving my programming skills all that much so i finally decided to learn python in earnest ive put together a few projects that combine general programming ml implementation and basic data analysis and overall i quite like python and it really hasnt been too difficult to pick up and the few times ive run into an issue ive generally blamed it on r eg the day i learned about mutable objects was a frustrating one however basic analysis like summary stats feels impossible all this time ive heard python users hype up pandas but now that i am actually learning it i cant help think why simple aggregations and other tasks require so much code but more confusng is the syntax which seems to be odds with itself at times sometimes we put the column name in the parentheses of a function other times be but the column name in brackets before the function sometimes we call the function normally egmean other times it is contain by quotations the whole thing reminds me of the angostura bitters bottle story where one of the brothers designed the bottles and the other designed the label without talking to one another anyway this wasnt really meant to be a rant im sticking with it but does it get better should i look at polars instead to r users everyone needs to figure out what hadley wickham drinks and send him a case of it,panda hype m r user m point m improve programming skill finally decide learn python earnest ve project combine general programming ml implementation basic data analysis overall like python not difficult pick time ve run issue ve generally blame r eg day learn mutable object frustrating basic analysis like summary stat feel impossible time ve hear python user hype panda actually learn not help think simple aggregation task require code confusng syntax odd time column parenthesis function time column bracket function function normally egmean time contain quotation thing remind angostura bitter bottle story brother design bottle design label talk not mean rant m stick well look polar instead r user need figure hadley wickham drink send case
1k3jt7b,Is there something similar tailored for Data Science interviews? | asking on behalf of my friend,,5,0,2025-04-20T10:42:51+00:00,datascience,/r/learnmachinelearning/comments/1k2z3g1/is_there_something_similar_tailored_for_data/,Is there something similar tailored for Data Science interviews? | asking on behalf of my friend ,is there something similar tailored for data science interviews asking on behalf of my friend,similar tailor datum science interview ask behalf friend
1k3e4nb,Unit tests,Serious question: Can anyone provide a real example of a series of unit tests applied to an MLOps flow? And when or how often do these unit tests get executed and who is checking them? Sorry if this question is too vague but I have never been presented an example of unit tests in production data science applications.,36,28,2025-04-20T04:03:47+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k3e4nb/unit_tests/,Unit tests Serious question: Can anyone provide a real example of a series of unit tests applied to an MLOps flow? And when or how often do these unit tests get executed and who is checking them? Sorry if this question is too vague but I have never been presented an example of unit tests in production data science applications.,unit tests serious question can anyone provide a real example of a series of unit tests applied to an mlops flow and when or how often do these unit tests get executed and who is checking them sorry if this question is too vague but i have never been presented an example of unit tests in production data science applications,unit test question provide real example series unit test apply mlop flow unit test execute check sorry question vague present example unit test production datum science application
1k33k6t,Finally releasing the Bambu Timelapse Dataset – open video data for print‑failure ML (sorry for the delay!),"Hey everyone!

I know it’s been a **long minute** since my original call‑for‑clips – life got hectic and the project had to sit on the back burner a bit longer than I’d hoped. 😅 Thanks for bearing with me!

# What’s new?

* **The dataset is live** on Hugging Face and ready for download or contribution.
* **First models are on the way** (starting with **build‑plate identification**) – but I can’t promise an exact release timeline yet. Life still throws curveballs!

🔗 **Dataset page:** [https://huggingface.co/datasets/v2thegreat/bambu-timelapse-dataset](https://huggingface.co/datasets/v2thegreat/bambu-timelapse-dataset)

# What’s inside?

* **627 timelapse videos** from P1/X1 printers
* **81 full‑length camera recordings** straight off the printer cam
* Thumbnails + CSV metadata for quick indexing
* CC‑BY‑4.0 license – free for hobby, research, and even commercial use with proper attribution

# Why bother?

* It’s the **first fully open corpus** of Bambu timelapses; most prior failure‑detection work never shares raw data.
* Bambu Lab printers are everywhere, so the footage mirrors real‑world conditions.
* Great sandbox for manufacturing / QA projects—failure classification, anomaly detection, build‑plate detection, and more.

# Contribute your clips

1. Open a **Pull Request** on the repo (`originals/timelapses/<your_id>/`).
2. If PRs aren’t your jam, DM me and we’ll arrange a transfer link.
3. Please crop or blur anything private; aim for bed‑only views.

# Skill level

If you know some Python and basic ML, this is a perfect **intermediate** project to dive into computer vision. Total beginners can still poke around with the sample code, but training solid models will take a bit of experience.

Thanks again for everyone’s patience and for the clips already shared—can’t wait to see what the community builds with this!",19,5,2025-04-19T18:58:05+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k33k6t/finally_releasing_the_bambu_timelapse_dataset/,"Finally releasing the Bambu Timelapse Dataset – open video data for print‑failure ML (sorry for the delay!) Hey everyone!

I know it’s been a **long minute** since my original call‑for‑clips – life got hectic and the project had to sit on the back burner a bit longer than I’d hoped. 😅 Thanks for bearing with me!

# What’s new?

* **The dataset is live** on Hugging Face and ready for download or contribution.
* **First models are on the way** (starting with **build‑plate identification**) – but I can’t promise an exact release timeline yet. Life still throws curveballs!

🔗 **Dataset page:** [https://huggingface.co/datasets/v2thegreat/bambu-timelapse-dataset](https://huggingface.co/datasets/v2thegreat/bambu-timelapse-dataset)

# What’s inside?

* **627 timelapse videos** from P1/X1 printers
* **81 full‑length camera recordings** straight off the printer cam
* Thumbnails + CSV metadata for quick indexing
* CC‑BY‑4.0 license – free for hobby, research, and even commercial use with proper attribution

# Why bother?

* It’s the **first fully open corpus** of Bambu timelapses; most prior failure‑detection work never shares raw data.
* Bambu Lab printers are everywhere, so the footage mirrors real‑world conditions.
* Great sandbox for manufacturing / QA projects—failure classification, anomaly detection, build‑plate detection, and more.

# Contribute your clips

1. Open a **Pull Request** on the repo (`originals/timelapses/<your_id>/`).
2. If PRs aren’t your jam, DM me and we’ll arrange a transfer link.
3. Please crop or blur anything private; aim for bed‑only views.

# Skill level

If you know some Python and basic ML, this is a perfect **intermediate** project to dive into computer vision. Total beginners can still poke around with the sample code, but training solid models will take a bit of experience.

Thanks again for everyone’s patience and for the clips already shared—can’t wait to see what the community builds with this!",finally releasing the bambu timelapse dataset open video data for printfailure ml sorry for the delay hey everyone i know its been a long minute since my original callforclips life got hectic and the project had to sit on the back burner a bit longer than id hoped grinningfacewithsweat thanks for bearing with me whats new the dataset is live on hugging face and ready for download or contribution first models are on the way starting with buildplate identification but i cant promise an exact release timeline yet life still throws curveballs link dataset page whats inside timelapse videos from px printers fulllength camera recordings straight off the printer cam thumbnails csv metadata for quick indexing ccby license free for hobby research and even commercial use with proper attribution why bother its the first fully open corpus of bambu timelapses most prior failuredetection work never shares raw data bambu lab printers are everywhere so the footage mirrors realworld conditions great sandbox for manufacturing qa projectsfailure classification anomaly detection buildplate detection and more contribute your clips open a pull request on the repo originalstimelapsesyourid if prs arent your jam dm me and well arrange a transfer link please crop or blur anything private aim for bedonly views skill level if you know some python and basic ml this is a perfect intermediate project to dive into computer vision total beginners can still poke around with the sample code but training solid models will take a bit of experience thanks again for everyones patience and for the clips already sharedcant wait to see what the community builds with this,finally release bambu timelapse dataset open video datum printfailure ml sorry delay hey know long minute original callforclip life get hectic project sit burner bit long d hope grinningfacewithsweat thank bear s new dataset live hug face ready download contribution model way start buildplate identification not promise exact release timeline life throw curveball link dataset page s inside timelapse video px printer fulllength camera recording straight printer cam thumbnail csv metadata quick indexing ccby license free hobby research commercial use proper attribution bother fully open corpus bambu timelapse prior failuredetection work share raw datum bambu lab printer footage mirror realworld conditions great sandbox manufacture qa projectsfailure classification anomaly detection buildplate detection contribute clip open pull request repo originalstimelapsesyourid prs not jam dm arrange transfer link crop blur private aim bedonly view skill level know python basic ml perfect intermediate project dive computer vision total beginner poke sample code train solid model bit experience thank everyone patience clip sharedcant wait community build
1k32lrl,"Python users, which R packages do you use, if any?","I'm currently writing an R package called [rixpress](https://github.com/b-rodrigues/rixpress) which aims to set up reproducible pipelines with simple R code by using Nix as the underlying build tool. Because it uses Nix as the build tool, it is also possible to write targets that are built using Python.
[Here is an example of a pipeline that mixes R and Python.](https://github.com/b-rodrigues/rixpress_demos/blob/master/python_r/gen-pipeline.R)

I think rixpress can be quite useful to Python users as well (and I might even translate the package to Python in the future), and I'm looking for examples of Python users that need to also work with certain R packages. These examples would help me make sure that passing objects from and between the two languages can be as seamless as possible.

So Python data scientists, which R packages do you use, if any? 
",101,75,2025-04-19T18:15:04+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k32lrl/python_users_which_r_packages_do_you_use_if_any/,"Python users, which R packages do you use, if any? I'm currently writing an R package called [rixpress](https://github.com/b-rodrigues/rixpress) which aims to set up reproducible pipelines with simple R code by using Nix as the underlying build tool. Because it uses Nix as the build tool, it is also possible to write targets that are built using Python.
[Here is an example of a pipeline that mixes R and Python.](https://github.com/b-rodrigues/rixpress_demos/blob/master/python_r/gen-pipeline.R)

I think rixpress can be quite useful to Python users as well (and I might even translate the package to Python in the future), and I'm looking for examples of Python users that need to also work with certain R packages. These examples would help me make sure that passing objects from and between the two languages can be as seamless as possible.

So Python data scientists, which R packages do you use, if any? 
",python users which r packages do you use if any im currently writing an r package called which aims to set up reproducible pipelines with simple r code by using nix as the underlying build tool because it uses nix as the build tool it is also possible to write targets that are built using python i think rixpress can be quite useful to python users as well and i might even translate the package to python in the future and im looking for examples of python users that need to also work with certain r packages these examples would help me make sure that passing objects from and between the two languages can be as seamless as possible so python data scientists which r packages do you use if any,python user r package use m currently write r package call aim set reproducible pipeline simple r code nix underlie build tool use nix build tool possible write target build python think rixpress useful python user translate package python future m look example python user need work certain r package example help sure pass object language seamless possible python data scientist r package use
1k2y84g,Data science content gap,"I’m trying to get back into the habit of writing data science articles. I can cover a wide range of topics, including A/B testing, causal inference, and model development and deployment. I’d love to hear from this community—what kinds of articles or posts would be most valuable to you? I know there’s already a lot of content out there, and I’m to understand I’m writing something people find valuable. 

Edit thanks for the response: 

I’ve learned that people want to see more real-world data science applications. Here are a few topics I could write about:

	•	Using time series forecasting to determine the best location for building a hydro power plant
	•	Developing top-line KPI metrics to track product or business health
	•	Modeling CLV for B2B businesses, especially where most revenue comes from a few accounts
	•	Applying quasi-experiments to measure the impact of marketing campaigns
	•	Prioritizing different GenAI opportunities 
	•	Detecting survey fraud by analyzing mouse movement
      - developing a full end-to- end modeling. ",58,36,2025-04-19T15:01:46+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k2y84g/data_science_content_gap/,"Data science content gap I’m trying to get back into the habit of writing data science articles. I can cover a wide range of topics, including A/B testing, causal inference, and model development and deployment. I’d love to hear from this community—what kinds of articles or posts would be most valuable to you? I know there’s already a lot of content out there, and I’m to understand I’m writing something people find valuable. 

Edit thanks for the response: 

I’ve learned that people want to see more real-world data science applications. Here are a few topics I could write about:

	•	Using time series forecasting to determine the best location for building a hydro power plant
	•	Developing top-line KPI metrics to track product or business health
	•	Modeling CLV for B2B businesses, especially where most revenue comes from a few accounts
	•	Applying quasi-experiments to measure the impact of marketing campaigns
	•	Prioritizing different GenAI opportunities 
	•	Detecting survey fraud by analyzing mouse movement
      - developing a full end-to- end modeling. ",data science content gap im trying to get back into the habit of writing data science articles i can cover a wide range of topics including ab testing causal inference and model development and deployment id love to hear from this communitywhat kinds of articles or posts would be most valuable to you i know theres already a lot of content out there and im to understand im writing something people find valuable edit thanks for the response ive learned that people want to see more realworld data science applications here are a few topics i could write about using time series forecasting to determine the best location for building a hydro power plant developing topline kpi metrics to track product or business health modeling clv for bb businesses especially where most revenue comes from a few accounts applying quasiexperiments to measure the impact of marketing campaigns prioritizing different genai opportunities detecting survey fraud by analyzing mouse movement developing a full endto end modeling,data science content gap m try habit write data science article cover wide range topic include ab testing causal inference model development deployment d love hear communitywhat kind article post valuable know s lot content m understand m write people find valuable edit thank response ve learn people want realworld datum science application topic write time series forecast determine good location build hydro power plant develop topline kpi metric track product business health modeling clv bb business especially revenue come account apply quasiexperiment measure impact marketing campaign prioritize different genai opportunity detect survey fraud analyze mouse movement develop endto end modeling
1k2u4nd,Leverage Points for a Design Matrix with Mainly Categorial Features,"Hello! I hope this is a stupid question and gets quickly resolved. As per title, I have a design matrix with a high amount of categorial features. I am applying a linear regression model on the data set (mainly for training myself to get familiarity with linear regression). The model has a high amount of categorial features that I have one-hot encoded.

Now I try to figure out high leverage points for the design matrix. After a couple of attempts I was wondering if that would even make sense and how to evaluate if determining high leverage points would generally make sense in this scenario.

After asking ChatGPT (which provided a weird answer I know is incorrect) and searching a bit I found nothing explaining this. So, I thought I come here and ask:

* In how far does it make sense to compute/check for leverage values given that there is a high amount of categorial features?
* How to compute them? Would I use the diagonal of the HAT matrix or is there eventually another technique?

  
I am happy about any advise or hint, explanation or approach that gives me some clarity in this scenario. Thank you!!

 ",8,1,2025-04-19T11:27:41+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k2u4nd/leverage_points_for_a_design_matrix_with_mainly/,"Leverage Points for a Design Matrix with Mainly Categorial Features Hello! I hope this is a stupid question and gets quickly resolved. As per title, I have a design matrix with a high amount of categorial features. I am applying a linear regression model on the data set (mainly for training myself to get familiarity with linear regression). The model has a high amount of categorial features that I have one-hot encoded.

Now I try to figure out high leverage points for the design matrix. After a couple of attempts I was wondering if that would even make sense and how to evaluate if determining high leverage points would generally make sense in this scenario.

After asking ChatGPT (which provided a weird answer I know is incorrect) and searching a bit I found nothing explaining this. So, I thought I come here and ask:

* In how far does it make sense to compute/check for leverage values given that there is a high amount of categorial features?
* How to compute them? Would I use the diagonal of the HAT matrix or is there eventually another technique?

  
I am happy about any advise or hint, explanation or approach that gives me some clarity in this scenario. Thank you!!

 ",leverage points for a design matrix with mainly categorial features hello i hope this is a stupid question and gets quickly resolved as per title i have a design matrix with a high amount of categorial features i am applying a linear regression model on the data set mainly for training myself to get familiarity with linear regression the model has a high amount of categorial features that i have onehot encoded now i try to figure out high leverage points for the design matrix after a couple of attempts i was wondering if that would even make sense and how to evaluate if determining high leverage points would generally make sense in this scenario after asking chatgpt which provided a weird answer i know is incorrect and searching a bit i found nothing explaining this so i thought i come here and ask in how far does it make sense to computecheck for leverage values given that there is a high amount of categorial features how to compute them would i use the diagonal of the hat matrix or is there eventually another technique i am happy about any advise or hint explanation or approach that gives me some clarity in this scenario thank you,leverage point design matrix mainly categorial feature hello hope stupid question get quickly resolve title design matrix high categorial feature apply linear regression model datum set mainly train familiarity linear regression model high categorial feature onehot encode try figure high leverage point design matrix couple attempt wonder sense evaluate determine high leverage point generally sense scenario ask chatgpt provide weird answer know incorrect search bit find explain think come ask far sense computecheck leverage value give high categorial feature compute use diagonal hat matrix eventually technique happy advise hint explanation approach give clarity scenario thank
1k2igce,What SWE/AI Engineer skills in 2025 can I learn to complement Data Science?,"At my company currently - the hype is to use LLMs and GenAI at every intersection.

I have seen this means that a lot of DS work is now instead handed to SWEs, and the 'modelling' is all a GPT/API call.

Maybe this is just a feature of my company and the way they look at their tech stack, but I feel that DS is not getting as many projects and things are going to the SWEs only, as they can quickly build, and rapidly deploy into product.

I want to better learn how to integrate GenAI features/apps in our JavaScript based product, so that I can also build and integrate, and build working PoCs, rather than being trapped in notebooks. 

I'm not sure if I should just learn raw JS, because I'd even want to know how to put things into a silent test as an example, where predictions are made but no prediction is shown to the user.

Maybe the more apt title is going from a DS -> AI Engineer, and what skills to learn to get there?",83,32,2025-04-18T23:15:55+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k2igce/what_sweai_engineer_skills_in_2025_can_i_learn_to/,"What SWE/AI Engineer skills in 2025 can I learn to complement Data Science? At my company currently - the hype is to use LLMs and GenAI at every intersection.

I have seen this means that a lot of DS work is now instead handed to SWEs, and the 'modelling' is all a GPT/API call.

Maybe this is just a feature of my company and the way they look at their tech stack, but I feel that DS is not getting as many projects and things are going to the SWEs only, as they can quickly build, and rapidly deploy into product.

I want to better learn how to integrate GenAI features/apps in our JavaScript based product, so that I can also build and integrate, and build working PoCs, rather than being trapped in notebooks. 

I'm not sure if I should just learn raw JS, because I'd even want to know how to put things into a silent test as an example, where predictions are made but no prediction is shown to the user.

Maybe the more apt title is going from a DS -> AI Engineer, and what skills to learn to get there?",what sweai engineer skills in can i learn to complement data science at my company currently the hype is to use llms and genai at every intersection i have seen this means that a lot of ds work is now instead handed to swes and the modelling is all a gptapi call maybe this is just a feature of my company and the way they look at their tech stack but i feel that ds is not getting as many projects and things are going to the swes only as they can quickly build and rapidly deploy into product i want to better learn how to integrate genai featuresapps in our javascript based product so that i can also build and integrate and build working pocs rather than being trapped in notebooks im not sure if i should just learn raw js because id even want to know how to put things into a silent test as an example where predictions are made but no prediction is shown to the user maybe the more apt title is going from a ds ai engineer and what skills to learn to get there,sweai engineer skill learn complement data science company currently hype use llm genai intersection see mean lot ds work instead hand swe modelling gptapi maybe feature company way look tech stack feel ds get project thing go swe quickly build rapidly deploy product want well learn integrate genai featuresapp javascript base product build integrate build work poc trap notebook m sure learn raw js d want know thing silent test example prediction prediction show user maybe apt title go ds ai engineer skill learn
1k2ax74,What does a good DS manager look like to you? How does one manage a DS project?,"Hi all, 

I have found myself numerous times in leadership roles for data science projects. I never feel that I am doing a sufficient job. I find that I either end have up doing a lot of the work on my own and failing to split up task in the data science realm. A lot of these projects, and I hate to say it like this without sounding cocky, I feel that I can do on my own from end to end. Maybe some minimal support from other teams in helping with data flow issues, etc. I'm not a manager by any means, I am individual contributor. 

For those in this subreddit who are managers, what are some ways you found success in managing data science teams and projects? For those as individual contributors, what are some things that you like to have in a data science manager?",57,23,2025-04-18T17:43:54+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k2ax74/what_does_a_good_ds_manager_look_like_to_you_how/,"What does a good DS manager look like to you? How does one manage a DS project? Hi all, 

I have found myself numerous times in leadership roles for data science projects. I never feel that I am doing a sufficient job. I find that I either end have up doing a lot of the work on my own and failing to split up task in the data science realm. A lot of these projects, and I hate to say it like this without sounding cocky, I feel that I can do on my own from end to end. Maybe some minimal support from other teams in helping with data flow issues, etc. I'm not a manager by any means, I am individual contributor. 

For those in this subreddit who are managers, what are some ways you found success in managing data science teams and projects? For those as individual contributors, what are some things that you like to have in a data science manager?",what does a good ds manager look like to you how does one manage a ds project hi all i have found myself numerous times in leadership roles for data science projects i never feel that i am doing a sufficient job i find that i either end have up doing a lot of the work on my own and failing to split up task in the data science realm a lot of these projects and i hate to say it like this without sounding cocky i feel that i can do on my own from end to end maybe some minimal support from other teams in helping with data flow issues etc im not a manager by any means i am individual contributor for those in this subreddit who are managers what are some ways you found success in managing data science teams and projects for those as individual contributors what are some things that you like to have in a data science manager,good ds manager look like manage ds project hi find numerous time leadership role datum science project feel sufficient job find end lot work fail split task data science realm lot project hate like sound cocky feel end end maybe minimal support team help data flow issue etc m manager mean individual contributor subreddit manager way find success manage datum science team project individual contributor thing like data science manager
1k2a8t6,"Forecasting: Principles and Practice, the Pythonic Way",,109,7,2025-04-18T17:15:21+00:00,datascience,https://otexts.com/fpppy/,"Forecasting: Principles and Practice, the Pythonic Way ",forecasting principles and practice the pythonic way,forecasting principle practice pythonic way
1k26kp3,What’s your 2025 data science coding stack + AI tools workflow?,"Curious how others are working these days. What’s your current setup?

IDE / notebook tools? (VS Code, Cursor, Jupyter, etc.)

Are you using AI tools like Cursor, Windsurf, Copilot, Cline, Roo?

How do they fit into your workflow? (e.g., prompting style, tasks they’re best at)

Any wins, limitations, or tips?",179,67,2025-04-18T14:41:25+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k26kp3/whats_your_2025_data_science_coding_stack_ai/,"What’s your 2025 data science coding stack + AI tools workflow? Curious how others are working these days. What’s your current setup?

IDE / notebook tools? (VS Code, Cursor, Jupyter, etc.)

Are you using AI tools like Cursor, Windsurf, Copilot, Cline, Roo?

How do they fit into your workflow? (e.g., prompting style, tasks they’re best at)

Any wins, limitations, or tips?",whats your data science coding stack ai tools workflow curious how others are working these days whats your current setup ide notebook tools vs code cursor jupyter etc are you using ai tools like cursor windsurf copilot cline roo how do they fit into your workflow eg prompting style tasks theyre best at any wins limitations or tips,s data science code stack ai tool workflow curious work day s current setup ide notebook tool vs code cursor jupyter etc ai tool like cursor windsurf copilot cline roo fit workflow eg prompt style task good win limitation tip
1k26920,How do you go about memorizing all the ML algorithms details for interviews?,"I’ve been preparing for interviews lately, but one area I’m struggling to optimize is the ML depth rounds. Right now, I’m reviewing ISLR and taking notes, but I’m not retaining the material as well as I’d like. Even though I studied this in grad school, it’s been a while since I dove deep into the algorithmic details.  

Do you have any advice for preparing for ML breadth/depth interviews? Any strategies for reinforcing concepts or alternative resources you’d recommend? ",151,66,2025-04-18T14:27:09+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k26920/how_do_you_go_about_memorizing_all_the_ml/,"How do you go about memorizing all the ML algorithms details for interviews? I’ve been preparing for interviews lately, but one area I’m struggling to optimize is the ML depth rounds. Right now, I’m reviewing ISLR and taking notes, but I’m not retaining the material as well as I’d like. Even though I studied this in grad school, it’s been a while since I dove deep into the algorithmic details.  

Do you have any advice for preparing for ML breadth/depth interviews? Any strategies for reinforcing concepts or alternative resources you’d recommend? ",how do you go about memorizing all the ml algorithms details for interviews ive been preparing for interviews lately but one area im struggling to optimize is the ml depth rounds right now im reviewing islr and taking notes but im not retaining the material as well as id like even though i studied this in grad school its been a while since i dove deep into the algorithmic details do you have any advice for preparing for ml breadthdepth interviews any strategies for reinforcing concepts or alternative resources youd recommend,memorize ml algorithm detail interview ve prepare interview lately area m struggle optimize ml depth round right m review islr take note m retain material d like study grad school dove deep algorithmic detail advice prepare ml breadthdepth interview strategy reinforce concept alternative resource d recommend
1k22cd4,Working with distance,"I'm super curious about the solutions you're using to calculate distances. 

I can't share too many details, but we have data that includes two addresses and the GPS coordinates between these locations. While the results we've obtained so far are interesting, they only reflect the straight-line distance.

Google has an API that allows you to query travel distances by car and even via public transport. However, my understanding is that their terms of service restrict storing the results of these queries and the volume of the calls.

Have any of you experts explored other tools or data sources that could fulfill this need? This is for a corporate solution in the UK, so it needs to be compliant with regulations.

Edit: thanks, you guys are legends ",16,32,2025-04-18T11:10:37+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k22cd4/working_with_distance/,"Working with distance I'm super curious about the solutions you're using to calculate distances. 

I can't share too many details, but we have data that includes two addresses and the GPS coordinates between these locations. While the results we've obtained so far are interesting, they only reflect the straight-line distance.

Google has an API that allows you to query travel distances by car and even via public transport. However, my understanding is that their terms of service restrict storing the results of these queries and the volume of the calls.

Have any of you experts explored other tools or data sources that could fulfill this need? This is for a corporate solution in the UK, so it needs to be compliant with regulations.

Edit: thanks, you guys are legends ",working with distance im super curious about the solutions youre using to calculate distances i cant share too many details but we have data that includes two addresses and the gps coordinates between these locations while the results weve obtained so far are interesting they only reflect the straightline distance google has an api that allows you to query travel distances by car and even via public transport however my understanding is that their terms of service restrict storing the results of these queries and the volume of the calls have any of you experts explored other tools or data sources that could fulfill this need this is for a corporate solution in the uk so it needs to be compliant with regulations edit thanks you guys are legends,work distance m super curious solution calculate distance not share detail datum include address gps coordinate location result ve obtain far interesting reflect straightline distance google api allow query travel distance car public transport understanding term service restrict store result query volume call expert explore tool data source fulfill need corporate solution uk need compliant regulation edit thank guy legend
1k20azb,Have a lot of experience but not getting any interviews - help,"Hi,

I was here a few weeks back and you helped me to cut down my CV and demo more impact.  I have applied to jobs all over and get only rejections.

I know the market is hard right now, but I would think that I would at least get invited to have at least initial conversations.  This makes me think, there must be something really missing.  Could you tell me what you think it could be?

Due to AI hype there are a lot of postings with LLMs.  I don't have corporate experience there but I plan to do projects to learn & demo it.

This week I have lowered my salary requirements by 10k and still get rejections.

I have 2 versions - a 2 pager and a 1 pager.  Have been applying with the 2 pager mostly until now.

Am grateful for your feedback and any help you can give me

https://preview.redd.it/e4pubfms4kve1.png?width=1414&format=png&auto=webp&s=853c4ae00db446784cb42ff17048611e5fb03a81

https://preview.redd.it/mzsfifmv4kve1.png?width=1414&format=png&auto=webp&s=ca35aeac336eb834a54b55008efc51936c26658d

https://preview.redd.it/l9jz6b6w4kve1.png?width=1414&format=png&auto=webp&s=802f98f4dfdb7cc5d39346c6d1a91cf6b08b95b6

",0,19,2025-04-18T08:53:19+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k20azb/have_a_lot_of_experience_but_not_getting_any/,"Have a lot of experience but not getting any interviews - help Hi,

I was here a few weeks back and you helped me to cut down my CV and demo more impact.  I have applied to jobs all over and get only rejections.

I know the market is hard right now, but I would think that I would at least get invited to have at least initial conversations.  This makes me think, there must be something really missing.  Could you tell me what you think it could be?

Due to AI hype there are a lot of postings with LLMs.  I don't have corporate experience there but I plan to do projects to learn & demo it.

This week I have lowered my salary requirements by 10k and still get rejections.

I have 2 versions - a 2 pager and a 1 pager.  Have been applying with the 2 pager mostly until now.

Am grateful for your feedback and any help you can give me

https://preview.redd.it/e4pubfms4kve1.png?width=1414&format=png&auto=webp&s=853c4ae00db446784cb42ff17048611e5fb03a81

https://preview.redd.it/mzsfifmv4kve1.png?width=1414&format=png&auto=webp&s=ca35aeac336eb834a54b55008efc51936c26658d

https://preview.redd.it/l9jz6b6w4kve1.png?width=1414&format=png&auto=webp&s=802f98f4dfdb7cc5d39346c6d1a91cf6b08b95b6

",have a lot of experience but not getting any interviews help hi i was here a few weeks back and you helped me to cut down my cv and demo more impact i have applied to jobs all over and get only rejections i know the market is hard right now but i would think that i would at least get invited to have at least initial conversations this makes me think there must be something really missing could you tell me what you think it could be due to ai hype there are a lot of postings with llms i dont have corporate experience there but i plan to do projects to learn demo it this week i have lowered my salary requirements by k and still get rejections i have versions a pager and a pager have been applying with the pager mostly until now am grateful for your feedback and any help you can give me,lot experience get interview help hi week help cut cv demo impact apply job rejection know market hard right think invite initial conversation make think miss tell think ai hype lot posting llm not corporate experience plan project learn demo week lower salary requirement k rejection version pager pager apply pager grateful feedback help
1k1x464,What is the difference between DiD and incremental testing? I did search online and gpt but didn’t find convincing difference,"Hi 

What is the difference between DiD and incremental testing? I did search online and gpt but didn’t find convincing difference, i don’t get it as both are basically difference between control and treatment group. If anyone could explain then would be great help. Thanks!",10,8,2025-04-18T05:10:50+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k1x464/what_is_the_difference_between_did_and/,"What is the difference between DiD and incremental testing? I did search online and gpt but didn’t find convincing difference Hi 

What is the difference between DiD and incremental testing? I did search online and gpt but didn’t find convincing difference, i don’t get it as both are basically difference between control and treatment group. If anyone could explain then would be great help. Thanks!",what is the difference between did and incremental testing i did search online and gpt but didnt find convincing difference hi what is the difference between did and incremental testing i did search online and gpt but didnt find convincing difference i dont get it as both are basically difference between control and treatment group if anyone could explain then would be great help thanks,difference incremental testing search online gpt not find convincing difference hi difference incremental testing search online gpt not find convincing difference not basically difference control treatment group explain great help thank
1k1wu9o,Forecasting models for small data in operations,"Hi, I work in a company that provides a weekly service to our customers.

One of the most important things for our operations is to know 1 to 5 weeks in advance how many customers we expect to have for each of those future weeks.

Company is operating for about 4 years so there are roughly 200 historical data points.

I wonder, which data science, ML models are best for small data with some seasonal trends?

Facebook prophet, Arima and Sarima are the ones we use but it feels like we are missing some.

Any thoughts?
",31,43,2025-04-18T04:53:31+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k1wu9o/forecasting_models_for_small_data_in_operations/,"Forecasting models for small data in operations Hi, I work in a company that provides a weekly service to our customers.

One of the most important things for our operations is to know 1 to 5 weeks in advance how many customers we expect to have for each of those future weeks.

Company is operating for about 4 years so there are roughly 200 historical data points.

I wonder, which data science, ML models are best for small data with some seasonal trends?

Facebook prophet, Arima and Sarima are the ones we use but it feels like we are missing some.

Any thoughts?
",forecasting models for small data in operations hi i work in a company that provides a weekly service to our customers one of the most important things for our operations is to know to weeks in advance how many customers we expect to have for each of those future weeks company is operating for about years so there are roughly historical data points i wonder which data science ml models are best for small data with some seasonal trends facebook prophet arima and sarima are the ones we use but it feels like we are missing some any thoughts,forecasting model small datum operation hi work company provide weekly service customer important thing operation know week advance customer expect future week company operate year roughly historical data point wonder datum science ml model good small datum seasonal trend facebook prophet arima sarima one use feel like miss thought
1k1vo23,Advice before getting data engineer fellowship position,"Hey everybody,

I need some advice. I have an MsC in Data Science and have really struggled to find jobs. I got an average paying, “data science adjacent but not data science enough” quantitative analyst job in a bank. In fact , I feel like I get dumber every day I’m there and I’m miserable. None of the skills or achievements there are noteworthy : no model building, no big analyses, no data engineering or Gen ai work, just model validation work (helping other people fix their modeling solutions).

Long story short, I’m interviewing for a fellowship position to be a data engineer in a nonprofit. It lasts for one year and exposes me to many clients that I will aid. At most I can extend the fellowship for one additional year. It sounds exciting. It pays 10K less, but it’s a step in the right direction. It gets me closer to what I actually studied.

The reason I write this post is because I want to know if it will negatively impact my resume or future chances. If I take this job, my resume will look like this : data analyst job (3 years) with a bit of sql and excel, two data science internships (one 3 months and one 8 months) at the university, quantitative analyst (6months), data engineer fellowship (1 year). Will this make companies look at me like a problem and not give me a chance to even interview? Thanks in advance, everybody.
",7,4,2025-04-18T03:43:49+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k1vo23/advice_before_getting_data_engineer_fellowship/,"Advice before getting data engineer fellowship position Hey everybody,

I need some advice. I have an MsC in Data Science and have really struggled to find jobs. I got an average paying, “data science adjacent but not data science enough” quantitative analyst job in a bank. In fact , I feel like I get dumber every day I’m there and I’m miserable. None of the skills or achievements there are noteworthy : no model building, no big analyses, no data engineering or Gen ai work, just model validation work (helping other people fix their modeling solutions).

Long story short, I’m interviewing for a fellowship position to be a data engineer in a nonprofit. It lasts for one year and exposes me to many clients that I will aid. At most I can extend the fellowship for one additional year. It sounds exciting. It pays 10K less, but it’s a step in the right direction. It gets me closer to what I actually studied.

The reason I write this post is because I want to know if it will negatively impact my resume or future chances. If I take this job, my resume will look like this : data analyst job (3 years) with a bit of sql and excel, two data science internships (one 3 months and one 8 months) at the university, quantitative analyst (6months), data engineer fellowship (1 year). Will this make companies look at me like a problem and not give me a chance to even interview? Thanks in advance, everybody.
",advice before getting data engineer fellowship position hey everybody i need some advice i have an msc in data science and have really struggled to find jobs i got an average paying data science adjacent but not data science enough quantitative analyst job in a bank in fact i feel like i get dumber every day im there and im miserable none of the skills or achievements there are noteworthy no model building no big analyses no data engineering or gen ai work just model validation work helping other people fix their modeling solutions long story short im interviewing for a fellowship position to be a data engineer in a nonprofit it lasts for one year and exposes me to many clients that i will aid at most i can extend the fellowship for one additional year it sounds exciting it pays k less but its a step in the right direction it gets me closer to what i actually studied the reason i write this post is because i want to know if it will negatively impact my resume or future chances if i take this job my resume will look like this data analyst job years with a bit of sql and excel two data science internships one months and one months at the university quantitative analyst months data engineer fellowship year will this make companies look at me like a problem and not give me a chance to even interview thanks in advance everybody,advice get datum engineer fellowship position hey everybody need advice msc data science struggle find job get average pay datum science adjacent datum science quantitative analyst job bank fact feel like dumber day m m miserable skill achievement noteworthy model build big analysis data engineering gen ai work model validation work help people fix modeling solution long story short m interview fellowship position data engineer nonprofit last year expose client aid extend fellowship additional year sound exciting pay k step right direction get close actually study reason write post want know negatively impact resume future chance job resume look like data analyst job year bit sql excel datum science internship month month university quantitative analyst month data engineer fellowship year company look like problem chance interview thank advance everybody
1k1ohsp,Website that allow comparing VLMs and LLMs?,"I am trying to initiate a project in which I will describe images (then the descriptions will go through another pipeline). I already tested ChatGPT and saw that it was successful in giving me the description I needed. However, it is expensive and infeasible for my project (there are going to be billions of images). 

I am searching for an online platform that enables comparison of various VLM outputs. 

  
Thanks!",2,1,2025-04-17T21:39:22+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k1ohsp/website_that_allow_comparing_vlms_and_llms/,"Website that allow comparing VLMs and LLMs? I am trying to initiate a project in which I will describe images (then the descriptions will go through another pipeline). I already tested ChatGPT and saw that it was successful in giving me the description I needed. However, it is expensive and infeasible for my project (there are going to be billions of images). 

I am searching for an online platform that enables comparison of various VLM outputs. 

  
Thanks!",website that allow comparing vlms and llms i am trying to initiate a project in which i will describe images then the descriptions will go through another pipeline i already tested chatgpt and saw that it was successful in giving me the description i needed however it is expensive and infeasible for my project there are going to be billions of images i am searching for an online platform that enables comparison of various vlm outputs thanks,website allow compare vlm llm try initiate project describe image description pipeline test chatgpt see successful give description need expensive infeasible project go billion image search online platform enable comparison vlm output thank
1k1mjok,Lead DS book suggestions,"Ive landed my first role as a lead DS. My responsibilities outside actual DS work is upskilling the analytics team in Python, R and powerBI which I've got 5+ experience with. However, this is the first role where I'm mentoring/coaching/leading a team. I would welcome any suggestions for reading materials that would help me in this new leadership role. Thank you for your time!",83,23,2025-04-17T20:15:22+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k1mjok/lead_ds_book_suggestions/,"Lead DS book suggestions Ive landed my first role as a lead DS. My responsibilities outside actual DS work is upskilling the analytics team in Python, R and powerBI which I've got 5+ experience with. However, this is the first role where I'm mentoring/coaching/leading a team. I would welcome any suggestions for reading materials that would help me in this new leadership role. Thank you for your time!",lead ds book suggestions ive landed my first role as a lead ds my responsibilities outside actual ds work is upskilling the analytics team in python r and powerbi which ive got experience with however this is the first role where im mentoringcoachingleading a team i would welcome any suggestions for reading materials that would help me in this new leadership role thank you for your time,lead ds book suggestion ve land role lead ds responsibility outside actual ds work upskille analytic team python r powerbi ve get experience role m mentoringcoachingleade team welcome suggestion read material help new leadership role thank time
1k1lh3r,Experiences from past Open Data Science Conferences (ODSC)?,"I have an opportunity to attend ODSC East (https://odsc.com/boston/) and want to see if this is worth it as a M.S. CS graduate looking for networking and employment opportunities.

  
I am less interested in tutorials and workshops than in networking and employment. Is it worth it to show up with a resume and portfolio links looking to network?

  
I searched this sub and reviews are mixed but fairly old. Anyone gone recently?",8,4,2025-04-17T19:30:23+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k1lh3r/experiences_from_past_open_data_science/,"Experiences from past Open Data Science Conferences (ODSC)? I have an opportunity to attend ODSC East (https://odsc.com/boston/) and want to see if this is worth it as a M.S. CS graduate looking for networking and employment opportunities.

  
I am less interested in tutorials and workshops than in networking and employment. Is it worth it to show up with a resume and portfolio links looking to network?

  
I searched this sub and reviews are mixed but fairly old. Anyone gone recently?",experiences from past open data science conferences odsc i have an opportunity to attend odsc east and want to see if this is worth it as a ms cs graduate looking for networking and employment opportunities i am less interested in tutorials and workshops than in networking and employment is it worth it to show up with a resume and portfolio links looking to network i searched this sub and reviews are mixed but fairly old anyone gone recently,experience past open datum science conference odsc opportunity attend odsc east want worth ms cs graduate look networking employment opportunity interested tutorial workshop networking employment worth resume portfolio link look network search sub review mixed fairly old go recently
1k0zcye,Data Engineer trying to understand data science to provide better support.,"I work as a data engineer who mainly builds & maintains data warehouses but now I’m starting to get projects assigned to me asking me to build custom data pipelines for various data science projects and I’m assuming deployment of Data Science/ML models to production. 

Since my background is data engineering, how can I learn data science in a structured bottom up manner so that I can best understand what exactly the data scientists want? 

This may sound like overkill to some but so far the data scientist I’m working with is trying to build a data science model that requires enriched historical data for the training of the data science model. Ok no problem so far. 

However, they then want to run the data science model on the data as it’s collected (before enrichment) but the problem is this data science model is trained on enriched historical data that wont have the exact same schema as the data that’s being collected real time?

What’s even more confusing is some data scientists have said this is ok and some said it isn’t.

I don’t know which person is right. So, I’d rather learn at least the basics, preferably through some good books & projects so that I can understand when the data scientists are asking for something unreasonable.

I need to be able to easily speak the language of data scientists so I can provide better support and let them know when there’s an issue with the data that may effect their data science model in unexpected ways. ",62,34,2025-04-17T00:02:25+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k0zcye/data_engineer_trying_to_understand_data_science/,"Data Engineer trying to understand data science to provide better support. I work as a data engineer who mainly builds & maintains data warehouses but now I’m starting to get projects assigned to me asking me to build custom data pipelines for various data science projects and I’m assuming deployment of Data Science/ML models to production. 

Since my background is data engineering, how can I learn data science in a structured bottom up manner so that I can best understand what exactly the data scientists want? 

This may sound like overkill to some but so far the data scientist I’m working with is trying to build a data science model that requires enriched historical data for the training of the data science model. Ok no problem so far. 

However, they then want to run the data science model on the data as it’s collected (before enrichment) but the problem is this data science model is trained on enriched historical data that wont have the exact same schema as the data that’s being collected real time?

What’s even more confusing is some data scientists have said this is ok and some said it isn’t.

I don’t know which person is right. So, I’d rather learn at least the basics, preferably through some good books & projects so that I can understand when the data scientists are asking for something unreasonable.

I need to be able to easily speak the language of data scientists so I can provide better support and let them know when there’s an issue with the data that may effect their data science model in unexpected ways. ",data engineer trying to understand data science to provide better support i work as a data engineer who mainly builds maintains data warehouses but now im starting to get projects assigned to me asking me to build custom data pipelines for various data science projects and im assuming deployment of data scienceml models to production since my background is data engineering how can i learn data science in a structured bottom up manner so that i can best understand what exactly the data scientists want this may sound like overkill to some but so far the data scientist im working with is trying to build a data science model that requires enriched historical data for the training of the data science model ok no problem so far however they then want to run the data science model on the data as its collected before enrichment but the problem is this data science model is trained on enriched historical data that wont have the exact same schema as the data thats being collected real time whats even more confusing is some data scientists have said this is ok and some said it isnt i dont know which person is right so id rather learn at least the basics preferably through some good books projects so that i can understand when the data scientists are asking for something unreasonable i need to be able to easily speak the language of data scientists so i can provide better support and let them know when theres an issue with the data that may effect their data science model in unexpected ways,data engineer try understand datum science provide well support work data engineer mainly build maintain data warehouse m start project assign ask build custom datum pipeline datum science project m assume deployment datum scienceml model production background datum engineer learn datum science structured manner well understand exactly data scientist want sound like overkill far data scientist m work try build data science model require enriched historical datum training data science model ok problem far want run data science model datum collect enrichment problem datum science model train enriched historical datum will not exact schema datum s collect real time s confusing data scientist say ok say not not know person right d learn basic preferably good book project understand data scientist ask unreasonable need able easily speak language data scientist provide well support let know s issue datum effect data science model unexpected way
1k0vdku,Quick question regarding nested resampling and model selection workflow,"EDIT!!!!!! Post wording is confusing, when I refer to models I mean one singular model tuned N number of ways. E.g. random Forrest tuned to 4 different depths would be model a,b,c,d in my diagram.

Just wanted some feedback regarding my model selection approach.

The premise:  
Need to train dev a model and I will need to perform nested resmapling to prevent against spatial and temporal leakage.  
Outer samples will handle spatial leakage.  
Inner samples will handle temporal leakage.  
I will also be tuning a model.

Via the diagram below, my model tuning and selection will be as follows:  
\-Make inital 70/30 data budget  
\-Perfrom some number of spatial resamples (4 shown here)  
\-For each spatial resample (1-4), I will make N (4 shown) spatial splits  
\-For each inner time sample i will train and test N (4 shown) models and mark their perfromance  
\-For each outer samples' inner samples - one winner model will be selected based on some criteria  
\--e.g Model A out performs all models trained innner samples 1-4 for outer sample #1  
\----Outer/spatial #1 -- winner model A  
\----Outer/spatial #2 -- winner model D  
\----Outer/spatial #3 -- winner model C  
\----Outer/spatial #4 -- winner model A  
\-I take each winner from the previous step and train them on their entire train sets and validate on their test sets  
\--e.g train model A on outer #1 train and test on outer #1 test  
\----- train model D on outer #2 train and test on outer #2 test  
\----- and so on  
\-From this step the model the perfroms the best is then selected from these 4 and then trained on the entire inital 70% train and evalauated on the inital 30% holdout.

Should I change my method up at all?  
I was thinking that I might be adding bias in to the second modeling step (training the winning models on the outer/spatial samples) because there could be differences in the spatial samples themselves.   
Potentially some really bad data ends up exclusively in the test set for one of the outer folds and by default make one of the models not be selected that otherwise might have. 

https://preview.redd.it/kw6ogyygg9ve1.png?width=1080&format=png&auto=webp&s=7d6ac472bd91269bd9790ee3b8111b053cffa351

  
",4,4,2025-04-16T21:02:18+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k0vdku/quick_question_regarding_nested_resampling_and/,"Quick question regarding nested resampling and model selection workflow EDIT!!!!!! Post wording is confusing, when I refer to models I mean one singular model tuned N number of ways. E.g. random Forrest tuned to 4 different depths would be model a,b,c,d in my diagram.

Just wanted some feedback regarding my model selection approach.

The premise:  
Need to train dev a model and I will need to perform nested resmapling to prevent against spatial and temporal leakage.  
Outer samples will handle spatial leakage.  
Inner samples will handle temporal leakage.  
I will also be tuning a model.

Via the diagram below, my model tuning and selection will be as follows:  
\-Make inital 70/30 data budget  
\-Perfrom some number of spatial resamples (4 shown here)  
\-For each spatial resample (1-4), I will make N (4 shown) spatial splits  
\-For each inner time sample i will train and test N (4 shown) models and mark their perfromance  
\-For each outer samples' inner samples - one winner model will be selected based on some criteria  
\--e.g Model A out performs all models trained innner samples 1-4 for outer sample #1  
\----Outer/spatial #1 -- winner model A  
\----Outer/spatial #2 -- winner model D  
\----Outer/spatial #3 -- winner model C  
\----Outer/spatial #4 -- winner model A  
\-I take each winner from the previous step and train them on their entire train sets and validate on their test sets  
\--e.g train model A on outer #1 train and test on outer #1 test  
\----- train model D on outer #2 train and test on outer #2 test  
\----- and so on  
\-From this step the model the perfroms the best is then selected from these 4 and then trained on the entire inital 70% train and evalauated on the inital 30% holdout.

Should I change my method up at all?  
I was thinking that I might be adding bias in to the second modeling step (training the winning models on the outer/spatial samples) because there could be differences in the spatial samples themselves.   
Potentially some really bad data ends up exclusively in the test set for one of the outer folds and by default make one of the models not be selected that otherwise might have. 

https://preview.redd.it/kw6ogyygg9ve1.png?width=1080&format=png&auto=webp&s=7d6ac472bd91269bd9790ee3b8111b053cffa351

  
",quick question regarding nested resampling and model selection workflow edit post wording is confusing when i refer to models i mean one singular model tuned n number of ways eg random forrest tuned to different depths would be model abcd in my diagram just wanted some feedback regarding my model selection approach the premise need to train dev a model and i will need to perform nested resmapling to prevent against spatial and temporal leakage outer samples will handle spatial leakage inner samples will handle temporal leakage i will also be tuning a model via the diagram below my model tuning and selection will be as follows make inital data budget perfrom some number of spatial resamples shown here for each spatial resample i will make n shown spatial splits for each inner time sample i will train and test n shown models and mark their perfromance for each outer samples inner samples one winner model will be selected based on some criteria eg model a out performs all models trained innner samples for outer sample outerspatial winner model a outerspatial winner model d outerspatial winner model c outerspatial winner model a i take each winner from the previous step and train them on their entire train sets and validate on their test sets eg train model a on outer train and test on outer test train model d on outer train and test on outer test and so on from this step the model the perfroms the best is then selected from these and then trained on the entire inital train and evalauated on the inital holdout should i change my method up at all i was thinking that i might be adding bias in to the second modeling step training the winning models on the outerspatial samples because there could be differences in the spatial samples themselves potentially some really bad data ends up exclusively in the test set for one of the outer folds and by default make one of the models not be selected that otherwise might have,quick question nest resampling model selection workflow edit post wording confusing refer model mean singular model tune n number way eg random forrest tune different depth model abcd diagram want feedback model selection approach premise need train dev model need perform nest resmapling prevent spatial temporal leakage outer sample handle spatial leakage inner sample handle temporal leakage tune model diagram model tuning selection follow inital datum budget perfrom number spatial resample show spatial resample n show spatial split inner time sample train test n show model mark perfromance outer sample inner sample winner model select base criterion eg model perform model train innner sample outer sample outerspatial winner model outerspatial winner model d outerspatial winner model c outerspatial winner model winner previous step train entire train set validate test set eg train model outer train test outer test train model d outer train test outer test step model perfrom good select train entire inital train evalauate inital holdout change method think add bias second modeling step train win model outerspatial sample difference spatial sample potentially bad datum end exclusively test set outer fold default model select
1k0v0dc,"Does anyone here work for DoorDash, Discover, Home Depot, or Liberty Mutual?",Why do you keep posting the same jobs over and over again?,58,31,2025-04-16T20:46:54+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k0v0dc/does_anyone_here_work_for_doordash_discover_home/,"Does anyone here work for DoorDash, Discover, Home Depot, or Liberty Mutual? Why do you keep posting the same jobs over and over again?",does anyone here work for doordash discover home depot or liberty mutual why do you keep posting the same jobs over and over again,work doordash discover home depot liberty mutual post job
1k0c459,Data science is not about...,"There's a lot of posts on LinkedIn which claim:
- Data science is not about Python
- It's not about SQL
- It's not about models
- It's not about stats
...

But it's about storytelling and business value. 

There is a huge amount of people who are trying to convince everyone else in this BS, IMHO. It's just not clear why... 

Technical stuff is much more important. It reminds me of some rich people telling everyone else that money doesn't matter.  ",725,164,2025-04-16T04:38:29+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k0c459/data_science_is_not_about/,"Data science is not about... There's a lot of posts on LinkedIn which claim:
- Data science is not about Python
- It's not about SQL
- It's not about models
- It's not about stats
...

But it's about storytelling and business value. 

There is a huge amount of people who are trying to convince everyone else in this BS, IMHO. It's just not clear why... 

Technical stuff is much more important. It reminds me of some rich people telling everyone else that money doesn't matter.  ",data science is not about theres a lot of posts on linkedin which claim data science is not about python its not about sql its not about models its not about stats but its about storytelling and business value there is a huge amount of people who are trying to convince everyone else in this bs imho its just not clear why technical stuff is much more important it reminds me of some rich people telling everyone else that money doesnt matter,data science s lot post linkedin claim datum science python sql model stat storytelling business value huge people try convince bs imho clear technical stuff important remind rich people tell money not matter
1k082ij,Is TimeSeriesSplit appropriate for purchase propensity prediction?”,"I have a dataset of price quotes for a service, with the following structure: client ID, quote ID, date (daily), target variable indicating whether the client purchased the service, and several features.

I'm building a model to predict the likelihood of a client completing the purchase after receiving a quote.

Does it make sense to use TimeSeriesSplit for training and validation in this case?
Would this type of problem be considered a time series problem, even though the prediction target is not a continuous time-dependent variable?",21,15,2025-04-16T00:58:27+00:00,datascience,https://www.reddit.com/r/datascience/comments/1k082ij/is_timeseriessplit_appropriate_for_purchase/,"Is TimeSeriesSplit appropriate for purchase propensity prediction?” I have a dataset of price quotes for a service, with the following structure: client ID, quote ID, date (daily), target variable indicating whether the client purchased the service, and several features.

I'm building a model to predict the likelihood of a client completing the purchase after receiving a quote.

Does it make sense to use TimeSeriesSplit for training and validation in this case?
Would this type of problem be considered a time series problem, even though the prediction target is not a continuous time-dependent variable?",is timeseriessplit appropriate for purchase propensity prediction i have a dataset of price quotes for a service with the following structure client id quote id date daily target variable indicating whether the client purchased the service and several features im building a model to predict the likelihood of a client completing the purchase after receiving a quote does it make sense to use timeseriessplit for training and validation in this case would this type of problem be considered a time series problem even though the prediction target is not a continuous timedependent variable,timeseriessplit appropriate purchase propensity prediction dataset price quote service following structure client d quote d date daily target variable indicate client purchase service feature m build model predict likelihood client complete purchase receive quote sense use timeseriessplit training validation case type problem consider time series problem prediction target continuous timedependent variable
1jzml32,Is Agentic AI remotely useful for real business problems?,"Agentic AI is the latest hype train to leave the station, and there has been an explosion of frameworks, tools etc. for developing LLM-based agents. The terminology is all over the place, although the definitions in the Anthropic blog ‘Building Effective Agents’ seem to be popular (I like them). 

Has anyone actually deployed an agentic solution to solve a business problem? Is it in production (i.e more than a PoC)? Is it actually agentic or just a workflow? I can see clear utility for open-ended web searching tasks (e.g. deep research, where the user validates everything) - but having agents autonomously navigate the internal systems of a business (and actually being useful and reliable) just seems fanciful to me, for all kinds of reasons. How can you debug these things? 

There seems to be a vast disconnect between expectation and reality, more than we’ve ever seen in AI. Am I wrong?",99,62,2025-04-15T08:17:24+00:00,datascience,https://www.reddit.com/r/datascience/comments/1jzml32/is_agentic_ai_remotely_useful_for_real_business/,"Is Agentic AI remotely useful for real business problems? Agentic AI is the latest hype train to leave the station, and there has been an explosion of frameworks, tools etc. for developing LLM-based agents. The terminology is all over the place, although the definitions in the Anthropic blog ‘Building Effective Agents’ seem to be popular (I like them). 

Has anyone actually deployed an agentic solution to solve a business problem? Is it in production (i.e more than a PoC)? Is it actually agentic or just a workflow? I can see clear utility for open-ended web searching tasks (e.g. deep research, where the user validates everything) - but having agents autonomously navigate the internal systems of a business (and actually being useful and reliable) just seems fanciful to me, for all kinds of reasons. How can you debug these things? 

There seems to be a vast disconnect between expectation and reality, more than we’ve ever seen in AI. Am I wrong?",is agentic ai remotely useful for real business problems agentic ai is the latest hype train to leave the station and there has been an explosion of frameworks tools etc for developing llmbased agents the terminology is all over the place although the definitions in the anthropic blog building effective agents seem to be popular i like them has anyone actually deployed an agentic solution to solve a business problem is it in production ie more than a poc is it actually agentic or just a workflow i can see clear utility for openended web searching tasks eg deep research where the user validates everything but having agents autonomously navigate the internal systems of a business and actually being useful and reliable just seems fanciful to me for all kinds of reasons how can you debug these things there seems to be a vast disconnect between expectation and reality more than weve ever seen in ai am i wrong,agentic ai remotely useful real business problem agentic ai late hype train leave station explosion framework tool etc develop llmbased agent terminology place definition anthropic blog build effective agent popular like actually deploy agentic solution solve business problem production ie poc actually agentic workflow clear utility openende web search task eg deep research user validate have agent autonomously navigate internal system business actually useful reliable fanciful kind reason debug thing vast disconnect expectation reality ve see ai wrong
1jz4teg,Why won’t they let you run your code!?,"So I just got done with a SQL zoom screen. I practiced for a long time on mediums and hards. One thing that threw me off was I was not allowed to run the query to see the result. The problems were medium and hard often requiring multiple joins and CTEs. 2 mediums 2 hards. 25 mins. Only got done with 3 and they wouldn’t even tell me if I was right or wrong. Just “logic looks sound” 

All the practice resources like leetcode and data lemur allow you to run your code. I did not expect this. Is this common practice? Definitely failed and feel totally dejected 😞 ",190,40,2025-04-14T17:36:38+00:00,datascience,https://www.reddit.com/r/datascience/comments/1jz4teg/why_wont_they_let_you_run_your_code/,"Why won’t they let you run your code!? So I just got done with a SQL zoom screen. I practiced for a long time on mediums and hards. One thing that threw me off was I was not allowed to run the query to see the result. The problems were medium and hard often requiring multiple joins and CTEs. 2 mediums 2 hards. 25 mins. Only got done with 3 and they wouldn’t even tell me if I was right or wrong. Just “logic looks sound” 

All the practice resources like leetcode and data lemur allow you to run your code. I did not expect this. Is this common practice? Definitely failed and feel totally dejected 😞 ",why wont they let you run your code so i just got done with a sql zoom screen i practiced for a long time on mediums and hards one thing that threw me off was i was not allowed to run the query to see the result the problems were medium and hard often requiring multiple joins and ctes mediums hards mins only got done with and they wouldnt even tell me if i was right or wrong just logic looks sound all the practice resources like leetcode and data lemur allow you to run your code i did not expect this is this common practice definitely failed and feel totally dejected disappointedface,will not let run code get sql zoom screen practice long time medium hard thing throw allow run query result problem medium hard require multiple join cte medium hard min get not tell right wrong logic look sound practice resource like leetcode datum lemur allow run code expect common practice definitely fail feel totally dejected disappointedface
1jz0h1y,*Saw Greg pinged me & logged off immediately*,,489,18,2025-04-14T14:39:04+00:00,datascience,https://i.redd.it/rp4lu4ruatue1.png,*Saw Greg pinged me & logged off immediately* ,saw greg pinged me logged off immediately,see greg ping log immediately
1jyu503,PowerBI but not PowerBI,"Figured this was the best community to ask this question:

I have a bunch of personal data (think personal finance spreadsheet type stuff), and I'd love to build a dashboard for it - purely for me. I have access to Power BI through my work so I know how to build the sort of thing I want.

However

I obviously can't use my work account to create a personal dashboard with my personal data etc, so I'm trying to find alternative solutions.

To set up a personal PBI account seems to need a lot of hoops like owning your own domain for an email address etc, so I'm wondering if anyone in this community might use any other dashboard tools that they reccomend and that would have similar basic functionality and be a bit less faff to try and set up a personal account?",29,40,2025-04-14T08:46:26+00:00,datascience,https://www.reddit.com/r/datascience/comments/1jyu503/powerbi_but_not_powerbi/,"PowerBI but not PowerBI Figured this was the best community to ask this question:

I have a bunch of personal data (think personal finance spreadsheet type stuff), and I'd love to build a dashboard for it - purely for me. I have access to Power BI through my work so I know how to build the sort of thing I want.

However

I obviously can't use my work account to create a personal dashboard with my personal data etc, so I'm trying to find alternative solutions.

To set up a personal PBI account seems to need a lot of hoops like owning your own domain for an email address etc, so I'm wondering if anyone in this community might use any other dashboard tools that they reccomend and that would have similar basic functionality and be a bit less faff to try and set up a personal account?",powerbi but not powerbi figured this was the best community to ask this question i have a bunch of personal data think personal finance spreadsheet type stuff and id love to build a dashboard for it purely for me i have access to power bi through my work so i know how to build the sort of thing i want however i obviously cant use my work account to create a personal dashboard with my personal data etc so im trying to find alternative solutions to set up a personal pbi account seems to need a lot of hoops like owning your own domain for an email address etc so im wondering if anyone in this community might use any other dashboard tools that they reccomend and that would have similar basic functionality and be a bit less faff to try and set up a personal account,powerbi powerbi figure good community ask question bunch personal datum think personal finance spreadsheet type stuff d love build dashboard purely access power bi work know build sort thing want obviously not use work account create personal dashboard personal datum etc m try find alternative solution set personal pbi account need lot hoop like own domain email address etc m wonder community use dashboard tool reccomend similar basic functionality bit faff try set personal account
1jyq1tk,"Weekly Entering & Transitioning - Thread 14 Apr, 2025 - 21 Apr, 2025"," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",10,60,2025-04-14T04:01:49+00:00,datascience,https://www.reddit.com/r/datascience/comments/1jyq1tk/weekly_entering_transitioning_thread_14_apr_2025/,"Weekly Entering & Transitioning - Thread 14 Apr, 2025 - 21 Apr, 2025  

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",weekly entering transitioning thread apr apr welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the and resources pages on our wiki you can also search for answers in,weekly enter transition thread apr apr welcome week enter transition thread thread question getting start study transition data science field topic include learn resource eg book tutorial video traditional education eg schools degree elective alternative education eg online course bootcamp job search question eg resume apply career prospect elementary question eg start wait answer community check resource page wiki search answer
1jyloqi,Reputed Graduate Certificates?,"Since finishing my Master's in Stats 4+ years ago the field has changed a lot. I feel like my education had a lot of useless classes and missed things like bayesian, graphs, DL, big data, etc.

Stanford seems to have some good graduate certs with classes I'm interested in and my employer will cover 2/3 the costs. Are these worth taking or is there a better way to get this info online? I have 3 YOE as DS at well known companies, so will these graduate certs from reputed unis improve my resume or is it similar to coursera?",30,17,2025-04-14T00:01:06+00:00,datascience,https://www.reddit.com/r/datascience/comments/1jyloqi/reputed_graduate_certificates/,"Reputed Graduate Certificates? Since finishing my Master's in Stats 4+ years ago the field has changed a lot. I feel like my education had a lot of useless classes and missed things like bayesian, graphs, DL, big data, etc.

Stanford seems to have some good graduate certs with classes I'm interested in and my employer will cover 2/3 the costs. Are these worth taking or is there a better way to get this info online? I have 3 YOE as DS at well known companies, so will these graduate certs from reputed unis improve my resume or is it similar to coursera?",reputed graduate certificates since finishing my masters in stats years ago the field has changed a lot i feel like my education had a lot of useless classes and missed things like bayesian graphs dl big data etc stanford seems to have some good graduate certs with classes im interested in and my employer will cover the costs are these worth taking or is there a better way to get this info online i have yoe as ds at well known companies so will these graduate certs from reputed unis improve my resume or is it similar to coursera,repute graduate certificate finish master stat year ago field change lot feel like education lot useless class miss thing like bayesian graph dl big datum etc stanford good graduate cert class m interested employer cover cost worth take well way info online yoe ds know company graduate cert reputed uni improve resume similar coursera
1jyicx6,Why are methods like forward/backward selection still taught?,"When you could just use lasso/relaxed lasso instead?


https://www.stat.cmu.edu/~ryantibs/papers/bestsubset.pdf",84,97,2025-04-13T21:19:41+00:00,datascience,https://www.reddit.com/r/datascience/comments/1jyicx6/why_are_methods_like_forwardbackward_selection/,"Why are methods like forward/backward selection still taught? When you could just use lasso/relaxed lasso instead?


https://www.stat.cmu.edu/~ryantibs/papers/bestsubset.pdf",why are methods like forwardbackward selection still taught when you could just use lassorelaxed lasso instead,method like forwardbackward selection teach use lassorelaxe lasso instead
1jygakg,Features you would love,If someone were to create a new cloud based data system. What features would you love it to have? What features do other services lack?,0,4,2025-04-13T19:48:56+00:00,datascience,https://www.reddit.com/r/datascience/comments/1jygakg/features_you_would_love/,Features you would love If someone were to create a new cloud based data system. What features would you love it to have? What features do other services lack?,features you would love if someone were to create a new cloud based data system what features would you love it to have what features do other services lack,feature love create new cloud base datum system feature love feature service lack
1jy2pe0,Is a Master’s Still Necessary?,"Can I break into DS with just a bachelor’s? I have 3 YOE of relevant experience although not titled as “data scientist”. I always come across roles with bachelor’s as a minimum requirement but master’s as a preferred. However, I have not been picked up for an interview at all. 

I do not want to take the financial burden of a masters degree since I already have the knowledge and experience to succeed. But it feels like I am just putting myself at a disadvantage in the field. Should I just get an online degree for the masters stamp? ",125,119,2025-04-13T08:04:16+00:00,datascience,https://www.reddit.com/r/datascience/comments/1jy2pe0/is_a_masters_still_necessary/,"Is a Master’s Still Necessary? Can I break into DS with just a bachelor’s? I have 3 YOE of relevant experience although not titled as “data scientist”. I always come across roles with bachelor’s as a minimum requirement but master’s as a preferred. However, I have not been picked up for an interview at all. 

I do not want to take the financial burden of a masters degree since I already have the knowledge and experience to succeed. But it feels like I am just putting myself at a disadvantage in the field. Should I just get an online degree for the masters stamp? ",is a masters still necessary can i break into ds with just a bachelors i have yoe of relevant experience although not titled as data scientist i always come across roles with bachelors as a minimum requirement but masters as a preferred however i have not been picked up for an interview at all i do not want to take the financial burden of a masters degree since i already have the knowledge and experience to succeed but it feels like i am just putting myself at a disadvantage in the field should i just get an online degree for the masters stamp,master necessary break ds bachelor yoe relevant experience title datum scientist come role bachelor minimum requirement master prefer pick interview want financial burden masters degree knowledge experience succeed feel like put disadvantage field online degree master stamp
1jxtzs1,Which topics or questions frequently asked for a data science role in traditional banks? Or for fraud detection/risk modeling topics?,"Hi,

I am proficient with statistics(causal inference , parametric non parametric tests) and ML models, but i don’t what models, statistical techniques are used in fraud detection and risk modeling, especially in finance industry. So, could anyone suggest FAQs? Or topics i should focus more on? Or any not common topic you ask to candidates that are crucial to know? Role requires 3+ years of experience.

Also, would like to know what techniques you work on in your day to work in fraud detection. It would help me great how it works in industry and prepare for a potential interview. Thanks! 


Edit-
Would you consider it to be similar like anomaly detection in time series? If so what methods you use in your company, i know concept of a few methods like z-score, arima, sarima, med and other but would like to know in practice what you use as well

Edit 2- i am interested more on the topics that i could learn, like i know sql and python will be there",24,15,2025-04-12T23:11:08+00:00,datascience,https://www.reddit.com/r/datascience/comments/1jxtzs1/which_topics_or_questions_frequently_asked_for_a/,"Which topics or questions frequently asked for a data science role in traditional banks? Or for fraud detection/risk modeling topics? Hi,

I am proficient with statistics(causal inference , parametric non parametric tests) and ML models, but i don’t what models, statistical techniques are used in fraud detection and risk modeling, especially in finance industry. So, could anyone suggest FAQs? Or topics i should focus more on? Or any not common topic you ask to candidates that are crucial to know? Role requires 3+ years of experience.

Also, would like to know what techniques you work on in your day to work in fraud detection. It would help me great how it works in industry and prepare for a potential interview. Thanks! 


Edit-
Would you consider it to be similar like anomaly detection in time series? If so what methods you use in your company, i know concept of a few methods like z-score, arima, sarima, med and other but would like to know in practice what you use as well

Edit 2- i am interested more on the topics that i could learn, like i know sql and python will be there",which topics or questions frequently asked for a data science role in traditional banks or for fraud detectionrisk modeling topics hi i am proficient with statisticscausal inference parametric non parametric tests and ml models but i dont what models statistical techniques are used in fraud detection and risk modeling especially in finance industry so could anyone suggest faqs or topics i should focus more on or any not common topic you ask to candidates that are crucial to know role requires years of experience also would like to know what techniques you work on in your day to work in fraud detection it would help me great how it works in industry and prepare for a potential interview thanks edit would you consider it to be similar like anomaly detection in time series if so what methods you use in your company i know concept of a few methods like zscore arima sarima med and other but would like to know in practice what you use as well edit i am interested more on the topics that i could learn like i know sql and python will be there,topic question frequently ask data science role traditional bank fraud detectionrisk model topic hi proficient statisticscausal inference parametric non parametric test ml model not model statistical technique fraud detection risk modeling especially finance industry suggest faqs topic focus common topic ask candidate crucial know role require year experience like know technique work day work fraud detection help great work industry prepare potential interview thank edit consider similar like anomaly detection time series method use company know concept method like zscore arima sarima med like know practice use edit interested topic learn like know sql python
1lvmxce,Linda Yaccarino resigns as CEO of X,,1,0,2025-07-09T16:15:49+00:00,technology,https://www.politico.com/news/2025/07/09/linda-yaccarino-x-ceo-resign-00443742,Linda Yaccarino resigns as CEO of X ,linda yaccarino resigns as ceo of x,linda yaccarino resign ceo x
1lvmuiy,OpenAI's Altman Says He's No Longer a Democrat,,0,6,2025-07-09T16:12:42+00:00,technology,https://finance.yahoo.com/news/openais-altman-says-hes-no-130143356.html,OpenAI's Altman Says He's No Longer a Democrat ,openais altman says hes no longer a democrat,openais altman say s long democrat
1lvm058,Sky Broadband Launch WiFi 7 Router and 5Gbps UK Broadband via CityFibre,,1,0,2025-07-09T15:39:50+00:00,technology,https://www.ispreview.co.uk/index.php/2025/07/sky-broadband-launch-5gbps-uk-broadband-via-cityfibre-and-wifi-7-router.html,Sky Broadband Launch WiFi 7 Router and 5Gbps UK Broadband via CityFibre ,sky broadband launch wifi router and gbps uk broadband via cityfibre,sky broadband launch wifi router gbps uk broadband cityfibre
1lvlwru,"China wants to challenge Airbus and Boeing and shake up global aviation. Here's what you need to know about its upstart planemaker, Comac.",,10,10,2025-07-09T15:36:10+00:00,technology,https://www.businessinsider.com/comac-china-boeing-airbus-rival-what-you-need-to-know-2025-7,"China wants to challenge Airbus and Boeing and shake up global aviation. Here's what you need to know about its upstart planemaker, Comac. ",china wants to challenge airbus and boeing and shake up global aviation heres what you need to know about its upstart planemaker comac,china want challenge airbus boeing shake global aviation here need know upstart planemaker comac
1lvlv2x,Supercharging Solar With Quantum Dots,,2,0,2025-07-09T15:34:20+00:00,technology,https://www.wsj.com/articles/supercharging-solar-with-quantum-dots-d1188f9d?mod=author_content_page_1_pos_1,Supercharging Solar With Quantum Dots ,supercharging solar with quantum dots,supercharge solar quantum dot
1lvlqie,"Student visa seekers are deleting posts, photos and memes, for fear of divergence from “founding principles of the United States”",,14,1,2025-07-09T15:29:16+00:00,technology,https://www.washingtonpost.com/world/2025/07/09/international-students-visas-trump-social-media-online-vetting/,"Student visa seekers are deleting posts, photos and memes, for fear of divergence from “founding principles of the United States” ",student visa seekers are deleting posts photos and memes for fear of divergence from founding principles of the united states,student visa seeker delete post photo meme fear divergence found principle united states
1lvli17,Linda Yaccarino Resigns as CEO of X,,173,36,2025-07-09T15:19:56+00:00,technology,https://variety.com/2025/digital/news/linda-yaccarino-resigns-ceo-x-twitter-1236450704/,Linda Yaccarino Resigns as CEO of X ,linda yaccarino resigns as ceo of x,linda yaccarino resign ceo x
1lvl85b,"Medicaid Middleman Ships Jobs, Tech to India Despite State Rules",,21,4,2025-07-09T15:09:04+00:00,technology,https://news.bloomberglaw.com/health-law-and-business/medicaid-middleman-ships-jobs-tech-to-india-despite-state-rules,"Medicaid Middleman Ships Jobs, Tech to India Despite State Rules ",medicaid middleman ships jobs tech to india despite state rules,medicaid middleman ship job tech india despite state rule
1lvl4a8,"Perplexity launches Comet, an AI-powered web browser",,0,2,2025-07-09T15:04:57+00:00,technology,https://techcrunch.com/2025/07/09/perplexity-launches-comet-an-ai-powered-web-browser/,"Perplexity launches Comet, an AI-powered web browser ",perplexity launches comet an aipowered web browser,perplexity launch comet aipowere web browser
1lvkni4,X CEO Linda Yaccarino to step down,,319,92,2025-07-09T14:46:34+00:00,technology,https://www.axios.com/2025/07/09/x-ceo-linda-yaccarino-resigns,X CEO Linda Yaccarino to step down ,x ceo linda yaccarino to step down,x ceo linda yaccarino step
1lvkdjn,AI is changing the world faster than most realize,,6,11,2025-07-09T14:35:09+00:00,technology,https://www.axios.com/2025/07/09/ai-rapid-change-work-school,AI is changing the world faster than most realize ,ai is changing the world faster than most realize,ai change world fast realize
1lvk0w4,"How algorithms, alpha males and tradwives are winning the war for kids’ minds",,63,69,2025-07-09T14:20:48+00:00,technology,https://19thnews.org/2025/06/internet-culture-algorithms-alpha-males-tradwives/,"How algorithms, alpha males and tradwives are winning the war for kids’ minds ",how algorithms alpha males and tradwives are winning the war for kids minds,algorithm alpha male tradwive win war kid mind
1lvjms5,Nvidia beats Apple and Microsoft to become the world’s first $4 trillion public company,,1631,155,2025-07-09T14:04:25+00:00,technology,https://www.cnn.com/2025/07/09/investing/nvidia-is-the-first-usd4-trillion-company,Nvidia beats Apple and Microsoft to become the world’s first $4 trillion public company ,nvidia beats apple and microsoft to become the worlds first trillion public company,nvidia beat apple microsoft world trillion public company
1lvjm45,"Thread count: Ikea is stitching together a smarter home | With plans to launch more than 20 Matter-over-Thread devices, Ikea is embracing Matter in a move to make its smart home simpler and more affordable",,0,1,2025-07-09T14:03:37+00:00,technology,https://www.theverge.com/smart-home/701697/ikea-matter-thread-new-products-new-smart-home-strategy,"Thread count: Ikea is stitching together a smarter home | With plans to launch more than 20 Matter-over-Thread devices, Ikea is embracing Matter in a move to make its smart home simpler and more affordable ",thread count ikea is stitching together a smarter home with plans to launch more than matteroverthread devices ikea is embracing matter in a move to make its smart home simpler and more affordable,thread count ikea stitch smart home plan launch matteroverthread device ikea embrace matter smart home simple affordable
1lvjjia,Record EU solar generation helped stabilize power supply during heatwave,,15,1,2025-07-09T14:00:41+00:00,technology,https://www.pv-magazine.com/2025/07/09/record-eu-solar-generation-helped-stabilize-power-supply-during-heatwave/,Record EU solar generation helped stabilize power supply during heatwave ,record eu solar generation helped stabilize power supply during heatwave,record eu solar generation help stabilize power supply heatwave
1lvjgpp,ICE Is Searching a Massive Insurance and Medical Bill Database to Find Deportation Targets,,25,4,2025-07-09T13:57:24+00:00,technology,https://www.404media.co/ice-is-searching-a-massive-insurance-and-medical-bill-database-to-find-deportation-targets/,ICE Is Searching a Massive Insurance and Medical Bill Database to Find Deportation Targets ,ice is searching a massive insurance and medical bill database to find deportation targets,ice search massive insurance medical bill database find deportation target
1lvira3,Google co-founder Sergey Brin calls U.N. ‘transparently antisemitic’ after report on tech firms and Gaza,,119,83,2025-07-09T13:26:15+00:00,technology,https://www.washingtonpost.com/technology/2025/07/08/sergey-brin-united-nations-gaza-israel/,Google co-founder Sergey Brin calls U.N. ‘transparently antisemitic’ after report on tech firms and Gaza ,google cofounder sergey brin calls un transparently antisemitic after report on tech firms and gaza,google cofounder sergey brin call un transparently antisemitic report tech firm gaza
1lvim9c,"That white guy who can't get a job at Tim Hortons? He's AI | TikTok removes racially charged videos, made with latest version of Google's Veo",,658,74,2025-07-09T13:20:05+00:00,technology,https://www.cbc.ca/news/ai-generated-fake-marketing-1.7578772,"That white guy who can't get a job at Tim Hortons? He's AI | TikTok removes racially charged videos, made with latest version of Google's Veo ",that white guy who cant get a job at tim hortons hes ai tiktok removes racially charged videos made with latest version of googles veo,white guy not job tim horton s ai tiktok remove racially charge video late version google veo
1lvi698,"Japan breaks world internet speed records with 1.02 million GB per second data transfer over 1,118 miles",,84,16,2025-07-09T13:00:20+00:00,technology,https://economymiddleeast.com/news/japan-breaks-world-internet-speed-records-with-1-02-million-gb-per-second-data-transfer-over-1118-miles/,"Japan breaks world internet speed records with 1.02 million GB per second data transfer over 1,118 miles ",japan breaks world internet speed records with million gb per second data transfer over miles,japan break world internet speed record million gb second data transfer mile
1lvgm03,Chinese firm behind AI agent Manus relocates to Singapore amid US chip curbs,,12,1,2025-07-09T11:42:51+00:00,technology,https://www.scmp.com/tech/tech-trends/article/3317568/chinese-firm-behind-ai-agent-manus-relocates-singapore-amid-us-chip-curbs?module=top_story&pgtype=homepage,Chinese firm behind AI agent Manus relocates to Singapore amid US chip curbs ,chinese firm behind ai agent manus relocates to singapore amid us chip curbs,chinese firm ai agent manus relocate singapore amid chip curb
1lvgcqe,Grok Is Spewing Antisemitic Garbage on X,,1765,234,2025-07-09T11:28:31+00:00,technology,https://www.wired.com/story/grok-antisemitic-posts-x-xai/,Grok Is Spewing Antisemitic Garbage on X ,grok is spewing antisemitic garbage on x,grok spew antisemitic garbage x
1lvgaff,Marco Rubio Impersonated by AI Scam Contacting Foreign Officials,,25,2,2025-07-09T11:25:04+00:00,technology,https://www.rollingstone.com/politics/politics-news/marco-rubio-impersonated-ai-scam-foreign-officials-1235380514/,Marco Rubio Impersonated by AI Scam Contacting Foreign Officials ,marco rubio impersonated by ai scam contacting foreign officials,marco rubio impersonate ai scam contact foreign official
1lvfn20,Turkey bans xAI's Grok over offensive content,,1162,63,2025-07-09T10:47:47+00:00,technology,https://breakingthenews.net/Article/Turkey-bans-xAI's-Grok-over-offensive-content/64424770,Turkey bans xAI's Grok over offensive content ,turkey bans xais grok over offensive content,turkey bans xais grok offensive content
1lvf9hr,"Chinese researchers unveil MemOS, the first 'memory operating system' that gives AI human-like recall",,0,8,2025-07-09T10:24:59+00:00,technology,https://venturebeat.com/ai/chinese-researchers-unveil-memos-the-first-memory-operating-system-that-gives-ai-human-like-recall/,"Chinese researchers unveil MemOS, the first 'memory operating system' that gives AI human-like recall ",chinese researchers unveil memos the first memory operating system that gives ai humanlike recall,chinese researcher unveil memo memory operating system give ai humanlike recall
1lvf618,AI translation service launched for fiction writers and publishers prompts dismay among translators,,16,11,2025-07-09T10:19:05+00:00,technology,https://www.theguardian.com/books/2025/jul/08/globescribe-ai-translation-service-fiction-writers-publishers-prompts-dismay-among-translators,AI translation service launched for fiction writers and publishers prompts dismay among translators ,ai translation service launched for fiction writers and publishers prompts dismay among translators,ai translation service launch fiction writer publisher prompt dismay translator
1lvf519,How terrorist groups are leveraging AI to recruit and finance their operations | Counter-terrorism agencies are scrambling to maintain an advantage and thwart attacks as access to digital tools eases,,15,5,2025-07-09T10:17:26+00:00,technology,https://www.theguardian.com/world/2025/jul/08/terrorist-groups-artificial-intelligence,How terrorist groups are leveraging AI to recruit and finance their operations | Counter-terrorism agencies are scrambling to maintain an advantage and thwart attacks as access to digital tools eases ,how terrorist groups are leveraging ai to recruit and finance their operations counterterrorism agencies are scrambling to maintain an advantage and thwart attacks as access to digital tools eases,terrorist group leverage ai recruit finance operation counterterrorism agency scramble maintain advantage thwart attack access digital tool ease
1lvf4c8,"Middle managers fade as AI rises |  People managers now oversee about twice as many workers as just five years ago, per a new analysis.",,5,1,2025-07-09T10:16:16+00:00,technology,https://www.axios.com/2025/07/08/ai-middle-managers-flattening-layoffs,"Middle managers fade as AI rises |  People managers now oversee about twice as many workers as just five years ago, per a new analysis. ",middle managers fade as ai rises people managers now oversee about twice as many workers as just five years ago per a new analysis,middle manager fade ai rise people manager oversee twice worker year ago new analysis
1lve924,Appeals court voids FTC's 'click to cancel' rule just before it starts,,345,41,2025-07-09T09:20:21+00:00,technology,https://thehill.com/policy/technology/5390731-appeals-court-voids-ftcs-click-to-cancel-rule-just-before-it-starts/,Appeals court voids FTC's 'click to cancel' rule just before it starts ,appeals court voids ftcs click to cancel rule just before it starts,appeal court voids ftcs click cancel rule start
1lve5ot,Court nullifies “click-to-cancel” rule that required easy methods of cancellation,,6150,502,2025-07-09T09:14:12+00:00,technology,https://arstechnica.com/tech-policy/2025/07/us-court-cancels-ftc-rule-that-would-have-made-canceling-subscriptions-easier/,Court nullifies “click-to-cancel” rule that required easy methods of cancellation ,court nullifies clicktocancel rule that required easy methods of cancellation,court nullifie clicktocancel rule require easy method cancellation
1lvds7w,Students can’t use AI to cheat on standardized tests,,0,3,2025-07-09T08:49:11+00:00,technology,https://www.fraserinstitute.org/commentary/students-cant-use-ai-cheat-standardized-tests,Students can’t use AI to cheat on standardized tests ,students cant use ai to cheat on standardized tests,student not use ai cheat standardized test
1lvdi5e,Instagram wrongly accuses some users of breaching child sex abuse rules,,103,16,2025-07-09T08:30:05+00:00,technology,https://www.bbc.com/news/articles/cy8kjdz9nr3o,Instagram wrongly accuses some users of breaching child sex abuse rules ,instagram wrongly accuses some users of breaching child sex abuse rules,instagram wrongly accuse user breach child sex abuse rule
1lvcxoa,Turkey blocks X's Grok chatbot for alleged insults to Erdogan,,85,15,2025-07-09T07:50:34+00:00,technology,https://www.reuters.com/business/media-telecom/turkey-blocks-xs-grok-chatbot-alleged-insults-erdogan-2025-07-09/,Turkey blocks X's Grok chatbot for alleged insults to Erdogan ,turkey blocks xs grok chatbot for alleged insults to erdogan,turkey blocks xs grok chatbot alleged insult erdogan
1lvai0d,"GlobalFoundries to make RISC-V CPUs — fab acquires MIPS, will integrate RISC-V and AI IP into its portfolio",,23,3,2025-07-09T05:13:59+00:00,technology,https://www.tomshardware.com/pc-components/cpus/globalfoundries-to-make-risc-v-cpus-fab-acquires-mips-will-integrate-risc-v-and-ai-ip-into-its-portfolio,"GlobalFoundries to make RISC-V CPUs — fab acquires MIPS, will integrate RISC-V and AI IP into its portfolio ",globalfoundries to make riscv cpus fab acquires mips will integrate riscv and ai ip into its portfolio,globalfoundrie riscv cpus fab acquire mips integrate riscv ai ip portfolio
1lv9syt,Rubio impersonation campaign underscores broad risk of AI voice scams,,45,3,2025-07-09T04:32:51+00:00,technology,https://www.axios.com/2025/07/08/rubio-ai-impersonation-voice-cloning-risk,Rubio impersonation campaign underscores broad risk of AI voice scams ,rubio impersonation campaign underscores broad risk of ai voice scams,rubio impersonation campaign underscore broad risk ai voice scam
1lv8g9a,Abu Dhabi-based Burjeel teams up with Axiom Space for first-ever diabetes study in orbit,,1,0,2025-07-09T03:18:41+00:00,technology,https://americanbazaaronline.com/2025/06/09/burjeel-teams-up-with-axiom-space-for-diabetes-study-in-orbit-463476/,Abu Dhabi-based Burjeel teams up with Axiom Space for first-ever diabetes study in orbit ,abu dhabibased burjeel teams up with axiom space for firstever diabetes study in orbit,abu dhabibased burjeel team axiom space firstever diabetes study orbit
1lv81du,Feds brag about hefty Oracle discount – licensing experts smell a lock-in,,516,33,2025-07-09T02:57:39+00:00,technology,https://www.theregister.com/2025/07/08/gsa_oracle_deal/,Feds brag about hefty Oracle discount – licensing experts smell a lock-in ,feds brag about hefty oracle discount licensing experts smell a lockin,fed brag hefty oracle discount licensing expert smell lockin
1lv6gtm,Hertz AI Scanner Charges $350 for Tiny 'Dings' on Rental and This Is Going Off the Rails,,7377,476,2025-07-09T01:39:24+00:00,technology,https://www.thedrive.com/news/hertz-ai-scanner-charging-350-for-dime-sized-dings-proves-this-is-going-off-the-rails,Hertz AI Scanner Charges $350 for Tiny 'Dings' on Rental and This Is Going Off the Rails ,hertz ai scanner charges for tiny dings on rental and this is going off the rails,hertz ai scanner charge tiny ding rental go rail
1lv6e4j,Immortality at a price: How the promise of delaying death has become a consumer marketing bonanza,,23,7,2025-07-09T01:35:41+00:00,technology,https://phys.org/news/2025-06-immortality-price-delaying-death-consumer.html,Immortality at a price: How the promise of delaying death has become a consumer marketing bonanza ,immortality at a price how the promise of delaying death has become a consumer marketing bonanza,immortality price promise delay death consumer marketing bonanza
1lv5lnz,Call Center Workers Are Tired of Being Mistaken for AI,,34,14,2025-07-09T00:56:18+00:00,technology,https://www.bloomberg.com/news/articles/2025-06-27/as-ai-infiltrates-call-centers-human-workers-are-being-mistaken-for-bots,Call Center Workers Are Tired of Being Mistaken for AI ,call center workers are tired of being mistaken for ai,center worker tired mistake ai
1lv54a3,AI is Dulling Your Kid's Critical Thinking and Dating Your Partner,,302,57,2025-07-09T00:33:19+00:00,technology,https://www.levelman.com/ai-is-dulling-your-kids-critical-thinking-and-dating-your-partner/,AI is Dulling Your Kid's Critical Thinking and Dating Your Partner ,ai is dulling your kids critical thinking and dating your partner,ai dull kid critical thinking date partner
1lv290x,Elon Musk’s AI chatbot churns out antisemitic posts days after update,,549,59,2025-07-08T22:24:07+00:00,technology,https://www.nbcnews.com/tech/internet/elon-musk-grok-antisemitic-posts-x-rcna217634,Elon Musk’s AI chatbot churns out antisemitic posts days after update ,elon musks ai chatbot churns out antisemitic posts days after update,elon musk ai chatbot churn antisemitic post day update
1lv3agc,SpaceX in talks to raise new funding at $400B valuation,,4,5,2025-07-08T23:09:48+00:00,technology,https://techcrunch.com/2025/07/08/spacex-in-talks-to-raise-new-funding-at-400b-valuation/,SpaceX in talks to raise new funding at $400B valuation ,spacex in talks to raise new funding at b valuation,spacex talk raise new funding b valuation
1lv36z0,"Streaming Subscriptions May Get Tougher to Cancel Under the FTC's ""Click to Cancel"" rule, businesses would've had make it as easy to cancel subscriptions as it is to sign up. An appeals court has now struck that measure down.",,679,68,2025-07-08T23:05:25+00:00,technology,https://www.hollywoodreporter.com/business/business-news/it-may-get-harder-cancel-streaming-services-again-1236309793/,"Streaming Subscriptions May Get Tougher to Cancel Under the FTC's ""Click to Cancel"" rule, businesses would've had make it as easy to cancel subscriptions as it is to sign up. An appeals court has now struck that measure down. ",streaming subscriptions may get tougher to cancel under the ftcs click to cancel rule businesses wouldve had make it as easy to cancel subscriptions as it is to sign up an appeals court has now struck that measure down,streaming subscription tough cancel ftcs click cancel rule business ve easy cancel subscription sign appeal court strike measure
1lv23f9,Brazil and China to study South American transcontinental railway project,,6,0,2025-07-08T22:17:33+00:00,technology,https://www.scmp.com/news/china/diplomacy/article/3317462/brazil-and-china-study-south-american-transcontinental-railway-project?module=top_story&pgtype=homepage,Brazil and China to study South American transcontinental railway project ,brazil and china to study south american transcontinental railway project,brazil china study south american transcontinental railway project
1lv22zg,China to speed up bullet-train connectivity with neighbours,,10,4,2025-07-08T22:17:03+00:00,technology,https://www.scmp.com/economy/china-economy/article/3317391/china-speed-bullet-train-connectivity-neighbours?module=top_story&pgtype=homepage,China to speed up bullet-train connectivity with neighbours ,china to speed up bullettrain connectivity with neighbours,china speed bullettrain connectivity neighbour
1lv1rtx,Malicious Chrome extensions with 1.7M installs found on Web Store,,742,70,2025-07-08T22:03:58+00:00,technology,https://www.bleepingcomputer.com/news/security/malicious-chrome-extensions-with-17m-installs-found-on-web-store/,Malicious Chrome extensions with 1.7M installs found on Web Store ,malicious chrome extensions with m installs found on web store,malicious chrome extension m install find web store
1lv1n0l,"Microsoft July 2025 Patch Tuesday fixes one zero-day, 137 flaws",,11,1,2025-07-08T21:58:35+00:00,technology,https://www.bleepingcomputer.com/news/microsoft/microsoft-july-2025-patch-tuesday-fixes-one-zero-day-137-flaws/,"Microsoft July 2025 Patch Tuesday fixes one zero-day, 137 flaws ",microsoft july patch tuesday fixes one zeroday flaws,microsoft july patch tuesday fix zeroday flaw
1lv0wxb,Lawsuit challenging age verification for adult websites dropped in Florida,,522,118,2025-07-08T21:28:43+00:00,technology,https://www.palmbeachpost.com/story/news/local/state/2025/07/08/lawsuit-against-florida-law-requiring-age-checks-on-porn-sites-dropped/84507875007/,Lawsuit challenging age verification for adult websites dropped in Florida ,lawsuit challenging age verification for adult websites dropped in florida,lawsuit challenge age verification adult website drop florida
1lv0sn0,Scholars sneaking phrases into papers to fool AI reviewers,,267,18,2025-07-08T21:23:48+00:00,technology,https://www.theregister.com/2025/07/07/scholars_try_to_fool_llm_reviewers/,Scholars sneaking phrases into papers to fool AI reviewers ,scholars sneaking phrases into papers to fool ai reviewers,scholar sneak phrase paper fool ai reviewer
1lv0nu9,Popular industry security tool repurposed by cybercriminals to deploy infostealer malware — Shellter developer blasts 'reckless and unprofessional' researchers for not disclosing issue for months,,9,0,2025-07-08T21:18:20+00:00,technology,https://www.tomshardware.com/tech-industry/cyber-security/popular-industry-security-tool-repurposed-by-cybercriminals-to-deploy-infostealer-malware-shellter-developer-blasts-reckless-and-unprofessional-researchers-for-not-disclosing-issue-for-months,Popular industry security tool repurposed by cybercriminals to deploy infostealer malware — Shellter developer blasts 'reckless and unprofessional' researchers for not disclosing issue for months ,popular industry security tool repurposed by cybercriminals to deploy infostealer malware shellter developer blasts reckless and unprofessional researchers for not disclosing issue for months,popular industry security tool repurpose cybercriminal deploy infosteal malware shellter developer blast reckless unprofessional researcher disclose issue month
1lv0byk,Why Americans Can’t Buy the World’s Best Electric Car,,489,309,2025-07-08T21:05:12+00:00,technology,https://www.nytimes.com/2025/07/08/opinion/byd-china-car-ev.html?unlocked_article_code=1.U08.cQTa.Gb4QhsgH70W9,Why Americans Can’t Buy the World’s Best Electric Car ,why americans cant buy the worlds best electric car,americans not buy world good electric car
1lv041d,Apple announces chief operating officer transition,,92,38,2025-07-08T20:56:48+00:00,technology,https://www.apple.com/newsroom/2025/07/apple-announces-chief-operating-officer-transition/,Apple announces chief operating officer transition ,apple announces chief operating officer transition,apple announce chief operating officer transition
1lv0090,CEO of My Pillow Mike Lindell's lawyers fined for using AI for court documents,,4890,70,2025-07-08T20:52:37+00:00,technology,https://cbsaustin.com/news/nation-world/ceo-of-my-pillow-mike-lindell-lawyers-fined-for-using-ai-court-documents-denver-intelligence-eric-coomer-dominion-voting-system-generative,CEO of My Pillow Mike Lindell's lawyers fined for using AI for court documents ,ceo of my pillow mike lindells lawyers fined for using ai for court documents,ceo pillow mike lindell lawyer fine ai court document
1luzzlj,Bezos Expedition Leads $72 Million Investment in AI Data Firm Toloka,,0,0,2025-07-08T20:51:54+00:00,technology,https://www.pymnts.com/news/investment-tracker/2025/bezos-expedition-leads-72-million-investment-in-ai-data-firm-toloka/,Bezos Expedition Leads $72 Million Investment in AI Data Firm Toloka ,bezos expedition leads million investment in ai data firm toloka,bezos expedition lead million investment ai datum firm toloka
1luzyuy,Jeff Bezos gave $100 million for a satellite. It just got lost in space,,5600,447,2025-07-08T20:51:07+00:00,technology,https://www.the-independent.com/tech/jeff-bezos-satellite-lost-space-b2780984.html,Jeff Bezos gave $100 million for a satellite. It just got lost in space ,jeff bezos gave million for a satellite it just got lost in space,jeff bezos give million satellite get lose space
1luzr1h,A New Era of Internet Regulation Is About to Begin,,1,4,2025-07-08T20:42:33+00:00,technology,https://www.theatlantic.com/ideas/archive/2025/07/supreme-court-pornography-ai-internet/683449/?gift=eTYG9R-ZfDG5bOekmkvUouNze_9uD1K-QMlfeOKQ_JI,A New Era of Internet Regulation Is About to Begin ,a new era of internet regulation is about to begin,new era internet regulation begin
1luzjlw,A Man Had His Identity Stolen By A Child Exploitation Trader. Then The FBI Raided His Home,,1660,49,2025-07-08T20:34:23+00:00,technology,https://www.forbes.com/sites/thomasbrewster/2025/07/08/the-wiretap-a-man-had-his-identity-stolen-by-a-child-exploitation-trader-then-the-fbi-raided-his-home/,A Man Had His Identity Stolen By A Child Exploitation Trader. Then The FBI Raided His Home ,a man had his identity stolen by a child exploitation trader then the fbi raided his home,man identity steal child exploitation trader fbi raid home
1luzib7,A Marco Rubio impostor is using AI voice to call high-level officials,,25,10,2025-07-08T20:32:57+00:00,technology,https://www.washingtonpost.com/national-security/2025/07/08/marco-rubio-ai-imposter-signal/?pwapi_token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJyZWFzb24iOiJnaWZ0IiwibmJmIjoxNzUxOTQ3MjAwLCJpc3MiOiJzdWJzY3JpcHRpb25zIiwiZXhwIjoxNzUzMzI5NTk5LCJpYXQiOjE3NTE5NDcyMDAsImp0aSI6IjhkYzljMTliLTQ4OTItNDU1Yy04ZWM1LTk3OTZkNDJhOWFhNCIsInVybCI6Imh0dHBzOi8vd3d3Lndhc2hpbmd0b25wb3N0LmNvbS9uYXRpb25hbC1zZWN1cml0eS8yMDI1LzA3LzA4L21hcmNvLXJ1YmlvLWFpLWltcG9zdGVyLXNpZ25hbC8ifQ.FXo72snQ4-mCIcX0ZziTprUYrRvc5av38deD9RnjkUc,A Marco Rubio impostor is using AI voice to call high-level officials ,a marco rubio impostor is using ai voice to call highlevel officials,marco rubio impostor ai voice highlevel official
1lux2h8,Rivian’s RAD Tuner Is Like An Equalizer For Your EV’s Powertrain,,51,3,2025-07-08T18:58:15+00:00,technology,https://www.thedrive.com/news/rivians-rad-tuner-is-like-an-equalizer-for-your-evs-powertrain,Rivian’s RAD Tuner Is Like An Equalizer For Your EV’s Powertrain ,rivians rad tuner is like an equalizer for your evs powertrain,rivian rad tuner like equalizer evs powertrain
1luwjy1,"Rivian’s new Quad-Motor R1T and R1S beat the competition in any conditions | Faster than a supercar to 60, still able to rock crawl with the best of them.",,176,77,2025-07-08T18:38:33+00:00,technology,https://arstechnica.com/cars/2025/07/rivians-new-quad-motor-r1t-and-r1s-beat-the-competition-in-any-conditions/,"Rivian’s new Quad-Motor R1T and R1S beat the competition in any conditions | Faster than a supercar to 60, still able to rock crawl with the best of them. ",rivians new quadmotor rt and rs beat the competition in any conditions faster than a supercar to still able to rock crawl with the best of them,rivian new quadmotor rt rs beat competition condition fast supercar able rock crawl good
1luujwl,Waymo offers teen accounts for driverless rides,,94,47,2025-07-08T17:23:21+00:00,technology,https://www.cnbc.com/2025/07/08/waymo-teen-accounts.html,Waymo offers teen accounts for driverless rides ,waymo offers teen accounts for driverless rides,waymo offer teen account driverless ride
1luuiwl,Linux Foundation adopts A2A protocol to help solve one of AI's most pressing challenges,,7,3,2025-07-08T17:22:18+00:00,technology,https://www.zdnet.com/article/linux-foundation-adopts-a2a-protocol-to-help-solve-one-of-ais-most-pressing-challenges/,Linux Foundation adopts A2A protocol to help solve one of AI's most pressing challenges ,linux foundation adopts aa protocol to help solve one of ais most pressing challenges,linux foundation adopt aa protocol help solve ais pressing challenge
1luu9gs,‘Cyber warriors’ initiative targeting online ‘Russophobia’ announced in Russian region,,29,9,2025-07-08T17:12:19+00:00,technology,https://novayagazeta.eu/articles/2025/07/08/cyber-warriors-initiative-targeting-online-russophobia-announced-in-russian-region-en-news,‘Cyber warriors’ initiative targeting online ‘Russophobia’ announced in Russian region ,cyber warriors initiative targeting online russophobia announced in russian region,cyber warrior initiative target online russophobia announce russian region
1lut9e1,Mastodon 4.4 released,,0,2,2025-07-08T16:33:45+00:00,technology,https://blog.joinmastodon.org/2025/07/mastodon-4.4/,Mastodon 4.4 released ,mastodon released,mastodon release
1lut3sf,How artificial intelligence is transforming the world,,0,7,2025-07-08T16:27:51+00:00,technology,https://www.brookings.edu/articles/how-artificial-intelligence-is-transforming-the-world/?b=1,How artificial intelligence is transforming the world ,how artificial intelligence is transforming the world,artificial intelligence transform world
1lut3df,"US Air Force suspends SpaceX rocket project on Pacific atoll, report says",,90,2,2025-07-08T16:27:24+00:00,technology,https://www.reuters.com/world/us/us-air-force-suspends-spacex-rocket-project-pacific-atoll-report-says-2025-07-04/,"US Air Force suspends SpaceX rocket project on Pacific atoll, report says ",us air force suspends spacex rocket project on pacific atoll report says,air force suspend spacex rocket project pacific atoll report say
1lusr7r,Why AI is out performing humans and what it means for our jobs,,0,9,2025-07-08T16:14:16+00:00,technology,https://www.forbes.com/sites/forbestechcouncil/2024/05/22/how-ai-is-replacing-humans-in-the-workplace-and-what-to-do-about-it/,Why AI is out performing humans and what it means for our jobs ,why ai is out performing humans and what it means for our jobs,ai perform human mean job
1lus72z,Trump pulls plug on UK research into air pollution and global warming,,2723,105,2025-07-08T15:52:48+00:00,technology,https://inews.co.uk/news/trump-pulls-uk-research-air-pollution-global-warming-3793773?ITO=newsnow,Trump pulls plug on UK research into air pollution and global warming ,trump pulls plug on uk research into air pollution and global warming,trump pull plug uk research air pollution global warming
1lurj3y,"Mamona attacks without internet, erases itself, and fools your antivirus: here's what makes it terrifyingly effective",,169,58,2025-07-08T15:27:12+00:00,technology,https://www.techradar.com/pro/security/security-researchers-discover-dangerous-malware-thats-small-fast-can-work-locally-and-doesnt-need-a-master-command-heres-what-you-need-to-know,"Mamona attacks without internet, erases itself, and fools your antivirus: here's what makes it terrifyingly effective ",mamona attacks without internet erases itself and fools your antivirus heres what makes it terrifyingly effective,mamona attack internet erase fool antivirus here make terrifyingly effective
1luqm12,Marjorie Taylor Greene Is Going After 'Chemtrails' With New Bill to Ban Weather Modification,,18348,1669,2025-07-08T14:52:00+00:00,technology,https://gizmodo.com/marjorie-taylor-greene-is-going-after-chemtrails-with-new-bill-to-ban-weather-modification-2000625097,Marjorie Taylor Greene Is Going After 'Chemtrails' With New Bill to Ban Weather Modification ,marjorie taylor greene is going after chemtrails with new bill to ban weather modification,marjorie taylor greene go chemtrail new bill ban weather modification
1lupcyw,Second study finds Uber used opaque algorithm to dramatically boost profits,,382,34,2025-07-08T14:02:00+00:00,technology,https://www.theguardian.com/technology/2025/jun/25/second-study-finds-uber-used-opaque-algorithm-to-dramatically-boost-profits?CMP=share_btn_url,Second study finds Uber used opaque algorithm to dramatically boost profits ,second study finds uber used opaque algorithm to dramatically boost profits,second study find uber opaque algorithm dramatically boost profit
1lup260,Researchers Jailbreak AI by Flooding It With Bullshit Jargon,,663,26,2025-07-08T13:49:32+00:00,technology,https://www.404media.co/researchers-jailbreak-ai-by-flooding-it-with-bullshit-jargon/,Researchers Jailbreak AI by Flooding It With Bullshit Jargon ,researchers jailbreak ai by flooding it with bullshit jargon,researcher jailbreak ai flood bullshit jargon
1luojio,"Threads is nearing X's daily app users, new data shows | TechCrunch",,168,48,2025-07-08T13:27:03+00:00,technology,https://techcrunch.com/2025/07/07/threads-is-nearing-xs-daily-app-users-new-data-shows/,"Threads is nearing X's daily app users, new data shows | TechCrunch ",threads is nearing xs daily app users new data shows techcrunch,thread near xs daily app user new datum show techcrunch
1lunrok,Apple appeals $580 million EU fine over App Store restrictions,,159,29,2025-07-08T12:52:06+00:00,technology,https://www.techspot.com/news/108590-apple-appeals-580-million-eu-fine-over-app.html,Apple appeals $580 million EU fine over App Store restrictions ,apple appeals million eu fine over app store restrictions,apple appeal million eu fine app store restriction
1luno13,It’s time to retire the ticket: An IT roadmap for agentic AI,,0,12,2025-07-08T12:47:20+00:00,technology,https://www.cio.com/article/4018133/its-time-to-retire-the-ticket-an-it-roadmap-for-agentic-ai.html,It’s time to retire the ticket: An IT roadmap for agentic AI ,its time to retire the ticket an it roadmap for agentic ai,time retire ticket roadmap agentic ai
1luncji,SCOTUS Porn Ruling A Boon For Age Verification Companies; 40% Of Americans Now Live Under Anti-Porn Age-Gating Laws,,3266,494,2025-07-08T12:32:05+00:00,technology,https://www.techdirt.com/2025/07/07/scotus-porn-ruling-a-boon-for-age-verification-companies-40-of-americans-now-live-under-anti-porn-age-gating-laws/,SCOTUS Porn Ruling A Boon For Age Verification Companies; 40% Of Americans Now Live Under Anti-Porn Age-Gating Laws ,scotus porn ruling a boon for age verification companies of americans now live under antiporn agegating laws,scotu porn rule boon age verification company americans live antiporn agegate law
1lun1tk,A Marco Rubio impostor is using AI voice to call high-level officials,,1088,50,2025-07-08T12:17:40+00:00,technology,https://www.washingtonpost.com/national-security/2025/07/08/marco-rubio-ai-imposter-signal/,A Marco Rubio impostor is using AI voice to call high-level officials ,a marco rubio impostor is using ai voice to call highlevel officials,marco rubio impostor ai voice highlevel official
1lulrbq,"Honda delays, downsizes next-gen hydrogen fuel cell plans",,14,11,2025-07-08T11:08:25+00:00,technology,https://www.autonews.com/honda/an-honda-scales-back-hydrogen-fuel-cell-plans-0701/,"Honda delays, downsizes next-gen hydrogen fuel cell plans ",honda delays downsizes nextgen hydrogen fuel cell plans,honda delay downsize nextgen hydrogen fuel cell plan
1lul1q2,EU launches Quantum Act to boost private investment in quantum tech by 2030,,3,0,2025-07-08T10:26:07+00:00,technology,https://www.reuters.com/business/eu-turns-private-funding-boost-quantum-technology-ambition-2025-07-02,EU launches Quantum Act to boost private investment in quantum tech by 2030 ,eu launches quantum act to boost private investment in quantum tech by,eu launch quantum act boost private investment quantum tech
1luksuf,Samsung to buy US healthcare services company Xealth,,13,2,2025-07-08T10:10:45+00:00,technology,https://www.reuters.com/business/healthcare-pharmaceuticals/samsung-elec-buy-healthcare-services-company-xealth-2025-07-08/,Samsung to buy US healthcare services company Xealth ,samsung to buy us healthcare services company xealth,samsung buy healthcare services company xealth
1luknzl,Nvidia’s Jensen Huang unveils next-gen Rubin AI chips at GTC 2025 big leap in reasoning & robotics ahead,,10,1,2025-07-08T10:02:17+00:00,technology,https://apnews.com/article/nvidia-gtc-jensen-huang-ai-457e9260aa2a34c1bbcc07c98b7a0555,Nvidia’s Jensen Huang unveils next-gen Rubin AI chips at GTC 2025 big leap in reasoning & robotics ahead ,nvidias jensen huang unveils nextgen rubin ai chips at gtc big leap in reasoning robotics ahead,nvidias jensen huang unveil nextgen rubin ai chip gtc big leap reasoning robotic ahead
1luk3ke,CoreWeave acquires data center provider Core Scientific in $9B stock deal,,0,0,2025-07-08T09:25:01+00:00,technology,https://techcrunch.com/2025/07/07/coreweave-acquires-data-center-provider-core-scientific-in-9b-stock-deal/,CoreWeave acquires data center provider Core Scientific in $9B stock deal ,coreweave acquires data center provider core scientific in b stock deal,coreweave acquire datum center provider core scientific b stock deal
1lujod3,DeepMind Patent Gives AI Robots ‘Inner Speech’,,0,5,2025-07-08T08:56:10+00:00,technology,https://www.thedailyupside.com/cio/enterprise-ai/deepmind-patent-gives-ai-robots-inner-speech/,DeepMind Patent Gives AI Robots ‘Inner Speech’ ,deepmind patent gives ai robots inner speech,deepmind patent give ai robot inner speech
1lujnr0,Sakana AI's new algorithm lets large language models work together to solve complex problems,,1,1,2025-07-08T08:54:57+00:00,technology,https://the-decoder.com/sakana-ais-new-algorithm-lets-large-language-models-work-together-to-solve-complex-problems/,Sakana AI's new algorithm lets large language models work together to solve complex problems ,sakana ais new algorithm lets large language models work together to solve complex problems,sakana ais new algorithm let large language model work solve complex problem
1lujm24,How Should We Regulate AI? The Same Way We Do Airlines,,9,7,2025-07-08T08:51:37+00:00,technology,https://www.bloomberg.com/opinion/articles/2025-07-07/how-do-we-regulate-ai-the-same-way-we-do-airlines,How Should We Regulate AI? The Same Way We Do Airlines ,how should we regulate ai the same way we do airlines,regulate ai way airline
1luhtzm,Amazon asks corporate workers to ‘volunteer’ help with grocery deliveries as Prime Day frenzy approaches,,1213,181,2025-07-08T06:50:13+00:00,technology,https://www.theguardian.com/technology/2025/jul/07/amazon-grocery-deliveries-prime-day,Amazon asks corporate workers to ‘volunteer’ help with grocery deliveries as Prime Day frenzy approaches ,amazon asks corporate workers to volunteer help with grocery deliveries as prime day frenzy approaches,amazon ask corporate worker volunteer help grocery delivery prime day frenzy approach
1lugocv,"Unless users take action, Android will let Gemini access third-party apps",,261,52,2025-07-08T05:35:47+00:00,technology,https://arstechnica.com/security/2025/07/unless-users-take-action-android-will-let-gemini-access-third-party-apps/,"Unless users take action, Android will let Gemini access third-party apps ",unless users take action android will let gemini access thirdparty apps,user action android let gemini access thirdparty app
1lug58b,Tennis players criticize AI technology used by Wimbledon,,63,44,2025-07-08T05:03:20+00:00,technology,https://techcrunch.com/2025/07/07/tennis-players-criticize-ai-technology-used-by-wimbledon/,Tennis players criticize AI technology used by Wimbledon ,tennis players criticize ai technology used by wimbledon,tennis player criticize ai technology wimbledon
1luekp2,Magnetic resonance technique can detect fentanyl through packaging,,66,5,2025-07-08T03:36:07+00:00,technology,https://phys.org/news/2025-07-magnetic-resonance-technique-fentanyl-packaging.html,Magnetic resonance technique can detect fentanyl through packaging ,magnetic resonance technique can detect fentanyl through packaging,magnetic resonance technique detect fentanyl packaging
1lueer1,Russia allegedly field-testing deadly next-gen AI drone powered by Nvidia Jetson Orin — Ukrainian military official says Shahed MS001 is a 'digital predator' that identifies targets on its own,,1729,167,2025-07-08T03:27:32+00:00,technology,https://www.tomshardware.com/tech-industry/artificial-intelligence/russia-allegedly-field-testing-deadly-next-gen-ai-drone-powered-by-nvidia-jetson-orin-ukrainian-military-official-says-shahed-ms001-is-a-digital-predator-that-identifies-targets-on-its-own,Russia allegedly field-testing deadly next-gen AI drone powered by Nvidia Jetson Orin — Ukrainian military official says Shahed MS001 is a 'digital predator' that identifies targets on its own ,russia allegedly fieldtesting deadly nextgen ai drone powered by nvidia jetson orin ukrainian military official says shahed ms is a digital predator that identifies targets on its own,russia allegedly fieldteste deadly nextgen ai drone power nvidia jetson orin ukrainian military official say shahe ms digital predator identify target
1ludu8i,The Path to Medical Superintelligence,,0,0,2025-07-08T02:58:38+00:00,technology,https://microsoft.ai/new/the-path-to-medical-superintelligence,The Path to Medical Superintelligence ,the path to medical superintelligence,path medical superintelligence
1ludobw,Chinese scientists create cooling technology for deep coal mines,,2,2,2025-07-08T02:50:28+00:00,technology,https://globalenergyprize.org/en/2025/06/11/chinese-scientists-create-cooling-technology-for-deep-coal-mines/,Chinese scientists create cooling technology for deep coal mines ,chinese scientists create cooling technology for deep coal mines,chinese scientist create cool technology deep coal mine
1lud621,Tech founders call on Sequoia Capital to denounce VC Shaun Maguire's Mamdani comments,,247,15,2025-07-08T02:25:30+00:00,technology,https://www.cnbc.com/2025/07/07/founders-sign-letter-to-sequoia-on-shaun-maguires-mamdani-remarks.html,Tech founders call on Sequoia Capital to denounce VC Shaun Maguire's Mamdani comments ,tech founders call on sequoia capital to denounce vc shaun maguires mamdani comments,tech founder sequoia capital denounce vc shaun maguire mamdani comment
1lucd4k,Starlink-powered drone narco-sub intercepted by Colombian Navy — boat was converted into a drone for uncrewed smuggling,,553,60,2025-07-08T01:46:02+00:00,technology,https://www.tomshardware.com/tech-industry/starlink-powered-drone-narco-sub-intercepted-by-colombian-navy-boat-was-converted-into-a-drone-for-uncrewed-smuggling,Starlink-powered drone narco-sub intercepted by Colombian Navy — boat was converted into a drone for uncrewed smuggling ,starlinkpowered drone narcosub intercepted by colombian navy boat was converted into a drone for uncrewed smuggling,starlinkpowere drone narcosub intercept colombian navy boat convert drone uncrewed smuggling
1lubbsi,Context engineering emerges as crucial discipline for AI agent success,,10,0,2025-07-08T00:56:00+00:00,technology,https://ppc.land/context-engineering-emerges-as-crucial-discipline-for-ai-agent-success/#google_vignette,Context engineering emerges as crucial discipline for AI agent success ,context engineering emerges as crucial discipline for ai agent success,context engineering emerge crucial discipline ai agent success
1lub9ad,US scientists unveil thorium nuclear fuel breakthrough for advanced reactors,,893,51,2025-07-08T00:52:36+00:00,technology,https://www.msn.com/en-us/money/markets/us-scientists-unveil-thorium-nuclear-fuel-breakthrough-for-advanced-reactors/ar-AA1GENVG,US scientists unveil thorium nuclear fuel breakthrough for advanced reactors ,us scientists unveil thorium nuclear fuel breakthrough for advanced reactors,scientist unveil thorium nuclear fuel breakthrough advanced reactor
1lub6h8,Waymo robotaxis are heading to Philadelphia and NYC,,86,19,2025-07-08T00:48:49+00:00,technology,https://techcrunch.com/2025/07/07/waymo-heading-to-philadelphia-and-nyc/,Waymo robotaxis are heading to Philadelphia and NYC ,waymo robotaxis are heading to philadelphia and nyc,waymo robotaxis head philadelphia nyc
1luak6d,"GitHub CEO To Engineers: 'Smartest' Companies Will Hire More Software Engineers, Not Less As…",,3182,196,2025-07-08T00:19:36+00:00,technology,https://timesofindia.indiatimes.com/technology/tech-news/github-ceo-to-engineers-smartest-companies-will-hire-more-software-engineers-not-less-as/amp_articleshow/122282233.cms,"GitHub CEO To Engineers: 'Smartest' Companies Will Hire More Software Engineers, Not Less As… ",github ceo to engineers smartest companies will hire more software engineers not less as,github ceo engineer smart company hire software engineer
1luaex8,Samsung expects second-quarter profits to more than halve as it struggles to capture AI demand,,75,35,2025-07-08T00:12:51+00:00,technology,https://www.cnbc.com/2025/07/08/samsung-projects-second-quarter-profits-drop-56-percent-struggles-ai-demand-nvidia-sk-hynix-micron.html,Samsung expects second-quarter profits to more than halve as it struggles to capture AI demand ,samsung expects secondquarter profits to more than halve as it struggles to capture ai demand,samsung expect secondquarter profit halve struggle capture ai demand
1luaenu,DOJ goes after US citizen for developing anti-ICE app,,42419,2057,2025-07-08T00:12:29+00:00,technology,https://appleinsider.com/articles/25/07/07/doj-goes-after-us-citizen-for-developing-anti-ice-app/amp/,DOJ goes after US citizen for developing anti-ICE app ,doj goes after us citizen for developing antiice app,doj go citizen develop antiice app
1lu9ajz,VMware’s rivals ramp up their efforts to create alternative stacks,,12,0,2025-07-07T23:21:26+00:00,technology,https://www.theregister.com/2025/07/07/vmware_rivals_ramp_virtualization_efforts/?td=rt-3a,VMware’s rivals ramp up their efforts to create alternative stacks ,vmwares rivals ramp up their efforts to create alternative stacks,vmware rivals ramp effort create alternative stack
1lu99nh,'Rising ASIC coalition' seeks to jettison Nvidia — Industry report claims firms are accelerating development in order to reduce dependence on the giant,,16,1,2025-07-07T23:20:18+00:00,technology,https://www.tomshardware.com/tech-industry/rising-asic-coalition-seeks-to-jettison-nvidia-industry-report-claims-firms-are-accelerating-development-in-order-to-reduce-dependence-on-the-giant,'Rising ASIC coalition' seeks to jettison Nvidia — Industry report claims firms are accelerating development in order to reduce dependence on the giant ,rising asic coalition seeks to jettison nvidia industry report claims firms are accelerating development in order to reduce dependence on the giant,rise asic coalition seek jettison nvidia industry report claim firm accelerate development order reduce dependence giant
1lu8ugr,Apple Loses Top AI Models Executive to Meta’s Hiring Spree,,18,2,2025-07-07T23:01:37+00:00,technology,https://www.bloomberg.com/news/articles/2025-07-07/apple-loses-its-top-ai-models-executive-to-meta-s-hiring-spree,Apple Loses Top AI Models Executive to Meta’s Hiring Spree ,apple loses top ai models executive to metas hiring spree,apple lose ai model executive metas hire spree
1lu8a7m,xAI updated Grok to be more ‘politically incorrect’,,806,88,2025-07-07T22:37:33+00:00,technology,https://www.theverge.com/ai-artificial-intelligence/699788/xai-updated-grok-to-be-more-politically-incorrect,xAI updated Grok to be more ‘politically incorrect’ ,xai updated grok to be more politically incorrect,xai update grok politically incorrect
1lu7wgt,"Call of Duty: WW2 pulled from PC following reports of remote code exploit trolling players with 'Notepad pop-ups, PC shutdowns' and desktop wallpaper of a lawyer",,49,9,2025-07-07T22:21:24+00:00,technology,https://www.pcgamer.com/games/call-of-duty/call-of-duty-ww2-pulled-from-pc-following-reports-of-remote-code-exploit-trolling-players-with-notepad-pop-ups-pc-shutdowns-and-desktop-wallpaper-of-a-lawyer/,"Call of Duty: WW2 pulled from PC following reports of remote code exploit trolling players with 'Notepad pop-ups, PC shutdowns' and desktop wallpaper of a lawyer ",call of duty ww pulled from pc following reports of remote code exploit trolling players with notepad popups pc shutdowns and desktop wallpaper of a lawyer,duty ww pull pc follow report remote code exploit trolling player notepad popup pc shutdown desktop wallpaper lawyer
1lu6ibd,Trump and Congress finalize law that could hurt your Wi-Fi,,4287,222,2025-07-07T21:24:22+00:00,technology,https://arstechnica.com/tech-policy/2025/07/trump-and-congress-finalize-law-that-could-hurt-your-wi-fi/,Trump and Congress finalize law that could hurt your Wi-Fi ,trump and congress finalize law that could hurt your wifi,trump congress finalize law hurt wifi
1lu6g1v,Intel layoffs begin: Chipmaker is cutting many thousands of jobs,,795,95,2025-07-07T21:21:50+00:00,technology,https://www.oregonlive.com/silicon-forest/2025/07/intel-layoffs-begin-chipmaker-is-cutting-many-thousands-of-jobs.html,Intel layoffs begin: Chipmaker is cutting many thousands of jobs ,intel layoffs begin chipmaker is cutting many thousands of jobs,intel layoff begin chipmaker cut thousand job
1lu63ur,Anthropic and OpenAI Have Begun The Subprime AI Crisis,,802,127,2025-07-07T21:08:27+00:00,technology,https://www.wheresyoured.at/anthropic-and-openai-have-begun-the-subprime-ai-crisis/,Anthropic and OpenAI Have Begun The Subprime AI Crisis ,anthropic and openai have begun the subprime ai crisis,anthropic openai begin subprime ai crisis
1lu3wgf,How Let's Encrypt made the internet safer and HTTPS standard - and free,,108,6,2025-07-07T19:43:50+00:00,technology,https://www.zdnet.com/home-and-office/networking/how-lets-encrypt-made-the-internet-safer-and-https-standard-and-free/,How Let's Encrypt made the internet safer and HTTPS standard - and free ,how lets encrypt made the internet safer and https standard and free,let encrypt internet safe https standard free
1lu2zwf,Fubo pays $3.4M to settle claims it illegally shared user data with advertisers,,92,7,2025-07-07T19:08:43+00:00,technology,https://arstechnica.com/gadgets/2025/07/fubo-pays-3-4m-to-settle-claims-it-illegally-shared-user-data-with-advertisers/,Fubo pays $3.4M to settle claims it illegally shared user data with advertisers ,fubo pays m to settle claims it illegally shared user data with advertisers,fubo pay m settle claim illegally share user datum advertiser
1lu2okd,Welcome to Your Job Interview. Your Interviewer Is A.I.,,17,9,2025-07-07T18:56:52+00:00,technology,https://www.nytimes.com/2025/07/07/technology/ai-job-interviews.html,Welcome to Your Job Interview. Your Interviewer Is A.I. ,welcome to your job interview your interviewer is ai,welcome job interview interviewer ai
1lu2048,My Kingdom for a Meet Cute. The apps have shaped dating life for years. Why many are now ditching them in search of real-life romance.,,0,1,2025-07-07T18:31:00+00:00,technology,https://thetyee.ca/Culture/2025/06/13/Ditch-Dating-Apps-Find-Real-Life-Romance/,My Kingdom for a Meet Cute. The apps have shaped dating life for years. Why many are now ditching them in search of real-life romance. ,my kingdom for a meet cute the apps have shaped dating life for years why many are now ditching them in search of reallife romance,kingdom meet cute app shape date life year ditch search reallife romance
1lu1xnv,Does students’ use of AI spell the end for homework?,,46,71,2025-07-07T18:28:28+00:00,technology,https://www.chicagotribune.com/2025/07/02/opinion-ai-homework-education-students/,Does students’ use of AI spell the end for homework? ,does students use of ai spell the end for homework,student use ai spell end homework
1lu1nbi,Universities are rethinking computer science curriculum in response to AI tools,,51,23,2025-07-07T18:17:27+00:00,technology,https://www.techspot.com/news/108574-universities-rethinking-computer-science-curriculum-response-ai-tools.html,Universities are rethinking computer science curriculum in response to AI tools ,universities are rethinking computer science curriculum in response to ai tools,university rethink computer science curriculum response ai tool
1lu1lcq,“No honor among thieves”: M&S hacking group starts turf war,,15,0,2025-07-07T18:15:22+00:00,technology,https://arstechnica.com/security/2025/07/no-honor-among-thieves-ms-hacking-group-starts-turf-war/,“No honor among thieves”: M&S hacking group starts turf war ,no honor among thieves ms hacking group starts turf war,honor thief ms hack group start turf war
1lu1elj,Which Workers Will A.I. Hurt Most: The Young or the Experienced?,,10,23,2025-07-07T18:08:07+00:00,technology,https://www.nytimes.com/2025/07/07/business/ai-job-cuts.html?unlocked_article_code=1.Uk8.1ZrA.dJASBCtLvtau,Which Workers Will A.I. Hurt Most: The Young or the Experienced? ,which workers will ai hurt most the young or the experienced,worker ai hurt young experienced
1lu142d,Tech Companies Have Created a Loneliness Doom Loop,,75,6,2025-07-07T17:57:25+00:00,technology,https://www.nytimes.com/2025/07/07/opinion/loneliness-ai-social-media.html?unlocked_article_code=1.Uk8.xKYy.BMC7BSbhSQka,Tech Companies Have Created a Loneliness Doom Loop ,tech companies have created a loneliness doom loop,tech company create loneliness doom loop
1lu0zdh,"Freedom Cities: Deregulating ""The American Dream""",,34,33,2025-07-07T17:52:34+00:00,technology,https://www.bendsource.com/news/freedom-cities-deregulating-the-american-dream-23417557,"Freedom Cities: Deregulating ""The American Dream"" ",freedom cities deregulating the american dream,freedom city deregulate american dream
1lu0vco,"Activists call on storytellers to stop making surveillance tech copaganda, launch toolkit",,45,4,2025-07-07T17:48:23+00:00,technology,https://www.fightforthefuture.org/news/2025-07-02-activists-call-on-storytellers-to-stop-making-surveillance-tech-copaganda-launch-toolkit/,"Activists call on storytellers to stop making surveillance tech copaganda, launch toolkit ",activists call on storytellers to stop making surveillance tech copaganda launch toolkit,activist storyteller stop make surveillance tech copaganda launch toolkit
1ltzs67,Jack Dorsey launches a WhatsApp messaging rival built on Bluetooth,,2578,325,2025-07-07T17:08:01+00:00,technology,https://www.cnbc.com/2025/07/07/jack-dorsey-whatsapp-bluetooth.html?taid=686bfe2c0f347d0001f8a93f&utm_campaign=trueanthem&utm_content=main&utm_medium=social&utm_source=twitter,Jack Dorsey launches a WhatsApp messaging rival built on Bluetooth ,jack dorsey launches a whatsapp messaging rival built on bluetooth,jack dorsey launch whatsapp messaging rival build bluetooth
1ltzrqu,Springer Nature book on machine learning is full of made-up citations,,170,11,2025-07-07T17:07:35+00:00,technology,https://retractionwatch.com/2025/06/30/springer-nature-book-on-machine-learning-is-full-of-made-up-citations/,Springer Nature book on machine learning is full of made-up citations ,springer nature book on machine learning is full of madeup citations,springer nature book machine learning madeup citation
1ltz2f4,China's BYD to start assembling electric cars in Brazil,,150,8,2025-07-07T16:41:19+00:00,technology,https://www.reuters.com/business/autos-transportation/chinas-byd-start-assembling-electric-cars-brazil-2025-07-07/,China's BYD to start assembling electric cars in Brazil ,chinas byd to start assembling electric cars in brazil,chinas byd start assemble electric car brazil
1ltynxf,EU holds back on signing climate action pledge with China,,10,0,2025-07-07T16:26:16+00:00,technology,https://www.reuters.com/sustainability/cop/eu-holds-back-signing-climate-action-pledge-with-china-ft-says-2025-07-07/,EU holds back on signing climate action pledge with China ,eu holds back on signing climate action pledge with china,eu hold sign climate action pledge china
1ltx6nz,"AI is learning to lie, scheme, and threaten its creators during stress-testing scenarios",,294,83,2025-07-07T15:29:47+00:00,technology,https://fortune.com/2025/06/29/ai-lies-schemes-threats-stress-testing-claude-openai-chatgpt/,"AI is learning to lie, scheme, and threaten its creators during stress-testing scenarios ",ai is learning to lie scheme and threaten its creators during stresstesting scenarios,ai learn lie scheme threaten creator stressteste scenario
1ltwv32,Ubisoft Wants Gamers To Destroy All Copies of A Game Once It Goes Offline,,12767,998,2025-07-07T15:17:16+00:00,technology,https://tech4gamers.com/ubisoft-eula-destroy-all-copies-game-goes-offline/,Ubisoft Wants Gamers To Destroy All Copies of A Game Once It Goes Offline ,ubisoft wants gamers to destroy all copies of a game once it goes offline,ubisoft want gamer destroy copy game go offline
1ltwjxb,The Open-Source Software Saving the Internet From AI Bot Scrapers,,526,32,2025-07-07T15:05:08+00:00,technology,https://www.404media.co/the-open-source-software-saving-the-internet-from-ai-bot-scrapers/?ref=daily-stories-newsletter,The Open-Source Software Saving the Internet From AI Bot Scrapers ,the opensource software saving the internet from ai bot scrapers,opensource software save internet ai bot scraper
1ltwd7q,People Are Using AI Chatbots to Guide Their Psychedelic Trips,,0,13,2025-07-07T14:58:10+00:00,technology,https://www.wired.com/story/people-are-using-ai-chatbots-to-guide-their-psychedelic-trips/,People Are Using AI Chatbots to Guide Their Psychedelic Trips ,people are using ai chatbots to guide their psychedelic trips,people ai chatbot guide psychedelic trip
1ltuni3,"Some workers are quitting over their depressing office designs, but AV tech is helping",,0,3,2025-07-07T13:49:03+00:00,technology,https://www.techspot.com/news/108577-workers-quitting-over-their-depressing-offices-but-av.html,"Some workers are quitting over their depressing office designs, but AV tech is helping ",some workers are quitting over their depressing office designs but av tech is helping,worker quit depress office design av tech help
1ltukq7,'The transfer of user data by DeepSeek to China is unlawful': Germany calls for Google and Apple to remove the AI app from their stores,,1485,99,2025-07-07T13:45:48+00:00,technology,https://www.pcgamer.com/software/ai/the-transfer-of-user-data-by-deepseek-to-china-is-unlawful-germany-calls-for-google-and-apple-to-remove-the-ai-app-from-their-stores/,'The transfer of user data by DeepSeek to China is unlawful': Germany calls for Google and Apple to remove the AI app from their stores ,the transfer of user data by deepseek to china is unlawful germany calls for google and apple to remove the ai app from their stores,transfer user datum deepseek china unlawful germany call google apple remove ai app store
1ltu4sq,4 Differences Between Nvidia And AMD GPUs,,34,37,2025-07-07T13:26:36+00:00,technology,https://www.xda-developers.com/4-differences-between-nvidia-and-amd-gpus-that-i-wasnt-prepared-for/,4 Differences Between Nvidia And AMD GPUs ,differences between nvidia and amd gpus,difference nvidia amd gpu
1ltu3xw,Humanoid Robots in Hotels Stir Curiosity and Concern as Global Use Expands,,34,6,2025-07-07T13:25:36+00:00,technology,https://hoteltechnologynews.com/2025/07/humanoid-robots-in-hotels-stir-curiosity-and-concern-as-global-use-expands/,Humanoid Robots in Hotels Stir Curiosity and Concern as Global Use Expands ,humanoid robots in hotels stir curiosity and concern as global use expands,humanoid robot hotel stir curiosity concern global use expand
1ltu0w5,Multisensory VR forest reboots your brain and lifts mood—study confirms,,76,27,2025-07-07T13:21:46+00:00,technology,https://www.sciencedaily.com/releases/2025/07/250705084325.htm,Multisensory VR forest reboots your brain and lifts mood—study confirms ,multisensory vr forest reboots your brain and lifts moodstudy confirms,multisensory vr forest reboot brain lift moodstudy confirm
1ltth5k,Trump’s Washington Is a Technofascist Fantasy,,5142,144,2025-07-07T12:56:59+00:00,technology,https://www.motherjones.com/politics/2025/06/donald-trump-elon-musk-andreesen-technofascism-doge/,Trump’s Washington Is a Technofascist Fantasy ,trumps washington is a technofascist fantasy,trumps washington technofascist fantasy
1ltstvj,Amazon built a massive AI supercluster for Anthropic called Project Rainier – here's what we know so far,,942,127,2025-07-07T12:26:38+00:00,technology,https://www.theregister.com/2025/07/04/project_rainier_deep_dive/?td=rt-3a,Amazon built a massive AI supercluster for Anthropic called Project Rainier – here's what we know so far ,amazon built a massive ai supercluster for anthropic called project rainier heres what we know so far,amazon build massive ai supercluster anthropic call project rainier here know far
1ltsh5k,Apple challenges €500M EU fine over App Store steering rules,,782,63,2025-07-07T12:09:08+00:00,technology,https://www.macrumors.com/2025/07/07/apple-appeals-eu-500m-euro-fine/,Apple challenges €500M EU fine over App Store steering rules ,apple challenges m eu fine over app store steering rules,apple challenge m eu fine app store steering rule
1ltrdl5,Intel's poorly received Core Ultra 200S CPUs could be getting a much-needed refresh this year,,223,50,2025-07-07T11:09:05+00:00,technology,https://www.pcguide.com/news/intels-poorly-received-core-ultra-200s-cpus-could-be-getting-a-much-needed-refresh-this-year/,Intel's poorly received Core Ultra 200S CPUs could be getting a much-needed refresh this year ,intels poorly received core ultra s cpus could be getting a muchneeded refresh this year,intel poorly receive core ultra s cpus get muchneeded refresh year
1ltqpty,Scientists reverse Parkinson’s symptoms in mice — Could humans be next?,,915,64,2025-07-07T10:30:50+00:00,technology,https://www.sciencedaily.com/releases/2025/07/250705083956.htm,Scientists reverse Parkinson’s symptoms in mice — Could humans be next? ,scientists reverse parkinsons symptoms in mice could humans be next,scientist reverse parkinson symptom mouse human
1ltql4f,South Korea’s construction rivals join forces to automate job sites,,37,0,2025-07-07T10:22:33+00:00,technology,https://www.chosun.com/english/industry-en/2025/07/07/NV5D4TBQNZDPZAXVE43HKNUHFU/,South Korea’s construction rivals join forces to automate job sites ,south koreas construction rivals join forces to automate job sites,south korea construction rival join force automate job site
1ltqh18,Nissan mulling tie-up with Taiwanese firm to build EVs,,41,2,2025-07-07T10:15:36+00:00,technology,https://www.asahi.com/sp/ajw/articles/15888935,Nissan mulling tie-up with Taiwanese firm to build EVs ,nissan mulling tieup with taiwanese firm to build evs,nissan mull tieup taiwanese firm build evs
1ltpqth,TikTok building new version of app ahead of expected US sale and expected to be release this September,,334,72,2025-07-07T09:30:00+00:00,technology,https://theedgemalaysia.com/node/761647,TikTok building new version of app ahead of expected US sale and expected to be release this September ,tiktok building new version of app ahead of expected us sale and expected to be release this september,tiktok build new version app ahead expect sale expect release september
1ltp7g5,"The Apple AirPods Pro 3 release date may have been delayed, here’s what we know",,0,5,2025-07-07T08:55:22+00:00,technology,https://www.the-independent.com/extras/indybest/gadgets-tech/headphones-earphones/apple-airpods-pro-3-rumours-b2781984.html,"The Apple AirPods Pro 3 release date may have been delayed, here’s what we know ",the apple airpods pro release date may have been delayed heres what we know,apple airpod pro release date delay here know
1ltkzkg,Move Over Messi: China's New Robot Soccer League Is Wild!,,0,2,2025-07-07T04:26:32+00:00,technology,https://gizmodo.com/move-over-messi-chinas-new-robot-soccer-league-is-wild-2000624533,Move Over Messi: China's New Robot Soccer League Is Wild! ,move over messi chinas new robot soccer league is wild,messi china new robot soccer league wild
1ltjq1d,Kids are ditching traditional college for career tech programs. Parents are concerned.,,5454,836,2025-07-07T03:16:25+00:00,technology,https://www.usatoday.com/story/news/education/2025/06/15/kids-ditch-traditional-college-after-high-school/84027992007/,Kids are ditching traditional college for career tech programs. Parents are concerned. ,kids are ditching traditional college for career tech programs parents are concerned,kid ditch traditional college career tech program parent concern
1ltjdvc,Wimbledon Line Call Blunder in Kartal Match Renews Concerns Over Technology,,26,15,2025-07-07T02:58:34+00:00,technology,https://lastwordonsports.com/tennis/2025/07/06/wimbledon-line-call-blunder/,Wimbledon Line Call Blunder in Kartal Match Renews Concerns Over Technology ,wimbledon line call blunder in kartal match renews concerns over technology,wimbledon line blunder kartal match renew concern technology
1lteycc,At least 36 new tech unicorns were minted in 2025 so far,,0,3,2025-07-06T23:13:35+00:00,technology,https://techcrunch.com/2025/07/06/7-new-tech-unicorns-were-minted-in-2025-so-far/,At least 36 new tech unicorns were minted in 2025 so far ,at least new tech unicorns were minted in so far,new tech unicorn mint far
1ltey96,AI Is a Boon to ‘High Agency’ People,,0,18,2025-07-06T23:13:28+00:00,technology,https://www.wsj.com/opinion/ai-is-a-boon-to-high-agency-people-entrepreneur-replit-cb495999?st=Ssngyq,AI Is a Boon to ‘High Agency’ People ,ai is a boon to high agency people,ai boon high agency people
1ltexoa,‘Improved’ Grok criticizes Democrats and Hollywood’s ‘Jewish executives’,,16532,650,2025-07-06T23:12:41+00:00,technology,https://techcrunch.com/2025/07/06/improved-grok-criticizes-democrats-and-hollywoods-jewish-executives/,‘Improved’ Grok criticizes Democrats and Hollywood’s ‘Jewish executives’ ,improved grok criticizes democrats and hollywoods jewish executives,improved grok criticize democrats hollywood jewish executive
1ltebti,"Japan ramps up shipbuilding with national yard, industry merger",,256,4,2025-07-06T22:44:46+00:00,technology,https://www.chosun.com/english/industry-en/2025/07/04/OVR7ZM6UJRGBZLAN5FV5HPGNIQ/,"Japan ramps up shipbuilding with national yard, industry merger ",japan ramps up shipbuilding with national yard industry merger,japan ramp shipbuilde national yard industry merger
1lsvo2m,"Bitcoin investor moves $8 billion worth of crypto after 14 years, originally bought for less than $210,000 — 80,000 BTC transferred from dormant Satoshi-era wallet",,871,110,2025-07-06T07:45:34+00:00,technology,https://www.tomshardware.com/tech-industry/cryptocurrency/satoshi-era-bitcoin-investor-moves-usd8-billion-worth-of-crypto-after-14-years-80-000-btc-originally-bought-for-less-than-usd200-000,"Bitcoin investor moves $8 billion worth of crypto after 14 years, originally bought for less than $210,000 — 80,000 BTC transferred from dormant Satoshi-era wallet ",bitcoin investor moves billion worth of crypto after years originally bought for less than btc transferred from dormant satoshiera wallet,bitcoin investor move billion worth crypto year originally buy btc transfer dormant satoshiera wallet
1ltdu51,Copenhagen Atomics Receives Millions In EU Funding For Thorium Molten Salt Reactors,,422,14,2025-07-06T22:22:32+00:00,technology,https://www.nucnet.org/news/copenhagen-atomics-receives-millions-in-eu-funding-for-thorium-molten-salt-reactors-7-4-2025,Copenhagen Atomics Receives Millions In EU Funding For Thorium Molten Salt Reactors ,copenhagen atomics receives millions in eu funding for thorium molten salt reactors,copenhagen atomic receive million eu funding thorium molten salt reactor
1ltdjt1,Your Privacy Is On The Line,,138,19,2025-07-06T22:09:34+00:00,technology,https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/14680_sv,Your Privacy Is On The Line ,your privacy is on the line,privacy line
1ltbewp,"Plenty of skepticism of AI in dating apps, especially among women, survey says",,174,21,2025-07-06T20:38:18+00:00,technology,https://www.bu.edu/com/articles/plenty-of-skepticism-of-ai-in-dating-apps-especially-among-women-survey-says/,"Plenty of skepticism of AI in dating apps, especially among women, survey says ",plenty of skepticism of ai in dating apps especially among women survey says,plenty skepticism ai date app especially woman survey say
1ltave3,Out of the blue: How a Quake blog turned PC gaming news site has stayed a haven from 'internet enshittification' for nearly 30 years,,244,22,2025-07-06T20:15:34+00:00,technology,https://www.pcgamer.com/gaming-industry/out-of-the-blue-how-a-quake-blog-turned-pc-gaming-news-site-has-stayed-a-haven-from-internet-enshittification-for-nearly-30-years/,Out of the blue: How a Quake blog turned PC gaming news site has stayed a haven from 'internet enshittification' for nearly 30 years ,out of the blue how a quake blog turned pc gaming news site has stayed a haven from internet enshittification for nearly years,blue quake blog turn pc gaming news site stay haven internet enshittification nearly year
1ltaeq0,Scientists can tell how fast you’re aging from a single brain scan,,432,36,2025-07-06T19:56:05+00:00,technology,https://today.duke.edu/2025/07/scientists-can-tell-how-fast-youre-aging-single-brain-scan,Scientists can tell how fast you’re aging from a single brain scan ,scientists can tell how fast youre aging from a single brain scan,scientist tell fast age single brain scan
1lt9rhb,AI is now screening job candidates before humans ever see them,,1583,196,2025-07-06T19:28:56+00:00,technology,https://www.washingtonpost.com/business/2025/06/30/virtual-recruiters-ai-jobs/,AI is now screening job candidates before humans ever see them ,ai is now screening job candidates before humans ever see them,ai screen job candidate human
1lt9n6r,A couple tried for 18 years to get pregnant. AI made it happen,,0,18,2025-07-06T19:23:59+00:00,technology,https://www.cnn.com/2025/07/03/health/ai-male-infertility-sperm-wellness,A couple tried for 18 years to get pregnant. AI made it happen ,a couple tried for years to get pregnant ai made it happen,couple try year pregnant ai happen
1lt8u6c,TikTok Building New Version of App Ahead of Expected U.S. Sale,,1001,148,2025-07-06T18:50:36+00:00,technology,https://www.theinformation.com/articles/tiktok-building-new-version-app-ahead-expected-u-s-sale,TikTok Building New Version of App Ahead of Expected U.S. Sale ,tiktok building new version of app ahead of expected us sale,tiktok build new version app ahead expect sale
1lt8hwz,"TikTok building new version of app ahead of expected US sale, The Information reports",,48,25,2025-07-06T18:36:34+00:00,technology,https://www.reuters.com/world/china/tiktok-building-new-version-app-ahead-expected-us-sale-information-reports-2025-07-06/,"TikTok building new version of app ahead of expected US sale, The Information reports ",tiktok building new version of app ahead of expected us sale the information reports,tiktok build new version app ahead expect sale information report
1lt7wjy,America Has Pulled Off the Impossible. It Made Getting a Passport Simple. | Washington isn’t known for tech innovation. How did a team of bureaucrats put their stamp on a process that hadn’t changed in 50 years?,,0,9,2025-07-06T18:11:53+00:00,technology,https://www.wsj.com/business/us-passport-online-renewal-e58b51d1?st=8sfCgP,America Has Pulled Off the Impossible. It Made Getting a Passport Simple. | Washington isn’t known for tech innovation. How did a team of bureaucrats put their stamp on a process that hadn’t changed in 50 years? ,america has pulled off the impossible it made getting a passport simple washington isnt known for tech innovation how did a team of bureaucrats put their stamp on a process that hadnt changed in years,america pull impossible get passport simple washington not know tech innovation team bureaucrat stamp process not change year
1lt6oat,The EU's border security software (SIS II) is reportedly full of holes,,143,16,2025-07-06T17:21:13+00:00,technology,https://www.engadget.com/cybersecurity/the-eus-border-security-software-is-reportedly-full-of-holes-162033816.html,The EU's border security software (SIS II) is reportedly full of holes ,the eus border security software sis ii is reportedly full of holes,eus border security software sis ii reportedly hole
1lt6lv2,"Google DeepMind has grand ambitions to 'cure all diseases' with AI. Now, it's gearing up for its first human trials",,507,105,2025-07-06T17:18:23+00:00,technology,https://fortune.com/2025/07/06/deepmind-isomorphic-labs-cure-all-diseases-ai-now-first-human-trials/,"Google DeepMind has grand ambitions to 'cure all diseases' with AI. Now, it's gearing up for its first human trials ",google deepmind has grand ambitions to cure all diseases with ai now its gearing up for its first human trials,google deepmind grand ambition cure disease ai gearing human trial
1lt6hqa,UN official calls for criminal penalties for fossil fuel disinformation and lobbying bans,,1577,13,2025-07-06T17:13:33+00:00,technology,https://www.dailyclimate.org/un-official-calls-for-criminal-penalties-for-fossil-fuel-disinformation-and-lobbying-bans-2672577812.html,UN official calls for criminal penalties for fossil fuel disinformation and lobbying bans ,un official calls for criminal penalties for fossil fuel disinformation and lobbying bans,un official call criminal penalty fossil fuel disinformation lobbying ban
1lt6gzu,US military cuts climate scientists off from vital satellite sea-ice data,,7124,162,2025-07-06T17:12:40+00:00,technology,https://www.space.com/astronomy/earth/us-military-cuts-climate-scientists-off-from-vital-satellite-sea-ice-data,US military cuts climate scientists off from vital satellite sea-ice data ,us military cuts climate scientists off from vital satellite seaice data,military cut climate scientist vital satellite seaice datum
1lt6ddc,EVs Will Decimate Big Oil. Even Without U.S. Tax Credits.,,8556,757,2025-07-06T17:08:35+00:00,technology,https://insideevs.com/news/764730/evs-displace-millions-of-barrels-of-oil/,EVs Will Decimate Big Oil. Even Without U.S. Tax Credits. ,evs will decimate big oil even without us tax credits,evs decimate big oil tax credit
1lt5bjb,Behind the scenes with the Labubu-loving hackathon king of SF,,0,2,2025-07-06T16:25:06+00:00,technology,https://sfstandard.com/2025/07/05/rene-turcios-hackathon-labubu-vibe-coding-chatgpt/,Behind the scenes with the Labubu-loving hackathon king of SF ,behind the scenes with the labubuloving hackathon king of sf,scene labubuloving hackathon king sf
1lt271k,Large Language Model Performance Doubles Every 7 Months,,144,125,2025-07-06T14:11:49+00:00,technology,https://spectrum.ieee.org/large-language-model-performance,Large Language Model Performance Doubles Every 7 Months ,large language model performance doubles every months,large language model performance double month
1lt1gxi,"Laid-off workers should use AI to manage their emotions, says Xbox exec",,306,62,2025-07-06T13:38:32+00:00,technology,https://www.theverge.com/news/698468/xbox-exec-reccommends-ai-to-laid-off-staff,"Laid-off workers should use AI to manage their emotions, says Xbox exec ",laidoff workers should use ai to manage their emotions says xbox exec,laidoff worker use ai manage emotion say xbox exec
1lt1bzm,"ChatGPT is pushing people towards mania, psychosis and death",,7499,828,2025-07-06T13:31:57+00:00,technology,https://www.independent.co.uk/tech/chatgpt-psychosis-ai-therapy-chatbot-b2781202.html,"ChatGPT is pushing people towards mania, psychosis and death ",chatgpt is pushing people towards mania psychosis and death,chatgpt push people mania psychosis death
1lt12ch,"""He crushed the interview"": Silicon Valley duped by software engineer secretly working four jobs",,3348,195,2025-07-06T13:19:33+00:00,technology,https://www.techspot.com/news/108566-crushed-interview-silicon-valley-duped-software-engineer-secretly.html,"""He crushed the interview"": Silicon Valley duped by software engineer secretly working four jobs ",he crushed the interview silicon valley duped by software engineer secretly working four jobs,crush interview silicon valley dupe software engineer secretly work job
1lt0yrl,Ingram Micro outage caused by SafePay ransomware attack,,24,8,2025-07-06T13:14:51+00:00,technology,https://www.bleepingcomputer.com/news/security/ingram-micro-outage-caused-by-safepay-ransomware-attack/,Ingram Micro outage caused by SafePay ransomware attack ,ingram micro outage caused by safepay ransomware attack,ingram micro outage cause safepay ransomware attack
1lsznm4,The Rise of AI Is Making Life Even Harder for Real People in Gaza. Gizmodo spoke with desperate Palestinians who were accused of being AI creations.,,23,4,2025-07-06T12:07:55+00:00,technology,https://gizmodo.com/the-rise-of-ai-is-making-life-even-harder-for-real-people-in-gaza-2000607395,The Rise of AI Is Making Life Even Harder for Real People in Gaza. Gizmodo spoke with desperate Palestinians who were accused of being AI creations. ,the rise of ai is making life even harder for real people in gaza gizmodo spoke with desperate palestinians who were accused of being ai creations,rise ai make life hard real people gaza gizmodo speak desperate palestinians accuse ai creation
1lsz6mn,Paul Tudor Jones: Why AI Rings Every One of My Alarm Bells,,163,26,2025-07-06T11:40:24+00:00,technology,https://time.com/7297582/ai-safety-risks-paul-tudor-jones-essay/,Paul Tudor Jones: Why AI Rings Every One of My Alarm Bells ,paul tudor jones why ai rings every one of my alarm bells,paul tudor jones ai ring alarm bell
1lsyyky,A cowboy hat-wearing robot is running around Austin handing out compliments,,83,18,2025-07-06T11:26:49+00:00,technology,https://eu.usatoday.com/story/tech/2025/07/02/jake-robot-unitree-ai-texas/84433230007/,A cowboy hat-wearing robot is running around Austin handing out compliments ,a cowboy hatwearing robot is running around austin handing out compliments,cowboy hatwearing robot run austin hand compliment
1lsyxoa,US reportedly plans to curb sales of AI GPUs to Malaysia and Thailand to prevent smuggling to China,,81,4,2025-07-06T11:25:14+00:00,technology,https://www.tomshardware.com/pc-components/gpus/us-reportedly-plans-to-curb-sales-of-ai-gpus-to-malaysia-and-thailand-to-prevent-smuggling-to-china,US reportedly plans to curb sales of AI GPUs to Malaysia and Thailand to prevent smuggling to China ,us reportedly plans to curb sales of ai gpus to malaysia and thailand to prevent smuggling to china,reportedly plan curb sale ai gpu malaysia thailand prevent smuggling china
1lsyx5r,I was accepted into a well-regarded graduate program. I turned down the offer because AI is destroying my desired industry.,,0,7,2025-07-06T11:24:19+00:00,technology,https://www.businessinsider.com/turned-down-graduate-program-ai-destroys-industry-2025-7,I was accepted into a well-regarded graduate program. I turned down the offer because AI is destroying my desired industry. ,i was accepted into a wellregarded graduate program i turned down the offer because ai is destroying my desired industry,accept wellregarde graduate program turn offer ai destroy desire industry
1lsytbm,AI 'Band' the Velvet Sundown Officially Admits They're AI,,0,93,2025-07-06T11:17:44+00:00,technology,https://www.rollingstone.com/music/music-features/ai-band-the-velvet-sundown-confirm-ai-1235379354/,AI 'Band' the Velvet Sundown Officially Admits They're AI ,ai band the velvet sundown officially admits theyre ai,ai band velvet sundown officially admit ai
1lsxlo2,The creator of the ICEBlock app — which tracks ICE agents in real time — dares Donald Trump to arrest him.,,44850,1213,2025-07-06T09:59:16+00:00,technology,https://www.msnbc.com/weekends-with-alex-witt/watch/app-developer-explains-why-the-trump-administration-is-targeting-his-app-to-report-ice-sightings-242743877904,The creator of the ICEBlock app — which tracks ICE agents in real time — dares Donald Trump to arrest him. ,the creator of the iceblock app which tracks ice agents in real time dares donald trump to arrest him,creator iceblock app track ice agent real time dare donald trump arrest
1lswzx2,Sharp sells camera module business to Foxconn as part of ongoing asset transfers,,22,1,2025-07-06T09:16:47+00:00,technology,https://biz.chosun.com/en/en-it/2025/07/06/QRJ7J7FVU5BFLJY7USDU54KDF4/,Sharp sells camera module business to Foxconn as part of ongoing asset transfers ,sharp sells camera module business to foxconn as part of ongoing asset transfers,sharp sell camera module business foxconn ongoing asset transfer
1lswugq,"We May Have Found the Swole Pill
ozempic burns muscle plus fat, creating legions of people who look like empty sacks. but pharma has finally found a way to make people look like they lift.",,0,20,2025-07-06T09:06:32+00:00,technology,https://www.piratewires.com/p/we-may-have-found-the-swole-pill,"We May Have Found the Swole Pill
ozempic burns muscle plus fat, creating legions of people who look like empty sacks. but pharma has finally found a way to make people look like they lift. ",we may have found the swole pill ozempic burns muscle plus fat creating legions of people who look like empty sacks but pharma has finally found a way to make people look like they lift,find swole pill ozempic burns muscle plus fat create legion people look like sack pharma finally find way people look like lift
1lswtdl,"Startling 97% of Gen Z students are using AI to write essays, do homework — and even get into college",,258,125,2025-07-06T09:04:29+00:00,technology,https://nypost.com/2025/07/05/lifestyle/gen-z-turns-to-ai-for-homework-essays-and-college-apps/,"Startling 97% of Gen Z students are using AI to write essays, do homework — and even get into college ",startling of gen z students are using ai to write essays do homework and even get into college,startling gen z student ai write essay homework college
1lswnus,College grad unemployment surges as employers replace new hires with AI,,3980,316,2025-07-06T08:54:24+00:00,technology,https://www.cbsnews.com/video/college-grad-unemployment-surges-employers-replace-new-hires-ai/,College grad unemployment surges as employers replace new hires with AI ,college grad unemployment surges as employers replace new hires with ai,college grad unemployment surge employer replace new hire ai
1lswhxl,Arkane founder: Game Pass is unsustainable and damages the industry,,561,181,2025-07-06T08:42:44+00:00,technology,https://www.tweaktown.com/news/106235/arkane-founder-game-pass-is-unsustainable-and-damages-the-industry/index.html,Arkane founder: Game Pass is unsustainable and damages the industry ,arkane founder game pass is unsustainable and damages the industry,arkane founder game pass unsustainable damage industry
1lsvpbb,Massive spike in use of .es domains for phishing abuse,,48,1,2025-07-06T07:47:56+00:00,technology,https://www.theregister.com/2025/07/05/spain_domains_phishing/,Massive spike in use of .es domains for phishing abuse ,massive spike in use of es domains for phishing abuse,massive spike use es domain phishe abuse
1lsvooq,UK Royal Navy builds 'esports suite' loaded with gaming PCs onboard its newest warship — eight high-powered PC battle stations added to war room,,517,55,2025-07-06T07:46:40+00:00,technology,https://www.tomshardware.com/video-games/pc-gaming/uk-royal-navy-builds-esports-suite-loaded-with-gaming-pcs-onboard-its-newest-warship-eight-high-powered-pc-battle-stations-added-to-war-room,UK Royal Navy builds 'esports suite' loaded with gaming PCs onboard its newest warship — eight high-powered PC battle stations added to war room ,uk royal navy builds esports suite loaded with gaming pcs onboard its newest warship eight highpowered pc battle stations added to war room,uk royal navy build esport suite load gaming pc onboard new warship highpowered pc battle station add war room
1lsvg5y,CEOs Start Saying the Quiet Part Out Loud: AI Will Wipe Out Jobs,,319,112,2025-07-06T07:30:25+00:00,technology,https://www.wsj.com/tech/ai/ai-white-collar-job-loss-b9856259?gaa_at=eafs&gaa_n=ASWzDAiha6czIeew9GErAujwOy7_mr35XdLN9D2YNKMB3gI3BI48lZ84slwLczFAlRc%3D&gaa_ts=686a2954&gaa_sig=qwkudU_UgI0woTl0vfhMb27qXX4run2jzQsXP_Oyicb22Ehmvnz8ErWtOh6YvKtWISX3So4U5G-aY-U3apav2A%3D%3D,CEOs Start Saying the Quiet Part Out Loud: AI Will Wipe Out Jobs ,ceos start saying the quiet part out loud ai will wipe out jobs,ceo start say quiet loud ai wipe job
1lsvbwm,"China, India may miss emission goals despite green energy push",,19,13,2025-07-06T07:22:07+00:00,technology,https://asia.nikkei.com/Spotlight/Environment/Climate-Change/China-India-may-miss-emission-goals-despite-green-energy-push-report,"China, India may miss emission goals despite green energy push ",china india may miss emission goals despite green energy push,china india miss emission goal despite green energy push
1lsuihd,"On July 7, Gemini AI will access your WhatsApp and more. Learn how to disable it on Android.",,1384,100,2025-07-06T06:28:32+00:00,technology,https://tuta.com/blog/how-to-disable-gemini-on-android,"On July 7, Gemini AI will access your WhatsApp and more. Learn how to disable it on Android. ",on july gemini ai will access your whatsapp and more learn how to disable it on android,july gemini ai access whatsapp learn disable android
1lsua3h,myNoise | What a Hacker Stole From Me,,42,5,2025-07-06T06:13:33+00:00,technology,https://mynoise.net/blog.php,myNoise | What a Hacker Stole From Me ,mynoise what a hacker stole from me,mynoise hacker steal
1ls27mk,DDR4 prices are now so high that vendors have decided to start making it again — manufacturers want a slice now that it's more expensive than DDR5,,48,24,2025-07-05T05:15:25+00:00,technology,https://www.tomshardware.com/pc-components/ddr4/ddr4-prices-are-now-so-high-that-vendors-have-decided-to-start-making-it-again-manufacturers-want-a-slice-now-that-its-more-expensive-than-ddr5,DDR4 prices are now so high that vendors have decided to start making it again — manufacturers want a slice now that it's more expensive than DDR5 ,ddr prices are now so high that vendors have decided to start making it again manufacturers want a slice now that its more expensive than ddr,ddr price high vendor decide start make manufacturer want slice expensive ddr
1lsrfhq,"European game publisher group responds to Stop Killing Games, claims 'These proposals would curtail developer choice"" | Video Games Europe voices opposition to Stop Killing Games movement as it clears threshold to become an EU Citizens' Initiative.",,581,163,2025-07-06T03:21:02+00:00,technology,https://www.pcgamer.com/gaming-industry/european-game-publisher-group-responds-to-stop-killing-games-claims-these-proposals-would-curtail-developer-choice/,"European game publisher group responds to Stop Killing Games, claims 'These proposals would curtail developer choice"" | Video Games Europe voices opposition to Stop Killing Games movement as it clears threshold to become an EU Citizens' Initiative. ",european game publisher group responds to stop killing games claims these proposals would curtail developer choice video games europe voices opposition to stop killing games movement as it clears threshold to become an eu citizens initiative,european game publisher group respond stop kill game claim proposal curtail developer choice video game europe voice opposition stop kill game movement clear threshold eu citizen initiative
1lspqti,How a Canadian's AI hoax duped the media and propelled a 'band' to streaming success,,85,23,2025-07-06T01:45:41+00:00,technology,https://www.cbc.ca/news/entertainment/ai-band-hoax-velvet-sundown-1.7575874,How a Canadian's AI hoax duped the media and propelled a 'band' to streaming success ,how a canadians ai hoax duped the media and propelled a band to streaming success,canadians ai hoax dupe medium propel band stream success
1lsnz0n,FCC gets thousands of complaints over Blue Alert in Texas shooting,,2044,220,2025-07-06T00:10:57+00:00,technology,https://www.cbsnews.com/texas/news/fcc-gets-thousands-of-complaints-blue-alert-in-texas-shooting/,FCC gets thousands of complaints over Blue Alert in Texas shooting ,fcc gets thousands of complaints over blue alert in texas shooting,fcc get thousand complaint blue alert texas shooting
1lsnpj6,Grok uses climate change stats to explain Trump’s post about Texas floods,,5398,152,2025-07-05T23:57:58+00:00,technology,https://www.independent.co.uk/news/world/americas/us-politics/grok-karoline-leavitt-texas-floods-b2783351.html,Grok uses climate change stats to explain Trump’s post about Texas floods ,grok uses climate change stats to explain trumps post about texas floods,grok use climate change stat explain trump post texas flood
1lsls9i,‘Blatant misinformation’: Social Security Administration email praising Trump’s tax bill blasted as a ‘lie’,,13974,188,2025-07-05T22:23:13+00:00,technology,https://www.theguardian.com/us-news/2025/jul/05/social-security-administration-email-trump-tax-bill,‘Blatant misinformation’: Social Security Administration email praising Trump’s tax bill blasted as a ‘lie’ ,blatant misinformation social security administration email praising trumps tax bill blasted as a lie,blatant misinformation social security administration email praise trump tax bill blast lie
1lskvct,Another bill wants to ban kids from social media,,329,88,2025-07-05T21:40:10+00:00,technology,https://www.theverge.com/news/607603/kids-off-social-media-act-bill-child-safety,Another bill wants to ban kids from social media ,another bill wants to ban kids from social media,bill want ban kid social medium
1lsj3ms,Trump administration shuts down U.S. website on climate change,,37787,1186,2025-07-05T20:20:28+00:00,technology,https://www.latimes.com/environment/story/2025-07-01/trump-us-climate-website,Trump administration shuts down U.S. website on climate change ,trump administration shuts down us website on climate change,trump administration shut website climate change
1lsj0hr,"The prospective buyer of TikTok’s American operations cited by President Donald Trump is the same investor consortium including Oracle Corp., Blackstone Inc. and venture capital firm Andreessen Horowitz",,275,33,2025-07-05T20:16:26+00:00,technology,https://www.bloomberg.com/news/articles/2025-06-30/tiktok-buyer-cited-by-trump-is-same-investor-group-as-before,"The prospective buyer of TikTok’s American operations cited by President Donald Trump is the same investor consortium including Oracle Corp., Blackstone Inc. and venture capital firm Andreessen Horowitz ",the prospective buyer of tiktoks american operations cited by president donald trump is the same investor consortium including oracle corp blackstone inc and venture capital firm andreessen horowitz,prospective buyer tiktok american operation cite president donald trump investor consortium include oracle corp blackstone inc venture capital firm andreessen horowitz
1lsi3qu,Beware: Those dating app responses you're getting could be AI,,176,58,2025-07-05T19:35:25+00:00,technology,https://www.pocket-lint.com/ai-dating-apps-chat-gpt/,Beware: Those dating app responses you're getting could be AI ,beware those dating app responses youre getting could be ai,beware date app response get ai
1lshtzm,Free Lunch Is Over for the AI That Broke the Web,,658,114,2025-07-05T19:23:03+00:00,technology,https://gizmodo.com/free-lunch-is-over-for-the-ai-that-broke-the-web-2000623837,Free Lunch Is Over for the AI That Broke the Web ,free lunch is over for the ai that broke the web,free lunch ai break web
1lsh8ng,Trump Says He Will Start Talks With China on TikTok Deal,,15,38,2025-07-05T18:57:13+00:00,technology,https://www.nytimes.com/2025/07/05/us/politics/trump-china-tiktok.html,Trump Says He Will Start Talks With China on TikTok Deal ,trump says he will start talks with china on tiktok deal,trump say start talk china tiktok deal
1lsg6rd,Fed’s hidden immigration weapon – Virginia’s surveillance network,,409,49,2025-07-05T18:11:26+00:00,technology,https://vcij.org/stories/flock-cameras-are-used-for-immigration-enforcement,Fed’s hidden immigration weapon – Virginia’s surveillance network ,feds hidden immigration weapon virginias surveillance network,feds hide immigration weapon virginia surveillance network
1lsezj5,A Tesla robotaxi inexplicably drove into a parked car,,2024,323,2025-07-05T17:18:20+00:00,technology,https://www.engadget.com/transportation/a-tesla-robotaxi-inexplicably-drove-into-a-parked-car-171004400.html,A Tesla robotaxi inexplicably drove into a parked car ,a tesla robotaxi inexplicably drove into a parked car,tesla robotaxi inexplicably drive park car
1lserxf,"Valve's reported profit-per-head from Steam commissions is out there, and at $3.5 million per employee it makes Apple and Facebook look like a lemonade stand",,5270,280,2025-07-05T17:09:09+00:00,technology,https://www.pcgamer.com/gaming-industry/valves-reported-profit-per-head-from-steam-commissions-is-out-there-and-at-usd3-5-million-per-employee-it-makes-apple-and-facebook-look-like-a-lemonade-stand/,"Valve's reported profit-per-head from Steam commissions is out there, and at $3.5 million per employee it makes Apple and Facebook look like a lemonade stand ",valves reported profitperhead from steam commissions is out there and at million per employee it makes apple and facebook look like a lemonade stand,valve report profitperhead steam commission million employee make apple facebook look like lemonade stand
1lscr9x,“Astounding” Results: Blocking One Enzyme Brings Parkinson’s-Damaged Cells Back to Life,,1927,33,2025-07-05T15:41:25+00:00,technology,https://scitechdaily.com/astounding-results-blocking-one-enzyme-brings-parkinsons-damaged-cells-back-to-life/,“Astounding” Results: Blocking One Enzyme Brings Parkinson’s-Damaged Cells Back to Life ,astounding results blocking one enzyme brings parkinsonsdamaged cells back to life,astounding result block enzyme bring parkinsonsdamage cell life
1lsc42k,The EU wants to decrypt your private data by 2030,,1262,132,2025-07-05T15:12:15+00:00,technology,https://www.techradar.com/vpn/vpn-privacy-security/the-eu-wants-to-decrypt-your-private-data-by-2030,The EU wants to decrypt your private data by 2030 ,the eu wants to decrypt your private data by,eu want decrypt private datum
1lsbhrm,Schools turn to handwritten exams as AI cheating surges,,5861,452,2025-07-05T14:44:28+00:00,technology,https://www.foxnews.com/tech/schools-turn-handwritten-exams-ai-cheating-surges,Schools turn to handwritten exams as AI cheating surges ,schools turn to handwritten exams as ai cheating surges,school turn handwritten exam ai cheating surge
1lsbg5c,"New research warns against trusting AI for moral guidance, revealing that these systems are not only biased towards inaction but are so easily manipulated by a question's phrasing",,150,5,2025-07-05T14:42:24+00:00,technology,https://www.psypost.org/new-research-reveals-hidden-biases-in-ais-moral-advice/,"New research warns against trusting AI for moral guidance, revealing that these systems are not only biased towards inaction but are so easily manipulated by a question's phrasing ",new research warns against trusting ai for moral guidance revealing that these systems are not only biased towards inaction but are so easily manipulated by a questions phrasing,new research warn trusting ai moral guidance reveal system biased inaction easily manipulate question phrase
1ls9t22,EU says it will continue rolling out AI legislation on schedule,,111,1,2025-07-05T13:23:41+00:00,technology,https://techcrunch.com/2025/07/04/eu-says-it-will-continue-rolling-out-ai-legislation-on-schedule/,EU says it will continue rolling out AI legislation on schedule ,eu says it will continue rolling out ai legislation on schedule,eu say continue roll ai legislation schedule
1ls9fh1,EA sets ambitious 100 million player goal for Battlefield 6 as development costs reach $400 million,,241,158,2025-07-05T13:04:41+00:00,technology,https://www.techspot.com/news/108563-ea-sets-ambitious-100-million-player-goal-battlefield.html,EA sets ambitious 100 million player goal for Battlefield 6 as development costs reach $400 million ,ea sets ambitious million player goal for battlefield as development costs reach million,ea set ambitious million player goal battlefield development cost reach million
1ls90p7,‘The vehicle suddenly accelerated with our baby in it’: the terrifying truth about why Tesla’s cars keep crashing | Tesla,,8839,661,2025-07-05T12:42:54+00:00,technology,https://www.theguardian.com/technology/2025/jul/05/the-vehicle-suddenly-accelerated-with-our-baby-in-it-the-terrifying-truth-about-why-teslas-cars-keep-crashing,‘The vehicle suddenly accelerated with our baby in it’: the terrifying truth about why Tesla’s cars keep crashing | Tesla ,the vehicle suddenly accelerated with our baby in it the terrifying truth about why teslas cars keep crashing tesla,vehicle suddenly accelerate baby terrifying truth tesla car crash tesla
1ls6wcj,"Tell Etsy, Reddit, Tinder & Duolingo: Stop Feeding Surveillance Tech",,1538,50,2025-07-05T10:34:38+00:00,technology,https://www.mozillafoundation.org/en/campaigns/no-data-for-surveillance-tech,"Tell Etsy, Reddit, Tinder & Duolingo: Stop Feeding Surveillance Tech ",tell etsy reddit tinder duolingo stop feeding surveillance tech,tell etsy reddit tinder duolingo stop feed surveillance tech
1ls6sj1,Global Carbon Emissions Reach Record High Despite Green Efforts,,229,101,2025-07-05T10:27:09+00:00,technology,https://oilprice.com/Alternative-Energy/Renewable-Energy/Global-Carbon-Emissions-Reach-Record-High-Despite-Green-Efforts.html,Global Carbon Emissions Reach Record High Despite Green Efforts ,global carbon emissions reach record high despite green efforts,global carbon emission reach record high despite green effort
1ls6ezx,European Commission calls for 90% carbon reduction by 2040,,324,29,2025-07-05T10:01:19+00:00,technology,https://www.power-technology.com/news/eu-climate-law-target-2040/,European Commission calls for 90% carbon reduction by 2040 ,european commission calls for carbon reduction by,european commission call carbon reduction
1ls69dx,Samsung delays $44 billion Texas chip fab — sources say completion halted because 'there are no customers',,4530,235,2025-07-05T09:50:28+00:00,technology,https://www.tomshardware.com/tech-industry/semiconductors/samsung-delays-usd44-billion-texas-chip-fab-sources-say-completion-halted-because-there-are-no-customers,Samsung delays $44 billion Texas chip fab — sources say completion halted because 'there are no customers' ,samsung delays billion texas chip fab sources say completion halted because there are no customers,samsung delay billion texas chip fab source completion halt customer
1ls62n8,New Research Debunks Myth That Brain Cells Stop Growing After Childhood,,1001,31,2025-07-05T09:36:50+00:00,technology,https://gizmodo.com/new-research-debunks-myth-that-brain-cells-stop-growing-after-childhood-2000623506,New Research Debunks Myth That Brain Cells Stop Growing After Childhood ,new research debunks myth that brain cells stop growing after childhood,new research debunk myth brain cell stop grow childhood
1ls3xwr,Brain Stimulation Reverses Synaptic Damage in Alzheimer’s,,703,35,2025-07-05T07:08:12+00:00,technology,https://neurosciencenews.com/brain-stimulation-alzheimers-synapses-29277/,Brain Stimulation Reverses Synaptic Damage in Alzheimer’s ,brain stimulation reverses synaptic damage in alzheimers,brain stimulation reverse synaptic damage alzheimer
1ls2ncs,The Trump administration appears to be planning its own chatbot,,73,42,2025-07-05T05:43:53+00:00,technology,https://www.theverge.com/news/684579/ai-api-trump-administration-doge-gsa,The Trump administration appears to be planning its own chatbot ,the trump administration appears to be planning its own chatbot,trump administration appear plan chatbot
1lry7js,"Sony's got an Xperia 1 VII problem so bad, it had to temporarily halt sales | Problems with 'the device shutting down, rebooting, or not turning on' sound no fun at all.",,8,10,2025-07-05T01:12:16+00:00,technology,https://www.androidauthority.com/xperia-1-vii-sales-stop-3574202/,"Sony's got an Xperia 1 VII problem so bad, it had to temporarily halt sales | Problems with 'the device shutting down, rebooting, or not turning on' sound no fun at all. ",sonys got an xperia vii problem so bad it had to temporarily halt sales problems with the device shutting down rebooting or not turning on sound no fun at all,sony get xperia vii problem bad temporarily halt sale problem device shut reboot turn sound fun
1lrwlwp,Artificial Intelligence Helps Craft the World’s Best White Wine,,0,6,2025-07-04T23:43:10+00:00,technology,https://hungarytoday.hu/artificial-intelligence-helps-craft-the-worlds-best-white-wine/,Artificial Intelligence Helps Craft the World’s Best White Wine ,artificial intelligence helps craft the worlds best white wine,artificial intelligence help craft world well white wine
1lr61lg,Meta’s “AI superintelligence” effort sounds just like its failed “metaverse” &#x2d; Ars Technica,,40,0,2025-07-04T01:07:34+00:00,technology,https://arstechnica.com/ai/2025/07/metas-ai-superintelligence-effort-sounds-just-like-its-failed-metaverse/,Meta’s “AI superintelligence” effort sounds just like its failed “metaverse” &#x2d; Ars Technica ,metas ai superintelligence effort sounds just like its failed metaverse xd ars technica,metas ai superintelligence effort sound like fail metaverse xd ar technica
1lrsc82,"Elon Musk confirms xAI is buying an overseas power plant and shipping the whole thing to the U.S. to power its new data center — 1 million AI GPUs and up to 2 Gigawatts of power under one roof, equivalent to powering 1.9 million homes",,777,142,2025-07-04T20:17:36+00:00,technology,https://www.tomshardware.com/tech-industry/artificial-intelligence/elon-musk-xai-power-plant-overseas-to-power-1-million-gpus,"Elon Musk confirms xAI is buying an overseas power plant and shipping the whole thing to the U.S. to power its new data center — 1 million AI GPUs and up to 2 Gigawatts of power under one roof, equivalent to powering 1.9 million homes ",elon musk confirms xai is buying an overseas power plant and shipping the whole thing to the us to power its new data center million ai gpus and up to gigawatts of power under one roof equivalent to powering million homes,elon musk confirm xai buy overseas power plant ship thing power new datum center million ai gpu gigawatt power roof equivalent power million home
1lrw49b,Windows 11 surpasses Windows 10 as most used desktop OS,,0,37,2025-07-04T23:18:11+00:00,technology,https://www.windowscentral.com/microsoft/windows-11/windows-11-is-now-the-most-popular-desktop-os-in-the-world-finally-surpasses-windows-10-after-4-years,Windows 11 surpasses Windows 10 as most used desktop OS ,windows surpasses windows as most used desktop os,windows surpass window desktop os
1lrvell,Understanding Carbon Capture - Science Or Shell Game,,3,2,2025-07-04T22:42:12+00:00,technology,https://www.forbes.com/sites/dianneplummer/2025/07/04/understanding-carbon-capturescience-or-shell-game/,Understanding Carbon Capture - Science Or Shell Game ,understanding carbon capture science or shell game,understand carbon capture science shell game
1lrv4fw,Ted Cruz’s Dumb Plan To Punish States That Regulate AI By Withholding Broadband Grants Falls Apart,,1201,36,2025-07-04T22:28:20+00:00,technology,https://www.techdirt.com/2025/07/02/ted-cruzs-dumb-plan-to-punish-states-that-regulate-ai-by-withholding-broadband-grants-falls-apart/,Ted Cruz’s Dumb Plan To Punish States That Regulate AI By Withholding Broadband Grants Falls Apart ,ted cruzs dumb plan to punish states that regulate ai by withholding broadband grants falls apart,ted cruzs dumb plan punish state regulate ai withhold broadband grant fall apart
1lruli7,Trump megabill gives the oil industry everything it wants and ends key support for solar and wind,,5219,208,2025-07-04T22:02:48+00:00,technology,https://www.cnbc.com/2025/07/03/trump-one-big-beautiful-bill-oil-gas-coal-solar-wind-ira-tax-incentive-repeal.html,Trump megabill gives the oil industry everything it wants and ends key support for solar and wind ,trump megabill gives the oil industry everything it wants and ends key support for solar and wind,trump megabill give oil industry want end key support solar wind
1lru89u,"GOP Budget Bill Includes Massive Spectrum Handout To Large Wireless Carriers, Hurting WiFi Speeds",,1078,41,2025-07-04T21:45:35+00:00,technology,https://www.techdirt.com/2025/07/03/gop-budget-bill-includes-massive-spectrum-handout-to-large-wireless-carriers-hurting-wifi-speeds/,"GOP Budget Bill Includes Massive Spectrum Handout To Large Wireless Carriers, Hurting WiFi Speeds ",gop budget bill includes massive spectrum handout to large wireless carriers hurting wifi speeds,gop budget bill include massive spectrum handout large wireless carrier hurt wifi speed
1lrt194,French City of Lyon Kicks Out Microsoft,,330,10,2025-07-04T20:49:38+00:00,technology,https://news.itsfoss.com/french-city-replaces-microsoft/,French City of Lyon Kicks Out Microsoft ,french city of lyon kicks out microsoft,french city lyon kick microsoft
1lrt0lt,Anthropic destroyed millions of print books to build its AI models,,8,31,2025-07-04T20:48:46+00:00,technology,https://arstechnica.com/ai/2025/06/anthropic-destroyed-millions-of-print-books-to-build-its-ai-models/,Anthropic destroyed millions of print books to build its AI models ,anthropic destroyed millions of print books to build its ai models,anthropic destroy million print book build ai model
1lrsydj,The Great American EV Fire Sale Is About to Begin,,3489,545,2025-07-04T20:45:55+00:00,technology,https://gizmodo.com/the-great-american-ev-fire-sale-is-about-to-begin-2000624324,The Great American EV Fire Sale Is About to Begin ,the great american ev fire sale is about to begin,great american ev fire sale begin
1lrsrl0,Tesla’s Cybertruck flop is historic. The brand collapse is even worse,,29744,1385,2025-07-04T20:37:06+00:00,technology,https://www.dailykos.com/stories/2025/7/3/2331384/-Tesla-s-Cybertruck-flop-is-historic-The-brand-collapse-is-even-worse,Tesla’s Cybertruck flop is historic. The brand collapse is even worse ,teslas cybertruck flop is historic the brand collapse is even worse,teslas cybertruck flop historic brand collapse bad
1lrsqkt,‘It’s almost like we never even spoke’: AI is making everyone on dating apps sound charming,,308,68,2025-07-04T20:35:51+00:00,technology,https://www.washingtonpost.com/technology/2025/07/03/ai-online-dating-match/,‘It’s almost like we never even spoke’: AI is making everyone on dating apps sound charming ,its almost like we never even spoke ai is making everyone on dating apps sound charming,like speak ai make date app sound charming
1lrsog2,CBP Wants New Tech to Search for Hidden Data on Seized Phones,,57,5,2025-07-04T20:33:08+00:00,technology,https://www.wired.com/story/cbp-wants-new-tech-to-search-for-hidden-data-on-seized-phones/,CBP Wants New Tech to Search for Hidden Data on Seized Phones ,cbp wants new tech to search for hidden data on seized phones,cbp want new tech search hide datum seized phone
1lrsjrm,Ingram Micro suffers global outage as internal systems inaccessible,,13,3,2025-07-04T20:27:06+00:00,technology,https://www.bleepingcomputer.com/news/security/ingram-micro-suffers-global-outage-as-internal-systems-inaccessible/,Ingram Micro suffers global outage as internal systems inaccessible ,ingram micro suffers global outage as internal systems inaccessible,ingram micro suffer global outage internal system inaccessible
1lrsdzf,10 Biggest 2025 Layoffs Announced So Far: Inside the Massive Job Cuts,,90,8,2025-07-04T20:19:53+00:00,technology,https://upperclasscareer.com/10-biggest-2025-layoffs-announced-so-far-inside-the-massive-job-cuts/,10 Biggest 2025 Layoffs Announced So Far: Inside the Massive Job Cuts ,biggest layoffs announced so far inside the massive job cuts,big layoff announce far inside massive job cut
1lrscwm,"""Everything Changed"": How Microsoft Lost Their Way in Just Three Years",,2610,389,2025-07-04T20:18:30+00:00,technology,https://www.frandroid.com/marques/microsoft/2722413_tout-a-change-comment-microsoft-sest-egare-en-seulement-trois-ans,"""Everything Changed"": How Microsoft Lost Their Way in Just Three Years ",everything changed how microsoft lost their way in just three years,change microsoft lose way year
1lrrn8i,First human trial of regenerative cell therapy for sensorineural hearing loss approved,,93,6,2025-07-04T19:46:30+00:00,technology,https://www.openaccessgovernment.org/first-human-trial-of-regenerative-cell-therapy-for-sensorineural-hearing-loss-approved/194974/,First human trial of regenerative cell therapy for sensorineural hearing loss approved ,first human trial of regenerative cell therapy for sensorineural hearing loss approved,human trial regenerative cell therapy sensorineural hearing loss approve
1lrqyg8,Ohio Supreme Court: Your phone app location data is not protected by Fourth Amendment,,1555,83,2025-07-04T19:15:51+00:00,technology,https://www.dispatch.com/story/news/courts/2025/07/02/ohio-supreme-court-police-phone-app-location-data-4th-amendment/84445270007/,Ohio Supreme Court: Your phone app location data is not protected by Fourth Amendment ,ohio supreme court your phone app location data is not protected by fourth amendment,ohio supreme court phone app location datum protect fourth amendment
1lrqsw0,"Yes, Your TV Is Probably Spying on You. Your Fridge, Too. Here’s What They Know.",,504,141,2025-07-04T19:09:01+00:00,technology,https://www.nytimes.com/wirecutter/reviews/advice-smart-devices-data-tracking/,"Yes, Your TV Is Probably Spying on You. Your Fridge, Too. Here’s What They Know. ",yes your tv is probably spying on you your fridge too heres what they know,yes tv probably spy fridge here know
1lrnmgy,Could the Electric Hydrofoil Ferry Change the Way We Commute?,,0,3,2025-07-04T16:55:51+00:00,technology,https://www.nytimes.com/2025/07/04/business/electric-hydrofoil-ferry-commute.html?unlocked_article_code=1.T08.EI-R.LdNfMXwcmi9n,Could the Electric Hydrofoil Ferry Change the Way We Commute? ,could the electric hydrofoil ferry change the way we commute,electric hydrofoil ferry change way commute
1lrlpav,"AI could create a 'Mad Max' scenario where everyone's skills are basically worthless, a top economist says",,1831,396,2025-07-04T15:35:17+00:00,technology,https://www.businessinsider.com/ai-threatens-skills-with-mad-max-economy-warns-top-economist-2025-7,"AI could create a 'Mad Max' scenario where everyone's skills are basically worthless, a top economist says ",ai could create a mad max scenario where everyones skills are basically worthless a top economist says,ai create mad max scenario everyone skill basically worthless economist say
1lrku57,Fossil Fuel Billionaires Are Bankrolling the Anti-Trans Movement,,6146,364,2025-07-04T15:00:00+00:00,technology,https://atmos.earth/fossil-fuel-billionaires-are-bankrolling-the-anti-trans-movement/,Fossil Fuel Billionaires Are Bankrolling the Anti-Trans Movement ,fossil fuel billionaires are bankrolling the antitrans movement,fossil fuel billionaire bankroll antitrans movement
1lrk96d,"13-year-old hacks Teams, forces Microsoft to change bug bounty",,3126,108,2025-07-04T14:35:04+00:00,technology,https://interestingengineering.com/culture/teenager-rewrites-microsoft-bug-bounty-rules,"13-year-old hacks Teams, forces Microsoft to change bug bounty ",yearold hacks teams forces microsoft to change bug bounty,yearold hack team force microsoft change bug bounty
1lrjx88,‘It’s too late’: David Suzuki says the fight against climate change is lost,,18317,2025,2025-07-04T14:21:04+00:00,technology,https://www.ipolitics.ca/2025/07/02/its-too-late-david-suzuki-says-the-fight-against-climate-change-is-lost/,‘It’s too late’: David Suzuki says the fight against climate change is lost ,its too late david suzuki says the fight against climate change is lost,late david suzuki say fight climate change lose
1lriqjy,Governments Spreading Misinformation to Fuel Climate Denial & Inaction: Study,,1200,26,2025-07-04T13:27:32+00:00,technology,https://www.greenqueen.com.hk/climate-misinformation-denial-governments-trump-fossil-fuels/,Governments Spreading Misinformation to Fuel Climate Denial & Inaction: Study ,governments spreading misinformation to fuel climate denial inaction study,government spread misinformation fuel climate denial inaction study
1lrimpa,Xbox exec suggests people use AI to lessen the pain of being laid off,,580,113,2025-07-04T13:22:28+00:00,technology,https://www.techspot.com/news/108562-xbox-exec-suggests-people-use-ai-lessen-pain.html,Xbox exec suggests people use AI to lessen the pain of being laid off ,xbox exec suggests people use ai to lessen the pain of being laid off,xbox exec suggest people use ai lessen pain lay
1lri5ak,"Typos and slang spur AI to discourage seeking medical care. AI models change their medical recommendations when people ask them questions that include colourful language, typos, odd formatting and even gender-neutral pronouns",,423,54,2025-07-04T12:59:18+00:00,technology,https://www.newscientist.com/article/2486372-typos-and-slang-spur-ai-to-discourage-seeking-medical-care,"Typos and slang spur AI to discourage seeking medical care. AI models change their medical recommendations when people ask them questions that include colourful language, typos, odd formatting and even gender-neutral pronouns ",typos and slang spur ai to discourage seeking medical care ai models change their medical recommendations when people ask them questions that include colourful language typos odd formatting and even genderneutral pronouns,typo slang spur ai discourage seek medical care ai model change medical recommendation people ask question include colourful language typo odd formatting genderneutral pronoun
1lri10h,"Why Microsoft's enshittification of Xbox, Surface, and even Windows itself — are all by design",,1191,183,2025-07-04T12:53:24+00:00,technology,https://www.windowscentral.com/gaming/xbox/microsoft-has-made-it-impossible-to-be-a-fan,"Why Microsoft's enshittification of Xbox, Surface, and even Windows itself — are all by design ",why microsofts enshittification of xbox surface and even windows itself are all by design,microsoft enshittification xbox surface window design
1lrhs4o,14-hour+ global blackout at Ingram Micro halts customer orders,,8,2,2025-07-04T12:41:05+00:00,technology,https://www.theregister.com/2025/07/04/ingram_micro_technical_difficulties/?td=rt-3b,14-hour+ global blackout at Ingram Micro halts customer orders ,hour global blackout at ingram micro halts customer orders,hour global blackout ingram micro halts customer order
1lrheqw,Microsoft investigates ongoing SharePoint Online access issues,,5,3,2025-07-04T12:22:08+00:00,technology,https://www.bleepingcomputer.com/news/microsoft/microsoft-investigates-ongoing-sharepoint-online-access-issues/,Microsoft investigates ongoing SharePoint Online access issues ,microsoft investigates ongoing sharepoint online access issues,microsoft investigates ongoing sharepoint online access issue
1lrh3ln,"Microsoft shuts down Pakistan operations after 25 years, claims founding CEO; Ex-Pak President calls it a troubling sign for economy",,197,2,2025-07-04T12:05:55+00:00,technology,https://m.economictimes.com/news/new-updates/microsoft-shuts-down-pakistan-operations-after-25-years-claims-founding-ceo-ex-pak-president-calls-it-a-troubling-sign-for-economy/articleshow/122248323.cms,"Microsoft shuts down Pakistan operations after 25 years, claims founding CEO; Ex-Pak President calls it a troubling sign for economy ",microsoft shuts down pakistan operations after years claims founding ceo expak president calls it a troubling sign for economy,microsoft shut pakistan operation year claim found ceo expak president call troubling sign economy
1lrh2fq,Wrongful Death Lawsuit Says Big Oil Contributed to Heat Wave and Woman’s Death,,297,15,2025-07-04T12:04:10+00:00,technology,https://www.theenergymix.com/wrongful-death-lawsuit-says-big-oil-contributed-to-heat-wave-and-womans-death/,Wrongful Death Lawsuit Says Big Oil Contributed to Heat Wave and Woman’s Death ,wrongful death lawsuit says big oil contributed to heat wave and womans death,wrongful death lawsuit say big oil contribute heat wave woman death
1lrh0m9,Exclusive: Google's AI Overviews hit by EU antitrust complaint from independent publishers,,29,2,2025-07-04T12:01:27+00:00,technology,https://www.reuters.com/legal/litigation/googles-ai-overviews-hit-by-eu-antitrust-complaint-independent-publishers-2025-07-04/,Exclusive: Google's AI Overviews hit by EU antitrust complaint from independent publishers ,exclusive googles ai overviews hit by eu antitrust complaint from independent publishers,exclusive google ai overview hit eu antitrust complaint independent publisher
1lrh0c8,"Xbox executive producer offers ""best advice I can"" to those caught up in Microsoft's latest lay-off spree – AI prompts to ""help reduce the emotional and cognitive load that comes with job loss""",,650,70,2025-07-04T12:01:07+00:00,technology,https://www.gamesradar.com/games/xbox-executive-producer-offers-best-advice-i-can-to-those-caught-up-in-microsofts-latest-lay-off-spree-ai-prompts-to-help-reduce-the-emotional-and-cognitive-load-that-comes-with-job-loss/,"Xbox executive producer offers ""best advice I can"" to those caught up in Microsoft's latest lay-off spree – AI prompts to ""help reduce the emotional and cognitive load that comes with job loss"" ",xbox executive producer offers best advice i can to those caught up in microsofts latest layoff spree ai prompts to help reduce the emotional and cognitive load that comes with job loss,xbox executive producer offer good advice catch microsoft late layoff spree ai prompt help reduce emotional cognitive load come job loss
1lrh05x,Capcom's financials show that embracing Steam has paid off handsomely: It now accounts for a third of all the publisher's revenue,,305,24,2025-07-04T12:00:55+00:00,technology,https://www.pcgamer.com/games/capcoms-financials-show-that-embracing-steam-has-paid-off-handsomely-it-now-accounts-for-a-third-of-all-the-publishers-revenue/,Capcom's financials show that embracing Steam has paid off handsomely: It now accounts for a third of all the publisher's revenue ,capcoms financials show that embracing steam has paid off handsomely it now accounts for a third of all the publishers revenue,capcom financial embrace steam pay handsomely account publisher revenue
1lrgznv,"Cluely’s ARR doubled in a week to $7M, founder Roy Lee says. But rivals are coming.",,0,0,2025-07-04T12:00:17+00:00,technology,https://techcrunch.com/2025/07/03/cluelys-arr-doubled-in-a-week-to-7m-founder-roy-lee-says-but-rivals-are-coming/,"Cluely’s ARR doubled in a week to $7M, founder Roy Lee says. But rivals are coming. ",cluelys arr doubled in a week to m founder roy lee says but rivals are coming,cluelys arr double week m founder roy lee say rival come
1lrfkm0,Mauna Loa Observatory captured the reality of climate change. The US plans to shut it down,,5576,131,2025-07-04T10:37:18+00:00,technology,https://www.unsw.edu.au/newsroom/news/2025/07/mauna-loa-observatory-climate-change-us-plans-to-shut-it-down,Mauna Loa Observatory captured the reality of climate change. The US plans to shut it down ,mauna loa observatory captured the reality of climate change the us plans to shut it down,mauna loa observatory capture reality climate change plan shut
1lreo70,Ilya Sutskever will lead Safe Superintelligence following his CEO's exit,,23,10,2025-07-04T09:40:07+00:00,technology,https://techcrunch.com/2025/07/03/ilya-sutskever-will-lead-safe-superintelligence-following-his-ceos-exit/,Ilya Sutskever will lead Safe Superintelligence following his CEO's exit ,ilya sutskever will lead safe superintelligence following his ceos exit,ilya sutskever lead safe superintelligence follow ceo exit
1lrcgwo,Kawasaki and Foxconn build robot nursing assistant to tackle hospital scutwork,,25,8,2025-07-04T07:12:19+00:00,technology,https://www.theregister.com/2025/07/04/kawasaki_foxconn_/,Kawasaki and Foxconn build robot nursing assistant to tackle hospital scutwork ,kawasaki and foxconn build robot nursing assistant to tackle hospital scutwork,kawasaki foxconn build robot nursing assistant tackle hospital scutwork
1lrcfj3,ChatGPT creates phisher’s paradise by recommending the wrong URLs for major companies,,365,11,2025-07-04T07:09:48+00:00,technology,https://www.theregister.com/2025/07/03/ai_phishing_websites/,ChatGPT creates phisher’s paradise by recommending the wrong URLs for major companies ,chatgpt creates phishers paradise by recommending the wrong urls for major companies,chatgpt create phisher paradise recommend wrong url major company
1lrb79g,Windows 11 should have been an easy upgrade - Microsoft chose to unleash chaos on us instead,,2029,433,2025-07-04T05:52:16+00:00,technology,https://www.zdnet.com/article/windows-11-should-have-been-an-easy-upgrade-microsoft-chose-to-unleash-chaos-on-us-instead/,Windows 11 should have been an easy upgrade - Microsoft chose to unleash chaos on us instead ,windows should have been an easy upgrade microsoft chose to unleash chaos on us instead,window easy upgrade microsoft choose unleash chaos instead
1lrb33e,Chip Design Software Makers Win US Reprieve in China Trade Deal,,9,1,2025-07-04T05:45:19+00:00,technology,https://www.bloomberg.com/news/articles/2025-07-03/siemens-says-us-has-rescinded-chip-software-curbs-on-china?embedded-checkout=true,Chip Design Software Makers Win US Reprieve in China Trade Deal ,chip design software makers win us reprieve in china trade deal,chip design software maker win reprieve china trade deal
1lravhm,Helldivers 2 is the first PlayStation-published Xbox game | Sony is bringing its popular live-service third-person shooter to more players.,,44,10,2025-07-04T05:32:39+00:00,technology,https://www.theverge.com/news/697430/helldivers-2-xbox-playstation-published-release-date,Helldivers 2 is the first PlayStation-published Xbox game | Sony is bringing its popular live-service third-person shooter to more players. ,helldivers is the first playstationpublished xbox game sony is bringing its popular liveservice thirdperson shooter to more players,helldiver playstationpublishe xbox game sony bring popular liveservice thirdperson shooter player
1lra566,HMD(Nokia) partners with India's tech conglomerate TATA (Tejas Networks) to make streaming free for all with D2M Technology,,11,1,2025-07-04T04:49:23+00:00,technology,https://sbgi.net/indias-direct-to-mobile-d2m-phones-free-stream-technologies-lava-international-and-hmd-partner-ahead-of-field-trials,HMD(Nokia) partners with India's tech conglomerate TATA (Tejas Networks) to make streaming free for all with D2M Technology ,hmdnokia partners with indias tech conglomerate tata tejas networks to make streaming free for all with dm technology,hmdnokia partner indias tech conglomerate tata tejas network streaming free dm technology
1lr9t6s,Meta backs EU digital majority age,,8,1,2025-07-04T04:30:10+00:00,technology,https://www.rte.ie/news/2025/0704/1521746-meta-eu/,Meta backs EU digital majority age ,meta backs eu digital majority age,meta back eu digital majority age
1lr9ax2,"Slate Auto drops 'under $20,000' pricing after Trump administration ends federal EV tax credit",,4087,358,2025-07-04T04:01:47+00:00,technology,https://techcrunch.com/2025/07/03/slate-auto-drops-under-20000-pricing-after-trump-administration-ends-federal-ev-tax-credit/,"Slate Auto drops 'under $20,000' pricing after Trump administration ends federal EV tax credit ",slate auto drops under pricing after trump administration ends federal ev tax credit,slate auto drop pricing trump administration end federal ev tax credit
1lr8ody,Xfinity just added Wi-Fi-powered motion tracking to its routers — here's why it could be a privacy nightmare,,161,70,2025-07-04T03:27:26+00:00,technology,https://www.tomsguide.com/computing/online-security/xfinity-just-added-wi-fi-powered-motion-tracking-to-its-routers-heres-why-it-could-be-a-privacy-nightmare,Xfinity just added Wi-Fi-powered motion tracking to its routers — here's why it could be a privacy nightmare ,xfinity just added wifipowered motion tracking to its routers heres why it could be a privacy nightmare,xfinity add wifipowered motion track router here privacy nightmare
1lr8m2z,Microsoft asks users to ignore Windows Firewall config errors,,84,24,2025-07-04T03:23:59+00:00,technology,"https://www.bleepingcomputer.com/news/microsoft/microsoft-asks-users-to-ignore-windows-firewall-config-errors/#origin=https%3A%2F%2Fwww.google.com%2F&cap=swipe,education&webview=1&dialog=1&viewport=natural&visibilityState=prerender&prerenderSize=1&viewerUrl=https%3A%2F%2Fwww.google.com%2Famp%2Fs%2Fwww-bleepingcomputer-com.cdn.ampproject.org%2Fc%2Fs%2Fwww.bleepingcomputer.com%2Fnews%2Fmicrosoft%2Fmicrosoft-asks-users-to-ignore-windows-firewall-config-errors%3Fusqp=mq331AQIUAKwASCAAgM%25253D&amp_kit=1",Microsoft asks users to ignore Windows Firewall config errors ,microsoft asks users to ignore windows firewall config errors,microsoft ask user ignore windows firewall config error
1lr8541,China bans uncertified and recalled power banks on planes,,42,8,2025-07-04T02:58:25+00:00,technology,https://www.reuters.com/technology/china-bans-uncertified-recalled-power-banks-planes-2025-06-27/,China bans uncertified and recalled power banks on planes ,china bans uncertified and recalled power banks on planes,china ban uncertified recall power bank plane
1lr7uml,Big Oil-Backed Republicans Push Senate Rules to the Limit to Sabotage Clean Energy in Updated Billionaire Bill Text,,427,18,2025-07-04T02:42:24+00:00,technology,https://www.evergreenaction.com/press/big-oil-backed-republicans-push-senate-rules-to-the-limit-to-sabotage-clean-energy-in-updated-billionaire-bill-text,Big Oil-Backed Republicans Push Senate Rules to the Limit to Sabotage Clean Energy in Updated Billionaire Bill Text ,big oilbacked republicans push senate rules to the limit to sabotage clean energy in updated billionaire bill text,big oilbacke republicans push senate rule limit sabotage clean energy update billionaire bill text
1lr70qr,Here are the letters that convinced Google and Apple to keep TikTok online,,63,9,2025-07-04T01:58:29+00:00,technology,https://www.theverge.com/tiktok/697982/trump-tiktok-ban-apple-google-letters-pam-bondi,Here are the letters that convinced Google and Apple to keep TikTok online ,here are the letters that convinced google and apple to keep tiktok online,letter convince google apple tiktok online
1lr6ovi,A couple tried for 18 years to get pregnant. AI made it happen,,0,14,2025-07-04T01:40:59+00:00,technology,https://www.ctvnews.ca/sci-tech/article/a-couple-tried-for-18-years-to-get-pregnant-ai-made-it-happen/,A couple tried for 18 years to get pregnant. AI made it happen ,a couple tried for years to get pregnant ai made it happen,couple try year pregnant ai happen
1lr5moi,"See How Much Meta Pays Engineers, Researchers, and Other Workers",,12,7,2025-07-04T00:46:06+00:00,technology,https://www.businessinsider.com/meta-salaries-what-it-pays-ai-engineers-researchers-compensation-2025-7,"See How Much Meta Pays Engineers, Researchers, and Other Workers ",see how much meta pays engineers researchers and other workers,meta pay engineer researcher worker
1lr58mb,The Person in Charge of Testing Tech for US Spies Has Resigned,,1000,35,2025-07-04T00:25:57+00:00,technology,https://www.wired.com/story/iarpa-director-resigns-odni/,The Person in Charge of Testing Tech for US Spies Has Resigned ,the person in charge of testing tech for us spies has resigned,person charge test tech spy resign
1lr3vyu,"Solar minigrid brings light and hope to a Goma neighborhood, offering blueprint for rest of Congo",,27,0,2025-07-03T23:19:42+00:00,technology,https://apnews.com/article/congo-solar-energy-goma-drc-72700d7dd98824a8007b658ba39d281e,"Solar minigrid brings light and hope to a Goma neighborhood, offering blueprint for rest of Congo ",solar minigrid brings light and hope to a goma neighborhood offering blueprint for rest of congo,solar minigrid bring light hope goma neighborhood offering blueprint rest congo
1lr2nit,YouTube in ‘productive discussions’ with Trump over Jan. 6 ban lawsuit,,926,154,2025-07-03T22:22:52+00:00,technology,https://thehill.com/policy/technology/5384572-youtube-trump-january-6-ban-lawsuit/,YouTube in ‘productive discussions’ with Trump over Jan. 6 ban lawsuit ,youtube in productive discussions with trump over jan ban lawsuit,youtube productive discussion trump jan ban lawsuit
1lr2jvq,"Who is Soham Parekh, the serial moonlighter Silicon Valley startups can’t stop hiring?",,14,11,2025-07-03T22:18:23+00:00,technology,https://techcrunch.com/2025/07/03/who-is-soham-parekh-the-serial-moonlighter-silicon-valley-startups-cant-stop-hiring/,"Who is Soham Parekh, the serial moonlighter Silicon Valley startups can’t stop hiring? ",who is soham parekh the serial moonlighter silicon valley startups cant stop hiring,soham parekh serial moonlighter silicon valley startup not stop hire
1lr1ckm,SCOTUS Refuses To Hear Anti-Vax Group’s Claim That Meta’s Private Actions Are 1A Violations,,255,8,2025-07-03T21:25:10+00:00,technology,https://www.techdirt.com/2025/07/03/scotus-refuses-to-hear-anti-vax-groups-claim-that-metas-private-actions-are-1a-violations/,SCOTUS Refuses To Hear Anti-Vax Group’s Claim That Meta’s Private Actions Are 1A Violations ,scotus refuses to hear antivax groups claim that metas private actions are a violations,scotus refuse hear antivax group claim metas private action violation
1lr0sgu,New imaging technique reconstructs the shapes of hidden objects,,13,8,2025-07-03T21:01:41+00:00,technology,https://news.mit.edu/2025/new-imaging-technique-reconstructs-hidden-object-shapes-0701,New imaging technique reconstructs the shapes of hidden objects ,new imaging technique reconstructs the shapes of hidden objects,new imaging technique reconstruct shape hidden object
1lqzox0,"Provider of covert surveillance app spills passwords for 62,000 users ; Ars Technica",,106,6,2025-07-03T20:15:46+00:00,technology,https://arstechnica.com/security/2025/07/provider-of-covert-surveillance-app-spills-passwords-for-62000-users/,"Provider of covert surveillance app spills passwords for 62,000 users ; Ars Technica ",provider of covert surveillance app spills passwords for users ars technica,provider covert surveillance app spill password user ar technica
1lqzg89,Age verification is coming to search engines in Australia,,92,50,2025-07-03T20:05:53+00:00,technology,https://mashable.com/article/microsoft-google-search-age-verification-rules-australia,Age verification is coming to search engines in Australia ,age verification is coming to search engines in australia,age verification come search engine australia
1lqytoz,Republicans’ Megabill Will Put U.S. Climate Goals Out of Reach,,7057,247,2025-07-03T19:40:25+00:00,technology,https://www.scientificamerican.com/article/republicans-one-big-beautiful-bill-act-will-raise-u-s-climate-emissions/,Republicans’ Megabill Will Put U.S. Climate Goals Out of Reach ,republicans megabill will put us climate goals out of reach,republicans megabill climate goal reach
1lqylkg,"U.S. Budget Cuts Are Robbing Early-Career Scientists of Their Future.
Canceled grants and slashed budgets are disproportionately affecting junior health researchers, dealing a major blow to the future of science and society in the U.S.",,645,25,2025-07-03T19:31:01+00:00,technology,https://www.scientificamerican.com/article/how-trumps-federal-funding-cuts-are-hurting-early-career-researchers-and/?utm_campaign=socialflow&utm_medium=social&utm_source=reddit,"U.S. Budget Cuts Are Robbing Early-Career Scientists of Their Future.
Canceled grants and slashed budgets are disproportionately affecting junior health researchers, dealing a major blow to the future of science and society in the U.S. ",us budget cuts are robbing earlycareer scientists of their future canceled grants and slashed budgets are disproportionately affecting junior health researchers dealing a major blow to the future of science and society in the us,budget cut rob earlycareer scientist future cancel grant slash budget disproportionately affect junior health researcher deal major blow future science society
1lqyba6,‘AI doesn’t know what an orgasm sounds like’: audiobook actors grapple with the rise of robot narrators,,387,77,2025-07-03T19:19:19+00:00,technology,https://www.theguardian.com/books/2025/jul/03/audiobook-voice-actors-ai-robot-narrators,‘AI doesn’t know what an orgasm sounds like’: audiobook actors grapple with the rise of robot narrators ,ai doesnt know what an orgasm sounds like audiobook actors grapple with the rise of robot narrators,ai not know orgasm sound like audiobook actor grapple rise robot narrator
1lqy8x2,North Vancouver student's cancer detection app a finalist in Apple developer challenge,,29,0,2025-07-03T19:16:38+00:00,technology,https://www.nsnews.com/local-news/north-vancouver-students-cancer-detection-app-asasfagfasf-finalist-in-apple-developer-challenge-10885954,North Vancouver student's cancer detection app a finalist in Apple developer challenge ,north vancouver students cancer detection app a finalist in apple developer challenge,north vancouver student cancer detection app finalist apple developer challenge
1lqy8cm,Amazon Warehouses Now Have Nearly 1 Robot Per Human Worker,,77,21,2025-07-03T19:15:57+00:00,technology,https://www.inc.com/kit-eaton/amazon-warehouses-now-have-nearly-1-robot-per-human-worker/91208957,Amazon Warehouses Now Have Nearly 1 Robot Per Human Worker ,amazon warehouses now have nearly robot per human worker,amazon warehouse nearly robot human worker
1lqxwl4,"Displays, imaging and sensing: New blue fluorophore breaks efficiency records in both solids and solutions",,13,1,2025-07-03T19:02:43+00:00,technology,https://phys.org/news/2025-07-displays-imaging-blue-fluorophore-efficiency.html,"Displays, imaging and sensing: New blue fluorophore breaks efficiency records in both solids and solutions ",displays imaging and sensing new blue fluorophore breaks efficiency records in both solids and solutions,display image sense new blue fluorophore break efficiency record solid solution
1lqwwx9,'Positive review only': Researchers hide AI prompts in papers,,59,5,2025-07-03T18:23:31+00:00,technology,https://asia.nikkei.com/Business/Technology/Artificial-intelligence/Positive-review-only-Researchers-hide-AI-prompts-in-papers,'Positive review only': Researchers hide AI prompts in papers ,positive review only researchers hide ai prompts in papers,positive review researcher hide ai prompt paper
1lqwrnn,Trump Officials Want to Prosecute Over the ICEBlock App. Lawyers Say That’s Unconstitutional. The platform is currently the third most downloaded iPhone app.,,143,6,2025-07-03T18:17:34+00:00,technology,https://www.wired.com/story/trump-officials-want-to-prosecute-over-the-iceblock-app-lawyers-say-thats-unconstitutional,Trump Officials Want to Prosecute Over the ICEBlock App. Lawyers Say That’s Unconstitutional. The platform is currently the third most downloaded iPhone app. ,trump officials want to prosecute over the iceblock app lawyers say thats unconstitutional the platform is currently the third most downloaded iphone app,trump official want prosecute iceblock app lawyer s unconstitutional platform currently download iphone app
1lqv6iq,Trump officials create searchable national citizenship database.  Homeland security and Doge merge immigration data with social security to create index it claims will stop voter fraud.,,7283,461,2025-07-03T17:15:21+00:00,technology,https://www.theguardian.com/us-news/2025/jun/30/trump-citizenship-database,Trump officials create searchable national citizenship database.  Homeland security and Doge merge immigration data with social security to create index it claims will stop voter fraud. ,trump officials create searchable national citizenship database homeland security and doge merge immigration data with social security to create index it claims will stop voter fraud,trump official create searchable national citizenship database homeland security doge merge immigration datum social security create index claim stop voter fraud
1lqv1tx,FaceTime in iOS 26 will freeze your call if someone starts undressing,,2012,283,2025-07-03T17:10:15+00:00,technology,https://9to5mac.com/2025/07/02/facetime-in-ios-26-will-freeze-your-call-if-someone-starts-undressing/,FaceTime in iOS 26 will freeze your call if someone starts undressing ,facetime in ios will freeze your call if someone starts undressing,facetime io freeze start undress
1lqujge,"Supreme Court says Texas can restrict porn, ignoring the greater danger to minors",,1078,141,2025-07-03T16:50:14+00:00,technology,https://www.expressnews.com/opinion/commentary/article/texas-porn-ban-fail-20408374.php,"Supreme Court says Texas can restrict porn, ignoring the greater danger to minors ",supreme court says texas can restrict porn ignoring the greater danger to minors,supreme court say texas restrict porn ignore great danger minor
1lquclr,Google rolls out its new Veo 3 video generation model globally,,63,42,2025-07-03T16:42:44+00:00,technology,https://techcrunch.com/2025/07/03/google-rolls-out-its-new-veo-3-video-generation-model-globally/,Google rolls out its new Veo 3 video generation model globally ,google rolls out its new veo video generation model globally,google roll new veo video generation model globally
1lqt1oi,"Leaked docs reveal Meta is training its chatbots to message you first, remember your chats, and keep you talking",,376,40,2025-07-03T15:50:20+00:00,technology,https://www.businessinsider.com/meta-ai-studio-chatbot-training-proactive-leaked-documents-alignerr-2025-7,"Leaked docs reveal Meta is training its chatbots to message you first, remember your chats, and keep you talking ",leaked docs reveal meta is training its chatbots to message you first remember your chats and keep you talking,leak doc reveal meta train chatbot message remember chat talk
1lqstlx,Ford CEO Says Blue-Collar Workers 'Safe' As AI Will Replace 'Literally Half Of All White-Collar Workers',,3299,640,2025-07-03T15:41:44+00:00,technology,https://www.theautopian.com/ford-ceo-says-blue-collar-workers-safe-as-ai-will-replace-literally-half-of-all-white-collar-workers/,Ford CEO Says Blue-Collar Workers 'Safe' As AI Will Replace 'Literally Half Of All White-Collar Workers' ,ford ceo says bluecollar workers safe as ai will replace literally half of all whitecollar workers,ford ceo say bluecollar worker safe ai replace literally half whitecollar worker
1lqsgw5,ICE Agents Deserve No Privacy,,57700,1828,2025-07-03T15:27:56+00:00,technology,https://theintercept.com/2025/07/01/masked-ice-agents-victimization-accountability/,ICE Agents Deserve No Privacy ,ice agents deserve no privacy,ice agent deserve privacy
1lqsgud,"'We Live in a Surveillance State': Reddit Users Explode Over Reports of ICE’s New Face and Fingerprint Scanning App | A new mobile tool used by ICE is sparking fear and fury online, and Reddit users are not holding back.",,3978,140,2025-07-03T15:27:53+00:00,technology,https://gizmodo.com/we-live-in-a-surveillance-state-reddit-users-explode-over-reports-of-ices-new-face-and-fingerprint-scanning-app-2000623746,"'We Live in a Surveillance State': Reddit Users Explode Over Reports of ICE’s New Face and Fingerprint Scanning App | A new mobile tool used by ICE is sparking fear and fury online, and Reddit users are not holding back. ",we live in a surveillance state reddit users explode over reports of ices new face and fingerprint scanning app a new mobile tool used by ice is sparking fear and fury online and reddit users are not holding back,live surveillance state reddit user explode report ice new face fingerprint scan app new mobile tool ice spark fear fury online reddit user hold
1lqs3aa,Revealed: How Windows 11's new Start menu auto-categorizes your apps,,0,4,2025-07-03T15:12:37+00:00,technology,https://www.pcworld.com/article/2836178/revealed-how-windows-11-new-start-menu-will-categorize-your-apps.html,Revealed: How Windows 11's new Start menu auto-categorizes your apps ,revealed how windows s new start menu autocategorizes your apps,reveal window s new start menu autocategorize app
1lqri2y,"FCC chair decides inmates and their families must keep paying high phone prices | Chairman Carr waives new price caps until 2027, may raise them before then.",,489,50,2025-07-03T14:49:09+00:00,technology,https://arstechnica.com/tech-policy/2025/07/fcc-lets-prisons-keep-charging-high-phone-rates-delaying-new-caps-by-two-years/,"FCC chair decides inmates and their families must keep paying high phone prices | Chairman Carr waives new price caps until 2027, may raise them before then. ",fcc chair decides inmates and their families must keep paying high phone prices chairman carr waives new price caps until may raise them before then,fcc chair decide inmate family pay high phone price chairman carr waive new price cap raise
1lqrgwv,Google open-sources zero-knowledge proof code for enhanced online privacy,,24,8,2025-07-03T14:47:51+00:00,technology,https://www.neowin.net/news/google-open-sources-zero-knowledge-proof-code-for-enhanced-online-privacy/,Google open-sources zero-knowledge proof code for enhanced online privacy ,google opensources zeroknowledge proof code for enhanced online privacy,google opensource zeroknowledge proof code enhanced online privacy
1lqr01n,"The Past, Present, and Future of Police Body Cameras",,13,5,2025-07-03T14:28:34+00:00,technology,https://www.rstreet.org/research/the-past-present-and-future-of-police-body-cameras/,"The Past, Present, and Future of Police Body Cameras ",the past present and future of police body cameras,past present future police body camera
